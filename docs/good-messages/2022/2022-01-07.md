# [<](2022-01-06.md) 2022-01-07 [>](2022-01-08.md)

1,668,887 events recorded by [gharchive.org](https://www.gharchive.org/) of which 1,668,887 were push events containing 2,633,508 commit messages that amount to 194,941,333 characters filtered with [words.py@e23d022007...](https://github.com/defgsus/good-github/blob/e23d022007992279f9bcb3a9fd40126629d787e2/src/words.py) to these 31 messages:


## [Hellokali1984/octocat.github.io](https://github.com/Hellokali1984/octocat.github.io)@[bbc3729394...](https://github.com/Hellokali1984/octocat.github.io/commit/bbc3729394dac0fc935fc059ea4d86cb325ed6fe)
#### Friday 2022-01-07 00:54:42 by Hellokali1984

Create Tabernacle-mankind

I had an epiphany and these visions came to me and it's involving both God and the devil the reason why the devil became Satan was because he was banished from heaven for trying to cut God's throat as I would say in so many words and God said the only way the devil will be able to even whisper to me again is this he built a whole world of Tabernacles and my life success story is to help every every man woman and child animals creatures all those things so I have a lot of Lucifer's energy as I would say luciferic energy and I don't believe that luciferic energy is bad because it gives you the the rain in the the authority over your life like God does anyway he gives you the power to choose what you do whether it's good or bad and live with those decisions once judgment Day come why I am a religious person is because I always face the right decision the wrong decision and usually 90% of the people make the wrong decision because they look they're looking for the instant gratification look where I am right now I'm sitting in a storage unit in Hollywood California probably look like I'm select them soliciting sex or looking for something to getting into when I'm really a diabolical positive force for mankind but this is not something that I want to brag about my what came out of my mouth is building a world of Tabernacles to be to help him be able to whisper to God cuz maybe he has something to say you know Lucifer became Satan but I think it's there two different people I don't think Satan ever was in heaven but maybe he's trying to change his life and he wants to go

---
## [LetterN/CEV-Eris](https://github.com/LetterN/CEV-Eris)@[c3fb43155f...](https://github.com/LetterN/CEV-Eris/commit/c3fb43155f41f2f0409bd4269b1a10546f6d3a97)
#### Friday 2022-01-07 01:15:41 by Wouju

Reality Complicator, i luv me terror button (#6836)

* Yeah we're back

* Revert "Yeah we're back"

This reverts commit ddb5b5ed146c154be8cc6089621f6b332eb3086f.

* complicatorium

* map shit

* Update code/game/objects/items/complicator.dm

Co-authored-by: hyperioo <64754494+hyperioo@users.noreply.github.com>

---
## [beesdev/quarantine](https://github.com/beesdev/quarantine)@[89ab35e5af...](https://github.com/beesdev/quarantine/commit/89ab35e5afe6fefaca9e02e2097f062935276fb1)
#### Friday 2022-01-07 03:48:27 by pigeon-crystal

remember to buff the ruins of alph wild levels dumb idiot bitch baby

---
## [MrJamesGaming/FtcRobotController](https://github.com/MrJamesGaming/FtcRobotController)@[48d655d111...](https://github.com/MrJamesGaming/FtcRobotController/commit/48d655d1113fa285c8b7cb14ba9727b90a01c464)
#### Friday 2022-01-07 03:50:27 by ProDCG

package teamcode.common;  import com.acmerobotics.roadrunner.geometry.Pose2d; import com.qualcomm.hardware.bosch.BNO055IMU; import com.qualcomm.hardware.bosch.JustLoggingAccelerationIntegrator; import com.qualcomm.robotcore.hardware.DcMotor; import com.qualcomm.robotcore.hardware.DcMotorSimple; import com.qualcomm.robotcore.hardware.HardwareMap; import com.qualcomm.robotcore.hardware.NormalizedColorSensor; import com.qualcomm.robotcore.hardware.NormalizedRGBA; import com.qualcomm.robotcore.hardware.Servo; import com.qualcomm.robotcore.util.ReadWriteFile; import com.spartronics4915.lib.T265Camera; import com.spartronics4915.lib.T265Helper;  import org.apache.commons.math3.analysis.function.Abs; import org.apache.commons.math3.geometry.euclidean.threed.Vector3D; import org.apache.commons.math3.linear.Array2DRowRealMatrix; import org.apache.commons.math3.linear.DecompositionSolver; import org.apache.commons.math3.linear.LUDecomposition; import org.apache.commons.math3.linear.MatrixUtils; import org.apache.commons.math3.linear.RealMatrix; import org.checkerframework.checker.units.qual.A; import org.checkerframework.checker.units.qual.Angle; import org.firstinspires.ftc.robotcore.internal.system.AppUtil; import org.openftc.revextensions2.ExpansionHubEx; import org.openftc.revextensions2.ExpansionHubMotor; import org.openftc.revextensions2.RevBulkData;  import java.io.File; import java.io.FileNotFoundException; import java.io.PrintStream; import java.util.ArrayList; import java.util.Arrays; import java.util.List; import java.util.Vector; import java.util.concurrent.atomic.AtomicBoolean;  import teamcode.common.PositionStuff.Point; import teamcode.common.PositionStuff.Pose; import teamcode.common.PurePursuit.MathFunctions;  import static java.lang.Math.*;  public class Localizer extends Thread {     //TODO before reading this file please note the static import of the math class,     // odds are if you see a math function it is from that and not a constatnt/method I created     //https://docs.google.com/document/d/1JQuU2M--rVFEa9ApKkOcc0CalsBxKjH-l0PQLRW7F3c/edit?usp=sharing proof behind the math      //odometry wheel constants, MUST BE CALIBRATED FOR EACH ROBOT     private static final double TICKS_PER_REV = 8192;     private static final double WHEEL_DIAMETER = 1.378; //1.181 for 60 mm, 1.417 for 72mm     private static final double GEAR_RATIO = 1;     private static final double CHASSIS_LENGTH = 7.078;     private static final double ODO_XY_DISTANCE = 4.05; //x value     private static final double ODO_YX_DISTANCE = 3.5; //Y value     private static final double WINCH_RADIUS = 1;        //debugging constants, not used very much      File loggingFile = AppUtil.getInstance().getSettingsFile("x.txt");     File secondaryLoggingFile = AppUtil.getInstance().getSettingsFile("y.txt");     File tertiaryloggingFile = AppUtil.getInstance().getSettingsFile("pos.txt");     File fourthLoggingFile = AppUtil.getInstance().getSettingsFile("Rotation.txt");     File fifthLoggingFile = AppUtil.getInstance().getSettingsFile("vomega.txt");     File sixthLoggingFile = AppUtil.getInstance().getSettingsFile("vy.txt");     public String loggingString, secondaryLoggingString, tertiaryLoggingString, fourthLoggingString, fifthLoggingString, sixthLoggingString;     private int iterator;     //-2.641358450698 - (-2.641358450698 * 1.2)        // set to true when thread is requested to shutdown     private AtomicBoolean stop = new AtomicBoolean(false);     // sensors run at 300 Hz     // this is the length of that interval in milliseconds     private long runInterval = (long)Math.round(1.0/50.0 * 1000.0);     //1.0/300.0 * 1,000,000.0      //hardware and timing constants, all of this is set up in the constructor     private long elapsedTime, startingTime;     private RobotPositionStateUpdater state;     private final ExpansionHubMotor leftVertical, rightVertical, horizontal; //general odometry encoders, universal for each year     private final ExpansionHubEx hub1;     private RevBulkData data1, data2;     private BNO055IMU imu;     private double previousOuterArcLength = 0;     private double previousInnerArcLength = 0;     private double previousHorizontalArcLength = 0;     private long minElapsedTime, maxElapsedTime;      //Kalman filter parameters, the ones declared up here must also be tuned for EVERY ROBOT      private static final double INCHES_TO_METERS = 0.0254; //-8.628937         Pose2d cameraToRobot = new Pose2d(0,0,0); //-7.965 * INCHES_TO_METERS,  0 * INCHES_TO_METERS 0.8, -7.2     private static T265Camera slamra;     T265Camera.CameraUpdate currentSlamraPos;     private Pose2d slamraStartingPose = new Pose2d(0,0,0);     private static double TAO = 1.0; //0.9 optimal     private static final double MEASUREMENT_VARIANCE = 0.01; // 0.01 + 0.02? account more for odo variance     private double previousEstimateUncertainty;     Matrix previousOdoMat;     Matrix previousIdealMat;     Matrix previousVislamMat;      //Game specific fields     Servo odoWinch, secondaryOdoWinch;     OdoState odoState;       /**      * Adjust the following to weigh the following out of your program      *      * High Frequency Sensor, TAO = 0      * Low Frequency Sensor, TAO = 1      *      */          //Non Kalman constructor, may make this an option later but for now this is deprecated     /**      * @param position in inches      * @param globalRads in radians      */     @Deprecated     public Localizer(HardwareMap hardwareMap, Vector2D position, double globalRads) {         minElapsedTime = 0;         maxElapsedTime = 0;         hub1 = hardwareMap.get(ExpansionHubEx.class,"Control Hub");         loggingString = "";         secondaryLoggingString = "";         //hub2 = hardwareMap.get(ExpansionHubEx.class,"Expansion Hub 2");         // initialize hardware         leftVertical = (ExpansionHubMotor)hardwareMap.dcMotor.get(Constants.LEFT_VERTICAL_ODOMETER_NAME);         rightVertical = (ExpansionHubMotor)hardwareMap.dcMotor.get(Constants.RIGHT_VERTICAL_ODOMETER_NAME);         horizontal = (ExpansionHubMotor)hardwareMap.dcMotor.get(Constants.HORIZONTAL_ODOMETER_NAME);           // setup initial position;         previousHorizontalArcLength = 0;         previousInnerArcLength = 0;         previousOuterArcLength = 0;         startingTime = System.currentTimeMillis();         state = new RobotPositionStateUpdater(position, new Vector2D(0,0), globalRads, 0);         resetEncoders();          odoState = OdoState.LOWERED;         type = constructorType.DEPRECATED;      }      //Kalman Constructor      /**      *      * @param hardwareMap hardware interface we use, just passing in the opModes HardwareMap      *                    field is always sufficient      * @param position the starting position of the robot as a vector in inches      * @param globalRads the starting orientation of the robot in radians      * @param previousEstimateUncertainty the covariance of the kinematic models estimate,      *                                    greater value means trusting the measured values more and      *                                    smaller value means trusting the kinematic models estimate more      */     public Localizer(HardwareMap hardwareMap, Vector2D position, double globalRads, double previousEstimateUncertainty){          if(slamra == null) {             Debug.log("here");             slamra = new T265Camera(new T265Camera.OdometryInfo(cameraToRobot, 1.0), hardwareMap.appContext);             currentSlamraPos = slamra.getLastReceivedCameraUpdate();         }         slamraStartingPose = new Pose2d(0 , 0, globalRads);         this.previousEstimateUncertainty = previousEstimateUncertainty; //this should always be a high value otherwise bad things will happen         minElapsedTime = 0;         maxElapsedTime = 0;         hub1 = hardwareMap.get(ExpansionHubEx.class,"Control Hub");         loggingString = "";         secondaryLoggingString = "";         //hub2 = hardwareMap.get(ExpansionHubEx.class,"Expansion Hub 2");         // initialize hardware         imu = hardwareMap.get(BNO055IMU.class, "imu");         leftVertical = (ExpansionHubMotor)hardwareMap.dcMotor.get(Constants.LEFT_VERTICAL_ODOMETER_NAME);         rightVertical = (ExpansionHubMotor)hardwareMap.dcMotor.get(Constants.RIGHT_VERTICAL_ODOMETER_NAME);         horizontal = (ExpansionHubMotor)hardwareMap.dcMotor.get(Constants.HORIZONTAL_ODOMETER_NAME);          odoWinch = hardwareMap.servo.get("OdoWinch");         secondaryOdoWinch = hardwareMap.servo.get("SecondaryOdoWinch");          // setup initial position;         previousHorizontalArcLength = 0;         previousInnerArcLength = 0;         previousOuterArcLength = 0;          previousVislamMat = new Matrix(6,1);         previousIdealMat = new Matrix(6,1);         startingTime = System.currentTimeMillis();         state = new RobotPositionStateUpdater(position, new Vector2D(0,0), globalRads, 0);          double[][] previousOdoArray = {                 {state.getCurrentState().getPosition().getX()},                 {state.getCurrentState().getPosition().getY()},                 {state.getCurrentState().getRotation()},                 {0},                 {0}, //this whole class assumes constant velocity and it is fair to assume the robot starts still                 {0}         };         previousOdoMat = new Matrix(previousOdoArray);          //lowerOdo();         resetEncoders();         iterator = 1;         odoState = OdoState.LOWERED;         type = constructorType.KALMAN;     }        public void stopThread() {         if(slamra != null) {             Debug.log("end");             slamra.stop();         }         this.stop.set(true);     }     @Override     public void run() {         // make sure we reset our accounting of start times         state.resetUpdateTime();         startingTime = System.currentTimeMillis();         if(slamra != null) {             slamra.start();             currentSlamraPos = slamra.getLastReceivedCameraUpdate();             //slamra.setPose(new Pose2d(0,0,0));          }         // max speed 300 Hz)         while (!stop.get()) {             long millis = System.currentTimeMillis();             if(type == constructorType.DEPRECATED) {                 update();             }else if(type == constructorType.KALMAN) {                 updateKalman();             }else if(type == constructorType.MAT) {                 matUpdate();             }             long runtime = System.currentTimeMillis() - millis;              if (runtime > runInterval) {                 // this is very bad                 // todo break here.                 minElapsedTime++;                 runtime=runInterval;             }             maxElapsedTime++; //            loggingString += (runInterval - runtime) +"\n"; //            ReadWriteFile.writeFile(loggingFile, loggingString);             try {                 // cast should be fine here since we're likely dealing with only                 // a few milliseconds                 sleep(runInterval - runtime);             } catch (InterruptedException e) {                 // this probably isn't bad.                 e.printStackTrace();             }         }     }      //initializing the odo, not to be confused with zeroing it     private void resetEncoders() {         leftVertical.setMode(DcMotor.RunMode.STOP_AND_RESET_ENCODER);         rightVertical.setMode(DcMotor.RunMode.STOP_AND_RESET_ENCODER);         horizontal.setMode(DcMotor.RunMode.STOP_AND_RESET_ENCODER);         leftVertical.setMode(DcMotor.RunMode.RUN_WITHOUT_ENCODER);         rightVertical.setMode(DcMotor.RunMode.RUN_WITHOUT_ENCODER);         horizontal.setMode(DcMotor.RunMode.RUN_WITHOUT_ENCODER);         //horizontal.setDirection(DcMotorSimple.Direction.REVERSE);         //leftVertical.setDirection(DcMotorSimple.Direction.REVERSE);     }      public void liftOdo(){         odoWinch.setPosition(1.0);         secondaryOdoWinch.setPosition(0);         odoState = OdoState.RAISED;     }      public void lowerOdo(){         odoWinch.setPosition(0);         secondaryOdoWinch.setPosition(1.0);         odoState = OdoState.LOWERED;     }      private enum OdoState{         RAISED, LOWERED     }      private enum constructorType{         DEPRECATED, KALMAN, MAT     }      constructorType type;      //zeroing the odo     public void resetOdometersTravelling(){         leftVertical.setMode(DcMotor.RunMode.STOP_AND_RESET_ENCODER);         rightVertical.setMode(DcMotor.RunMode.STOP_AND_RESET_ENCODER);         horizontal.setMode(DcMotor.RunMode.STOP_AND_RESET_ENCODER);         previousHorizontalArcLength = 0;         previousInnerArcLength = 0;         previousOuterArcLength = 0;     }      //exposes the state to exterior classes     public RobotPositionStateUpdater.RobotPositionState getCurrentState() {         return state.getCurrentState();     }      //see top of class for formalized proof of the math     @Deprecated //use updateKalman instead     private synchronized void update() {         // read sensor data         data1 = hub1.getBulkInputData();           double innerArcLength = encoderTicksToInches(data1.getMotorCurrentPosition(leftVertical));         // encoder orientation is the same, which means they generate opposite rotation signals         double outerArcLength =  encoderTicksToInches(data1.getMotorCurrentPosition(rightVertical));         double horizontalArcLength = encoderTicksToInches(data1.getMotorCurrentPosition(horizontal));          double leftVerticalVelocity = encoderTicksToInches(data1.getMotorVelocity(leftVertical));         double rightVerticalVelocity = encoderTicksToInches(data1.getMotorVelocity(rightVertical));         double horizontalVelocity = encoderTicksToInches(data1.getMotorVelocity(horizontal));          // calculate positions         double deltaInnerArcLength = innerArcLength - previousInnerArcLength;         double deltaOuterArcLength = outerArcLength - previousOuterArcLength;         double deltaHorizontalArcLength = horizontalArcLength - previousHorizontalArcLength;          double arcLength = (deltaInnerArcLength + deltaOuterArcLength) / 2.0;         double deltaVerticalDiff = (deltaInnerArcLength - deltaOuterArcLength) / 2.0;  //(deltaOuterArcLength - deltaInnerArcLength)         // CHASSIS_LENGTH is the diamater of the circle.         // phi is arclength divided by radius for small phi         double phi =  (2.0 * deltaVerticalDiff) / (CHASSIS_LENGTH);         double hypotenuse;            // When phi is small, the full formula is numerically unstable.         // for small phi, sin(phi) = phi and cos(phi) = 1         // thus small phi, hypotense = arcLength         if(abs(phi) < 0.0001){             hypotenuse = arcLength;         }else{             hypotenuse = (arcLength * sin(phi)) / (phi * cos(phi / 2.0));         }          double horizontalDelta = deltaHorizontalArcLength - (phi * ODO_XY_DISTANCE);         double verticalDelta = hypotenuse * cos(phi/2.0)  + deltaVerticalDiff - (phi *ODO_YX_DISTANCE);           // calculate velocities         // a difference in velocity will be due to rotation.         // however since both encoders count this difference, this is double counted         // So arc length of rotation divided by the radius gives us the rotational velocity         // the factors of two cancel!         double omega = (leftVerticalVelocity - rightVerticalVelocity)/CHASSIS_LENGTH;         double deltaVy = (leftVerticalVelocity + rightVerticalVelocity)/2.0;         double deltaVx = horizontalVelocity;         //Debug.log(horizontalDelta);         state.updateDelta(horizontalDelta, verticalDelta, phi, deltaVx, deltaVy, omega);         previousInnerArcLength = innerArcLength;         previousOuterArcLength = outerArcLength;         previousHorizontalArcLength = horizontalArcLength;         elapsedTime = System.currentTimeMillis() - startingTime; //        loggingString +=  hypotenuse  + "\n"; //        loggingString +=  arcLength  + "\n"; //        loggingString += deltaVerticalDiff + "\n"; //        loggingString += phi + "\n"; //        loggingString += deltaInnerArcLength + "\n"; //        loggingString += deltaOuterArcLength + "\n"; //        loggingString += deltaHorizontalArcLength + "\n"; //        loggingString += "\n"; //        ReadWriteFile.writeFile(loggingFile, loggingString);         //AbstractOpMode.currentOpMode().telemetry.addData("AL:", arcLength);         //AbstractOpMode.currentOpMode().telemetry.addData("DVD:", deltaVerticalDiff); //        AbstractOpMode.currentOpMode().telemetry.addData("", this::getCurrentState); //        AbstractOpMode.currentOpMode().telemetry.update();     }         //updating a cycle using the Kalman Filter, a method which takes 3 measurements, Odometry, VISLAM     //and a third measurement using physics to predict where the robot is (we call this the kinematic model)     private synchronized void updateKalman(){         // read sensor data         data1 = hub1.getBulkInputData();         currentSlamraPos = slamra.getLastReceivedCameraUpdate();         RobotPositionStateUpdater.RobotPositionState currentState = getCurrentState();          int leftVerticalTics = data1.getMotorCurrentPosition(leftVertical);         int rightVerticalTics = data1.getMotorCurrentPosition(rightVertical);         int horizontalTics = data1.getMotorCurrentPosition(horizontal);          double innerArcLength = encoderTicksToInches(leftVerticalTics);         // encoder orientation is the same, which means they generate opposite rotation signals         double outerArcLength =  -encoderTicksToInches(rightVerticalTics);         double horizontalArcLength = -encoderTicksToInches(horizontalTics);  //        double leftVerticalVelocity = encoderTicksToInches(data1.getMotorVelocity(leftVertical)); //        double rightVerticalVelocity = -encoderTicksToInches(data1.getMotorVelocity(rightVertical)); //        double horizontalVelocity = -encoderTicksToInches(data1.getMotorVelocity(horizontal));          // calculate positions         double deltaInnerArcLength = innerArcLength - previousInnerArcLength;         double deltaOuterArcLength = outerArcLength - previousOuterArcLength;         double deltaHorizontalArcLength = horizontalArcLength - previousHorizontalArcLength;          double leftVerticalVelocity =deltaInnerArcLength / 0.02;         double rightVerticalVelocity = deltaOuterArcLength / 0.02;         double horizontalVelocity = deltaHorizontalArcLength/ 0.02;          double arcLength = (deltaInnerArcLength + deltaOuterArcLength) / 2.0;         double deltaVerticalDiff = (deltaInnerArcLength - deltaOuterArcLength) / 2.0;           // CHASSIS_LENGTH is the diamater of the circle.         // phi is arclength divided by radius for small phi         double phi =  (2.0 * deltaVerticalDiff) / (CHASSIS_LENGTH);         double hypotenuse;          double rotation = previousOdoMat.getValue(2,0);          //loggingString += currentState.getPosition().getX() + " , " + currentState.getPosition().getY() + " , " + currentState.getRotation() + "\n";         // When phi is small, the full formula is numerically unstable.         // for small phi, sin(phi) = phi and cos(phi) = 1         // thus small phi, hypotense = arcLength         if(abs(phi) < 0.1){ //0.001             hypotenuse = arcLength;         }else{             hypotenuse = (arcLength * sin(rotation + phi)) / (phi * cos(rotation + phi / 2.0));         }          double horizontalDelta = deltaHorizontalArcLength  + hypotenuse * sin(rotation +phi); // - (phi * ODO_XY_DISTANCE) X         double verticalDelta = hypotenuse * cos(rotation + phi) - (phi * ODO_YX_DISTANCE); //y           // calculate velocities         // a difference in velocity will be due to rotation.         // however since both encoders count this difference, this is double counted         // So arc length of rotation divided by the radius gives us the rotational velocity         // the factors of two cancel!         double omega = (leftVerticalVelocity - rightVerticalVelocity)/CHASSIS_LENGTH;         double deltaVy = (leftVerticalVelocity + rightVerticalVelocity)/2.0;         double deltaVx = horizontalVelocity;  //        if(odoState == OdoState.RAISED){ //            TAO = 0; //        }else{ //            TAO = 1; //        }          //scaling the deltas to make the Odometry its own independent measurement         horizontalDelta *= TAO;         verticalDelta *= TAO;         phi *= TAO;         omega *= TAO;         deltaVx *= TAO;         deltaVy *= TAO;           //matrix declarations         final double robotRadius = 7.7;         Pose2d slamraEstimatePose = currentSlamraPos.pose;         double slamx = -slamraEstimatePose.getY() / INCHES_TO_METERS;         double slamy = 7.7 + (slamraEstimatePose.getX() / INCHES_TO_METERS);         double slamRotation = currentSlamraPos.pose.getHeading();         double trueX = slamx + sin(slamRotation) * robotRadius;         double trueY = slamy - (cos(slamRotation) * robotRadius);          double[][] vislamMat = {                 {trueX},                 {trueY},                 {slamRotation},                 {currentSlamraPos.velocity.getX()},                 {currentSlamraPos.velocity.getY()},                 {currentSlamraPos.velocity.getHeading()}         }; //        if(abs(vislamMat[3][0]) < 0.2){ //            vislamMat[3][0] = 0; //        } //        if(abs(vislamMat[4][0]) < 0.2){ //            vislamMat[4][0] = 0; //        } //        if(abs(vislamMat[5][0]) < 0.2){ //            vislamMat[5][0] = 0; //        }         Matrix slamraEstimate = new Matrix(vislamMat);          double[][] odoMat = {                 {previousOdoMat.getValue(0,0) + horizontalDelta},                 {previousOdoMat.getValue(1,0) + verticalDelta},                 {previousOdoMat.getValue(2,0) + phi},                 {deltaVx},                 {deltaVy},                 {omega}         };         Matrix odoEstimate = new Matrix(odoMat);          double[][] currentStateMat = {                 {currentState.getPosition().getX()},                 {currentState.getPosition().getY()},                 {currentState.getRotation()},                 {currentState.getVelocity().getX()},                 {currentState.getVelocity().getY()},                 {currentState.getAngularVelocity()}         };         Matrix currentStateEstimate = new Matrix(currentStateMat);          elapsedTime = System.currentTimeMillis() - startingTime;          double[][] deltaMat = {                 {currentState.getVelocity().getX() * elapsedTime / 1000.0},                 {currentState.getVelocity().getY() * elapsedTime / 1000.0},                 {currentState.getAngularVelocity() * elapsedTime / 1000.0},                 {0},                 {0},                 {0}         };           Matrix kinematicModel = new Matrix(deltaMat);         Matrix idealEstimate = kinematicModel.add(currentStateEstimate);          //update this here to keep odo estimate truly independent of everything else,         //if one system starts drifting we dont want the covariance of the odo to suffer         double[][] previousOdoArray = {                 {odoEstimate.getValue(0,0)},                 {odoEstimate.getValue(1,0)},                 {odoEstimate.getValue(2,0)},                 {odoEstimate.getValue(3,0)},                 {odoEstimate.getValue(4,0)},                 {odoEstimate.getValue(5,0)},         };             previousOdoMat = new Matrix(previousOdoArray);          slamraEstimate.multiply(1.0-TAO);         Matrix complementaryStateEstimtate = odoEstimate.add(slamraEstimate); //measured state, Z          double kalmanGain = previousEstimateUncertainty / (previousEstimateUncertainty + MEASUREMENT_VARIANCE);          kalmanGain = 1;          double currentEstimateUncertainty = (1 - kalmanGain) * previousEstimateUncertainty;           idealEstimate.multiply(1 - kalmanGain);         //multiplying only the distance components since we assume constant velocity         //the kinematic model assumes constant velocity meaning that the values was         //being greatly diminished causing overacceleration         complementaryStateEstimtate.setValue(0,0, complementaryStateEstimtate.getValue(0,0) * kalmanGain);         complementaryStateEstimtate.setValue(1,0, complementaryStateEstimtate.getValue(1,0) * kalmanGain);         complementaryStateEstimtate.setValue(2,0, complementaryStateEstimtate.getValue(2,0) * kalmanGain);         Matrix finalStateEstimate = complementaryStateEstimtate.add(idealEstimate);           double dx = finalStateEstimate.getValue(0,0);         double dy = finalStateEstimate.getValue(1,0);         double dphi = finalStateEstimate.getValue(2,0);         double dvx = complementaryStateEstimtate.getValue(3,0);         double dvy = complementaryStateEstimtate.getValue(4,0);         double domega = complementaryStateEstimtate.getValue(5,0);           state.updateState(dx, dy, dphi, dvx, dvy, domega);          loggingString += state.getCurrentState().getPosition().loggerToString()+ "\n";         secondaryLoggingString += iterator + "," +  state.getCurrentState().getPosition().getX() + "\n";         tertiaryLoggingString += iterator+ "," +  state.getCurrentState().getPosition().getY() + "\n"; //        fourthLoggingString += iterator + "," + rotation + "\n"; //        fifthLoggingString += iterator + "," + domega + "\n"; //        sixthLoggingString += iterator+ "," + dvy + "\n";         startingTime = System.currentTimeMillis();         previousInnerArcLength = innerArcLength;         previousOuterArcLength = outerArcLength;         previousHorizontalArcLength = horizontalArcLength;         previousEstimateUncertainty = currentEstimateUncertainty;         iterator++;     }      DecompositionSolver solver;      ArrayList<Pose> wheelPoses;     double[] lastWheelPositions;     private Pose odoEstimate;     private Pose poseVelocity;       //todo implment 3 wheel system BOTH HERE AND IN THE MATUPDATE     public Localizer(Pose start, HardwareMap hardwareMap){         hub1 = hardwareMap.get(ExpansionHubEx.class,"Control Hub");         loggingString = "";         secondaryLoggingString = "";         state = new RobotPositionStateUpdater();         if(slamra == null) {             slamra = T265Helper.getCamera(new T265Camera.OdometryInfo(new Pose2d(0,0, 0), 1.0),hardwareMap.appContext);//new T265Camera(cameraToRobot, 1.0, hardwareMap.appContext);             currentSlamraPos = slamra.getLastReceivedCameraUpdate();         }          //hub2 = hardwareMap.get(ExpansionHubEx.class,"Expansion Hub 2");         // initialize hardware         leftVertical = (ExpansionHubMotor)hardwareMap.dcMotor.get(Constants.LEFT_VERTICAL_ODOMETER_NAME);         rightVertical = (ExpansionHubMotor)hardwareMap.dcMotor.get(Constants.RIGHT_VERTICAL_ODOMETER_NAME);         horizontal = (ExpansionHubMotor)hardwareMap.dcMotor.get(Constants.HORIZONTAL_ODOMETER_NAME);         odoWinch = hardwareMap.servo.get("OdoWinch");         secondaryOdoWinch = hardwareMap.servo.get("SecondaryOdoWinch");  //        BNO055IMU.Parameters parameters = new BNO055IMU.Parameters(); //        parameters.angleUnit           = BNO055IMU.AngleUnit.RADIANS; //        parameters.accelUnit           = BNO055IMU.AccelUnit.METERS_PERSEC_PERSEC; //        parameters.calibrationDataFile = "BNO055IMUCalibration.json"; // see the calibration sample opmode //        parameters.loggingEnabled      = true; //        parameters.loggingTag          = "IMU"; //        parameters.accelerationIntegrationAlgorithm = new JustLoggingAccelerationIntegrator(); // //        imu = hardwareMap.get(BNO055IMU.class, "imu"); //        imu.initialize(parameters); //         type = constructorType.MAT;           Array2DRowRealMatrix inverseMatrix = new Array2DRowRealMatrix(3, 3);           wheelPoses = new ArrayList<>();         wheelPoses.add(new Pose(10,-2.8, 0)); //LV //-5.5 // -3.91885,-6.471937         wheelPoses.add(new Pose(3.3, 0,  Math.toRadians(90))); //H //-4.5222, 0.10685         wheelPoses.add(new Pose(0,2.8, 0)); //RV //-5.5            for (int i = 0; i < 3; i++) {             Pose position = wheelPoses.get(i);             double x = cos(position.heading);             double y = sin(position.heading);              double val = position.x * y - position.y * x;              inverseMatrix.setEntry(i, 0, x);             inverseMatrix.setEntry(i, 1, y);             inverseMatrix.setEntry(i, 2, val); //            Debug.log(positionVector.getX() * orientationVector.getY()); //            Debug.log(positionVector.getY() * orientationVector.getX());         }         // inverseMatrix.setEntry(2,2,1.0);          freezeUpdate = false;          solver = new LUDecomposition(inverseMatrix).getSolver();         Debug.log(solver.isNonSingular());         lastWheelPositions = new double[]{0,0,0};         odoEstimate = start.clone();         poseVelocity = new Pose(0,0,0);         slamraStartingPose = new Pose2d(0,0,0);         previousHeading = 0;         odoState = OdoState.LOWERED;           resetEncoders();         iterator = 1;      }      private volatile boolean freezeUpdate;       /**      *      * @param explicit set true if you want updates to resume immediately after reset has been executed      */     public void manualZero(boolean explicit){         freezeUpdate = true;         lastWheelPositions = new double[]{0,0,0};         previousHeading = 0;         odoEstimate = new Pose(0,0,0);         state.updateState(0,0,0,0,0,0);         if(explicit){             resumeUpdateCycles();         }      }      public void resumeUpdateCycles(){         //slamra.start();         leftVertical.setMode(DcMotor.RunMode.STOP_AND_RESET_ENCODER);         rightVertical.setMode(DcMotor.RunMode.STOP_AND_RESET_ENCODER);         horizontal.setMode(DcMotor.RunMode.STOP_AND_RESET_ENCODER);         leftVertical.setMode(DcMotor.RunMode.RUN_WITHOUT_ENCODER);         rightVertical.setMode(DcMotor.RunMode.RUN_WITHOUT_ENCODER);         horizontal.setMode(DcMotor.RunMode.RUN_WITHOUT_ENCODER);         freezeUpdate = false;      }      public double directionToHeading(double direction){         return Math.PI / 2.0 - direction;     }          double previousHeading;     double slamErrorX, slamErrorY;     //TODO implement 3 wheel system BOTH HERE AND IN THE CONSTRUCTOR     private synchronized void matUpdate() {        if(!freezeUpdate) {             data1 = hub1.getBulkInputData();             currentSlamraPos = slamra.getLastReceivedCameraUpdate(); //            double heading = (imu.getAngularOrientation().firstAngle); //            double dHeading = heading - previousHeading;              double[] wheelPositions = new double[]{encoderTicksToInches(data1.getMotorCurrentPosition(leftVertical)),                     -encoderTicksToInches(data1.getMotorCurrentPosition(horizontal)),                     -encoderTicksToInches((data1.getMotorCurrentPosition(rightVertical))),             };             double[] wheelDeltas = new double[]{wheelPositions[0] - lastWheelPositions[0], wheelPositions[1] - lastWheelPositions[1], wheelPositions[2] - lastWheelPositions[2]};             //double[] wheelDeltas = new double[]{wheelPositions[0] - lastWheelPositions[0], wheelPositions[1] - lastWheelPositions[1], dHeading};             Pose robotPoseDelta = calculatePoseDelta(wheelDeltas);             odoEstimate = relativeOdometryUpdate(robotPoseDelta);             double[] wheelVelocities = new double[]{wheelDeltas[0] / 0.02, wheelDeltas[1] / 0.02, wheelDeltas[2] / 0.02};              if (wheelVelocities != null) {                 poseVelocity = calculatePoseDelta(wheelVelocities);             }               final double robotRadius = 2.0;             Pose2d slamraEstimatePose = currentSlamraPos.pose;             double slamx =  (slamraEstimatePose.getX());             double slamy = robotRadius + slamraEstimatePose.getY();             double slamRotation = currentSlamraPos.pose.getHeading();             double trueX = slamx + sin(slamRotation) * robotRadius;             double trueY = slamy - (cos(slamRotation) * robotRadius);                if (odoState == OdoState.LOWERED) {                 TAO = 1.0; //0.9             } else {                 TAO = 0;             }   //            if(currentSlamraPos.confidence != T265Camera.PoseConfidence.High){ //                TAO = 1.0; //                slamErrorX = trueX - odoEstimate.x ; //                slamErrorY = trueY - odoEstimate.y; //            }              double[][] vislamMat = {                     {trueX - slamErrorX}, //trueX - slamErrorX                     {trueY - slamErrorY}, //trueY - slamErrorY                     {-currentSlamraPos.pose.getHeading()},                     {currentSlamraPos.velocity.getX()},                     {currentSlamraPos.velocity.getY()},                     {-currentSlamraPos.velocity.getHeading()}             };              Matrix slamraEstimate = new Matrix(vislamMat);              double[][] odoMat = {                     {odoEstimate.x},                     {odoEstimate.y},                     {odoEstimate.heading},                     {poseVelocity.x},                     {poseVelocity.y},                     {poseVelocity.heading}             };             Matrix odoMatrix = new Matrix(odoMat);              odoMatrix.multiply(TAO);              slamraEstimate.multiply(1.0 - TAO);             Matrix complementaryStateEstimtate = odoMatrix.add(slamraEstimate); //measured state, Z             state.updateState(complementaryStateEstimtate.getValue(0, 0),                     complementaryStateEstimtate.getValue(1, 0),                     complementaryStateEstimtate.getValue(2, 0),                     complementaryStateEstimtate.getValue(3, 0),                     complementaryStateEstimtate.getValue(4, 0),                     complementaryStateEstimtate.getValue(5, 0));              //previousHeading = heading;              lastWheelPositions = new double[]{wheelPositions[0], wheelPositions[1], wheelPositions[2]}; //            AbstractOpMode.currentOpMode().telemetry.addData("confidence", currentSlamraPos.confidence); //           AbstractOpMode.currentOpMode().telemetry.update();             loggingString += iterator + "," + state.getCurrentState().getPosition().getX() + "\n";            secondaryLoggingString += iterator + "," + state.getCurrentState().getPosition().getY() + "\n"; //            loggingString += odoEstimate.x + "," + odoEstimate.y + "\n"; //            secondaryLoggingString += iterator + "," + odoEstimate.x + "\n";             tertiaryLoggingString += state.getCurrentState().getPosition().loggerToString() + "\n";             iterator++;             }         }          private double angleWrap(double angle) {             while(angle >= PI){                 angle -= 2 * PI;             }             while(angle < -PI){                 angle += 2 * PI;             }             return angle;         }      private static final double EPSILON = 1e-6;      private synchronized Pose relativeOdometryUpdate(Pose robotPoseDelta) {         double dtheta = robotPoseDelta.heading;         double sineTerm, cosTerm;          if (approxEquals(dtheta, 0)) {             sineTerm = 1.0 - dtheta * dtheta / 6.0;             cosTerm = dtheta / 2.0;         } else {             sineTerm = Math.sin(dtheta) / dtheta;             cosTerm = (1 - Math.cos(dtheta)) / dtheta;         }          Point fieldPositionDelta = new Point(                 sineTerm * robotPoseDelta.x - cosTerm * robotPoseDelta.y,                 cosTerm * robotPoseDelta.x + sineTerm * robotPoseDelta.y         );          Pose fieldPoseDelta = new Pose(fieldPositionDelta.rotated(odoEstimate.heading), robotPoseDelta.heading);            Pose fieldPose = new Pose(odoEstimate.x,odoEstimate.y, odoEstimate.heading);          return fieldPose.add(fieldPoseDelta);     }      public static boolean approxEquals(double d1, double d2) {         if (Double.isInfinite(d1)) {             // Infinity - infinity is NaN, so we need a special case             return d1 == d2;         } else {             return Math.abs(d1 - d2) < EPSILON;         }     }      private synchronized Pose calculatePoseDelta(double[] wheelDeltas) {         RealMatrix m = MatrixUtils.createRealMatrix(new double[][]{wheelDeltas});         RealMatrix rawPoseDelta = solver.solve(m.transpose());         return new Pose(                 rawPoseDelta.getEntry(0, 0),                 rawPoseDelta.getEntry(1, 0),                 rawPoseDelta.getEntry(2, 0));      }       public Pose getOdoEstimate(){         return odoEstimate;     }      public Pose getPoseVelocity(){         return poseVelocity;     }      public int getIterator(){         return iterator;     }          /*      Array2DRowRealMatrix inverseMatrix = new Array2DRowRealMatrix(3, 3);         ArrayList<Vector3D> wheelPoses = new ArrayList<Vector3D>();         Vector3D LV_POSE = new Vector3D(0,0, 0); //x, y, angle from center         Vector3D RV_POSE = new Vector3D(0,0, Math.toRadians(180));         Vector3D H_POSE = new Vector3D(0,0, Math.toRadians(90));         wheelPoses.add(LV_POSE);         wheelPoses.add(RV_POSE);         wheelPoses.add(H_POSE);          for(Vector3D wheel: wheelPoses){             double wheelXOffset = Math.cos(wheel.getZ());             double wheelYOffset = Math.sin(wheel.getZ());          }      */      public void manualPositionWrite(RobotPositionStateUpdater.RobotPositionState newState){         state.updateState(newState.getPosition().getX(), newState.getPosition().getY(), newState.getRotation(), newState.getVelocity().getX(), newState.getVelocity().getY(), newState.getAngularVelocity());     }      private double linearSlideEncoderTicksToInches(int motorCurrentPosition) {         return motorCurrentPosition / TICKS_PER_REV;     }       public long getMinElapsedTime(){         return minElapsedTime;     }      public long getMaxElapsedTime(){         return maxElapsedTime;     }      public static double encoderTicksToInches(int ticks) {         return WHEEL_DIAMETER * PI * GEAR_RATIO * ticks / TICKS_PER_REV;     }     public static int inchesToEncoderTicks(double inches){         return (int)((TICKS_PER_REV / (WHEEL_DIAMETER  * PI * GEAR_RATIO)) * inches);     }      public double getLeftVerticalOdometerPosition(){         return leftVertical.getCurrentPosition();     }      public double getLeftVerticalOdometerVelocity(){         return leftVertical.getVelocity();     }      public double getRightVerticalOdometerVelocity(){         return rightVertical.getVelocity();     }      public double getHorizontalOdometerVelocity(){         return horizontal.getVelocity();     }      public double getRightVerticalOdometerPosition(){         return rightVertical.getCurrentPosition();     }      public double getHorizontalOdometerPosition(){         return horizontal.getCurrentPosition();     }      public void writeLoggerToFile(){         try {             PrintStream ps = new PrintStream(loggingFile);             PrintStream pstwo = new PrintStream(secondaryLoggingFile);             PrintStream psThree = new PrintStream(tertiaryloggingFile);             PrintStream psfour = new PrintStream(fourthLoggingFile);             PrintStream psfive = new PrintStream(fifthLoggingFile);             PrintStream psSix = new PrintStream(sixthLoggingFile);             ps.println(loggingString);             pstwo.println(secondaryLoggingString);             psThree.println(tertiaryLoggingString);             psfour.println(fourthLoggingString);             psfive.println(fifthLoggingString);             psSix.println(sixthLoggingString);         } catch (FileNotFoundException e) {             e.printStackTrace();         }      } }          //  Matrix shit, saving the start of my unsimplified proof of the math //        double[][] stateTransistionMat = { //                {currentState.getVelocity().getX() * elapsedTime * 1000, 0, 0, 0, 0, 0}, //                {0, currentState.getVelocity().getY() * elapsedTime * 1000, 0, 0, 0, 0}, //                {0, 0, currentState.getAngularVelocity() * elapsedTime * 1000, 0, 0, 0}, //                {0, 0, 0, currentState.getVelocity().getX(), 0, 0}, //                {0, 0, 0, 0, currentState.getVelocity().getY(), 0}, //                {0, 0, 0, 0, 0, currentState.getAngularVelocity()} //        }; // //        Matrix stateTransistionMatrix = new Matrix(stateTransistionMat); // //        //we have an estimate according to kinematics (assumes constant acceleration) //        //Matrix idealStateEstimate = currentStateEstimate.add(KinematicMotionModel); //        Matrix transposedStateTransitionMatrix = stateTransistionMatrix.transpose(); //        Matrix controlMatrix; // //        Matrix estimateUncertianty = stateTransistionMatrix.multiply(previousProcessNoise); //        estimateUncertianty = estimateUncertianty.multiply(transposedStateTransitionMatrix);

---
## [DillGetting/VagrantProject](https://github.com/DillGetting/VagrantProject)@[008f97b655...](https://github.com/DillGetting/VagrantProject/commit/008f97b655f6497cd5bd18e5e1b42be7fe2ef74f)
#### Friday 2022-01-07 07:47:53 by Dillon Wilcox

Centos7 git practice setup

fucking guest editions installation issues has forced me to use centos7.
package manager is yum
"33.10, 33.11, 33.12" ip endings.
vagrant ssh centos1 (centos2 or gitsvr)to ssh into the machines from any linux terminal. probably would work in windows command terminal have not tried it, 
for sure works in powershell if you have openssh.

The goal is to and not in this order but somehow, stage a file created with sudo touch test.txt with some text in the file.
then commit i think, or push, or probably one then the other and maybe merge to the branch you must also create the gitserver install in a directory first, cant remember the command. then that directory only is where you create the file. could be the home directory so you might not have to worry about that. 

then from centos2
pull or clone or something the file that was pushed or staged or committed and merged that was done from centos1 and see if you can see the file.
the machines can all connect via ssh using their respective ip addresses. 

yeah.

---
## [CrackerCat/Android-Mod-Menu](https://github.com/CrackerCat/Android-Mod-Menu)@[3595e6dfaa...](https://github.com/CrackerCat/Android-Mod-Menu/commit/3595e6dfaa0cd42f96d6cb081965b56571684ebe)
#### Friday 2022-01-07 09:19:17 by LGLTeam

Updated 2.0

DO NOT UPDATE if you are not prepared. You will need to read README again when you use this update

Changelog:
- Updated gradle and NDK target
- Can now force loading menu while waiting for the lib to be loaded
- Add saving logcat to file. It can be useful to diagnose the issues within the mod
- A rework of feature list. Now you must assign feature numbers manually. The benefit is you can easly remember the numbers and you don't need to re-order your Changes anymore when you remove/add/re-order your features. Feature numbers can be like 1,3,200,10... instead in order 0,1,2,3,4,5...
- Settings list has been moved to cpp. The numbers are assigned as negative
- Additional fixes for AIDE CMODs
- Updated README.md and README-MOBILE.md. Be sure to read it again
- Cleaned up codes again to stop the small kinderforum haters from hating us. You may notice some codes have been moved or removed
- Some minor fixes

Maybe there is more changes I forgot to list

To haters, stop using this template immediately and stop spreading hate please. There is no reason to hate. 95% of modders love this template already. To lovers, show us love by making videos of your cool mods with mod menu ❤️❤️❤️.

---
## [connectuum/warnings](https://github.com/connectuum/warnings)@[9cec97c5ff...](https://github.com/connectuum/warnings/commit/9cec97c5ff1dd9e27d282b86ece4eda48bccabc1)
#### Friday 2022-01-07 10:45:08 by connectuum

told of the depths and the next-steps

i felt i had lost some sense of direction today. i have been [a monkey swings] recursing through GitHub paths for a while now, looking for projects and people that [mental highlighter] stood out. surveying the fields.

this task was lovely for a while! fascinating people, projects, and ideas. but, all things begin to grind. this is when i (so carelessly) plucked a clew and began collapse: from GitHub API down to a loose plan for automating and visualizing my searches.

i realized as i wrote that i was now _conscious_ of that collapse, a touch more self-aware-- and then: the vexing text of _Theseus_, flowed into my mind, yet now i _saw_ it, out of riddle; it looked a most alluring prize.

i sought to explain via poetry. entered this unusual-for-me lockstep in fours. was rather quickly on my way, scouting paths ahead, when i found myself in close range of a rather lovely clew. i cannot wait until i can _write_ and _branch_ in time and flow [please take wing] [a monkey swings]. O, to never worry over lost branches in the train of thought...

now i `return`: to poem, interrupted. wait-- no, _another_ new image appears. the animal _us,_ the mythical _them._ animal:mythical. physical:possible. temporal:undefined. **nature:nurture.**

i saw communication channels betwixt these two domains. and when i saw, i felt such guilt and remorse, for it seems: i have made a grave sin.

i have amassed a great cache of ideas. words and pictures, code and verse. all denied their shine. a vault i _thought_ was mine. they'll wilt and die, in time. _oh god the brutal image:_ audacious servant, drowned in wine, hair gripped in hand-- **the hand is _mine._**

oh, i feel the _anger_ of her. escalates to CAPS and _name._ i am lashed and i accept it, i see the _murder_ of my caves. she relents, then on to learning: the dire scene begins to shape. they are ever-giving, while we forever _take._

this image next is hazy, but we _can_ answer back. we can _honor_ clew: by _growing_ all the best, and by sharing and communicating ideas to each other. the important bit is in the _listening,_ not the debate.

when art and ideas are _communicated,_ others listen; they _process_ the information. the crystallized idea, pulled from clew, now _executes_ in your mind. the {emotion|sentiment|image|response|reaction} that an idea generates in you... a portion of the _output_ from your brain's input-output `function()`... i think _that_ might be what communicates _back_.

lifecycle: in the domain of the `living` exists a mysterious creature -- the _clew._ in our domain of the `dead`, exist _hunters_, of varied skill and patience, seeking grasp of a notion, an attachment to canvas, to affix it in time. as the idea executes, or the human executes the idea, it becomes increasingly tangible -- increasingly _collapsed._ the clew: begins as cloud of probabilities and paths, then stepwise strangled into a single _grasped_ and _defined_ and _measured_ physical reality. `dead`.

my clews -- my _sin_ -- are still held in cold-storage. hopelessly _without growth,_ never to reverberate in others, never to allow the clew to **return home** -- with all the warnings of our resonances. without the chance of clews _gifted_ in response.

the work of the _nurture_ domain is **guidance.** our physical/animal realm requires it, else we become askew; _unbalanced._ guidance comes to us via [image] and clew. you _discover_ the former; you _hunt_ the latter. the _guidance_ cannot do its _work_ upon us while it remains stashed in a barn, barreled away in caves, or encrypted upon hard disk.

my earlier uncertain direction \
has become clearer than ever: \
i must unpack. \
_armor, anchor, lead, and stone._

---

I SHARE THIS CLEW \
i snared, and slew \
i _suffocated_ \
all for you.

read it through \
watch {it|me} move \
_does this ring to you as **True?**_

---
## [google/error-prone](https://github.com/google/error-prone)@[9fc2365a70...](https://github.com/google/error-prone/commit/9fc2365a7062cc90fa69a719084438a64a00e36a)
#### Friday 2022-01-07 12:26:30 by ghm

AlreadyChecked: handle early returns.

Also, use WellKnownMutability again to assume that _instance_ methods on immutable types are pure.

i.e., for the remainder of the method body in

```
void foo(boolean a) {
  if (a) {
    return;
  }
  // ...
}
```

`a` is known to be false.

Implementing tests for this made me realise my thinking was a bit flawed when looking for occurrences of known truths/falsehoods; really, we should be checking for all boolean expressions which might be known (and hence misleading).

I've done this instead, but in turn it inspired a heursitic to avoid annoying findings for stuff like:

```
if (isEmpty) {
  message.setIsEmpty(isEmpty);
}
```

Because that finding is quite low-value, and what would you suggest instead? If it's more than just a setter, you'd want a parameter comment

PiperOrigin-RevId: 416767440

---
## [R911-bot/Storage](https://github.com/R911-bot/Storage)@[1ebf946f31...](https://github.com/R911-bot/Storage/commit/1ebf946f31423821a68bb995ce16ee59a87d74b1)
#### Friday 2022-01-07 12:27:59 by R911-bot

You will not find me. Don't you get it?

Fuck you.

---
## [fatpowaranga/pfQuest-turtle](https://github.com/fatpowaranga/pfQuest-turtle)@[c72c6326e3...](https://github.com/fatpowaranga/pfQuest-turtle/commit/c72c6326e3a13f9d9889031d70996970499a9ca0)
#### Friday 2022-01-07 12:53:20 by Gurky

db: several quests, items, objects, units

Quests:
You Reap What You Sow
Fallen Adventurers
Preventive Strike
Trapped in the Nightmare
Serpentbloom
Down With the Sickness
Preventing Poison
Kodo Hunt
Mother of the Hollow
Troubles From Distant Lands
Trader's Misfortune
Mastering the Arcane
Arcane Arms
A Glittering Opportunity
A Bloody Good Deed

Items:
Country Pumpkin Seeds
Mountain Berries Seeds
Striped Melon Seeds
Magic Mushroom Spores
Squealer Thornmantle's Mane
Sickly Gazelle Flesh Sample
Summer Dew
Life's Dawn
Vulpa Bloom
Moontouched Wood
Crystal of the Serpent
Everchanging Essence

Objects:
Ripe Garden Pumpkin
Garden Berry Bush
Ripe Garden Watermelon
Summer Dew
Life's Dawn
Vulpa Bloom
Mysterious Glittering Object

Units:
Kern Mosshoof
Chok'Garok
Ureda
Kheyna Spinpistol
Aneka Konko

I believe some of the quests need races,faction,classes added to them which I will visit later.

---
## [ScarSymmetry/React-Invoice-App](https://github.com/ScarSymmetry/React-Invoice-App)@[b0b67e86b9...](https://github.com/ScarSymmetry/React-Invoice-App/commit/b0b67e86b94d274019a40d88024b4c814559181f)
#### Friday 2022-01-07 13:44:24 by ScarSymmetry

battling scroll issues on ios , fuck you apple retards

---
## [Zura1z/Programming-Fundamentals](https://github.com/Zura1z/Programming-Fundamentals)@[16ef51741c...](https://github.com/Zura1z/Programming-Fundamentals/commit/16ef51741cd7d2a6eca31aae165aa2dc829d8d2c)
#### Friday 2022-01-07 13:45:39 by Zuraiz Zahoor Ajaz

Assignment 6

Text processing is an important area in the field of Artificial Intelligence. One of the tasks
in text processing would be to gauge the readability of a particular piece of text. Automated
Readability Index(ARI) is a score designed to gauge the readability of a text.
The formula for calculating ARI is given below:

4.71
characters
words !
+ 0.5
words
sentences!
− 21.43

where characters is the number of letters and numbers, words is the number of alpha-numeric
sequences, and sentences is the number of sentences, which were counted manually by the typist
when the above formula was developed. Non-integer scores are always rounded up to the nearest
whole number, so a score of 10.1 or 10.6 would be converted to 11.
As a rough guide, grade level 1 corresponds to ages 6-8. Reading level grade 8 corresponds to
the typical reading level of a 14-year-old child. Grade 12, the highest secondary-school grade
before college and corresponds to the reading level of a 17-year-old. For reference see the table
below:

Score Age Grade Level
1 5-6 Kindergarten
2 6-7 First/Second Grade
3 7-9 Third Grade
4 9-10 Fourth Grade
5 10-11 Fifth Grade
6 11-12 Sixth Grade
7 12-13 Seventh Grade
8 13-14 Eighth Grade
9 14-15 Ninth Grade
10 15-16 Tenth Grade
11 16-17 Eleventh Grade
12 17-18 Twelfth grade
13 18-24 College student
14 24+ Professor

The index is calculated by a fixed set of rules for counting the number of sentences, words,
and characters in a piece of text. This can be automated via a computer program. Here is an
example. Consider the following sentence:
It was an extraordinarily windy day, and thus the riders were faced with several arduous
climbs up the mountain, with the wind trying to push them back down the road.
The Readability Index for that sentence is 15 using our algorithm. The following conveys almost
the same idea,
It was a very windy day. The riders had many hard climbs up mountains. The wind kept
pushing them back down the road.
This set of sentences has a Readability Index of 2. This method of determining the readability
of a piece of text does not do any sort of linguistic analysis so the results can be misleading, but
the method usually produces a reasonable answer.
Note, these rules are a heuristic. Heuristics may not always achieve the desired outcome, but
they are extremely valuable to problem-solving processes. Heuristics are valuable because they
simplify the problem solving process and usually give a good answer if not always a perfect
answer.
Your program must count the number of characters, number of words, and number of sentences.
Certain assumptions are made about what is a character, word, and sentence in order to make
it easier to write a program to do the analysis.
Sentences are the easiest to count. Each occurrence of a period, colon, semicolon, question
mark, and exclamation mark is counted as a sentence. Thus the String “Wow!!!” has 1 word
with 3 characters, but 3 sentences. (Again this set of rules is a heuristic. A set of rules that
often gives a good answer, but occasionally gives bad or nonsensical answers. It is possible per
these rules to have a sentence with no words). If a text has no sentence characters assume it
has 1 sentence.
A character is any alpha-numeric character. Punctuation marks and spaces are not counted
as characters. A word is sequence of one or more alpha-numeric characters delimited by white
space or by a sentence terminators as listed in rule 3, whether or not it is an actual English word.
White space is defined as a space, tab, a new line character, and the end of the string itself.
Again this gives some results that may not make sense. Any continuous sequence of alphabets
and digits is considered as a word.
For example the text
shopkeeper’s shoes 4 his child2ren.
contains 6 words and a single sentence containing 29 characters. In the above example shopkeeper
and s are considered as two separate words and 4 is also considered a word.
Your program should continuosly ask the user for input text until the user types quit as input.
You can assume that the text length shall not exceed 1000 characters including spaces and
punctuation marks. A sample run of the program is given below:
Enter sentence 1: This is a sentence. So is this!
Number of sentences: 2
Number of words: 7
Number of characters: 23
Readability index: 0

Enter sentence 2: It continued raining for many days. One day, a monkey wet in the
rain came into the forest. He sat on a branch, shivering with cold, water dripping
from its body.
Number of sentences: 3
Number of words: 31
Number of characters: 126
Readability index: 3
Enter sentence 3: There was once a poor servant-girl, who was industrious and cleanly,
and swept the house every day, and emptied her sweepings on the great heap in front of
the door. One morning when she was just going back to her work, she found a letter on
this heap, and as she could not read, she put her broom in the corner, and took the
letter to her master and mistress, and behold it was an invitation from the elves,
who asked the girl to hold a child for them at its christening. The girl did not know
what to do, but at length, after much persuasion, and as they told her that it was not
right to refuse an invitation of this kind, she consented.

Number of sentences: 3
Number of words: 126
Number of characters: 499
Readability index: 19
Enter sentence 4: quit

This above example is merely to show how the algorithm works regardless of if the input is
standard English or not. You could even run the algorithm on source code, although the answer
would not be very helpful or meaningful.
1. Implement a multi-pass algorithm. This means your run through the text three times.
Once to count the sentences, once to count the words, and once to count the characters.
You should create a different method for each of these passes.
2. Assume that the number of characters in each text is less than 1000.
3. Using the library functions in <ctype.h> will make things slightly easier.
Style issues. We will grade program hygiene as well as correctness. Did you provide a good structure
to the program using functions? Did you minimize the scope of variables to the smallest necessary?
Did you use meaningful identifiers? Did you provide consistent tabbing and spacing for code inside
functions and if statements? Did you provide comments for your functions?

---
## [Zura1z/Programming-Fundamentals](https://github.com/Zura1z/Programming-Fundamentals)@[ce436d7d68...](https://github.com/Zura1z/Programming-Fundamentals/commit/ce436d7d6854bfce9c4584307bab67b20e41f937)
#### Friday 2022-01-07 14:10:44 by Zuraiz Zahoor Ajaz

Assignment 9


Assignment Statement:
In the book ’The Dancing Men’ Sherlock Holmes cracks the code of a criminal mastermind
writing letters using a sequence of stick figures to encrypt sentences. This encryption method
is known as substitution cipher and the technique Holmes used to crack the code is known as
frequency analysis.

Figure 1: An example of encrypted message from The Dancing Men.

A more sophisticated version of substitution cipher was used by the Enigma machine during
World War II. In this assignment you are expected to apply frequency analysis to a set of
encrypted files and determine the cipher of the encrypted text. Your solution will be marked on
its ability to determine the cipher correctly. Your program will take an input file as input and
produce a cipher as output.
Background Information: A substitution cipher is a simple way of encrypting or encoding
text to try and keep unwanted people from knowing the contents of a message. The key or
cipher consists of a key as follows:
    A B C D E F G H I J K L M N O P Q R S T U V W X Y Z decoded or plaintext letter
    J I X O W H V Z M Q U D T B C Y P N A S E L G F K R encoded letter


To encrypt a message we simply match the letter we are trying to encrypt with the top row
and write down the letter directly below it from the bottom row. For example, if we wanted to
encrypt the sentence “PF IS FUN” we would see that C encrypts to X, S encrypts to A and so
forth. We would get the message “YH MA HER”. In order for the substitution cipher to work the
sender and the receiver need to agree on the key beforehand. 


Since you know the key used to
encrypt the message, what does “WFJT MA VCMBV SC IW SCEVZ!” decipher to?
At first the substitution cipher appears pretty hard to crack. Even if we only encrypt upper case
letters there are 26! = (403, 291, 461, 126, 605, 635, 584, 000, 000) possible keys. It seems like an
intractable task to try every possible key. However, code breakers have the English language (or
whatever language the message is in) on their side. In English, as with other languages, certain
characters are used much more frequently than others. A code breaker can use this fact and
do frequency analysis on a message. Frequency analysis is performed by taking an encrypted
message and counting up the occurrence of each letter or character. The longer the message the
better, so this task is a good candidate for automation with a computer program.



Assignment Description: For this assignment you will write a program that does a frequency
analysis on a file set of files. A key is created based on that frequency analysis. The file is then
decrypted using that key.
For determining the fequency of printable ASCII letters, you can use as many documents as you
like from the web (for e.g. from Wikipedia etc.). You do not need to display the frequency of
all the printable ASCII characters. You only need to handle printable ASCII characters (with
ASCII codes 10, 32 - 126). Where 10 represnts Line Feed (newline character). You can (Ignore
ASCII chars 0 - 31 (except 10) and 127). See the Wikipedia article for more information on the
printable ASCII characters. Thus your cipher will contain exactly 96 characters (as can be seen
in cipher1.txt and cipher2.txt).
You are given the following files:
• substitution: this is an executable for encryption and decryption
• plain1.txt: A sample plain text file
• encrypted1.txt: Encrypted version of plain1.txt
• cipher1.txt: The cipher used to encrypt plain1.txt to encrypted1.txt
• plain2.txt: Another sample plain text file
• encrypted2.txt: Encrypted version of plain2.txt
• cipher2.txt: The cipher used to encrypt plain2.txt to encrypted2.txt
• encrypted3.txt: Encrypted version of an unknown file - try to figure out its cipher!

To run the program substitution you should download the given files and change the permis-
sions of the executable using:

chmod 744 substitution
thereafter you can test the file to encrypt plaintext using:
./substitution -e cipher1.txt plain1.txt encrypted1.txt
The above command encrypts plain1.txt using the cipher given in cipher1.txt to generate
the file encrypted1.txt. The ciper file must contain exactly 96 characters with ASCII index 10
and 32-126. Only the same cipher can be used to decrypt encrypted1.txt using the command:
./substitution -d cipher1.txt encrypted1.txt decrypted1.txt
Recall, the cipher is used to decrypt the message. The returned decrypted file relies on mapping
given in the cipher. Thus the index of the character in the cipher indicates the ASCII code
of the character in the encrypted text and the actual element is character than the encrypted
character is changed into.

Here is an example. Assume we obtain the array of chars from the cipher file. Assume this is a
portion of the array. (I don’t show all of it.)

index 65 66 67 68 69 70 71 72 73 74
element @ ! = q w K H . s F

Again, that is only a portion of the array. Index 65 maps to ASCII character 65. ASCII code
65 is ’A’ mapping to ’!’. Thus an ’@’ in the encrypted message will decrypt to a ’A’ based
on the current key. ASCII code 66 is ’B’. Thus a ’!’ in the encrypted message will decrypt to
a ’B’ based on the current key. And so forth.
So if we had this encrypted message: !w@F@=CB
and used the key shown above to decrypt it we would get: BEAJACK
’!’ is the first character in the encrypted message. ’!’ is located at the index 66 in the cipher.
And 66 is the ASCII code for ’B’. So ’!’ becomes ’B’. The encrypted character in the message
is ’F’. ’F’ is located at the index has an 74 so ’F’ becomes ’J’ in the decrypted message.
And so forth. Thus, the cipher array returned is used to transform the encrypted message to a
decrypted message.
In your solution, you can use a lot of online text to calculate frequencies of printable characters
and match these with the frequencies of letters appearing in the encrypted text. The trouble
with this approach is that with short messages there will be differences between the expected
frequency of letters and the actual frequencies. The decrypted text probably won’t be perfect
unless it is several thousand characters long. Even then there could be mistakes due to differences
between the standard frequencies of characters and the actual frequency of characters in the
original text. Therefore, your solution will be marked on its ability to determine the cipher
as best as possible even if it is not 100% accurate. Your program will take an encrypted file
as input (as a command line parameter) and produce a cipher on the standard output. For
example, if your program is called holmes then the following is a sample run:
./holmes encrypted2.txt
] ~*;dfTy_<{8oXv’U(xW>VI[!L^l:Z|hDMH=j#‘C\Ea6K,%N2Fus"b/74RzQO+$}5)Y&?@1Jpm
iS.tGw9Anc-r3e0kgqBP

Things to remember:


We are mapping the ASCII values of chars to indices in the array. You can convert from a char
to an int without casting.
int x = ch; // if ch is a char, x now holds the ASCII code for that char
Converting from an int to a char requires casting
char ch = (char) x; // if x is an int, ch now holds the ASCII character associated with
the code x
Break the problem up into methods. Test methods before going on. This will require writing
some testing code that you delete before turning in your program. Simple printf statements
are VERY useful when testing and debugging. As always you must use good program hygiene.
(Constants, meaningful variable names, well structured code, removal of redundancy, correct spacing and tabbing and alignment of braces, and so forth as spelled out in the assignment
page.)

Approach: Divide the program into parts. Complete and test each part before moving on. Use
the methods from string and ctype (such as isprint())libraries to help make your job easier.
Divide the program up into methods to provide a structured solution. Some of the methods will
be void and others will return values. You will have to make use of parameters, for loops, while
loops, and if statements. Do not write all your code in main().

---
## [okias/linux](https://github.com/okias/linux)@[4fe62db913...](https://github.com/okias/linux/commit/4fe62db913ad78fd40c60648d902313d5bc7fabe)
#### Friday 2022-01-07 14:24:30 by Mauricio Faria de Oliveira

mm: fix race between MADV_FREE reclaim and blkdev direct IO read

Problem:
=======

Userspace might read the zero-page instead of actual data from a direct IO
read on a block device if the buffers have been called madvise(MADV_FREE)
on earlier (this is discussed below) due to a race between page reclaim on
MADV_FREE and blkdev direct IO read.

Race condition:
==============

During page reclaim, the MADV_FREE page check in try_to_unmap_one() checks
if the page is not dirty, then discards its PTE (vs remap it back if the
page is dirty).

However, after try_to_unmap_one() returns to shrink_page_list(), it might
keep the page _anyway_ if page_ref_freeze() fails (it expects a single
page ref from the isolation).

Well, blkdev_direct_IO() gets references for all pages, and on READ
operations it sets them dirty later.

So, if MADV_FREE pages (i.e., not dirty) are used as buffers (more later)
for direct IO read from block devices and page reclaim runs during
__blkdev_direct_IO[_simple]() AFTER bio_iov_iter_get_pages() but BEFORE it
sets pages dirty, that situation happens.

The direct IO read eventually completes.  Now, when userspace reads the
buffers, the PTE is no longer there and the page fault handler
do_anonymous_page() services that with the zero-page, NOT the data!

A synthetic reproducer is provided.

Page faults:
===========

The data read from the block device probably won't generate faults due to
DMA (no MMU) but even in the case it wouldn't use DMA, that happens on
different virtual addresses (not user-mapped addresses) because `struct
bio_vec` stores `struct page` to figure addresses out (which are different
from/unrelated to user-mapped addresses) for the data read.

Thus userspace reads (to user-mapped addresses) still fault, then
do_anonymous_page() gets another `struct page` that would address/ map to
other memory than the `struct page` used by `struct bio_vec` for the read
(which runs correctly as the page wasn't freed due to page_ref_freeze(),
and is reclaimed later) -- but even if the page addresses matched, that
handler maps the zero-page in the PTE, not that page's memory (on read
faults.)

If page reclaim happens BEFORE bio_iov_iter_get_pages() the issue doesn't
happen, because that faults-in all pages as writeable, so
do_anonymous_page() sets up a new page/rmap/PTE, and that is used by
direct IO.  The userspace reads don't fault as the PTE is there (thus
zero-page is not used.)

Solution:
========

One solution is to check for the expected page reference count in
try_to_unmap_one() too, which should be exactly two: one from the
isolation (checked by shrink_page_list()), and the other from the rmap
(dropped by the discard: label).  If that doesn't match, then remap the
PTE back, just like page dirty does.

The new check in try_to_unmap_one() should be safe in races with
bio_iov_iter_get_pages() in get_user_pages() fast and slow paths, as it's
done under the PTE lock.  The fast path doesn't take that lock but it
checks the PTE has changed, then drops the reference and leaves the page
for the slow path (which does take that lock).

- try_to_unmap_one()
  - page_vma_mapped_walk()
    - map_pte() # see pte_offset_map_lock():
        pte_offset_map()
        spin_lock()
  - page_ref_count() # new check
  - page_vma_mapped_walk_done() # see pte_unmap_unlock():
      pte_unmap()
      spin_unlock()

- bio_iov_iter_get_pages()
  - __bio_iov_iter_get_pages()
    - iov_iter_get_pages()
      - get_user_pages_fast()
        - internal_get_user_pages_fast()

          # fast path
          - lockless_pages_from_mm()
            - gup_{pgd,p4d,pud,pmd,pte}_range()
                ptep = pte_offset_map() # not _lock()
                pte = ptep_get_lockless(ptep)
                page = pte_page(pte)
                try_grab_compound_head(page) # get ref
                if (pte_val(pte) != pte_val(*ptep))
                        put_compound_head(page) # put ref
                        # leave page for slow path
          # slow path
          - __gup_longterm_unlocked()
            - get_user_pages_unlocked()
              - __get_user_pages_locked()
                - __get_user_pages()
                  - follow_{page,p4d,pud,pmd}_mask()
                    - follow_page_pte()
                        ptep = pte_offset_map_lock()
                        pte = *ptep
                        page = vm_normal_page(pte)
                        try_grab_page(page) # get ref
                        pte_unmap_unlock()

Regarding transparent hugepages, that number shouldn't change, as
MADV_FREE (aka lazyfree) pages are PageAnon() && !PageSwapBacked()
(madvise_free_pte_range() -> mark_page_lazyfree() -> lru_lazyfree_fn())
thus should reach shrink_page_list() -> split_huge_page_to_list() before
try_to_unmap[_one](), so it deals with normal pages only.

(And in case unlikely/TTU_SPLIT_HUGE_PMD/split_huge_pmd_address() happens,
which it should not or be rare, the page refcount is not two, as the head
page counts tail pages, and tail pages have zero.  That also prevents
checking the head `page` then incorrectly call page_remove_rmap(subpage)
for a tail page, that isn't even in the shrink_page_list()'s page_list (an
effect of split huge pmd/pmvw), as it might happen today in this unlikely
scenario.)

MADV_FREE'd buffers:
===================

So, back to the "if MADV_FREE pages are used as buffers" note.  The case
is arguable, and subject to multiple interpretations.

The madvise(2) manual page on the MADV_FREE advice value says:
- 'After a successful MADV_FREE ... data will be lost when
   the kernel frees the pages.'
- 'the free operation will be canceled if the caller writes
   into the page' / 'subsequent writes ... will succeed and
   then [the] kernel cannot free those dirtied pages'
- 'If there is no subsequent write, the kernel can free the
   pages at any time.'

Thoughts, questions, considerations...
- Since the kernel didn't actually free the page (page_ref_freeze()
  failed), should the data not have been lost? (on userspace read.)
- Should writes performed by the direct IO read be able to cancel
  the free operation?
  - Should the direct IO read be considered as 'the caller' too,
    as it's been requested by 'the caller'?
  - Should the bio technique to dirty pages on return to userspace
    (bio_check_pages_dirty() is called/used by __blkdev_direct_IO())
    be considered in another/special way here?
- Should an upcoming write from a previously requested direct IO
  read be considered as a subsequent write, so the kernel should
  not free the pages? (as it's known at the time of page reclaim.)

Technically, the last point would seem a reasonable consideration and
balance, as the madvise(2) manual page apparently (and fairly) seem to
assume that 'writes' are memory access from the userspace process (not
explicitly considering writes from the kernel or its corner cases; again,
fairly)..  plus the kernel fix implementation for the corner case of the
largely 'non-atomic write' encompassed by a direct IO read operation, is
relatively simple; and it helps.

Reproducer:
==========

@ test.c (simplified, but works)

	#define _GNU_SOURCE
	#include <fcntl.h>
	#include <stdio.h>
	#include <unistd.h>
	#include <sys/mman.h>

	int main() {
		int fd, i;
		char *buf;

		fd = open(DEV, O_RDONLY | O_DIRECT);

		buf = mmap(NULL, BUF_SIZE, PROT_READ | PROT_WRITE,
                	   MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);

		for (i = 0; i < BUF_SIZE; i += PAGE_SIZE)
			buf[i] = 1; // init to non-zero

		madvise(buf, BUF_SIZE, MADV_FREE);

		read(fd, buf, BUF_SIZE);

		for (i = 0; i < BUF_SIZE; i += PAGE_SIZE)
			printf("%p: 0x%x
", &buf[i], buf[i]);

		return 0;
	}

@ block/fops.c (formerly fs/block_dev.c)

	+#include <linux/swap.h>
	...
	... __blkdev_direct_IO[_simple](...)
	{
	...
	+	if (!strcmp(current->comm, "good"))
	+		shrink_all_memory(ULONG_MAX);
	+
         	ret = bio_iov_iter_get_pages(...);
	+
	+	if (!strcmp(current->comm, "bad"))
	+		shrink_all_memory(ULONG_MAX);
	...
	}

@ shell

	# yes | dd of=test.img bs=1k count=16
	# DEV=$(losetup -f --show test.img)
	# gcc -DDEV=\"$DEV\" -DBUF_SIZE=16384 -DPAGE_SIZE=4096 test.c -o test

	# od -tx1 $DEV
	0000000 79 0a 79 0a 79 0a 79 0a 79 0a 79 0a 79 0a 79 0a
	*
	0040000

	# mv test good
	# ./good
	0x7f1509206000: 0x79
	0x7f1509207000: 0x79
	0x7f1509208000: 0x79
	0x7f1509209000: 0x79

	# mv good bad
	# ./bad
	0x7fd87272f000: 0x0
	0x7fd872730000: 0x0
	0x7fd872731000: 0x0
	0x7fd872732000: 0x0

Ceph/TCMalloc:
=============

For documentation purposes, the use case driving the analysis/fix is Ceph
on Ubuntu 18.04, as the TCMalloc library there still uses MADV_FREE to
release unused memory to the system from the mmap'ed page heap (might be
committed back/used again; it's not munmap'ed.)
- PageHeap::DecommitSpan() -> TCMalloc_SystemRelease() -> madvise()
- PageHeap::CommitSpan() -> TCMalloc_SystemCommit() -> do nothing.

Note: TCMalloc switched back to MADV_DONTNEED a few commits after the
release in Ubuntu 18.04 (google-perftools/gperftools 2.5), so the issue
just 'disappeared' on Ceph on later Ubuntu releases but is still present
in the kernel, and can be hit by other use cases.

The observed issue seems to be the old Ceph bug #22464 [1], where checksum
mismatches are observed (and instrumentation with buffer dumps shows
zero-pages read from mmap'ed/MADV_FREE'd page ranges).

The issue in Ceph was reasonably deemed a kernel bug (comment #50) and
mostly worked around with a retry mechanism, but other parts of Ceph could
still hit that (rocksdb).  Anyway, it's less likely to be hit again as
TCMalloc switched out of MADV_FREE by default.

(Some kernel versions/reports from the Ceph bug, and relation with
the MADV_FREE introduction/changes; TCMalloc versions not checked.)
- 4.4 good
- 4.5 (madv_free: introduction)
- 4.9 bad
- 4.10 good? maybe a swapless system
- 4.12 (madv_free: no longer free instantly on swapless systems)
- 4.13 bad

[1] https://tracker.ceph.com/issues/22464

Thanks:
======

Several people contributed to analysis/discussions/tests/reproducers
in the first stages when drilling down on ceph/tcmalloc/linux kernel:

- Dan Hill
- Dan Streetman
- Dongdong Tao
- Gavin Guo
- Gerald Yang
- Heitor Alves de Siqueira
- Ioanna Alifieraki
- Jay Vosburgh
- Matthew Ruffell
- Ponnuvel Palaniyappan

Link: https://lkml.kernel.org/r/20211211022115.1547617-1-mfo@canonical.com
Signed-off-by: Mauricio Faria de Oliveira <mfo@canonical.com>
Cc: Dan Hill <daniel.hill@canonical.com>
Cc: Dan Streetman <dan.streetman@canonical.com>
Cc: Dongdong Tao <dongdong.tao@canonical.com>
Cc: Gavin Guo <gavin.guo@canonical.com>
Cc: Gerald Yang <gerald.yang@canonical.com>
Cc: Heitor Alves de Siqueira <halves@canonical.com>
Cc: Ioanna Alifieraki <ioanna-maria.alifieraki@canonical.com>
Cc: Jay Vosburgh <jay.vosburgh@canonical.com>
Cc: Matthew Ruffell <matthew.ruffell@canonical.com>
Cc: Ponnuvel Palaniyappan <ponnuvel.palaniyappan@canonical.com>
Cc: Minchan Kim <minchan@kernel.org>
Cc: Huang Ying <ying.huang@intel.com>
Cc: Miaohe Lin <linmiaohe@huawei.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

---
## [newstools/2022-national-daily-nigeria](https://github.com/newstools/2022-national-daily-nigeria)@[2c464f252b...](https://github.com/newstools/2022-national-daily-nigeria/commit/2c464f252bc4f20f132ac23dd069ab40951e5193)
#### Friday 2022-01-07 16:02:04 by Billy Einkamerer

Created Text For URL [nationaldailyng.com/i-killed-my-girlfriend-on-the-new-year-eve-suspect-confesses/]

---
## [oxidecomputer/hubris](https://github.com/oxidecomputer/hubris)@[8e0b13b865...](https://github.com/oxidecomputer/hubris/commit/8e0b13b86564fc7316428943dfe5fde88bb60ef4)
#### Friday 2022-01-07 16:14:37 by Cliff L. Biffle

Remove "standalone" build.

I introduced the standalone build early on as a way of quickly iterating
on a single task, without waiting for an entire image to build -- an
equivalent to `cargo check`. It has proven somewhat useful but also
breaks things.

- The standalone build does not build the actual code you'd ship, it
  instead configures the code in "standalone mode" where a bunch of
  stuff is arbitrarily stubbed out. This means that getting a successful
  standalone build tells you little about the real build.

- You can also _forget_ to put in the standalone magic, in which case
  your actual firmware builds, but then someone else doing a
  "standalone" build later faces a cryptic failure. This is why the
  standalone builds are run in CI -- to avoid this.

- As we introduce increasing levels of configurability in tasks,
  stubbing that configuration out in arbitrary ways is getting harder.
  When it was a matter of conditional compilation driven by board name,
  we could sprinkle in some `feature = "standalone"` hacks to guide it.
  As we move toward task slots and general configuration data in the
  app.toml, the main distinguishing feature of the standalone build --
  that it does not _have_ an app.toml -- starts to become a real pain.

My iteration workflow is currently served by `cargo xtask build`. I am
not aware of any reliable way of getting RLS/rust-analyzer to work on
Hubris, even _with_ the standalone build, so this shouldn't regress
editor support.

---
## [T-J-Teru/binutils-gdb](https://github.com/T-J-Teru/binutils-gdb)@[fb183df18c...](https://github.com/T-J-Teru/binutils-gdb/commit/fb183df18cebac88787a3b2cc9896d4a70c7c7ed)
#### Friday 2022-01-07 17:17:45 by Andrew Burgess

gdb/python: improve the auto help text for gdb.Parameter

This commit attempts to improve the help text that is generated for
gdb.Parameter objects when the user fails to provide their own
documentation.

Documentation for a gdb.Parameter is currently pulled from two
sources: the class documentation string, and the set_doc/show_doc
class attributes.  Thus, a fully documented parameter might look like
this:

  class Param_All (gdb.Parameter):
     """This is the class documentation string."""

     show_doc = "Show the state of this parameter"
     set_doc = "Set the state of this parameter"

     def get_set_string (self):
        val = "on"
        if (self.value == False):
           val = "off"
        return "Test Parameter has been set to " + val

     def __init__ (self, name):
        super (Param_All, self).__init__ (name, gdb.COMMAND_DATA, gdb.PARAM_BOOLEAN)
        self._value = True

  Param_All ('param-all')

Then in GDB we see this:

  (gdb) help set param-all
  Set the state of this parameter
  This is the class documentation string.

Which is fine.  But, if the user skips both of the documentation parts
like this:

  class Param_None (gdb.Parameter):

     def get_set_string (self):
        val = "on"
        if (self.value == False):
           val = "off"
        return "Test Parameter has been set to " + val

     def __init__ (self, name):
        super (Param_None, self).__init__ (name, gdb.COMMAND_DATA, gdb.PARAM_BOOLEAN)
        self._value = True

  Param_None ('param-none')

Now in GDB we see this:

  (gdb) help set param-none
  This command is not documented.
  This command is not documented.

That's not great, the duplicated text looks a bit weird.  If we drop
different parts we get different results.  Here's what we get if the
user drops the set_doc and show_doc attributes:

  (gdb) help set param-doc
  This command is not documented.
  This is the class documentation string.

That kind of sucks, we say it's undocumented, then proceed to print
the documentation.  Finally, if we drop the class documentation but
keep the set_doc and show_doc:

  (gdb) help set param-set-show
  Set the state of this parameter
  This command is not documented.

That seems OK.

So, I think there's room for improvement.

With this patch, for the four cases above we now see this:

  # All values provided by the user, no change in this case:
  (gdb) help set param-all
  Set the state of this parameter
  This is the class documentation string.

  # Nothing provided by the user, the first string is now different:
  (gdb) help set param-none
  Set the current value of 'param-none'.
  This command is not documented.

  # Only the class documentation is provided, the first string is
  # changed as in the previous case:
  (gdb) help set param-doc
  Set the current value of 'param-doc'.
  This is the class documentation string.

  # Only the set_doc and show_doc are provided, this case is unchanged
  # from before the patch:
  (gdb) help set param-set-show
  Set the state of this parameter
  This command is not documented.

The one place where this change might be considered a negative is when
dealing with prefix commands.  If we create a prefix command but don't
supply the set_doc / show_doc strings, then this is what we saw before
my patch:

  (gdb) python Param_None ('print param-none')
  (gdb) help set print
  set print, set pr, set p
  Generic command for setting how things print.

  List of set print subcommands:

  ... snip ...
  set print param-none -- This command is not documented.
  ... snip ...

And after my patch:

  (gdb) python Param_None ('print param-none')
  (gdb) help set print
  set print, set pr, set p
  Generic command for setting how things print.

  List of set print subcommands:

  ... snip ...
  set print param-none -- Set the current value of 'print param-none'.
  ... snip ...

This seems slightly less helpful than before, but I don't think its
terrible.

Additionally, I've changed what we print when the get_show_string
method is not provided in Python.

Back when gdb.Parameter was first added to GDB, we didn't provide a
show function when registering the internal command object within
GDB.  As a result, GDB would make use of its "magic" mangling of the
show_doc string to create a sentence that would display the current
value (see deprecated_show_value_hack in cli/cli-setshow.c).

However, when we added support for the get_show_string method to
gdb.Parameter, there was an attempt to maintain backward compatibility
by displaying the show_doc string with the current value appended, see
get_show_value in py-param.c.  Unfortunately, this isn't anywhere
close to what deprecated_show_value_hack does, and the results are
pretty poor, for example, this is GDB before my patch:

  (gdb) show param-none
  This command is not documented. off

I think we can all agree that this is pretty bad.

After my patch, we how show this:

  (gdb) show param-none
  The current value of 'param-none' is "off".

Which at least is a real sentence, even if it's not very informative.

This patch does change the way that the Python API behaves slightly,
but only in the cases when the user has missed providing GDB with some
information.  In most cases I think the new behaviour is a lot better,
there's the one case (noted above) which is a bit iffy, but I think is
still OK.

I've updated the existing gdb.python/py-parameter.exp test to cover
the modified behaviour.

Finally, I've updated the documentation to (I hope) make it clearer
how the various bits of help text come together.

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[7fe895c633...](https://github.com/mrakgr/The-Spiral-Language/commit/7fe895c633c651ddf4a794c1fc1e8f6a31fe916a)
#### Friday 2022-01-07 18:29:32 by Marko Grdinić

"10:45am. Dohna Dohna is great. In truth, even as I was praising LoboCorp, I was getting tired of it, and an erogame like Dohna is a breath of fresh air for me. I never expected it would get a translation so quickly. When I searched for it in the archives, at most I expected to see news that translation has started by some group.

10:55am. Now it is time to start. I poor sleep, but that does not matter. My will feels high.

I've created a path. Now how do I make use of them in geometry nodes?

11am. Let me take a look at a tutorial on how I could use a curve to make a road. I forgot how the old instancing stuff worked. With the stuff I have here, I think I could do it by simply taking the convex hull...

No wait no, that is the wrong answer. That would take the convex hull of everything, that can't be the answer. Something like a convex hull of neighboring points is what I would want. But even that is too hacky. There needs to be a better solution.

https://www.youtube.com/watch?v=RmLtV6E2TsI
How to Model a Road or Highway ALONG A PATH in Blender!

11am. I won't lie, unlikethe physics stuff, I really love the geomtry node stuff. Blender is an old program and has a lot of legacy stuff, but the stuff that arrived in 3.0 is wonderful. It isn't a hack, and definitely deserves to be a part of the fundamentals.

11:05am. At any rate, instead of rambling let me just watch it and then I'll get back into it. I really have everything I need at this point to be a good artist. I just need a few more months of practice to let it all sink in. Once that happens I will have a really powerful tool at my disposal, definitely worth the 6 months of practice I will have put in.

https://youtu.be/RmLtV6E2TsI?t=64

I did the road segment and as I am thinking about geometry nodes I had a burst of insight. Rather than instance on points, maybe it would be better to use instances on points. If that fails, there might be something about instances on curves.

Ah, wait that node is instances **to** points, not **on** points. And there isn't anything to put instances on curves.

11:20am. I am out of ideas, but I am sure this should be possible since I saw Ram doing a road. If I do not know how to do it in Blender it might be worth taking a look at Houdini tutorials.

https://youtu.be/RmLtV6E2TsI?t=159

I completely forgot about the curve modifier. But it does give me a hint as to what I should be looking at.

https://youtu.be/RmLtV6E2TsI?t=230

I remember. Curve + array. That is how it was.

https://www.youtube.com/results?search_query=blender+geometry+nodes+road

I honestly have no idea how to do it via gemotry nodes. But that is what I need to figure out.

CG Essentials has a lot of stuff that might be of interest to me later.

https://youtu.be/Wp_Fhbbfkxw
Make procedural pathway in Blender using Geometry nodes

This is using the old version, but it might give me some hint how to do it with the new one.

https://youtu.be/Wp_Fhbbfkxw?t=28

This CG stuff is so good. It a pinnacle of art in certain sense. Nothing else will give you so much expressive power for so little effort.

https://youtu.be/Wp_Fhbbfkxw?t=61

He is using the Alpha 3.0. Maybe it won't be too bad.

https://youtu.be/Wp_Fhbbfkxw?t=179

I do not think this node is in, but there is a specialized proximity node. I am guessing that is what I would need in order to immitate this here.

https://youtu.be/Wp_Fhbbfkxw?t=275

Ah, I see. It is adding the proximity to the vertex poxition. What is the result supposed to be doing?

I definitely need to study this, but this is not quite what I want. I want to connect road segments, rather than mark out a plane along a path.

https://blenderartists.org/t/geometry-nodes-for-non-destritive-roads-race-tracks/1274420

There should be stuff here, let me read this.

11:45am. There is nothing there, but wait...

I am thinking about this wrong. Curves can have a profile. That is what I should be thinking about.

https://docs.blender.org/manual/en/latest/modeling/geometry_nodes/curve/curve_to_mesh.html

Ah, wait, the profile is another curve, not a mesh. Whops.

12:05pm. I've managed to do it. Great. But I want to see what kind of topology this gives me, and I am getting trouble. I can't apply the geomtry nodes, it is telling me to transform the curve into a mesh.

Ahhh, maybe it wants me to transform the original curve into a mesh.

Let me take a break here.

1:25pm. Finally time for breakfast. The chores took a while.

2:20pm. Enough wasting time, let me resume. Internally I am always fighting between working and slacking off. So I always spend 2h when I could do with less.

Right now, I've figured out how to use the curve profile to make a road.

Now I need the fence. This is a bit different. I think it could work as intence on curve points. What I do not know is how to autoscale it.

Let me watch the path video now that I've come this far.

https://youtu.be/Wp_Fhbbfkxw?t=360

I want to finish this thing.

Right now, I am watching this and it seems they have moved on from doing everything with attributes.

https://youtu.be/Wp_Fhbbfkxw?t=508

Damn, this gave me a jolt.

https://youtu.be/Wp_Fhbbfkxw?t=608

Wow, did they use attributes for literally everything in alpha?

https://youtu.be/Wp_Fhbbfkxw?t=634

This is a bit interesting. I was wondering how to make use of input attributes? It seems in the modifier itself.

https://youtu.be/Wp_Fhbbfkxw?t=727

Interesting. How did he open this window?

Hmmm, if I had to do this, I'd consider the weight proximity modifier instead. Alternatively, I could do a similar thing to here, but pass it into the group output.

https://youtu.be/Wp_Fhbbfkxw?t=806

This is interesting. He using using the weight proximity in the shader. No doubt that will be for the sake of shading the path itself light brown and the rest green.

https://youtu.be/Wp_Fhbbfkxw?t=852

Yep, exactly as I thought. Brilliant.

Rather than this being programming, this is similar to my what I did in Logo back in middle school.

https://youtu.be/Wp_Fhbbfkxw?t=894

Since he is talking a grass, let me monologue a bit first. Yesterday I was playing with hair particle system for the carpet, but its tips ended up being very sharp. The way it looked is like a spiked floor. Nasty. This is how Blender works. The new geometry node system pretty much obliviates the legacy particle system as it can do everything the old one can except in a more generic, streamlined fashion.

Though, I suppose the hair system does have the haircut tools the old one does not.

https://youtu.be/Wp_Fhbbfkxw?t=1038

Oh, I can't forget the density.

Now that it has come to this I am not sure if there was even the point to use the proximity to move the path in the z direction. Instead, he could have used the vertex group itself for that. It would have streamlined things.

https://youtu.be/eGi_NGSW3Zs
Marvelous Designer Beginner Course - Part 1 - The Basics

Let me watch this just for a bit so I can get a sense of what this program is. Maybe I'll get it in the future.

...Ok, just the preview is enough enough. Nevermind this for now.

The fence is next. I need to figure out how to do the fence.

And before that, what I was trying to do is figure out how to turn a curve into a mesh.

Ohh, it is possible to tilt the curve at points.

No nevermind this. Even if I could turn a curve into a mesh directly, that would break the geomtry node.

3:05pm. For some reason the fence segment is not getting distributed correctly, but it does work with Suzzane and primitive cube. Let me just use the later I'll figure out what the problem is later.

Right now I am plugging in the rotation into instances on points and I see that it does distribute them along the curve inthe right rotation. This would be just what I need.

In some ways it is enough, but what if I wanted the cubes to be deformed along the curve. What would I do then? What if I wanted to tile another curve in a pattern?

I also want to connect the instances so that no empty space is between them.

3:10pm. Ok, what if I used the normal or the tangent as a displacement map for the instance.

3:15pm. I need more ideas.

https://youtu.be/hkvJ_k2DreY
Utility Poles with the new fields Geometry Nodes Blender Tutorial

https://code.blender.org/2021/09/procedural-curves-in-3-0-and-beyond/

I am surprised, there is a points to volume node. Apparently it is possible to do clouds with this!

https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/curve/fillet_curve.html
> The Fillet Curve rounds corners on curve control points, similar to the effect of the Bevel Modifier on a 2D mesh. However, a key difference is that the rounded portions created by the Fillet Curve node are always portions of a circle.

So that is what this does.

3:25pm. I am thinking, I am thinking. To deform the instances along the curve I do need proximity data to make the displacement map. Another question is how do I size the instances.

Ahh, curves to points has the length option. No need to do anything fancy then.

That answers how I should od the fence. But still how do I connect the fence segments. Suppose they had connectors running through them. How would I get such an effect?

Ok, let me study how to do utility poles, that should give me some inspiration.

https://youtu.be/hkvJ_k2DreY?t=208

This is a bit of a convoluted way of getting the rotation.

https://youtu.be/hkvJ_k2DreY?t=373

I see. So the rotation is done based on the origin point.

Set position, does that set the origin point?

https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/geometry/set_position.html
https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/input/position.html

No not really.

https://youtu.be/hkvJ_k2DreY?t=467

I can never grasp how the position node here works. I am guessing that just adding the height to the offset would have worked and would have been less convoluted.

https://youtu.be/hkvJ_k2DreY?t=521

This is complicated.

https://youtu.be/hkvJ_k2DreY?t=675

Yeah, the position sure is hard to understand.

https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/geometry/geometry_proximity.html

Damn I hate this dynamic behavior when it comes to getting the position. I find it very hard to understand.

4pm. https://youtu.be/xJasRMZvSJo?t=4

Let me watch this 2m vid.

4:05pm. I am thinking.

Suppose I had a bunch of points, or let's say torii. Can I connect a curve through the middle of them.

The way he did the utility poles was so awkward. It is good thing these people are artists because they would not do well as programmers. Not like that. Programming is a lot simpler. Rather than just going for the end result, there is a need to make the intermediate steps understandable.

4:20pm. I though maybe that I could use the position of the torus as custom XYZ. I tried connecting them to custom properties, but I see that moving the object does not change the properties. That won't work.

What I want to do is something similar to telephone poles, but do them in a custom manner. I'd parent the connectors to the pole, and somehow make it so their positions are as properties. Then connecting a curve through the instances would be just like going over all the poles.

But I can visualize how to do that with the tools at my disposal. There aren't any loops.

I'd need to start with a curve, the distribute the instances. But then I'd need to use that hacky brittle way to connect the curves somehow. The Youtuber guy only managed to draw a line because he used the original curve as the baseline. I'd like for a more elaborate way.

https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/attribute/capture_attribute.html?highlight=capture%20attribute

Let me think about the example here. It seems that today is a day to play with Blender.

I am really not going to get far with geometry nodes until I grasp how its scoping rules work.

Why does the capture node have geometry as an output?

I already have a theory that the way scoping works is that the language has some notion of hierarchy and when you try to take the position, it just looks up.

https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/index.html

You know, I think I should just go through the docs.

I am confused and it is no wonder. I've never seen a language such as this. My experience as a programmer is not helping me here.

4:35pm. https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/inspection.html

Come to think of it, I never figure out how to inspect these things.

Hmmm, curve line has start and end and the input nodes.

https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/attributes_reference.html

> Created by the Distribute Points on Faces to provide stability when the shape of the input mesh changes, and used on instances to create motion blur. Values are expected to be large, with no order. This attribute is used by nodes that generate randomness, like the Random Value Node. Unlike other built-in attributes, this attribute is not required, and can be removed.

You can create motion blur using id? How?

4:50pm. https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/fields.html

The example here is a bit interesting.

I am going to scrap my plans yet again. Wanting to go forward means nothing when I can't do a connected fence properly.

Hmmm, I should really consider that I want to do might involve writing a script. Ultimately I do not need anything in particular, I just want to push my limits of understanidng in order to master the material.

https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/curve/endpoint_selection.html

Ah, I get how this works. It is like take both from start and end.

5:10pm. Hmmm, curve to points can get in the way of endpoint selection. I remember Ram having trouble with this and had to resort to some kind of hack.

Still, it is strange that this does work. Sure Curve To Points might get rid of the curve, but the points should still be ordered.

5:15pm. Capturing an attribute and passing it through does not work. I guess that is a negative proof that the points are ordered. The results I get are complete nonsense.

It seems if I want to do selection, I'd be better off resampling the curve instead of turning it to points.

https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/fields.html#field-context

Ohhh here it is! Ram really should have mentioned this in his course. The context is very important. In fact, I was imagining it the wrong way around. I see my mistake now.

5:20pm. Focus me, let me not get lost in thought. Though I am building my mental model of how the contrxt works.

5:25pm. https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/instances.html

Let me pause here. Time for lunch.

5:40pm. I am back. Let me resume.

https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/attribute/transfer_attribute.html

I understand the way the context and capture attribute works now. I also understand the limitations of geometry nodes better.

I need to study what this here is now. After that, I am going to have to play with the proximity node. Now that I understand the contextbetter, I am not sure that I understand proximity after all.

///

Source Position
The position to start from when finding the closest location on the target mesh or point cloud. Used in the Nearest Face Interpolated and Nearest modes. By default, this is the same as if the Position Node was connected.

Index
Which index to use when retrieving the data from the input field in Index mode. By default, the Input Nodes is connected, meaning that the data from the source attribute is copied directly to the output. However, a different index can be connected, resulting in a “shuffling” of the values. Indices that are either too large or below 0 are clamped.

///

By now I am familiar with the first, but the second one caught my attention.

https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/input/input_index.html

Hmmm, could I use this to make pairs?

6pm. No I can't figure it out. Despite all their elaborate functionality, geometry nodes are a map operation. I can do anything interesting folds and unfolds as I would in a fully fledged language.

I guess to go beyond their capabilityies I'd have to write a script. Nevermind that.

Let me continue reading the docs. I'd want to try making the path example.

https://docs.blender.org/manual/en/dev/modeling/geometry_nodes/attribute/transfer_attribute.html

Ok, this is for proximity I think. I'll leave it aside for until after I've tested the actual proximity node.

Let me try doing the path.

6:15pm. No I can't get it to work. I do not know why. I am trying to put a dent into the plane based on the proximity to a curve, but it is not coming out right for me.

The one time I saw them in action was from the alpha version, and well from that utility pole tutorial, but that was convoluted.

https://youtu.be/0D4U4bM1KJM
[Tut] Geometry Proximity Node Explained - Blender Geometry Nodes 3.0 Field

Let me watch this. This guy seems to have some good stuff.

https://youtu.be/0D4U4bM1KJM?t=27

This is rougly the same input I started with, on the left side at least.

https://youtu.be/0D4U4bM1KJM?t=285

Hmmm, maybe I have this all wrong. There is no reason why multiple context could not work.

6:40pm. I got it to work with a just a bit of prompting. I needed to turn the curves into points to get it to work. Not what I expected.

....I am thinking about the program I made here, and I admit - I do not understand why this works. Just how does the proximity node know to compare with the other object?

Ah whatever, let me keep watching.

https://youtu.be/0D4U4bM1KJM?t=632

Did set position work like this 2 months ago. How weird. Back then it was still in Alpha.

7pm. https://www.youtube.com/results?search_query=blender+script

It is almost getting time to call it a day. I've decided to say no to physics simulations as it would be too slow, but why not check this out?

I'll that for tomorrow. Today I feel like I've significantly improved my understanding of geometry nodes. I feel that understanding how contexts work in Blender is the greatest first step I could make.

I need...

1) https://www.youtube.com/watch?v=Rkzp4vp-8rA - [Tut] Curve Deformation - Blender Geometry Nodes 3.0 Alpha Field
2) Transfer attribute.
3) Scripting

That first video caught my attention on the sidebar.

https://www.youtube.com/channel/UCP4I_8T3Ge3yHOnHz0Cnm8Q
Bradley Animation

Given what I am trying to learn, this guy is heaven sent for me. I've been imagining how I could do interesting effects using geometry nodes, and obviously this guy did his research. I should learn from him.

I really want to watch the curve deformation video, but I should just stop here for the day and take a bath instead rather than pushing myself. And that is how things will go. My rule is to stop past 6pm.

Let me try something out. Instead of an object, could I drag a collection into the geometry nodes field?

Oh, yes it is possible! That means I could easily scatter the fractures along curves without bothering with physics simulations. Though it is not like rigid body sims are particularly troublesome. The troublesome part would be doing the smoke and the explosion in tandem with it.

7:15pm. Forget it. It would look cartoony and I won't do actual animation. If I need animation to success then I guess I'll just have to fail.

What I need geometry nodes is to elevate my art to a new level. With regular painting you can only put strokes on paper, but with procedural generation you can do things a regular artist could only dream about. I absolutely should not ignore this aspect of art. It is an advantage unique to digital.

7:20pm. Hrmmm, ok. Let me close here instead of just dwelling on it.

I am definitely going to finish with the tutorials before long. I'll try to keep my learning to as I go along."

---
## [decentralized-identity/sidetree](https://github.com/decentralized-identity/sidetree)@[c19a1ec7ec...](https://github.com/decentralized-identity/sidetree/commit/c19a1ec7eca4a5d9ff24989b1f37a6ac6eff40f7)
#### Friday 2022-01-07 18:33:00 by Henry Tsai

fix(ref-imp): fixed an integer precision bug in how transaction number is constructed

This was discovered in https://github.com/decentralized-identity/ion/issues/240

As a result, rewrote how transaction number is constructed to produce a smaller integer. Also took the opportunity to make the transaction number much more human-friendly also, the current transaction number format had been annoying me for a long time.

Specifically, the current transaction number is simply a large ugly looking number that doesn't make any sense to a human. It would be much easier to make sense of (thus debug), now that a transaction on index position 500 in block 777777 is 777777000500, as opposed to 3340526778581492. Notice the number is smaller AND easier to make sense of.

Also, due to this internal transaction number scheme change, both core and blockchain service will be required to be upgraded to the same build at the same time, a bit painful, but isn't worth more engineering time IMO to mitigate this inconvenience.

---
## [benlk/misc-licenses](https://github.com/benlk/misc-licenses)@[027a23e5d6...](https://github.com/benlk/misc-licenses/commit/027a23e5d61268e03c14c1a374bfb762682c398a)
#### Friday 2022-01-07 18:38:00 by Eloy Degen

Add the Why The Fuck Would You Even Do That Holy Shit Public License

---
## [TeamNorden/SWAT](https://github.com/TeamNorden/SWAT)@[fbdf4b15cf...](https://github.com/TeamNorden/SWAT/commit/fbdf4b15cf1adfdb56c31dd59f4384f7c166fd2f)
#### Friday 2022-01-07 18:38:14 by Codeize

Added voting requirement for some commands.

- Only Top.gg is available because fuck the other sites' respective APIs.
- Working on a microservice under the TeamNorden namespace to not make handling votes a pain in the ass.

---
## [tgstation/TerraGov-Marine-Corps](https://github.com/tgstation/TerraGov-Marine-Corps)@[4529479889...](https://github.com/tgstation/TerraGov-Marine-Corps/commit/4529479889ccc617b1aee8519755e6ab5aa49b08)
#### Friday 2022-01-07 18:55:54 by hyper2snyper

Lasgun fixes (#9183)

* FUCK YOU SO MUCH EGUNS

* Update guns_codex.dm

---
## [Pippex/learn_python](https://github.com/Pippex/learn_python)@[25c7c015b0...](https://github.com/Pippex/learn_python/commit/25c7c015b05f3b434f03f8f00aa1f81c84f8cc59)
#### Friday 2022-01-07 20:18:20 by Pippex

I created this code, this create 4 docs, all_numbers, with the numbers from 0 to 100 to 101, FUCK_NON_PLANETS, that only says FUCK YOU PLUTON, because in this github we hate non planets, also creates a doc named hello_mars.txt, this says Hello Mars, too and other shit, and finally a document called hello_world.txt, this says Hello World

---
## [Skyrat-SS13/Skyrat-tg](https://github.com/Skyrat-SS13/Skyrat-tg)@[9df563cb76...](https://github.com/Skyrat-SS13/Skyrat-tg/commit/9df563cb768733fcecc97599d8815498bfd60346)
#### Friday 2022-01-07 20:21:39 by SkyratBot

[MIRROR] Dullahan Partial Refactor: They Work Again Edition [MDB IGNORE] (#10491)

* Dullahan Partial Refactor: They Work Again Edition (#63696)

So, a few months ago I was like "hmm there's something weird going on with party pods...", which got me looking into important_recursive_hearers or something like that. I spoke about it in the coding channel and Kyler actually fixed it before I did. But I also caught a similar glitch with Dullahans, so I decided to investigate...

Two months later...

I present to you a partial unfuckening of the Dullahans, in that I made them fully functional once again:

They only hear speech through their head (not sounds, sadly, someone else would have to tell me how to do that because I otherwise really wouldn't know how to do it in a sane way), they speak through their head, runechat-included.
When you spawn a Dullahan, you're set to look through the Dullahan's eyes (so from their head), and that doesn't reset when you log off and back in, or admin-ghost and come back in your body.
When you're looking through your head, your view will no longer be reset to your body upon entering a locker, which is nice to avoid not being blind while looking through your body.
Dullahan heads no longer look completely lifeless and without organs. They have eyes that don't look dead and that even match the player's intended eye color.
Dullahan can now properly examine things from their head, which was intended and 100% not functional.
Dullahan heads now speak with the proper name of their owner, instead of having a random name attached to it at round-start.
Dullahan heads are also now properly named too.
Dullahans can now properly whisper, sing and do all these funny things that they were unable to do before.
Dullahan whispers will now properly respect the range of the whisper.
Dullahans can now succumb in hardcrit by whispering, as intended. This potentially fixes other species that worked similarly not being able to succumb, like abductors, although I didn't test if they normally could, I just know they absolutely will be able to now.
When switching from Dullahans to a different species, your old head will no longer stay behind.
I also added a proc for species to do some code when we get a ckey login in our mob, which could potentially be useful for other stuff in the future, but it was necessary here as the view is reliant on the client, which we want to ensure doesn't get weird view glitches like having their head's vision overlay while actually being centered on their body.

I also made it so say() now takes a range argument, which is 7 by default, just so things that aren't humans can also whisper and do all those kinds of things. Going with that, there's probably a few more things that will be able to be done better thanks to this, although I haven't tested every edge case with this, but I doubt it will make much of a difference in the future.

* Dullahan Partial Refactor: They Work Again Edition

Co-authored-by: GoldenAlpharex <58045821+GoldenAlpharex@users.noreply.github.com>

---
## [Shurjo-M/pong-summative-ICS4U0](https://github.com/Shurjo-M/pong-summative-ICS4U0)@[096e26b55e...](https://github.com/Shurjo-M/pong-summative-ICS4U0/commit/096e26b55e813b4b3f500d89a133614eda2ad0c1)
#### Friday 2022-01-07 20:39:38 by plurb

i hate my life
So basically i am trying to make keyboard input work

Signed-off-by: plurb <36715300+plurb@users.noreply.github.com>

---
## [Dr-Pope/fulpstation](https://github.com/Dr-Pope/fulpstation)@[b59f03e592...](https://github.com/Dr-Pope/fulpstation/commit/b59f03e592ce72f069760eba0f9eb30eeacd16c1)
#### Friday 2022-01-07 20:40:27 by John Willard

Deputy update (#428)

* deputy berets cant be knocked off, deputies get tablets, service deputy beret buff.

* fuck you

---
## [Perkedel/Kaded-fnf-mods](https://github.com/Perkedel/Kaded-fnf-mods)@[b64980e63e...](https://github.com/Perkedel/Kaded-fnf-mods/commit/b64980e63ebd4539eecd9b9c0458d5412a9f57d9)
#### Friday 2022-01-07 21:01:31 by Joel Robert Justiawan

[skip ci] Well loading

dude, don't procrastinate! it's been 1 months! chart now! remember!!!

TODO:
- add custom countdown sound & images defined by _meta.json or Song Chart JSON???
- PUT THE BOTPLAY ON THE TOP!!! The Lyrics subtitle will be put down there! Yes, Psyched Botplay text position & size.

oops! wrong placement of loading image!

use LoadingState even on Preload supported platform!!! luckydog7 yess

NEW Threading simple interface! run thread now simple, check platform, with MUTEX wow!!!

unfortunately folks, that Hex Weekend loading screen uses that direct bitmapping access. yeah FlxDrawQuadItems seems has bug, which why Kade said camera related crash. that's the file you need to work it out. spoiler alert, just put the bitmap in a variable rather than direct, it works again. wtf?!?!?!?
disabled Hex weekend loading for now. encapsulate this feature under EXPERIMENTAL_HEX_WEEKEND Haxe definition

we should just put switch state internationally, CoreState & CoreSubstate yess.

freeplay threaded loading can be unstable here. maybe we should have option to enable/disable threaded loading!

OH SNEAKY sneaky SNEAKy sneakY, VideoPlayer.hx for Android, people. look, we got to change definition to adapt new Kade's way of definition over interface tricks yess!

sorry, we are unable to conquer almost all platform here HaxeFlixel can render and runs too. idk man. something wrong!

---
## [rhatdan/podman](https://github.com/rhatdan/podman)@[5acf8ae120...](https://github.com/rhatdan/podman/commit/5acf8ae120518cd69437bee778c5fa4ba03eff9b)
#### Friday 2022-01-07 21:32:18 by Ed Santiago

Eighty-six eighty-eighty

(Sorry, couldn't resist).

CI flakes have been coming down - thank you to everyone who has
been making them a priority.

This leaves a noisy subset that I've just been ignoring for months:

    Running: podman ... -p 8080:something
    ...cannot listen on the TCP port: listen tcp4 :8080: bind: address already in use

Sometimes these are one-time errors resolved on 2nd try; sometimes
they fail three times, forcing CI user to hit Rerun. In all cases
they make noise in my flake logs, which costs me time.

My assumption is that this has to do with ginkgo running random
tests in parallel. Since many e2e tests simplemindedly use 8080,
collisions are inevitable.

Solution: simplemindedly replace 8080 with other (also arbitrarily
picked) numbers. This is imperfect -- it requires human developers
to pick a number NNNN and 'grep NNNN test/e2e/*' before adding
new tests, which I am 100% confident ain't gonna happen -- but
it's better than what we have now.

Side note: I considered writing and using a RandomAvailablePort()
helper, but that would still be racy. Plus, it would be a pain
to interpolate strings into so many places. Finally, with this
hand-tooled approach, if/when we _do_ get conflicts on port NNNN,
it should be very easy to grep for NNNN, find the offending tests
that reuse that port, and fix one of them.

Signed-off-by: Ed Santiago <santiago@redhat.com>

---
## [ccho-mongodb/docs-worker-pool](https://github.com/ccho-mongodb/docs-worker-pool)@[5ca902efab...](https://github.com/ccho-mongodb/docs-worker-pool/commit/5ca902efabb02edb8406a78a8ded0a6054dd83df)
#### Friday 2022-01-07 21:50:13 by Allison Reinheimer Moore

Updates the URL whence we download pip2 (#387)

Per this lovely debugging message:
```
Hi there!

The URL you are using to fetch this script has changed, and this one will no
longer work. Please use get-pip.py from the following URL instead:

    https://bootstrap.pypa.io/pip/2.7/get-pip.py

Sorry if this change causes any inconvenience for you!

We don't have a good mechanism to make more gradual changes here, and this
renaming is a part of an effort to make it easier to us to update these
scripts, when there's a pip release. It's also essential for improving how we
handle the `get-pip.py` scripts, when pip drops support for a Python minor
version.

There are no more renames/URL changes planned, and we don't expect that a need
would arise to do this again in the near future.

Thanks for understanding!

- Pradyun, on behalf of the volunteers who maintain pip.
```

---
## [MrJamesGaming/FtcRobotController](https://github.com/MrJamesGaming/FtcRobotController)@[270d502236...](https://github.com/MrJamesGaming/FtcRobotController/commit/270d502236a0be40dff254661e1fc45582abde6d)
#### Friday 2022-01-07 22:56:18 by MrJamesGaming

A duck walked up to a lemonade stand And he said to the man, running the stand "Hey! (Bum bum bum) Got any grapes?" The man said "No we just sell lemonade. But it's cold And it's fresh And it's all home-made. Can I get you Glass?" The duck said, "I'll pass". Then he waddled away. (Waddle waddle) 'Til the very next day. (Bum bum bum bum ba-bada-dum) When the duck walked up to the lemonade stand And he said to the man running the stand, "Hey! (Bum bum bum) Got any grapes? The man said, "No, like I said yesterday We just sell lemonade OK? Why not give it a try?" The duck said, "Goodbye."good day Then he waddled away. (Waddle waddle) Then he waddled away. (Waddle waddle) Then he waddled away (Waddle waddle) 'Til the very next day. (Bum bum bum bum ba-ba-dum) When the duck walked up to the lemonade stand And he said to the man running the stand, "Hey! (bum bum bum) Got any grapes? The man said, Look, this is getting old. I mean, lemonade's all we've ever sold. Why not give it a go?" The duck said, "How 'bout, no." Then he waddled away (Waddle waddle) Then he waddled away. (Waddle waddle waddle) Then he waddled away (Waddle waddle) 'Til the very next day. (Bum bum bum bum ba-ba-dum) When the duck walked up to the lemonade stand And he said to the man running the stand, "Hey! (Bum bum bum) Got any grapes?" The man said, "THAT'S IT! If you don't stay away, duck, I'll glue you to a tree and leave you there all day, stuck So don't get to close!" The duck said, "Adios." Then he waddled away. (Waddle waddle) Then he waddled away. (Waddle waddle waddle) Then he waddled away (Waddle waddle) 'Til the very next day. (Bum bum bum bum ba-ba-dum) When the duck walked up to the lemonade stand And he said to the man that was running the stand, "Hey! (Bum bum bum) got any glue?" "What" "Got any glue?" "No, why would I– oh!" And one more question for you; "Got any grapes?" (Bum bum bum, bum bum bum) And the man just stopped. Then he started to smile. He started to laugh. He laughed for a while. He said, "Come on duck, let's walk to the store. I'll buy you some grapes So you won't have to ask anymore." So they walked to the store And the man bought some grapes. He gave one to the duck and the duck said, "Hmmm..No thanks. But you know what sounds good? It would make my day. Do you think this store Do you think this store Do you think this store has any lemonade?" Then he waddled away. (Waddle waddle) Then he waddled away. (Waddle waddle waddle) Then he waddled away (Waddle waddle)

---
## [naikari/naikari](https://github.com/naikari/naikari)@[9fcd3eea29...](https://github.com/naikari/naikari/commit/9fcd3eea29e34e17fad2273eba02fa74cc17bbf9)
#### Friday 2022-01-07 23:50:27 by diligentcircle

Replace delayed claim hackiness for Shadow Vigil.

This causes all text to be handled in-mission, and to avoid annoyance
from a hail that gets you nothing, it adds special text when Shadow
Vigil is unable to make the needed claims giving a 10,000 credit
consolation payment (with the excuse that the pilot mistook you for
someone else). I chose to do this because the whole delayed claim thing
leaves open the possibility of the player being given a mission,
accepting it, and having it just not show up, which is a bad user
experience I think.

---

# [<](2022-01-06.md) 2022-01-07 [>](2022-01-08.md)

