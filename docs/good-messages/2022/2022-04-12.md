# [<](2022-04-11.md) 2022-04-12 [>](2022-04-13.md)

1,713,780 events recorded by [gharchive.org](https://www.gharchive.org/) of which 1,713,780 were push events containing 2,727,391 commit messages that amount to 209,505,286 characters filtered with [words.py@e23d022007...](https://github.com/defgsus/good-github/blob/e23d022007992279f9bcb3a9fd40126629d787e2/src/words.py) to these 25 messages:


## [CS3733-D22-Team-V/TeamVeganVampires](https://github.com/CS3733-D22-Team-V/TeamVeganVampires)@[44e6e7ec81...](https://github.com/CS3733-D22-Team-V/TeamVeganVampires/commit/44e6e7ec812380caaa32de44caa6f61e12941235)
#### Tuesday 2022-04-12 00:07:14 by mchrpt

FIXED THE FUCKING STUPID ERROR HOLY SHIT AHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH

---
## [Innocentallity/Scripts](https://github.com/Innocentallity/Scripts)@[e84d9dfd98...](https://github.com/Innocentallity/Scripts/commit/e84d9dfd98dc3153008649a0321189ec014a232e)
#### Tuesday 2022-04-12 00:28:35 by Innocentallity

Create BAN MENU? NO WAY HOLY SHIT WHAT THE FUCK!?!? NO WAY BRO NOOO WAYAYY HOLDDYDY YWASJKNSJHFDNKSHBJCDNKASN NO WAY!?!?

---
## [thgvr/tgstation](https://github.com/thgvr/tgstation)@[351afe260b...](https://github.com/thgvr/tgstation/commit/351afe260b42764641a07385df5f7e24b840f631)
#### Tuesday 2022-04-12 01:13:24 by san7890

Fixes Mapping Icons For Bodylimbs (Don't Get A Shock!) (#65899)

* Fixes Mapping Icons For Bodylimbs (Don't Get A Shock!)

Hey there,

I implore you look at this photograph right here:

Ugly stupid base broken dumb /obj instead of the actual sprite fucking garbage idiotic purple-white square damn it i hate it so much fuck fuck fuck fuck let's fix it before the fire under my seat gets worse argh

Anyways, I checked with Kapu and did a bit of testing, and I managed to figure out a way to get the best of both the mapping world and the in-game world. Don't believe me? Check these out:

* addressses review

things still work

* kills female moth chests

---
## [uwstout-cs458-s22/advisor001](https://github.com/uwstout-cs458-s22/advisor001)@[bf6d5b5863...](https://github.com/uwstout-cs458-s22/advisor001/commit/bf6d5b586382c9138462004021ce71b34a564c9f)
#### Tuesday 2022-04-12 02:12:54 by Phosgenite

Current Attempt for api connection

pain.

Ruin has come to our family. You remember our venerable house, opulent and imperial, gazing proudly from its stoic perch above the moor? I lived all my years in that ancient, rumor shadowed manor, fattened by decadence and luxury - and yet I began to tire of conventional extravagance. Singular, unsettling tales suggested the mansion itself was a gateway to some fabulous and unnameable power. With relic and ritual I bent every effort towards the excavation and recovery of those long buried secrets, exhausting what remained of our family fortune on swarthy workmen and sturdy shovels.

At last in the salt soaked crags beneath the lowest foundations we unearthed that damnable portal of antediluvian evil. Our every step unsettled the ancient earth but we were in a realm of death and madness. In the end I alone fled laughing and wailing through those blackened arcades of antiquity until consciousness failed me.

You remember our venerable house, opulent and imperial. It is a festering abomination! I beg you. Return home; claim your birthright, and deliver our family from the ravenous, clutching shadows of the API functionality connection.

---
## [derockit/project-gutenberg](https://github.com/derockit/project-gutenberg)@[04b7901413...](https://github.com/derockit/project-gutenberg/commit/04b7901413ff3d4a4b4ef4687ed0909a8a9619a3)
#### Tuesday 2022-04-12 03:02:01 by Sajjad shirazy

[57050] Stavrogin's Confession and The Plan of The Life of a Great Sinner: With Introductory and Explanatory Notes

---
## [Lamella-0587/Skyrat-tg](https://github.com/Lamella-0587/Skyrat-tg)@[07e6768659...](https://github.com/Lamella-0587/Skyrat-tg/commit/07e67686593faeac75c1743a1f9c45a256f0e331)
#### Tuesday 2022-04-12 03:19:18 by SkyratBot

[MIRROR] Refactor and improve antimagic to be more robust [MDB IGNORE] (#12619)

* Refactor and improve antimagic to be more robust (#64124)

This refactors the antimagic component to use and have bitflags, documentation, defines, code comments, named arguments, and renames variable names for clarity.

- /obj/effect/proc_holder/spell/aoe_turf/conjure/creature/cult is not used anywhere and has been removed
- /obj/effect/proc_holder/spell/targeted/turf_teleport/blink/cult is not used anywhere and has been removed

- New sound effects are played when magic is blocked. Depending on the type of magic being used it will be either:

- Equipping antimagic now properly updates the magic buttons
- Any magic being blocked or restricting casting now displays a message
- MAGIC_RESISTANCE_MIND now properly blocks telepathy effects
- Removes blood splatter when fireball is blocked
- Magic projectiles for staff of locker no longer spawn lockers when blocked by antimagic
- Fire breath is no longer blocked by antimagic
- Spellcards are now blocked by antimagic

Any antimagic on a mob blocks that magic type from being casted. (certain spells such as mime abilities completely ignore antimagic)

- Foilhats prevent someone from casting mind magic (telepathy, mindswap, etc.)
- Bibles, ritual Totems, nullrods, holymelons, and TRAIT_HOLY prevent someone from casting unholy magic (cult spells, etc.)
- Nullrods, ritual totem, and holymelons prevent someone from casting wizard magic (fireball, magic missile, etc.)
- Immorality talismans, berserker suits, and TRAIT_ANTIMAGIC prevents all types of magic (except stuff like mime abilities)
- Touch of Madness and Mindswap is now blocked with MAGIC_RESISTANCE and MAGIC_RESISTANCE_MIND
- Voice of god is now blocked with MAGIC_RESISTANCE_HOLY and MAGIC_RESISTANCE_MIND

* Refactor and improve antimagic to be more robust

* Update tiedshoes.dm

Co-authored-by: Tim <timothymtorres@gmail.com>
Co-authored-by: Gandalf <9026500+Gandalf2k15@users.noreply.github.com>

---
## [OpenImageIO/oiio](https://github.com/OpenImageIO/oiio)@[4e985f6347...](https://github.com/OpenImageIO/oiio/commit/4e985f63474e21298974a3f96536597a7306e199)
#### Tuesday 2022-04-12 05:12:01 by Larry Gritz

Lay groundwork for unity builds (#3381)

As I learned recently, a "unity" (aka "jumbo") build is where multiple
.cpp files are combined into one translation unit -- imagine a unity.cpp
that simply has

    #include "file1.cpp"
    #include "file2.cpp"
    ...
    #include "fileN.cpp"

and so you compile unity.cpp instead of the separate file?.cpp files
individually.

Turns out that CMake understands this concept and can do it for you
automatically!

The benefit of a unity build is that file1...fileN probably include
most of the same headers, expand the same templates, etc., so a bunch
of the per-file work of the compiler can be done once rather than
redundantly for each file.

There are two potential downsides, however:

1. It may not be safe to concatenate your cpp files! For example, if
   both file1.cpp and file2.cpp each contain a `static int foo;`, that
   may have been safe when compiled separately, but is not allowed to
   happen twice in one compilation unit. Similarly, if you have headers
   that don't have proper guards against multiple includes, etc. So one
   should expect a whole lot of little fix-ups are needed for this to
   work properly. (We'll come back to that topic.)

2. Combining source file into these "jumbo" modules can make heavily
   parallelized builds on many-core machine not be able to load balance
   or keep all the cores busy. (Simplified examples: if you have 16 .cpp
   files on a 16 core machine, each core can compile one cpp file in
   parallel with the others. But if you mash the modules into just one
   huge cpp file, give that to one core, and your other 15 cores are
   idle, so the full build probably takes much longer.)

I tried this out, including the many fixups implied by (1) above, and
at first the unity builds were slower on both my laptop (8 cores) and
workstation at work (32 cores), because of downside (2) explained
earlier -- harder to take advantage of parallel builds when there are
fewer, bigger, compilation units. Some tweaking of strategy got me to
the point where I could always get the unity builds to go faster, but
not by a whole lot when many core were available. Slighty faster, but
not worth the trouble. A bit disappointing, nearly abandoned the whole
idea.

HOWEVER, in situation where you are limited to very few cores (like in our
CI, which allocates 2 cores, and it sure seems more like 1-1.5 for the
Windows and Mac CI runners), the unity builds are substantially faster --
there's already not much parallelism to exploit, so you come out ahead
with the savings of that redundant per-file work we talked about.

So my current thinking is to go ahead and make the changes that allow
unity builds. I don't particularly recommend them when highly parallel
builds are available to you, but it might help to cut our CI
turnaround time down on the GitHub runners. And maybe it will help in
other situations for other people.

Ok, then. The present patch introduces these concepts and makes the
CMake and other build system changes to allow unity builds. (N.B. It
won't WORK yet, so don't try it!) After we get that out of the way, in
subsequent PRs I'll show all the changs to the code that were
necessary to fix all the little things that went wrong when source
files got combined.

---
## [tsolawoyin/my-portfolio](https://github.com/tsolawoyin/my-portfolio)@[0dfe3d571e...](https://github.com/tsolawoyin/my-portfolio/commit/0dfe3d571ef0aaf09d178e46b200c5084867b404)
#### Tuesday 2022-04-12 08:42:43 by Temidayo Olawoyin

modified index.html and added index.js

fuck you emmanuel

---
## [odoo-dev/odoo](https://github.com/odoo-dev/odoo)@[cbc9279eaa...](https://github.com/odoo-dev/odoo/commit/cbc9279eaa169e65aeb2dab6dd36e3ffab4e481e)
#### Tuesday 2022-04-12 09:52:03 by Odoo's Mergebot

[MERGE] im_livechat: introduce chatbot scripts

PURPOSE

This commit introduces a chatbot operator that works based on a user-defined
script with various steps.

SPECS

A im_livechat.chatbot.script can be defined on a livechat rule.
When a end-user reaches a website page that matches the rule, the chat window
opens and the script of the bot starts iterating through its steps.

The chatbot code is currently directly integrated with the existing livechat
Javascript code.
It defines extra conditions and layout elements to be able to automate the
conversation and register user answers.

AVAILABLE STEPS

A script is defined with several steps that can currently be one of the
following types:

"text"

A simple text step where the bot posts a message without expecting an answer
e.g: "Hello! I'm a friendly robot!"

"question_selection"

The bot will ask a question and suggest answers, the end-user will have to
click on the answer he chooses
e.g: "How can I help you?
  -> Create a Ticket
  -> Create a Lead
  -> Speak with a human"

"question_email"

That step will ask the end user's email address (and validate it)
The result is saved on the linked im_livechat.im_livechatchatbot.mail.message

"question_phone"

Same logic as the 'question_email' for a phone number
We don't validate the input this time as it's a complicated process
(requires country, ...)

"forward_operator"

Special type of step that will add a human operator to the conversation when
reached, which stops the script and allow the visitor to discuss with a
real person.

The operator will be chosen among the available operators on the
livechat.channel.

If there is no operator available, the script continues normally which allows
to automate an "answering machine" that will redirect the user in case no
operator is available.

e.g: "I'm sorry, no operator is available right now, please contact us by email
at 'info@company.com', we will try to respond as soon as possible!".
(Or even something more complex with multiple questions / paths).

"free_input_single"

Will ask the visitor for a single line of text.
This text is not saved anywhere else than in the conversation, but it's still
useful when combined with steps that create leads / tickets since those print
the whole conversation into the description.

"free_input_multi"

Same as "free_input_single" but lets the user input multiple lines of text.
The frontend implementation is made by waiting a few seconds (currently 10) for
either the next submitted message or the next character typed into the input.

This lets visitors explain their issue / question with multiple messages.
Which is very useful since new messages are sent every time you press "Enter".

"create_lead"

Special step_type that allows creating a crm.lead when reaching it.
Usually used in addition to 'question_email' and 'question_phone' to create
interesting leads.

LINKS

Task-2030386

closes odoo/odoo#84000

Related: odoo/enterprise#24894
Signed-off-by: Thibault Delavallee (tde) <tde@openerp.com>
Co-authored-by: Patrick Hoste <pko@odoo.com>
Co-authored-by: Aurélien Warnon <awa@odoo.com>

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[f7d82bf638...](https://github.com/mrakgr/The-Spiral-Language/commit/f7d82bf638b58f80ae440f475b7d22ae443e88ef)
#### Tuesday 2022-04-12 11:21:16 by Marko Grdinić

"10:30am. I am investigating that Blender bug from yesterday.

No way I can resolve it, but I think I found another bug.

10:35am. Yeah, I did. Let me get the latest Alpha.

10:50am. I am running into weird issues with undo.

10:55am. I guess this is what I'll be messing with.

11:15am. Opened another bug report.

11:20am. It is not for the bug I had yesterday, but a minor different one.

Enough of that for now.

What I want to do now is learn more about the bevel workflow. Subdiv can be made to work, but I feel that it should be possible to get more control with bevels. I do not know how though. Right now they are just so awkward.

So far, I've only seen Josh cleaning up already finished topology instead of working from scratch. Let me go through his beginner's course.

https://youtu.be/1qVbGr_ie30?t=611

I do not know how he did this even scaling. Alt + S does not have that effect for me. It just moves according to the normals...

No wait, it actually does scale evenly. I just missed this repeatedly.

11:30am. Shrink flatten also has a different effect depending on whether you are in face or vertex mode.

12:40pm. Ok, the Bevel weight mod does work, but gives weird results when the weights are too far apart at intersections. The weird pinching issues just go away when you give them breathing room. This is not good enough for me though.

https://youtu.be/N6mfFv_7jYo
COMPLETE Hard Ops Tutorial for Blender

What I really want is as a better option for beveling. Something that I do not have to worry about leading to weird pinching and intersection.

Let me watch this to see if gives me any inspiration. I do not have this plugin, but I should be able to get it.

12:45pm. Instead of just talking about it, how about I get it?

https://cgpersia.com/2022/01/blendermarket-bundle-boxcutter-v7-19-6-4-hardops-hops-0-9-87-26-182294.html

Here it is.

///

Non-Destructive Bevel Stacking
We have systems built to behave in the background ensuring everything behaves exactly as you set when you set it. Modify behavior mid-tool. Set behaviors pre-use. We offer multiple options to help you get the behavior you want. And built to work hand in hand with each other and 3rd party tools.

///

Oh, this is exactly what I'd want. Right now I can't actually do this. The bevel weights are only a single set, so I'd only be able to use it on one modifier. If I use vertex groups, I can't give adjacent edges different weights. Blender is just not good enough to give me the kind of workflow that I'd want.

https://youtu.be/N6mfFv_7jYo?t=487

So far, this is not scary at all.

I read that Hops is difficult to use, but this feels smooth enough to me.

https://youtu.be/N6mfFv_7jYo?t=605
> I made a video titled Fixing Blender Biggest Issue With Bevel.

1:10pm. I am looking for that video and I can't find it.

https://cgpersia.com/2022/04/blendermarket-meshmachine-0-11-0-and-hardops-987-30-1-183524.html

Here is mesh machine.

> Info:
> MESHmachine is a blender mesh modeling addon with a focus on hard surface work without subdivision surfaces.
> Fuse and Unfuse Surfaces, create Variable Fillets and Washouts, edit and fix Bevel geometry, Unbevel and Unchamfer, create and clean up Boolean Intersections and create perimeter loops, keep earlier mesh states around as Stashes and use them for Normal Transfers, flatten and straighten normals, symmetrize and mirror custom normals, and detail surfaces flawlessly using Plugs – incl. your own custom made ones.

Maybe this is something more along the lines of what I am looking for.

https://youtu.be/M1GL4KKIGHI
Tapered Bevels with Mesh Machine

This is actually not possible with the tools I currently have. Let me watch the vid.

1:15pm. https://youtu.be/N6mfFv_7jYo?t=679

Let me pause here, I need to take a break. Hmmm...

I guess I'll dedicate today to checking out some of these plugins. Otherwise I'll be stuck using the subdiv workflow for everything. I am really not happy with how things went. If I have a chance to upgrade I should do so."

---
## [DarkKnight2019/terminal](https://github.com/DarkKnight2019/terminal)@[446f280757...](https://github.com/DarkKnight2019/terminal/commit/446f2807573ffda411f548a519835d15cacdcd9b)
#### Tuesday 2022-04-12 11:57:31 by Mike Griese

Try to silently fall back to a local monarch (#12825)

This is a crazy idea Dustin and I had.

> we can't repro this at will. But we kinda have an idea of where the deref is. We don't know if the small patch (throw, and try again) will fix it. We're sure that the "just fall back to an isolated monarch" will work. I'd almost rather take a build testing the small patch first, to see if that works

> This might seem crazy
> in 1.12, isolated monarch. In 1.13, "small patch". In 1.14, we can wait and see

I can write more details in the morning. It's 5pm here so if we want this today, here it is.

@dhowett double check my velocity flag logic here. Should be always true for Release, and off for Dev, Preview. 

* [x] closes #12774

---
## [rohittembhurne2194/ICTSBMNAGPURCMS](https://github.com/rohittembhurne2194/ICTSBMNAGPURCMS)@[158a6011cb...](https://github.com/rohittembhurne2194/ICTSBMNAGPURCMS/commit/158a6011cb8fa6c03024e5dbdec37fb219041f38)
#### Tuesday 2022-04-12 12:47:31 by umeshl@appynitty.com

Chnages Done By Me Its Fututre millionaire persone and I will Be definitely rich and finaicially free in my 30s. i going to dubai for vacation with my family and freinds.. ameen god bless me god with me angel supported me and thanks for everything

---
## [XenStuff/kernel_xiaomi_lavender](https://github.com/XenStuff/kernel_xiaomi_lavender)@[c2a6374017...](https://github.com/XenStuff/kernel_xiaomi_lavender/commit/c2a6374017b709fa76be9e06e21f7a4184e4af90)
#### Tuesday 2022-04-12 13:32:30 by Maciej Żenczykowski

FROMGIT: bpf: Do not change gso_size during bpf_skb_change_proto()

This is technically a backwards incompatible change in behaviour, but I'm
going to argue that it is very unlikely to break things, and likely to fix
*far* more then it breaks.

In no particular order, various reasons follow:

(a) I've long had a bug assigned to myself to debug a super rare kernel crash
on Android Pixel phones which can (per stacktrace) be traced back to BPF clat
IPv6 to IPv4 protocol conversion causing some sort of ugly failure much later
on during transmit deep in the GSO engine, AFAICT precisely because of this
change to gso_size, though I've never been able to manually reproduce it. I
believe it may be related to the particular network offload support of attached
USB ethernet dongle being used for tethering off of an IPv6-only cellular
connection. The reason might be we end up with more segments than max permitted,
or with a GSO packet with only one segment... (either way we break some
assumption and hit a BUG_ON)

(b) There is no check that the gso_size is > 20 when reducing it by 20, so we
might end up with a negative (or underflowing) gso_size or a gso_size of 0.
This can't possibly be good. Indeed this is probably somehow exploitable (or
at least can result in a kernel crash) by delivering crafted packets and perhaps
triggering an infinite loop or a divide by zero... As a reminder: gso_size (MSS)
is related to MTU, but not directly derived from it: gso_size/MSS may be
significantly smaller then one would get by deriving from local MTU. And on
some NICs (which do loose MTU checking on receive, it may even potentially be
larger, for example my work pc with 1500 MTU can receive 1520 byte frames [and
sometimes does due to bugs in a vendor plat46 implementation]). Indeed even just
going from 21 to 1 is potentially problematic because it increases the number
of segments by a factor of 21 (think DoS, or some other crash due to too many
segments).

(c) It's always safe to not increase the gso_size, because it doesn't result in
the max packet size increasing.  So the skb_increase_gso_size() call was always
unnecessary for correctness (and outright undesirable, see later). As such the
only part which is potentially dangerous (ie. could cause backwards compatibility
issues) is the removal of the skb_decrease_gso_size() call.

(d) If the packets are ultimately destined to the local device, then there is
absolutely no benefit to playing around with gso_size. It only matters if the
packets will egress the device. ie. we're either forwarding, or transmitting
from the device.

(e) This logic only triggers for packets which are GSO. It does not trigger for
skbs which are not GSO. It will not convert a non-GSO MTU sized packet into a
GSO packet (and you don't even know what the MTU is, so you can't even fix it).
As such your transmit path must *already* be able to handle an MTU 20 bytes
larger then your receive path (for IPv4 to IPv6 translation) - and indeed 28
bytes larger due to IPv4 fragments. Thus removing the skb_decrease_gso_size()
call doesn't actually increase the size of the packets your transmit side must
be able to handle. ie. to handle non-GSO max-MTU packets, the IPv4/IPv6 device/
route MTUs must already be set correctly. Since for example with an IPv4 egress
MTU of 1500, IPv4 to IPv6 translation will already build 1520 byte IPv6 frames,
so you need a 1520 byte device MTU. This means if your IPv6 device's egress
MTU is 1280, your IPv4 route must be 1260 (and actually 1252, because of the
need to handle fragments). This is to handle normal non-GSO packets. Thus the
reduction is simply not needed for GSO packets, because when they're correctly
built, they will already be the right size.

(f) TSO/GSO should be able to exactly undo GRO: the number of packets (TCP
segments) should not be modified, so that TCP's MSS counting works correctly
(this matters for congestion control). If protocol conversion changes the
gso_size, then the number of TCP segments may increase or decrease. Packet loss
after protocol conversion can result in partial loss of MSS segments that the
sender sent. How's the sending TCP stack going to react to receiving ACKs/SACKs
in the middle of the segments it sent?

(g) skb_{decrease,increase}_gso_size() are already no-ops for GSO_BY_FRAGS
case (besides triggering WARN_ON_ONCE). This means you already cannot guarantee
that gso_size (and thus resulting packet MTU) is changed. ie. you must assume
it won't be changed.

(h) changing gso_size is outright buggy for UDP GSO packets, where framing
matters (I believe that's also the case for SCTP, but it's already excluded
by [g]).  So the only remaining case is TCP, which also doesn't want it
(see [f]).

(i) see also the reasoning on the previous attempt at fixing this
(commit fa7b83bf3b156c767f3e4a25bbf3817b08f3ff8e) which shows that the current
behaviour causes TCP packet loss:

  In the forwarding path GRO -> BPF 6 to 4 -> GSO for TCP traffic, the
  coalesced packet payload can be > MSS, but < MSS + 20.

  bpf_skb_proto_6_to_4() will upgrade the MSS and it can be > the payload
  length. After then tcp_gso_segment checks for the payload length if it
  is <= MSS. The condition is causing the packet to be dropped.

  tcp_gso_segment():
    [...]
    mss = skb_shinfo(skb)->gso_size;
    if (unlikely(skb->len <= mss)) goto out;
    [...]

Thus changing the gso_size is simply a very bad idea. Increasing is unnecessary
and buggy, and decreasing can go negative.

Fixes: 6578171a7ff0 ("bpf: add bpf_skb_change_proto helper")
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Cc: Dongseok Yi <dseok.yi@samsung.com>
Cc: Willem de Bruijn <willemb@google.com>
Link: https://lore.kernel.org/bpf/CANP3RGfjLikQ6dg=YpBU0OeHvyv7JOki7CyOUS9modaXAi-9vQ@mail.gmail.com
Link: https://lore.kernel.org/bpf/20210617000953.2787453-2-zenczykowski@gmail.com

(cherry picked from commit 364745fbe981a4370f50274475da4675661104df https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next.git/commit/?id=364745fbe981a4370f50274475da4675661104df )
Test: builds, TreeHugger
Bug: 158835517
Bug: 188690383
Signed-off-by: Maciej Żenczykowski <maze@google.com>
Change-Id: I0ef3174cbd3caaa42d5779334a9c0bfdc9ab81f5
Signed-off-by: ImPrashantt <prashant33968@gmail.com>

---
## [ACRei/blog](https://github.com/ACRei/blog)@[c605026013...](https://github.com/ACRei/blog/commit/c605026013d9504f46211f64d2fc99c2647e2319)
#### Tuesday 2022-04-12 14:56:04 by ACRei

Add apple touch icon for fucking Safari. So , apple fuck you!

---
## [pytorch/pytorch](https://github.com/pytorch/pytorch)@[1b7d7d9327...](https://github.com/pytorch/pytorch/commit/1b7d7d93276eb37c009905ef87ea9c2a7c95481e)
#### Tuesday 2022-04-12 15:12:46 by Brian Hirsh

Reland: "free up dispatch key space (in C++)" (#74963)

Summary:
Pull Request resolved: https://github.com/pytorch/pytorch/pull/74963

This is a re-land of D35192346 (https://github.com/pytorch/pytorch/commit/9872a06d77582e91e834103db75f774ca75f7fff) and D35192317 (https://github.com/pytorch/pytorch/commit/a9216cde6cc57f94586ea71a75a35aaabee720ff), which together are a diff that changes the internal representation of `DispatchKeySet` in pytorch core to free up the number of dispatch keys that we have available. See a more detailed description of the design in the original PR: https://github.com/pytorch/pytorch/pull/69633.

The original PR broke Milan workflows, which use a pytorch mobile build, and manifested as a memory corruption bug inside of `liboacrmerged.so`.

**Background: Existing Mobile Optimization**
Pytorch mobile builds have an existing optimization (here https://github.com/pytorch/pytorch/blob/cc23725e89713138aa1c81ce5fb4a8dbcd440ccf/c10/core/DispatchKey.h#L382 and here https://github.com/pytorch/pytorch/blob/cc23725e89713138aa1c81ce5fb4a8dbcd440ccf/aten/src/ATen/core/dispatch/OperatorEntry.h#L214), which works as follows:

Every operator in pytorch has a "dispatch table" of function pointers, corresponding to all of the (up to 64) different kernels that we might dispatch to when we run an operator in pytorch (autograd, cpu, cuda, complex number support, etc).

In mobile builds, the size of that table is shrunk from 64 to 8 to save a bunch of space, because mobile doesn't end up using the functionality associated with most dispatch keys.

The dispatcher also has a notion of "fallback kernels", which are kernels that you can register to a particular dispatch key, but should be able to work for "any operator". The array of fallback kernels is defined here: https://github.com/pytorch/pytorch/blob/cc23725e89713138aa1c81ce5fb4a8dbcd440ccf/aten/src/ATen/core/dispatch/Dispatcher.h#L294.

The mobile-optimization currently does **not** extend to this array (it wouldn't be that useful anyway because there is only one array of fallback kernels globally - vs. there is a separate dispatch table of function pointers per operator). So the per-operator tables on mobile are size 8, while the fallback table is size 64.

**The Bug**
This PR actually makes it difficult to enable that optimization separately for the per-operator arrays vs. the fallback array, and incidentally shrunk the size of the fallback array from 64 to 8 for mobile (that happened on this line: https://github.com/pytorch/pytorch/pull/69633/files#diff-f735cd7aa68f15b624100cbc4bb3b5ea76ffc7c9d3bec3b0ccabaa09609e5319R294).

That isn't a problem by itself (since mobile doesn't actually use any of the fallbacks that can no longer be stored). However, pytorch core will still register all of those fallback kernels on startup in mobile builds, even if they aren't used. When we tried to register one of those fallbacks on startup, it would try to dump the kernel somewhere in memory past the bounds of the (now smaller) array inside of the `Dispatcher` object, `backendFallbackKernels_`.

**Why didn't this problem show up in OSS CI? Why didn't it break other internal mobile workflows aside from Milan?**

Ideally, this failure would show up as part of the OSS signal on GitHub, since we already have mobile OSS builds. Given that it was another memory corruption issue that only affected Milan (subset of mobile), I'm not sure what's specific about Milan's builds that caused it only to manifest there. dreiss I wonder if there's another flavor of mobile builds we could run in OSS CI that could potentially help catch this?

**The debugging experience was pretty difficult**

Debugging the Milan-specific failure was made difficult by the following:

(1) lack of CI
- the original Milan failure didn't surface on my original diff, because the Milan job(s) that failed weren't triggered to run on pytorch changes. There's probably a balance to strike here, since those jobs will only be useful if they aren't flaky, and if they can produce reliable failure logs for debugging.

(2) It's difficult to get a repro.
- my work laptop doesn't have the right specs to run the Milan development workflow (not enough disk space)
- There is an existing OnDemand workflow for Milan, but it appears to be relatively new, and after a bunch of help from MarcioPorto, we ran into issues forwarding the log output from Milan tests on the emulator back to the terminal (see the original discussion here: https://fb.workplace.com/groups/OnDemandFRL/permalink/1424937774645433/)

(3) Lack of stack-traces.
- Most Milan failures didn't include actionable stack traces. phding generously helped me debug by running my suggested patches locally, and reporting back if there were any failures. The failing test didn't include a stack trace though (just the line where the crash appeared), so I ended up making some educated guesses about what the issue was based on the area of the crash.
ghstack-source-id: 152688542

Test Plan: Confirmed with phding that the broken Milan workflow from the previous version of this diff is now passing.

Reviewed By: phding, albanD

Differential Revision: D35222806

fbshipit-source-id: 0ad115a0f768bc8ea5d4c203b2990254c7092d30
(cherry picked from commit 002b91966f11fd55ab3fa3801b636fa39a6dd12c)

---
## [ModruKinstealer/CS50ProblemSets](https://github.com/ModruKinstealer/CS50ProblemSets)@[83380aa019...](https://github.com/ModruKinstealer/CS50ProblemSets/commit/83380aa019955505aa37a90ebde54a868db3c3e9)
#### Tuesday 2022-04-12 15:40:11 by ModruKinstealer

lab 6: World Cup

distribution code provided the .csv files and some of the code within tournament.py.  Our task was to implement the two parts of main indicated with the TODO and the simulate_tournament(teams) function

Program takes a filename as an argument and then outputs the percentage chance each team within has of winning the World Cup.
.csv file contains the name of the team along with it's rating.

I did fairly ok on this lab. I wasn't familiar with the csv library but some of the lecture covered reading and writing from a .csv and I was able to use that and change it to suit my needs. 

I did have a couple issues with the program at first where I was improperly handling lists and the dictionaries within but I was able to resolve them fairly quickly with debug50 once I saw what was happening line by line it made the error make sense and I was able to adjust things to pull out the part I needed incrementally.
I did have to remind myself the proper syntax for adding to a dictionary as It's been a while and I had to remember which to use between [] () and {}

The last bit I ran into was that the check50 was claiming that my function for simulate_tournament wasn't handling brackets of 4, 8, 12, and 16 properly.  It turns out I had misread the comment in the function, I was supposed to only return the team's name, not the list item which was the dictionary of {"team" : England, "rating": 1024} or whatever. I had been managing that, but it was up in main where they wanted it down in simulate_tournament so it was just a manner of moving the two lines of code down and changing the variable names to those used within the function.
I didn't actually keep track of timing on this but I finished the whole thing in about 2 hours and probably spent 30-45 mins troubleshooting the various bits. Overall I'm fairly happy with the results.

---
## [stitchfix/hamilton](https://github.com/stitchfix/hamilton)@[87776a6c9e...](https://github.com/stitchfix/hamilton/commit/87776a6c9e92eddfdfc7da0896d83dcd0e6dff65)
#### Tuesday 2022-04-12 17:22:45 by skrawczyk

Adds parameterized_inputs decorator

This is a squashed commit of all the commits to create the parameterized_inputs
decorator. See the commits below that are in reverse chronological order.

Basically, this replaces `parameterized_input`, and provides a more succinct
API by using the function doc as a template, removing the need for a tuple.

We believe this is a simpler API to read/maintain — the kwargs assumption will
make it harder to extend the API, but we don’t think we need to.

——— Consolidated commits below ——

Adds format doc function to parameterized_inputs

To consolidate formatting in a single place. Want to keep
the code DRY. (+7 squashed commits)
Squashed commits:
[338c02a] Touches up documentation typos

And adds reraising original exception for formatting errors.
[f2725ec] Adds validate test for parameterized_inputs for the doc string

Doc string templates errors should be checked during validate.
That way we can throw a better error.
[4689177] Changes parameterized_inputs to use kwargs

1. So that we don't scope creep this API. Key words arguments are
assumed to be outputs. This removes a level of nesting on the API.
2. We're inline with other decorators in having the kwargs behavior, e.g. config.when.
[df571f3] Changes parameterized_inputs to take dict and format doc string

With the prior design, the issue was documentation. But after noodling on it
and prodding from Eljiah, I realized that the documentation string should just
be a template. Since you're going to be using the same function, the doc string
should be fairly generic, with only the parameters being passed changing the
meaning -- which with templatization, allows for that to come through.

Note - stylistically I think we prefer:

```python
@parametrized_inputs(
    parameterization={
        'output_123': dict(input_value_tbd1='input_1',
                           input_value_tbd2='input_2',
                           input_value_tbd3='input_3')
    }
)
```
because syntax highlighting will make it clearer what is being replaced in the
function with what input value.

to

```python
@parametrized_inputs(
    parameterization={
        'output_123': {
                 'input_value_tbd1'='input_1',
                 'input_value_tbd2='input_2',
                 'input_value_tbd3'='input_3'
        }
    }
)
```
or

```python
@parametrized_inputs(
    parameterization=dict(
        output_123={
                 'input_value_tbd1'='input_1',
                 'input_value_tbd2='input_2',
                 'input_value_tbd3'='input_3'
        }
    )
)
```
I think the last two ones are less clear/readable.

Otherwise I did have the thought of using actual functions in the mapping. It would
then be clearer to trace what is going on with an IDE.
However that brings up the possibility of people importing functions and running
into import messes... So punting on that for now. We can always add that in later
if we think that's required.
[0e21e9d] Changes parameterized_input to parameterized_inputs in decorator docs

Since parameterized_input is deprecated, we should just remove it from the
docs and instead just push parameterized_inputs.
[4379a38] Adds ParameterMapping named tuple object to adjust parameterized_inputs

People creating a dictionary of tuple to tuples is probably unwieldy. This is a power
use case, and thus it should afford a little more friction to use, and the net result of that
is that the code should become more readable.

We should preference keyword arguments everywhere here -- as that will make the code
much more readable than without it. E.g. :
```python
@parametrized_inputs(
    parameters=['input_value_tbd1', 'input_value_tbd2', 'input_value_tbd3'],
    parameter_mappings=[
        ParameterMapping(
            inputs=['input_1', 'input_2', 'input_3'],
            output_name='output_123',
            output_docs='function_with_multiple_inputs called using input_1'),
    ]
)
def func(...)

@parametrized_inputs(
    ['input_value_tbd1', 'input_value_tbd2', 'input_value_tbd3'],
    [ParameterMapping(['input_1', 'input_2', 'input_3'], 'output_123', 'function_with_multiple_inputs called using input_1')]
)
```

Adjusts tests and documentation accordingly.
[c1d5fa8] Adds parameterized_inputs

This change adds `paramterized_inputs` decorator, which
is almost a carbon copy of `paramterized_input` but that it allows
any number of parameters to be mapped.

Why is it a separate class? Well for backwards compatibility
we don't want to break parameterized_input. Should we try to
consolidate them? I think so -- so we should then mark `parameterized_input`
as deprecated and will be removed in a 2.0 release?

I should then probably update all documentation to reflect `parameterized_inputs`
and thus the documentation on `paramterized_input` to either be hidden or
non-existant? Hmm.

---
## [Opentrons/ot3-firmware](https://github.com/Opentrons/ot3-firmware)@[1593a10ee9...](https://github.com/Opentrons/ot3-firmware/commit/1593a10ee9822869ee083de0cbdc04f7787519c9)
#### Tuesday 2022-04-12 17:47:22 by Seth Foster

im so sorry

This commit contains two major pieces of work.

First, I was finally unable to resist the siren song of getting the i2c
stuff into its own subproject. I can only blame the crew, who did not
lash me to the mast tightly enough.

That comes with new github actions workflows, dependencies in the
pipette on the new subdirectory, and a whole bunch of renames in a whole
bunch of places.

Second, we finally found the problem that we were debugging: if you
memcpy std::functions, that obviously doesn't trigger their copy ctor,
so the memcpyd-from function gets destroyed when it leaves the scope
where it was memcpyd, and there goes its closure object. This is going
to be a consistent problem with anything with a non-trivial dtor that
goes through a message buffer.

The solution is to instead pass around queue handles that we can write
responses to. This is in itself kind of a pain since we can't use std
functions! We kind of have to bodge in manual c-style closures with
reinterpret cast, but we can at least protect the building of those
closures with some nice template concepts.

At this point, there also really didn't seem like a point keeping the
various different kinds of i2c messages so now there's just transact and
transactionresponse.

The i2c subdirectory compiles and passes the tests for i2c_task and
i2c_writer; it probably doesn't compile or pass the test for poller, but
a) it's kind of cool that the includes are clean enough that you can
just not run the poller tests and it's fine, and b) yeah no kidding. It
also For Sure will not be able to compile the pipettes until the sensor
and eeprom classes are adapted.

add memcpy test

add nicer comments

poll tests pass

more poller tests pass

all poller tests pass!

---
## [Perkedel/Kaded-fnf-mods](https://github.com/Perkedel/Kaded-fnf-mods)@[25d304921f...](https://github.com/Perkedel/Kaded-fnf-mods/commit/25d304921f18dbddbee17fc9362f2236edf893a5)
#### Tuesday 2022-04-12 19:15:08 by Joel Robert Justiawan

[skip ci] noff

if you want to protest, go ahead. but be sure and F88888 be sure, that you do, is nothing destructive, annoying, whatever that disrupt the normal working functionality. don't let politics, wars, or everything drama in between devours your pure will!

also No to war. People dies. Slava Ukraina yess.

speaking of devoured will, taking down mods because of drama is also not different than destroy commit, delete data if Russian, etc., anything. Just saying. I want all of those back. we left 1 more. C'mon, MFM people, you can do this!!! I will make mods for Full Ass if 3 of them come back.

well uh.. also make mods even if MFM not back. idk will MFM repost deletable by admin in Workshop. pls no. Other than reposting, there is nothing else that encourages destructive actions. idk.

AH PLS!!! WHY INCENTIVE HAS TO BE MOTIVATED UNDER ANY OF THESE CIRCUMTANCES?!?!??!?!

---
## [RandomGamer123/tgstation](https://github.com/RandomGamer123/tgstation)@[c8ef62c1fb...](https://github.com/RandomGamer123/tgstation/commit/c8ef62c1fb7027ea58b569f0e4bd7df5a7d58935)
#### Tuesday 2022-04-12 21:44:18 by LemonInTheDark

Fixes bartender drink throwing, makes smashing always spill (#65698)

Tohg's initial pr (9c0b0e5d4cc236e365ef0229400cefe98b184964) was rather poorly argued and a bit misleading, but the actual changes were honestly kinda harmless. You could already have thrown beakers to splash shit on someone, it wasn't a big issue.

However it did end up breaking bartending, because it removed the ranged
args that normally get passed into smash and SplashReagent.

I went in intending to fix that, but noticed some dumb copypasta in
broken bottle code, and decided to just start from there.

I've moved that logic to a proc on the broken bottle, and made smashing
a bottle on something splash its contents too.

I can't think of a case where you wouldn't want this, so I'ma just go
for it. Prevents future mistakes like this too.

Oh and because I'm passing ranged in properly now, splashing will not
always splash the whole amount of the bottle's reagents. Doubt that
really matters tho.

Love ya bestie

---
## [SagaraBattousai/falcie](https://github.com/SagaraBattousai/falcie)@[03bbebeb73...](https://github.com/SagaraBattousai/falcie/commit/03bbebeb73542dfed3e47aa9124b14bb378ddda6)
#### Tuesday 2022-04-12 22:08:22 by James Calo

Code cleaned up, Forget all that C/C++ stuff, I have been thinking about it all day and literally cannot stop thinking about it!!!!! I need to just chill out and stick with GO. Once I have a working system I can then be pedantic but at the moment I have no time and this is seriously not that important, I just hate not haveing full controll and hate garbage collection and no pointer aritmentic #NoXORLists :'(

---
## [mbs-octoml/mbs-tvm](https://github.com/mbs-octoml/mbs-tvm)@[c741db3a65...](https://github.com/mbs-octoml/mbs-tvm/commit/c741db3a65bdc6544002ed019db9d4111fdd2c03)
#### Tuesday 2022-04-12 22:51:01 by Mark Shields

** Collage v2 sketch ***

- Enable cudnn, get rid of support for op-predicate based BYOC integrations
- Enable cublas
- And yet another go at pruning unnecessary candidates.
- Another go at pruning unnecessary candidates
- Fix CompositePartitionRule use
- Fix a few bugs with new TensorRT pattern-based integration
- Rework RemoveSubCandidatesCombinerRule for soundness
- Better logging
- Bug fixes
- Implement critical nodes idea for avoiding obviously unnecessary candidates
- Promote DataflowGraph from alias to class so can cache downstream index set
- Quick check to avoid unioning candidates which would create a cycle
- Host out CandidatePartitionIndex and add rules to avoid small candidates subsumed by containing candidates
- GetFunction can legitimately return nullptr
- rename tuning log
- Support for int64 literals
- Switch GPT2 to plain model
- Fix library cloberring issue for cutlass
- actually checkin 'built in' tuning log (covers mnist & gpt2 only)
- trying to debug gpt2
- Update TargetKind attribute name
- working through gpt2 issues
- checkin tuning records for MNIST (with hack to not retry failed winograd)
- Autotvm tuning disabled if log file empty (default)
- Autotvm tuning during search working
- tune during search
  (but does not load tuned records after search!)
- About to add tuning to estimate_seconds
- Split out the combiner rules & make them FFI friendly
- Rework comments
- Estimate IRModule instead of Function (closer to meta_schedule iface)
- Add 'host' as first-class partitioning spec
  (Avoids special casing for the 'leave behind for the VM' case)
- Move CollagePartitioner to very start of VM compiler flow (not changing legacy)
- Fix bugs etc with new SubGraph::Rewrite approach
  Ready for updating RFC to focus on partitioning instead of fusion.
- Working again after partition<->fusion split.
- Add PrimitivePartitionRule
- Refactor SubGraph Extract/Rewrite
  *** CAUTION: Almost certainly broken ***
- Rename kernel->partition, fusion->partition
- Next: make nesting in "Primitive" an explicit transform
- respect existing target constraints from device planner
- make 'compiler' and 'fusion_rule' attributes avail on all target kinds
- moved design to tvm-rfcs, https://github.com/apache/tvm-rfcs/pull/62
- incorporate comments
- avoid repeated fusion
- fix trt type checking
- better logs
- pretty print primitive rules
- fix tensorrt
- multiple targets per spec
- don't extract candidate function until need cost
  Need to bring CombineByPrimitives back under control since lost depth limit.
- cleaned up fusion rule names
- added 'fuse anything touching' for BYOC
- Finish dd example
- Add notion of 'MustLower', even if a candidate fires may still need to consider
  leaving node behind for VM (especially for constants).
- starting example
- finished all the dd sections
- documentation checkpoint
- docs checkpoint
- more design
- starting on dd
- runs MNIST with TVM+CUTLASS+TRT
- cutlass function-at-a-time build
- need to account for build_cutlass_kernels_vm
- move cutlass tuning into relay.ext.cutlass path to avoid special case
- add utils
- don't fuse non-scalar constants for tvm target.
- stuck on cuda mem failure on conv2d, suspect bug in main
- where do the cutlass attrs come from?
- running, roughtly
- pretty printing, signs of life
- wire things up again
- Switch SubGraph and CandidateKernel to TVM objects
- naive CombineByKindFusionRule, just to see what we're up agaist
  Will switch to Object/ObjectRef for SubGraph and CandidateKernel to avoid excess copying.
- preparing to mimic FuseOps
- rework SubGraph to use IndexSet
- rough cut at MaximalFusion
- split SubGraph and IndexSet in preparation for caching input/output/entry/exit sets in SubGraph.
- top-down iterative handling of sub-sub-graphs
- about to give up on one-pass extraction with 'sub-sub-graphs'
- Add notion of 'labels' to sub-graphs
- Rework FusionRules to be more compositional
- partway through reworking fusion rules, broken
- SubGraph::IsValid, but still need to add no_taps check
- dataflow rework, preparing for SubGraph::IsValid
- explode into subdir
- mnist with one fusion rule (which fires twice) working
- switch to CandidateKernelIndex
- Confirm can measure 'pre-annotated' primitive functions
- checkpoint
- stuff
- more sketching
- dominator logging

---
## [CandleJaxx/tgstation](https://github.com/CandleJaxx/tgstation)@[ac21ef9078...](https://github.com/CandleJaxx/tgstation/commit/ac21ef9078d88f51a4e198e394ed56e3cc731b45)
#### Tuesday 2022-04-12 23:04:28 by Pickle-Coding

No, we don't want radiation getting released in large pipenets fuck you fuckr uyu! (#65212)

* Make it harder to release radiation in large pipenets. Squares the volume / 2,500 thingy, and adds the requirements to the proto-nitrate bz response and proto-nitrate tritium response gas reactions to release radiation. This will make it significantly harder to release radiation in large pipenets, because releasing radiation in large pipenets makes it harder for people to identify the cause on why they are getting irradiated, which is bad and goes against the modern radiation goals.

Squaring is not enough for deranged people that know we don't want radiation released in large pipenets. Cubes the requirement instead. If someone could get enough gases reacting at once after this, then there is a bigger problem with atmos.

Who had fun seeing everything green, then getting irradiated and not even knowing why? I don't know, because I don't know who put the gases in waste and why we must suffer.

---
## [A1Liu/tci](https://github.com/A1Liu/tci)@[3eeacd370c...](https://github.com/A1Liu/tci/commit/3eeacd370c65f038a13eca9a646c929d8367d572)
#### Tuesday 2022-04-12 23:08:47 by Albert Liu

Literally webpack and parcel are garbage

* fucking stupid

* welp

* fuck you

* fuck you

* FUCK

* FUCK YOU

* WHAT

---
## [iFreilicht/.dotfiles](https://github.com/iFreilicht/.dotfiles)@[b86f588026...](https://github.com/iFreilicht/.dotfiles/commit/b86f588026925f782b1c5f60a907ab15253aed7a)
#### Tuesday 2022-04-12 23:14:21 by Felix Uhl

Fix perl locale warnings

This is a hack, I know, but I really don't care at this point. These god
damned locale warnings pop up every now and then, but there's never a
good reason, zero functional impact, and debugging them is incredibly
annoying.

---

# [<](2022-04-11.md) 2022-04-12 [>](2022-04-13.md)

