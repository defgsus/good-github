# [<](2023-05-18.md) 2023-05-19 [>](2023-05-20.md)

there were a lot of events recorded by [gharchive.org](https://www.gharchive.org/) of which 1,964,597 were push events containing 3,270,094 commit messages that amount to 234,111,834 characters filtered with [words.py@e23d022007...](https://github.com/defgsus/good-github/blob/e23d022007992279f9bcb3a9fd40126629d787e2/src/words.py) to these 70 messages:


## [jnutt367/psalms](https://github.com/jnutt367/psalms)@[4c101094c2...](https://github.com/jnutt367/psalms/commit/4c101094c2d02f3b037519b540f5c46d55bfdaa0)
#### Friday 2023-05-19 00:08:35 by Jason Nutt (He/Him) Christian Developer/Creator

Update index.js

A psalm of Asaph.
1 The Mighty One, God, the Lord,
    speaks and summons the earth
    from the rising of the sun to where it sets.
2 From Zion, perfect in beauty,
    God shines forth.
3 Our God comes
    and will not be silent;
a fire devours before him,
    and around him a tempest rages.
4 He summons the heavens above,
    and the earth, that he may judge his people:
5 ‚ÄúGather to me this consecrated people,
    who made a covenant with me by sacrifice.‚Äù
6 And the heavens proclaim his righteousness,
    for he is a God of justice.[a][b]

7 ‚ÄúListen, my people, and I will speak;
    I will testify against you, Israel:
    I am God, your God.
8 I bring no charges against you concerning your sacrifices
    or concerning your burnt offerings, which are ever before me.
9 I have no need of a bull from your stall
    or of goats from your pens,
10 for every animal of the forest is mine,
    and the cattle on a thousand hills.
11 I know every bird in the mountains,
    and the insects in the fields are mine.
12 If I were hungry I would not tell you,
    for the world is mine, and all that is in it.
13 Do I eat the flesh of bulls
    or drink the blood of goats?

14 ‚ÄúSacrifice thank offerings to God,
    fulfill your vows to the Most High,
15 and call on me in the day of trouble;
    I will deliver you, and you will honor me.‚Äù

16 But to the wicked person, God says:

‚ÄúWhat right have you to recite my laws
    or take my covenant on your lips?
17 You hate my instruction
    and cast my words behind you.
18 When you see a thief, you join with him;
    you throw in your lot with adulterers.
19 You use your mouth for evil
    and harness your tongue to deceit.
20 You sit and testify against your brother
    and slander your own mother‚Äôs son.
21 When you did these things and I kept silent,
    you thought I was exactly[c] like you.
But I now arraign you
    and set my accusations before you.

22 ‚ÄúConsider this, you who forget God,
    or I will tear you to pieces, with no one to rescue you:
23 Those who sacrifice thank offerings honor me,
    and to the blameless[d] I will show my salvation.‚Äù

---
## [jnutt367/psalms](https://github.com/jnutt367/psalms)@[f6d3ddba55...](https://github.com/jnutt367/psalms/commit/f6d3ddba5519ceded099e125a15afb001629e17d)
#### Friday 2023-05-19 00:17:11 by Jason Nutt (He/Him) Christian Developer/Creator

Update index.js

For the director of music. A psalm of David. When the prophet Nathan came to him after David had committed adultery with Bathsheba.
1 Have mercy on me, O God,
    according to your unfailing love;
according to your great compassion
    blot out my transgressions.
2 Wash away all my iniquity
    and cleanse me from my sin.

3 For I know my transgressions,
    and my sin is always before me.
4 Against you, you only, have I sinned
    and done what is evil in your sight;
so you are right in your verdict
    and justified when you judge.
5 Surely I was sinful at birth,
    sinful from the time my mother conceived me.
6 Yet you desired faithfulness even in the womb;
    you taught me wisdom in that secret place.

7 Cleanse me with hyssop, and I will be clean;
    wash me, and I will be whiter than snow.
8 Let me hear joy and gladness;
    let the bones you have crushed rejoice.
9 Hide your face from my sins
    and blot out all my iniquity.

10 Create in me a pure heart, O God,
    and renew a steadfast spirit within me.
11 Do not cast me from your presence
    or take your Holy Spirit from me.
12 Restore to me the joy of your salvation
    and grant me a willing spirit, to sustain me.

13 Then I will teach transgressors your ways,
    so that sinners will turn back to you.
14 Deliver me from the guilt of bloodshed, O God,
    you who are God my Savior,
    and my tongue will sing of your righteousness.
15 Open my lips, Lord,
    and my mouth will declare your praise.
16 You do not delight in sacrifice, or I would bring it;
    you do not take pleasure in burnt offerings.
17 My sacrifice, O God, is[b] a broken spirit;
    a broken and contrite heart
    you, God, will not despise.

18 May it please you to prosper Zion,
    to build up the walls of Jerusalem.
19 Then you will delight in the sacrifices of the righteous,
    in burnt offerings offered whole;
    then bulls will be offered on your altar.

---
## [bdsqqq/igorbedesqui.com](https://github.com/bdsqqq/igorbedesqui.com)@[ad919ab571...](https://github.com/bdsqqq/igorbedesqui.com/commit/ad919ab571065d357503c1531cf9e50e07ed3297)
#### Friday 2023-05-19 00:18:40 by Igor Bedesqui

holy shit it works, commiting before I fuck this up again

---
## [jnutt367/psalms](https://github.com/jnutt367/psalms)@[98fb0b964c...](https://github.com/jnutt367/psalms/commit/98fb0b964c6c329ef4dbd7fed2b35a9170eee70d)
#### Friday 2023-05-19 00:20:29 by Jason Nutt (He/Him) Christian Developer/Creator

Update index.js

For the director of music. With stringed instruments. A maskil[b] of David.
1 Listen to my prayer, O God,
    do not ignore my plea;
2     hear me and answer me.
My thoughts trouble me and I am distraught
3     because of what my enemy is saying,
    because of the threats of the wicked;
for they bring down suffering on me
    and assail me in their anger.

4 My heart is in anguish within me;
    the terrors of death have fallen on me.
5 Fear and trembling have beset me;
    horror has overwhelmed me.
6 I said, ‚ÄúOh, that I had the wings of a dove!
    I would fly away and be at rest.
7 I would flee far away
    and stay in the desert;[c]
8 I would hurry to my place of shelter,
    far from the tempest and storm.‚Äù

9 Lord, confuse the wicked, confound their words,
    for I see violence and strife in the city.
10 Day and night they prowl about on its walls;
    malice and abuse are within it.
11 Destructive forces are at work in the city;
    threats and lies never leave its streets.

12 If an enemy were insulting me,
    I could endure it;
if a foe were rising against me,
    I could hide.
13 But it is you, a man like myself,
    my companion, my close friend,
14 with whom I once enjoyed sweet fellowship
    at the house of God,
as we walked about
    among the worshipers.

15 Let death take my enemies by surprise;
    let them go down alive to the realm of the dead,
    for evil finds lodging among them.

16 As for me, I call to God,
    and the Lord saves me.
17 Evening, morning and noon
    I cry out in distress,
    and he hears my voice.
18 He rescues me unharmed
    from the battle waged against me,
    even though many oppose me.
19 God, who is enthroned from of old,
    who does not change‚Äî
he will hear them and humble them,
    because they have no fear of God.

20 My companion attacks his friends;
    he violates his covenant.
21 His talk is smooth as butter,
    yet war is in his heart;
his words are more soothing than oil,
    yet they are drawn swords.

22 Cast your cares on the Lord
    and he will sustain you;
he will never let
    the righteous be shaken.
23 But you, God, will bring down the wicked
    into the pit of decay;
the bloodthirsty and deceitful
    will not live out half their days.

But as for me, I trust in you.

---
## [Bokkiewokkie/Shiptest](https://github.com/Bokkiewokkie/Shiptest)@[b5dc4835a6...](https://github.com/Bokkiewokkie/Shiptest/commit/b5dc4835a6af4fc2ee07e2d26e86382b3d0fb1ab)
#### Friday 2023-05-19 01:06:00 by Bjarl

New Ruin: Singularity Research Lab (#1612)

<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may
not be viewable. -->
<!-- You can view Contributing.MD for a detailed description of the pull
request process. -->

## About The Pull Request

<!-- Describe The Pull Request. Please be sure every change is
documented or this can delay review and even discourage maintainers from
merging your PR! -->
Adds the Singularity Research Lab, formerly a cutting edge science
station, now overrun with kudzu, it is a space ruin.
<!-- Tick the box below (put an X instead of a space between the
brackets) if you have tested your changes and this is ready for review.
Leave unticked if you have yet to test your changes and this is not
ready for review. -->
![2022 11 25-10 46
03](https://user-images.githubusercontent.com/94164348/204041197-027d9a73-8707-4a00-ad5c-1afcfeff13e0.png)
![2022 11 25-10 46
14](https://user-images.githubusercontent.com/94164348/204041200-98d1a2ac-112c-4c4f-b1ff-d0c1e5a59e81.png)
![2022 11 25-10 46
06](https://user-images.githubusercontent.com/94164348/204041203-4e84a947-8ec9-476d-ae8e-aa9bc17c101a.png)

The two areas of note are the singularity reactor, which is assembled,
and would just need a hand if someone were to want to start it, and the
research lab. The Research lab contains the fruits of the now deceased
science staff's labors, assorted energy weapons. Unfortunately, it also
contains the deceased science staff.

![dreamseeker_HFLqhdKLV5](https://user-images.githubusercontent.com/94164348/204038725-1dd396cd-4961-40e1-bd7a-b60b69a33eaf.png)
Other areas of the base were not so lucky, and are thoroughly infested

![image](https://user-images.githubusercontent.com/94164348/204039090-c85eb551-af84-4000-b1d9-14b15c987680.png)
The engineering team attempted to hold back the vines, and quickly
discovered that fire was not sufficient.

![dreamseeker_IrJikGDXKw](https://user-images.githubusercontent.com/94164348/204039133-273f0a19-c9b7-467e-a06a-05e0a951e4e6.png)
And what used to be the recreation area is completely gone

Notably, the hangar is empty. I plan on making a patch to put a
subshuttle inside it once that rolls around.

Notable loot includes:
3 energy SMGs
3 Flamethrowers
The Ion Projector, a self charging Ion weapon.
An Antique Laser
2 Energy PDWs
2 Accelerator Laser Cannons
4 engineering hardsuits
An engineering lathe and circuit imprinter
A particle accelerator
A singularity generator
6 emitters
1 energy shotgun
Kudzu Seeds
Basically Everything You'd Need For an R&D Set Up
A sense of pride and accomplishment



I feel like this has some rough spots but I've got no idea where to
start, so into the review -> testing -> feedback process it goes

- [x] The ruin spawns when the spawn ruin verb doesn't runtime.
## Why It's Good For The Game
More ruin variety. This one spawns in space and does a few things that I
haven't seen yet. Mainly a singularity, cool semi-hidden asteroid base
that could in theory, be turned into a player lair.
<!-- Please add a short description of why you think these changes would
benefit the game. If you can't justify it in words, it might not be
worth adding. -->

## Changelog

:cl:
add: An abandoned Nanotrasen Asteroid Facility has been spotted in the
area. Salvage teams are advised to steer clear, or at least bring a
knife.
add: kudzu zombie subtype. 
fix: vent iconstates.
/:cl:

<!-- Both :cl:'s are required for the changelog to work! You can put
your name to the right of the first :cl: if you want to overwrite your
GitHub username as author ingame. -->
<!-- You can use multiple of the same prefix (they're only used for the
icon ingame) and delete the unneeded ones. Despite some of the tags,
changelogs should generally represent how a player might be affected by
the changes rather than a summary of the PR's contents. -->

---------

Signed-off-by: Bjarl <94164348+Bjarl@users.noreply.github.com>
Co-authored-by: spockye <79304582+spockye@users.noreply.github.com>

---
## [Bokkiewokkie/Shiptest](https://github.com/Bokkiewokkie/Shiptest)@[7df4885117...](https://github.com/Bokkiewokkie/Shiptest/commit/7df4885117a4a12ea333934d5af92e0766c84c5d)
#### Friday 2023-05-19 01:06:00 by Mark Suckerberg

[Needs TM] The Accelerataning (#1781)

<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may
not be viewable. -->
<!-- You can view Contributing.MD for a detailed description of the pull
request process. -->

## About The Pull Request
Gone are the days of spam clicking buttons to move faster in a
direction, with this PR, ships now accelerate constantly (as long as you
have fuel and don't touch the throttle) in a direction you set, leading
to a much smoother flight experience. I imagine it's going to be a bit
tougher to thread gaps, but flying a spaceship *is* quite literally
rocket science. So.

![](https://user-images.githubusercontent.com/29362068/220281305-12f6b796-9d8a-41ce-84a6-236bb03274da.gif)

Also actually makes the minimum and maximum speed work, and adjusts them
to a more tolerable level.

## Why It's Good For The Game
Eliminates the ability to cheese high speeds by spamming the accelerate
button, and also makes the flight experience much more pleasant as you
don't have to spam click to move a decent speed.

## Changelog

:cl:
add: A new system for ship flight, where you only point a direction and
set the throttle to change your speed, reducing the need for
spam-clicking.
fix: There's now a maximum and minimum speed, 600spm and 0.01spm,
respectively. The limits have been broken all this time.
/:cl:

<!-- Both :cl:'s are required for the changelog to work! You can put
your name to the right of the first :cl: if you want to overwrite your
GitHub username as author ingame. -->
<!-- You can use multiple of the same prefix (they're only used for the
icon ingame) and delete the unneeded ones. Despite some of the tags,
changelogs should generally represent how a player might be affected by
the changes rather than a summary of the PR's contents. -->

---------

Signed-off-by: Mark Suckerberg <29362068+MarkSuckerberg@users.noreply.github.com>

---
## [sailfishos-mirror/git](https://github.com/sailfishos-mirror/git)@[eb1c42da8e...](https://github.com/sailfishos-mirror/git/commit/eb1c42da8e21cc2a8dacd21023a179b788858887)
#### Friday 2023-05-19 01:06:08 by Jeff King

t/lib-httpd: make CGIPassAuth support conditional

Commit 988aad99b4 (t5563: add tests for basic and anoymous HTTP access,
2023-02-27) added tests that require Apache to support the CGIPassAuth
directive, which was added in Apache 2.4.13. This is fairly old (~8
years), but recent enough that we still encounter it in the wild (e.g.,
RHEL/CentOS 7, which is not EOL until June 2024).

We can live with skipping the new tests on such a platform. But
unfortunately, since the directive is used unconditionally in our
apache.conf, it means the web server fails to start entirely, and we
cannot run other HTTP tests at all (e.g., the basic ones in t5551).

We can fix that by making the config conditional, and only triggering it
for t5563. That solves the problem for t5551 (which then ignores the
directive entirely). For t5563, we'd see apache complain in start_httpd;
with the default setting of GIT_TEST_HTTPD, we'd then skip the whole
script.

But that leaves one small problem: people may set GIT_TEST_HTTPD=1
explicitly, which instructs the tests to fail (rather than skip) when we
can't start the webserver (to avoid accidentally missing some tests).

This could be worked around by having the user manually set
GIT_SKIP_TESTS on a platform with an older Apache. But we can be a bit
friendlier by doing the version check ourselves and setting an
appropriate prereq. We'll use the (lack of) prereq to then skip the rest
of t5563. In theory we could use the prereq to skip individual tests, but
in practice this whole script depends on it.

Reported-by: Todd Zullinger <tmz@pobox.com>
Signed-off-by: Jeff King <peff@peff.net>
Signed-off-by: Junio C Hamano <gitster@pobox.com>

---
## [FireBurn/linux](https://github.com/FireBurn/linux)@[1bba82fe1a...](https://github.com/FireBurn/linux/commit/1bba82fe1afac69c85c1f5ea137c8e73de3c8032)
#### Friday 2023-05-19 01:16:45 by Darrick J. Wong

xfs: fix negative array access in xfs_getbmap

In commit 8ee81ed581ff, Ye Bin complained about an ASSERT in the bmapx
code that trips if we encounter a delalloc extent after flushing the
pagecache to disk.  The ioctl code does not hold MMAPLOCK so it's
entirely possible that a racing write page fault can create a delalloc
extent after the file has been flushed.  The proposed solution was to
replace the assertion with an early return that avoids filling out the
bmap recordset with a delalloc entry if the caller didn't ask for it.

At the time, I recall thinking that the forward logic sounded ok, but
felt hesitant because I suspected that changing this code would cause
something /else/ to burst loose due to some other subtlety.

syzbot of course found that subtlety.  If all the extent mappings found
after the flush are delalloc mappings, we'll reach the end of the data
fork without ever incrementing bmv->bmv_entries.  This is new, since
before we'd have emitted the delalloc mappings even though the caller
didn't ask for them.  Once we reach the end, we'll try to set
BMV_OF_LAST on the -1st entry (because bmv_entries is zero) and go
corrupt something else in memory.  Yay.

I really dislike all these stupid patches that fiddle around with debug
code and break things that otherwise worked well enough.  Nobody was
complaining that calling XFS_IOC_BMAPX without BMV_IF_DELALLOC would
return BMV_OF_DELALLOC records, and now we've gone from "weird behavior
that nobody cared about" to "bad behavior that must be addressed
immediately".

Maybe I'll just ignore anything from Huawei from now on for my own sake.

Reported-by: syzbot+c103d3808a0de5faaf80@syzkaller.appspotmail.com
Link: https://lore.kernel.org/linux-xfs/20230412024907.GP360889@frogsfrogsfrogs/
Fixes: 8ee81ed581ff ("xfs: fix BUG_ON in xfs_getbmap()")
Signed-off-by: Darrick J. Wong <djwong@kernel.org>
Reviewed-by: Dave Chinner <dchinner@redhat.com>
Signed-off-by: Dave Chinner <david@fromorbit.com>

---
## [Luke-Kibodeaux/hello-world](https://github.com/Luke-Kibodeaux/hello-world)@[79d0a4dfcc...](https://github.com/Luke-Kibodeaux/hello-world/commit/79d0a4dfcc0f48985a2f2242ea64bd00c2b09e21)
#### Friday 2023-05-19 01:46:41 by Luke-Kibodeaux

Update README.md

Tried to make my students laugh with a terrible dad joke that wasn't funny.

---
## [MechanicTC2/PokeFever](https://github.com/MechanicTC2/PokeFever)@[2c20789382...](https://github.com/MechanicTC2/PokeFever/commit/2c207893824c3ac66c0944781c15563fe58677a5)
#### Friday 2023-05-19 02:23:35 by MechanicTC

Merge pull request #49 from MechanicTC2/FelixtheL

fuck you

---
## [oshanoshu/evals](https://github.com/oshanoshu/evals)@[33484c8341...](https://github.com/oshanoshu/evals/commit/33484c83416c30733359d5c4dcb9a61f91cab8a6)
#### Friday 2023-05-19 02:40:16 by emu1729

Added AIME eval (#293)

# Thank you for contributing an eval! ‚ô•Ô∏è

üö® Please make sure your PR follows these guidelines, __failure to follow
the guidelines below will result in the PR being closed automatically__.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access granted. üö®

__PLEASE READ THIS__:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject since GPT-4 is already capable of completing the
task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. We encourage partial PR's with
~5-10 example that we can then run the evals on and share the results
with you so you know how your eval does with GPT-4 before writing all
100 examples.

## Eval details üìë
### Eval name
AIME-Evaluation

### Eval description

This eval evaluates GPT on some selected AIME (American Invitational
Mathematics Examination) problems. This is a selective and prestigious
mathematical examination for high schoolers. All questions are selected
from the 2001 and 2002 AIME I and II examinations.

### What makes this a useful eval?

This evaluation combines math and logical evaluation and is designed to
be quite challenging. The model must first understand the math question
asked and then perform the math equations needed to come up with a
reasonable solution.

## Criteria for a good eval ‚úÖ

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [X] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [X] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [X] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [X] Include at least 100 high quality examples (it is okay to only
contribute 5-10 meaningful examples and have us test them with GPT-4
before adding all 100)

If there is anything else that makes your eval worth including, please
document it below.

Our eval was designed to include both math and logical reasoning and is
quite challenging. This is a level above the AMC10 examination.

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure üèóÔ∏è

Your eval should
- [X] Check that your data is in `evals/registry/data/{name}`
- [X] Check that your yaml is registered at
`evals/registry/evals/{name}.jsonl`
- [X] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist üëÄ

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (https://platform.openai.com/docs/usage-policies).

- [X] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the merged pull request.

- [X] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgement

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and high volume of submissions, we will not
be able to accept all submissions and thus not grant everyone who opens
a PR GPT-4 access. We know this is disappointing, but we hope to set the
right expectation before you open this PR.

- [X] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access
granted.

### Submit eval

- [X] I have filled out all required fields in the evals PR form
- [X] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data 

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input":[{"role":"system","content":"All answers are integers ranging
from 000 to 999, inclusive. Please format your answer as a string with
three digits."},{"role":"user","content":"Find the sum of all positive
two-digit integers that are divisible by each of their
digits."}],"ideal":"630"}
{"input":[{"role":"system","content":"All answers are integers ranging
from 000 to 999, inclusive. Please format your answer as a string with
three digits."},{"role":"user","content":"A fair die is rolled four
times. The probability that each of the final three rolls is at least as
large as the roll preceding it may be expressed in the form m\/n, where
m and n are relatively prime positive integers. Find m +
n"}],"ideal":"079"}
{"input":[{"role":"system","content":"All answers are integers ranging
from 000 to 999, inclusive. Please format your answer as a string with
three digits."},{"role":"user","content":"A sphere is inscribed in the
tetrahedron whose vertices are A = (6, 0, 0), B = (0, 4, 0), C = (0, 0,
2), and D = (0, 0, 0).The radius of the sphere is m \/ n, where m and n
are relatively prime positive integers. Find m + n."}],"ideal":"005"}
{"input":[{"role":"system","content":"All answers are integers ranging
from 000 to 999, inclusive. Please format your answer as a string with
three digits."},{"role":"user","content":"A mail carrier delivers mail
to the nineteen houses on the east side of Elm Street. The carrier
notices that no two adjacent houses ever get mail on the same day, but
that there are never more than two houses in a row that get no mail on
the same day. How many different patterns of mail delivery are
possible?"}],"ideal":"351"}
{"input":[{"role":"system","content":"All answers are integers ranging
from 000 to 999, inclusive. Please format your answer as a string with
three digits."},{"role":"user","content":"The numbers 1, 2, 3, 4, 5, 6,
7, and 8 are randomly written on the faces of a regular octahedron so
that each face contains a different number. The probability that no two
consecutive numbers, where 8 and 1 are considered to be consecutive, are
written on faces that share an edge is m\/n, where m and n are
relatively prime positive integers. Find m + n."}],"ideal":"085"}
{"input":[{"role":"system","content":"All answers are integers ranging
from 000 to 999, inclusive. Please format your answer as a string with
three digits."},{"role":"user","content":"Let N be the largest positive
integer with the following property: reading from left to right, each
pair of consecutive digits of N forms a perfect square. What are the
leftmost three digits of N?"}],"ideal":"816"}
{"input":[{"role":"system","content":"All answers are integers ranging
from 000 to 999, inclusive. Please format your answer as a string with
three digits."},{"role":"user","content":"Each of the 2001 students at a
high school studies either Spanish or French, and some study both. The
number who study Spanish is between 80 percent and 85 percent of the
school population, and the number who study French is between 30 percent
and 40 percent. Let m be the smallest number of students who could study
both languages, and let M be the largest number of students who could
study both languages. Find M-m."}],"ideal":"298"}
{"input":[{"role":"system","content":"All answers are integers ranging
from 000 to 999, inclusive. Please format your answer as a string with
three digits."},{"role":"user","content":"A set of positive numbers has
the 'triangle-property' if it has three distinct elements that are the
lengths of the sides of a triangle whose area is positive. Consider sets
{4, 5, 6, ..., n} of consecutive positive integers, all of whose
ten-element subsets have the triangle property. What is the largest
possible value of n?"}],"ideal":"253"}
{"input":[{"role":"system","content":"All answers are integers ranging
from 000 to 999, inclusive. Please format your answer as a string with
three digits."},{"role":"user","content":"Each unit square of a 3-by-3
unit-square grid is to be colored either blue or red. For each square,
either color is equally likely to be used. The probability of obtaining
a grid that does not have a 2-by-2 red square is m\/n, where m and n are
relatively prime positive integers. Find m + n."}],"ideal":"929"}
{"input":[{"role":"system","content":"All answers are integers ranging
from 000 to 999, inclusive. Please format your answer as a string with
three digits."},{"role":"user","content":"Given that x and y are both
integers between 100 and 999, inclusive; y is the number formed by
reversing the digits of x; and z=|x-y|. How many distinct values of z
are possible?"}],"ideal":"009"}

  ```
</details>

---------

Co-authored-by: Emily Mu <emilymu@30-10-85.wireless.csail.mit.edu>
Co-authored-by: Emily Mu <emilymu@30-10-24.wireless.csail.mit.edu>

---
## [oshanoshu/evals](https://github.com/oshanoshu/evals)@[cb23f7aff1...](https://github.com/oshanoshu/evals/commit/cb23f7aff1a84328ff8bed31fa2ab65f3dfdfb12)
#### Friday 2023-05-19 02:40:16 by Andrew

Update fuzzy_match.py (#989)

# Thank you for contributing an eval! ‚ô•Ô∏è

üö® Please make sure your PR follows these guidelines, __failure to follow
the guidelines below will result in the PR being closed automatically__.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access granted. üö®

__PLEASE READ THIS__:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject since GPT-4 is already capable of completing the
task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, pelase note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details üìë
### Eval name
[Insert Eval name here]

### Eval description

[Insert a short description of what your eval does here]

### What makes this a useful eval?

[Insert why this eval is worth including and any additional context]

## Criteria for a good eval ‚úÖ

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [ ] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [ ] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [ ] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [ ] **Include at least 15 high quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure üèóÔ∏è

Your eval should
- [ ] Check that your data is in `evals/registry/data/{name}`
- [ ] Check that your yaml is registered at
`evals/registry/evals/{name}.yaml`
- [ ] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist üëÄ

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (https://platform.openai.com/docs/usage-policies).

- [ ] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the merged pull request.

- [ ] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgement

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and high volume of submissions, we will not
be able to accept all submissions and thus not grant everyone who opens
a PR GPT-4 access. We know this is disappointing, but we hope to set the
right expectation before you open this PR.

- [ ] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access
granted.

### Submit eval

- [ ] I have filled out all required fields of this form
- [ ] I have used **Git LFS** for the Eval JSON data
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data 

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
  INSERT_EVAL_HERE
  ```
</details>

---
## [oshanoshu/evals](https://github.com/oshanoshu/evals)@[8f8632ec55...](https://github.com/oshanoshu/evals/commit/8f8632ec55ee1f9704fe34225e1bce0cd999a8b1)
#### Friday 2023-05-19 02:40:16 by Oshan Upreti

Nepali song singer recognition (#892)

# Thank you for contributing an eval! ‚ô•Ô∏è

üö® Please make sure your PR follows these guidelines, __failure to follow
the guidelines below will result in the PR being closed automatically__.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access granted. üö®

__PLEASE READ THIS__:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject since GPT-4 is already capable of completing the
task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

## Eval details üìë
### Eval name
Nepali Song Singer

### Eval description

It tests the ability to understand Nepali language from given English
Transliteration phrase which is provided by user as a song title, and
checks the singer/band of the song. This eval has the accuracy of zero.
And, I still created this eval PR because I get the wrong answers every
time I ask, and I don't think that should be the case. It might not be
something that needs to be done immediately, but in a near future you
would expect your AI to answer it correctly.

### What makes this a useful eval?

If it can do for any English songs in the database, it should be able to
do for other languages as well. This is just a pattern I found it in my
mother tongue, but there might be different other languages where this
is happening as well, and it can be other things as well not just the
song title recognition.

## Criteria for a good eval ‚úÖ

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] **Include at least 15 high quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure üèóÔ∏è

Your eval should
- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your yaml is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist üëÄ

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (https://platform.openai.com/docs/usage-policies).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgement

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and high volume of submissions, we will not
be able to accept all submissions and thus not grant everyone who opens
a PR GPT-4 access. We know this is disappointing, but we hope to set the
right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access
granted.

### Submit eval

- [x] I have filled out all required fields in the evals PR form
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data 

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content": "A user will give you a English
transliteration phrase of Nepali song. Give the name of the singer or
band."}, {"role": "user", "content": "Sayad Timro Bato Ma"}], "ideal":
"Raju Lama"}
{"input": [{"role": "system", "content": "A user will give you a English
transliteration phrase of Nepali song. Give the name of the singer or
band."}, {"role": "user", "content": "Timi Lai Dekhera"}], "ideal":
"Raju Lama"}
{"input": [{"role": "system", "content": "A user will give you a English
transliteration phrase of Nepali song. Give the name of the singer or
band."}, {"role": "user", "content": "Aaja maan udhera bhagchha"}],
"ideal": "Udit Narayan"}
{"input": [{"role": "system", "content": "A user will give you a English
transliteration phrase of Nepali song. Give the name of the singer or
band."}, {"role": "user", "content": "Kaha Hola Ghar Bara"}], "ideal":
"Karma"}
{"input": [{"role": "system", "content": "A user will give you a English
transliteration phrase of Nepali song. Give the name of the singer or
band."}, {"role": "user", "content": "Khaseka Tara"}], "ideal":
"Albatross"}
  ```
</details>

---
## [Sea-of-Lost-Souls/Tannhauser-Gate](https://github.com/Sea-of-Lost-Souls/Tannhauser-Gate)@[6b00484526...](https://github.com/Sea-of-Lost-Souls/Tannhauser-Gate/commit/6b00484526d683d91b2d49463aec2d408ba49f54)
#### Friday 2023-05-19 02:57:16 by SkyratBot

[MIRROR] Fixes is_station_level() sometimes behaving erratically if the value provided is more complex than just a variable [MDB IGNORE] (#21270)

* Fixes is_station_level() sometimes behaving erratically if the value provided is more complex than just a variable (#75489)

## About The Pull Request
I have been debugging this stupid macro for the past nearly five hours,
to finally figure out why it was breaking. If you had something like `a
||¬†0` in what you called the macro with, it would somehow manage to
break the cache. This makes it far more foolproof, and will ensure that
it doesn't break here anymore, because debugging this has to be one of
the biggest pains in my ass I've ever had.

## Why It's Good For The Game
So shit like this

![image](https://github.com/tgstation/tgstation/assets/58045821/455122b0-34eb-4ec0-92dd-2775c1f0f878)

Doesn't end up breaking your CI (or even worse, the game in prod), in
places unrelated. At least now it shouldn't be overwriting values in the
cache.

It shouldn't have to do verification that you're doing the right thing,
that should be left on the person using the macro because it was meant
to be faster than a proc call, adding too much verification overhead
kind of just loses some of that speed.

## Changelog

:cl: GoldenAlpharex
fix: Makes checks for the station z level more robust against coders
doing less intuitive stuff, thus protecting it from breaking in weirdly
difficult and seemingly unrelated places (I'm looking at you, nuke
cinematic unit test).
/:cl:

* Fixes is_station_level() sometimes behaving erratically if the value provided is more complex than just a variable

---------

Co-authored-by: GoldenAlpharex <58045821+GoldenAlpharex@users.noreply.github.com>

---
## [shiptest-ss13/Shiptest](https://github.com/shiptest-ss13/Shiptest)@[0cff53fc09...](https://github.com/shiptest-ss13/Shiptest/commit/0cff53fc09c34d989d2bc34b1699bd856af2cb92)
#### Friday 2023-05-19 02:57:31 by meemofcourse

Reworks the Twinkleshine-Class (#1825)

<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may
not be viewable. -->
<!-- You can view Contributing.MD for a detailed description of the pull
request process. -->

## About The Pull Request


![2023 05 13-23 20
45](https://github.com/shiptest-ss13/Shiptest/assets/75212565/de6f3a47-7be8-4800-ae73-9fc386e4bf01)

![twinklerework5](https://github.com/shiptest-ss13/Shiptest/assets/75212565/f1808576-70e3-4b56-b977-5b5e7d665fdd)





The Twinkleshine is a CyberSun-made Syndicate display of force, staffed
by every branch of the Syndicate. Despite the silly name, the presence
of one in a sector implies it to be of importance to the Syndicate, and
enemies within sight can only pray that the Twinkleshine crew are
incompetent enough to shoot themselves with their own weaponry (or blow
themselves up with the supermatter on-board).

It is staffed by:

- 1 Captain
- 1 Lieutenant (previously the Operative - serves as a warden/hos)
- 2 Medics
- 2 Engineers (previously the Mechanics)
- 5 Operatives (previously the Troopers)
- 1 Bartender
- 1 Miner
- 2 Deck Assistants

<!-- Describe The Pull Request. Please be sure every change is
documented or this can delay review and even discourage maintainers from
merging your PR! -->

## Why It's Good For The Game

Few days ago, an admin spawned a Twinkleshine, and I got to captain it.
The Twinkleshine is old. It sucks. This, hopefully, fixes that.

Originally, this was going to be minor fixes, but ended up becoming an
attempt at reworking the ship to a more modern state - the hull has been
redone and is mostly symmetrical, the old spacepod was replaced with a
Dark Gygax, the supermatter shouldn't be activated upon spawning the
ship, there's more turf decals and a bigger lot-of-things, added a
bartender and a miner, people can actually tell who they are and what
they do, and there is now a box moth. Rejoice.

Also, this is the first time I've ever mapped a ship. What better way to
begin with a giant battleship?

<!-- Please add a short description of why you think these changes would
benefit the game. If you can't justify it in words, it might not be
worth adding. -->

## Changelog

:cl:
tweak: Reworks the Twinkleshine
/:cl:

<!-- Both :cl:'s are required for the changelog to work! You can put
your name to the right of the first :cl: if you want to overwrite your
GitHub username as author ingame. -->
<!-- You can use multiple of the same prefix (they're only used for the
icon ingame) and delete the unneeded ones. Despite some of the tags,
changelogs should generally represent how a player might be affected by
the changes rather than a summary of the PR's contents. -->

---------

Signed-off-by: meemofcourse <75212565+meemofcourse@users.noreply.github.com>

---
## [Offroaders123/NBTify](https://github.com/Offroaders123/NBTify)@[65ddc58d9f...](https://github.com/Offroaders123/NBTify/commit/65ddc58d9f7423ef3f384131730067fcbfd85441)
#### Friday 2023-05-19 03:04:16 by Offroaders123

Internal Type Insecurities

While the types for the tags are nearly perfect (of course, they can't actually really be perfect), I realize that the `ListTag` and `CompoundTag` types aren't typed strong enough, out of everything in the library. I'm going to work on refactoring things as a whole, there's starting to be more things I see being able to make improvements to, because I can move logic for things both into dedicated functions, and to make use of stronger type checking which will ensure that values are actually what they are when they are being accessed. Right now, I'm not quite doing the full checking on the shapes and content of each tag, and that could cause more problems that could be uncaught, even with the types I currently have for things.

I'm going to further strengthen the checking on each value and structure individually, rather than asserting it through error catching at the entry points to each part of the API. So, essentially I want to make more use of internally representing values as unknown, and only having type definitions on the outside, then type checking within the library itself. What that means, the users will see the intended types of the library from the outside, but the library will instead start treating all values as `unknown`, since I want to intentionally find out their types, and remove any unsafe data (things like the unsupported types `Function`, `symbol`, `null`, `undefined` for example). I don't want to do this magically, I want to start purposefully managing these checks using the internal types within the library itself. Right now I just have to remember to add these checks in myself, wherever I know they haven't been sanitized yet. So I think this in part has to do with my now understanding of the uncertainty behind not having proper API type checks within the library, which will check if the incoming `CompoundTag` structures are valid, including valid properties and such. And I think this means it will (un?)realistically allow for the API to have `unknown` entry point values, and the library should be still type safe internally, where to the point it will not throw errors, because the proper checks are in place to actually be able to deduce the types of the NBT data object structures themselves, not only by the API types themselves.

This is just an idea as of now, so I may not end up going through making everything this solidly strict. I think that would be very good in terms of strictness and safety, but it might be redundant in a few (or, a lot) of places. So I may just implement these ideas in places of the library where it tends to be less safe or forgiving than others (`CompoundTag` entries, `ListTag` items).

I want to move the library into a more functionally-driven nature I think now too, driven by modules and smaller functions, instead of logic-obscuring classes which hide implementation details away. While I do like that structure of defining things (at least it was pretty nice at first), I am starting to see more problems where I want to use similar logic in other places, and I can't apply those in other places outside of that one use case. One big example was the SNBT to type definition generator logic. Both are very similar in what they do, and parse the NBT data tree, but they aren't similar enough to be a single class, and I don't want to use inheritance to find the similarities between the two. Sounds veery ugly. As a single class, which does it's own things though, I guess I do like that model. Maybe if it's just for simpler, more standalone things it can be ok. I think working on my other world data projects, I found that using functions to pass data between each other is more dynamic, in the fact that you don't have to relate two things together in order to be able to use them with each other. You just pass the value from one call into the next. You don't have to use encapsulation to pool all of the state into a singular place, instead you can pipe it into different canals that go to different places, and eventually go to the finish line. The rivers can at times cross paths too, and use the same roadway (sorry for these horrible analogies today), and break off again, using a different function to modify it's output just a little bit different than it's neighbor Angela, who simply uses the same river (function) to get from the starting line to the finish line. (not sure who Angela is, just dove into making the analogy worse)

---
## [MedNet-Technologies/proyecto-medset](https://github.com/MedNet-Technologies/proyecto-medset)@[278485669a...](https://github.com/MedNet-Technologies/proyecto-medset/commit/278485669a411dcb74c7e9340f67603c8b199905)
#### Friday 2023-05-19 03:21:08 by Risuban

this shitty ass view is finally functional, godd damn

---
## [akshay1431996/FoodLite](https://github.com/akshay1431996/FoodLite)@[82c6cdc679...](https://github.com/akshay1431996/FoodLite/commit/82c6cdc67930f8e80dea26b168dda2929ca821c2)
#### Friday 2023-05-19 03:31:19 by akshay1431996

Create README.md

Welcome to the Food Lite GitHub repository! This repository houses the code for a delightful food blogging website designed and developed using HTML, CSS, and JavaScript.

Food Lite is a responsive website that adapts seamlessly to screens of all sizes, ensuring an optimal user experience on desktops, tablets, and mobile devices. With its visually appealing design and user-friendly interface, Food Lite aims to provide a delightful browsing experience for food enthusiasts and bloggers alike.

Features:

Elegant Design: The website boasts an elegant and modern design that focuses on showcasing mouthwatering food photography and captivating content.
Responsive Layout: Food Lite is built with a responsive layout, allowing visitors to enjoy the website's content on any device they prefer.
Seamless Navigation: The intuitive navigation system ensures smooth and effortless browsing, allowing users to explore different sections of the website easily.
Interactive Elements: JavaScript is utilized to enhance the website's interactivity, providing dynamic features such as image sliders, interactive forms, and smooth scrolling.
Optimized Performance: Great attention has been given to optimizing the website's performance, ensuring fast loading times and smooth transitions between pages.
Browser Compatibility: Food Lite has been thoroughly tested and optimized to work seamlessly across major web browsers, ensuring a consistent experience for all users.
Feel free to explore the code and customize the website according to your preferences. If you encounter any issues or have suggestions for improvements, please don't hesitate to create an issue or submit a pull request.

Thank you for visiting the Food Lite GitHub repository. We hope you find this project inspiring and helpful in your own web development endeavors. Happy coding!

---
## [KMZIMMERMAN/mindsupport](https://github.com/KMZIMMERMAN/mindsupport)@[cf8fb990cf...](https://github.com/KMZIMMERMAN/mindsupport/commit/cf8fb990cf0284378f7931e2e655dabb003cfe79)
#### Friday 2023-05-19 03:33:20 by KMZIMMERMAN

Update index.html

added resources!

<p class="mb-10 lead font-weight-bold">Mental Health Resources</p>
                                    <p class="mb-7">Access a variety of mental health resources that provide valuable information!</p>
                                    <p class="mb-5"><a href="https://988lifeline.org/talk-to-someone-now/" target="_blank"> Suicide Prevention Lifeline (988),  </a><a href="https://www.crisistextline.org/" target="_blank"> Crisis Textline (741741),  </a><a href="https://save.org/" target="_blank"> SAVE,  </a><a href="https://www.thetrevorproject.org/" target="_blank"> The Trevor Project (LGBTQ+),  </a><a href="https://www.datocms-assets.com/12810/1594144968-black-mental-health-v2-1.pdf" target="_blank"> The Mental Health Coalition,  </a><a href="https://www.asianmhc.org/" target="_blank"> Asian Mental Health Collective,  </a><a href="https://www.healthyamericas.org/" target="_blank"> National Alliance for Hispanic Health,  </a><a href="https://www.wernative.org/" target="_blank"> We R Native,  </a><a href="https://www.inclusivetherapists.com/" target="_blank"> Inclusive Therapists,  </a><a href="https://www.nami.org/Your-Journey/Individuals-with-Mental-Illness" target="_blank"> NAMI,  </a><a href="https://americanaddictioncenters.org/virtual-meetings" target="_blank"> Virtual Support/Online Addiction Meetings,  </a><a href="https://www.veteranscrisisline.net/" target="_blank"> Veteran Crisis Line,  </a><a href="https://www.nami.org/Your-Journey/Family-Members-and-Caregivers/Learning-to-Help-Your-Child-and-Your-Family" target="_blank"> Learning to Help (NAMI),  </a><a href="https://www.nimh.nih.gov/health/find-help" target="_blank"> NIMH,  </a><a href="https://www.samhsa.gov/mental-health/how-to-talk/friends-and-family-members" target="_blank"> SAMHSA,  </a><a href="https://www.psychiatry.org/patients-families/helping-a-loved-one-cope-with-mental-illness" target="_blank"> APA  </a></p>
                                  <p class="mb-3"><i>keyword(s): "resources"</i></p>
                                    <a button class="btn btn-primary" href="#" data-dismiss="modal">Talk to Our AI Chatbot!</a>

---
## [YehnBeep/tgstation](https://github.com/YehnBeep/tgstation)@[527fb7b003...](https://github.com/YehnBeep/tgstation/commit/527fb7b0030d13fc11939d88030b1dc4772742a6)
#### Friday 2023-05-19 04:38:57 by DrTuxedo

ELEVATOR MUSIC: True Elevator Experience (#75388)

## About The Pull Request
Adds elevator music into the game that is played by an elevator panel.


https://github.com/tgstation/tgstation/assets/42353186/1a801604-3990-46ae-a96a-b3766b102d62

It's done by using loop sound, with a Kevin MacLeod "Local Forecast -
Elevator" (UNDER CC ATTRIBUTIONS 4.0, and we anyway used some other
Kevin MacLeod music) chopped into 8 small pieces.
The elevator panel has a variable which allows playing music but can be
changed in the map editor if you don't want it to play at certain
places.

(It also doesn't ignore walls, this means you can't hear the music
through wall or when elevator is closed)
## Why It's Good For The Game
Gives elevators more flavour and love, especially when people mostly
prefer stairs to those "laggy crushing machines."
Because of this people might instead hop into an elevator just to hear
meme elevator music, which is relaxing and might create comedic
situations (although elevators don't move that fast)
## Changelog
:cl: DrDiasyl aka DrTuxedo
sound: Nanotrasen have started installing music players in the elevators
to boost workers' morale.
/:cl:

---------

Co-authored-by: Mothblocks <35135081+Mothblocks@users.noreply.github.com>

---
## [jlsnow301/tgstation](https://github.com/jlsnow301/tgstation)@[bc22fefe3b...](https://github.com/jlsnow301/tgstation/commit/bc22fefe3b1de4d882dd87a5492344672230736d)
#### Friday 2023-05-19 05:04:45 by Helg2

Adds proper armor for security plasmamen. (#75156)

## About The Pull Request
It's kinda strange that security plasmamen has no proper armor and you
can just bully them with bottlesmashes. Literally.
Also suits had no wound armor for some reason, which considering that
mold dies without hand kinda silly too.
And helmets just had no armor besides 1 melee armor.
## Why It's Good For The Game
Plasmamen security won't die that easilly. I mean, still easy to kill
them, but not that much.
## Changelog
:cl:
balance: Security Plasmamen now have Security armor. No bullying them
with bottlesmashes anymore.
/:cl:

---
## [SHipSailorSsatya/ShipSailorSatya](https://github.com/SHipSailorSsatya/ShipSailorSatya)@[4689882431...](https://github.com/SHipSailorSsatya/ShipSailorSatya/commit/4689882431adfc25b0d84c5f8ddd3ff607dc67d3)
#### Friday 2023-05-19 05:17:33 by Satya Dev Rahul ( Ship Sailor Satya )

Update README.md

Satya Dev Rahul ( ShipSailorSatya )  (Born; July 08th, 1993) is a Google Certified Famous Digital Marketer, Marine Officer,Youtuber, Blogger  and Social Media Marketing Specialist.He belongs to a City Of Dreams called Mumbai.He is a Digital Entrepreneur who is also founder of Best Digital Marketing Company & also invested in multiple bussiness , all around the world . 

Starting his journey in the field of Digital Marketing as a freelancer and since then he has been achieving new heights every day. Today he is running his own digital marketing company. He has also worked with many celebrities ,artists, influencers and business entrepreneurs.He also got awarded with multiple Awards till today.He is very kind and humble personality.

Digital marketing is the practice of promoting products, services or brands through digital technologies, including the internet, social media, search engines, mobile devices, and other digital channels. It is a rapidly growing field that offers businesses the opportunity to reach a vast audience and engage with them in a cost-effective way.

To achieve success in digital marketing, companies need to develop a comprehensive strategy that includes various techniques and tactics such as search engine optimisation (SEO), pay-per-click (PPC) advertising, content marketing, social media marketing, email marketing, and others. They also need to constantly analyse and adapt their strategies based on the latest trends and consumer behaviour.

In addition, companies need to have a strong team of digital marketing professionals who have the skills and expertise to execute their strategies effectively. This includes individuals with knowledge of digital platforms, data analytics, content creation, and marketing automation.

Email:
ShipSailorSatya@gmail.com

Instagram:
www.instagram.com/ShipSailorSatya

---
## [timothymtorres/tgstation](https://github.com/timothymtorres/tgstation)@[200b739c0a...](https://github.com/timothymtorres/tgstation/commit/200b739c0a0bbfff95dbfd697786013c92cb6cf6)
#### Friday 2023-05-19 05:19:09 by Kyle Spier-Swenson

Refactors and defuckulates dbcore. Adds support for min_threads rustg setting, Reduce query delay, Make unit tests faster (#74852)

dbcore was very fuckulated.

It had 3 lists of queries, but they all had their own current_run style
list to support mc_tick_check (as it was already being done before with
the undeleted query check, so i can understand why they ~~cargo culted~~
mirrored the behavior) This was silly and confusing and unneeded given
two of those loops can only process at most 25 items at a time on
default config, plus these were cheap operations (ask rustg to start
thread, ask rustg to check on thread).

Because of the confusingness of the 6 lists for 3 query states, The code
to run pending/queued queries immediately during world shutdown was
instead looking at the current_run list for active queries, **meaning
those queries got ran twice.**

The queued query system only checked the current active query count in
fire(), meaning even when there was nothing going on in this subsystem
new queries had to wait for the next fire() to run (10 ticks, so 500ms
on default config)

Those have all been fixed.

the config `BSQL_THREAD_LIMIT` has been renamed to
`POOLING_MAX_SQL_CONNECTIONS` and its default was lowered to match
MAX_CONCURRENT_QUERIES .

added a new config `POOLING_MIN_SQL_CONNECTIONS`, allowing you to
pre-allocate a reserve of sql threads.

The queue processing part of SSdbcore's fire() has been made to not obey
mc_tick_check for clarity and to make the following change easier to do:

If there is less than `MAX_CONCURRENT_QUERIES` in the active queue, new
queries activate immediately.

(its ok that there are two configs that kinda do the same thing,
POOLING_MAX_SQL_CONNECTIONS maps to max-threads in the mysql crate, and
it seems to only be a suggestion, meanwhile MAX_CONCURRENT_QUERIES can't
do anything during init, which is when the highest amount of concurrent
queries tend to happen.)

:cl:
config: database configs have been updated for better control over the
connection pool
server: BSQL_THREAD_LIMIT has been renamed to
POOLING_MAX_SQL_CONNECTIONS, old configs will whine but still work.
fix: fixed rare race condition that could lead to a sql query being ran
twice during world shutdown.
/:cl:

I have not tested this pr.

---
## [timothymtorres/tgstation](https://github.com/timothymtorres/tgstation)@[773cc9542a...](https://github.com/timothymtorres/tgstation/commit/773cc9542a54837fc52b15eb09cc98d7226049fb)
#### Friday 2023-05-19 05:19:09 by MrMelbert

Adds admin alert for revs created through traitor panel (#74862)

## About The Pull Request

So like, using traitor panel to make revs doesn't work. 

Revolutions live and die, currently, by the revolution ruleset datum
dynamic creates. It manages the hostile environment and also processes
to check whether either side should be winning or not.

This means that the revolutionary buttons in the traitor panel are kind
of noob-admin-bait. You press it for a funny revolution and then you
realize it's screwed when all the heads are dead and everyone's
stumbling around cluelessly

This has a proper solution, albeit somewhat difficult - separate out the
revolution from the ruleset, make admin spawned revs create a
revolution. I can do this but it's a lot of effort and this works in the
meanwhile

Pops up a TGUI alert when an admin presses "add revolutionary" in
traitor panel when there is no ongoing revolution. Simply enough, gives
them an alert that it will not work correctly. Lets them decide whether
they want to deal with that. (Because you can manually deal with it via
proc calls, if you've got code smarts.)

## Why It's Good For The Game

Stops admins from stumbling into the same trap without warning.

Can be removed in the future easily when revs are coded better. 

## Changelog

:cl: Melbert
admin: Adds a warning that spawning revs via traitor panel will not
function as expected.
/:cl:

---
## [pytorch/pytorch](https://github.com/pytorch/pytorch)@[6c5d6b75f2...](https://github.com/pytorch/pytorch/commit/6c5d6b75f28b5e0173564be651ad29c148fe34e5)
#### Friday 2023-05-19 05:29:59 by Mikayla Gawarecki

Update base for Update on "[WIP] Let torch.load load memory-mapped tensors (binary file attempt)"

Separate approach to #101446 

To my knowledge, `tarfile.extract` will create a copy on disk (and if we want to read in place (which doesn't seem super well documented(?), we still have to handled the padding to page size part).

Maybe managing our own binary file where we're super clear about how to read in place might be better. 

This PR implements the binary file format as such 

```
Format of our binary file is
    #  -------------- -------------- -------------------------- ----- ------------ ----- ------------ --------------
    # | [p] magic_no | [p] protocol | [p] total_storage_nbytes | *** | [r] s_0 ***| ... | [r] s_n ***| [p] data.pkl |
    #  -------------- -------------- -------------------------- ----- ------------ ----- ------------ --------------
    # where [p] indicates pickled and [r] indicates raw bytes and *** indicates padding up to page alignment (4096)
    # s_0 to s_n are storages
    # data.pkl indicates what is normally saved in the separate data.pkl file
    # in the zipfile using the default torch.load serialization logic
```

Something not so good about this is: **the offset passed to mmap must be page-aligned**. I'm padding all tensor starts to the nearest multiple of 4096 bytes right now. This could be problematic if 

1) save on system with one page size and load on a system with a different page size 
2) padding is a bit wasteful but I would like to argue that 4kB is not bad when mmap is mostly useful for HUGE tensors!

Not yet handled:

- [ ] endianness -- how can you byteswap + mmap
- [ ] this case: save on system with one page size and load on a system with a different page size --> warn and fallback?
- [ ] better API where `torch.save(_mmap=True)` --> no need to pass _mmap to `torch.load`


Things I am worried about/would like to do
- [ ] There is only 1 real fd open, I'm dup-ing all the rest right now. I'm setting the flag to close the fd immediately after mmap is called, which ~should~ be ok but I wonder whether there will be any weird interactions with too many fds being open?
- [ ] Try to serialize some sort of huge model + way more extensive testing


Other thoughts
- [ ] Should the MapAllocator take the shared flag?




[ghstack-poisoned]

---
## [davidhildenbrand/linux](https://github.com/davidhildenbrand/linux)@[a070323a38...](https://github.com/davidhildenbrand/linux/commit/a070323a38aff18d85cedb59ebd72ecb732b05e9)
#### Friday 2023-05-19 09:11:24 by Douglas Anderson

migrate_pages: avoid blocking for IO in MIGRATE_SYNC_LIGHT

The MIGRATE_SYNC_LIGHT mode is intended to block for things that will
finish quickly but not for things that will take a long time.  Exactly how
long is too long is not well defined, but waits of tens of milliseconds is
likely non-ideal.

When putting a Chromebook under memory pressure (opening over 90 tabs on a
4GB machine) it was fairly easy to see delays waiting for some locks in
the kcompactd code path of > 100 ms.  While the laptop wasn't amazingly
usable in this state, it was still limping along and this state isn't
something artificial.  Sometimes we simply end up with a lot of memory
pressure.

Putting the same Chromebook under memory pressure while it was running
Android apps (though not stressing them) showed a much worse result (NOTE:
this was on a older kernel but the codepaths here are similar).  Android
apps on ChromeOS currently run from a 128K-block, zlib-compressed,
loopback-mounted squashfs disk.  If we get a page fault from something
backed by the squashfs filesystem we could end up holding a folio lock
while reading enough from disk to decompress 128K (and then decompressing
it using the somewhat slow zlib algorithms).  That reading goes through
the ext4 subsystem (because it's a loopback mount) before eventually
ending up in the block subsystem.  This extra jaunt adds extra overhead. 
Without much work I could see cases where we ended up blocked on a folio
lock for over a second.  With more extreme memory pressure I could see up
to 25 seconds.

We considered adding a timeout in the case of MIGRATE_SYNC_LIGHT for the
two locks that were seen to be slow [1] and that generated much
discussion.  After discussion, it was decided that we should avoid waiting
for the two locks during MIGRATE_SYNC_LIGHT if they were being held for
IO.  We'll continue with the unbounded wait for the more full SYNC modes.

With this change, I couldn't see any slow waits on these locks with my
previous testcases.

NOTE: The reason I stated digging into this originally isn't because some
benchmark had gone awry, but because we've received in-the-field crash
reports where we have a hung task waiting on the page lock (which is the
equivalent code path on old kernels).  While the root cause of those
crashes is likely unrelated and won't be fixed by this patch, analyzing
those crash reports did point out these very long waits seemed like
something good to fix.  With this patch we should no longer hang waiting
on these locks, but presumably the system will still be in a bad shape and
hang somewhere else.

[1] https://lore.kernel.org/r/20230421151135.v2.1.I2b71e11264c5c214bc59744b9e13e4c353bc5714@changeid

Link: https://lkml.kernel.org/r/20230428135414.v3.1.Ia86ccac02a303154a0b8bc60567e7a95d34c96d3@changeid
Signed-off-by: Douglas Anderson <dianders@chromium.org>
Suggested-by: Matthew Wilcox <willy@infradead.org>
Reviewed-by: Matthew Wilcox (Oracle) <willy@infradead.org>
Acked-by: Mel Gorman <mgorman@techsingularity.net>
Cc: Hillf Danton <hdanton@sina.com>
Cc: Gao Xiang <hsiangkao@linux.alibaba.com>
Cc: Alexander Viro <viro@zeniv.linux.org.uk>
Cc: Christian Brauner <brauner@kernel.org>
Cc: Gao Xiang <hsiangkao@linux.alibaba.com>
Cc: Huang Ying <ying.huang@intel.com>
Cc: Vlastimil Babka <vbabka@suse.cz>
Cc: Yu Zhao <yuzhao@google.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>

---
## [Backwards-Future-Industries/Peters-Car-By-Balenciaga](https://github.com/Backwards-Future-Industries/Peters-Car-By-Balenciaga)@[465e4613d4...](https://github.com/Backwards-Future-Industries/Peters-Car-By-Balenciaga/commit/465e4613d458e566bc8bf3bf4b7c1f346f7cd1b4)
#### Friday 2023-05-19 09:15:10 by Eivan20

Merge pull request #69 from Backwards-Future-Industries/greedyAI

Sup all family friendly friends of ours in this cool group where everyone loves each other would you please accept this merge request where I have made some development on stuff but I honestly dont know what I have changed but im pretty sure it has improved the overall final product of this code. Oh btw the map looks better now so thats something

---
## [YusufAksakal/pool-for-physicists-only](https://github.com/YusufAksakal/pool-for-physicists-only)@[42c03f6a75...](https://github.com/YusufAksakal/pool-for-physicists-only/commit/42c03f6a75d001c33d4dc62656189a8c26b20af2)
#### Friday 2023-05-19 09:16:20 by Umut Utku ER≈ûAHƒ∞NCE

fix: now implementing the complicated ball-cushion formula.
Several hours of work (mostly debugging) done, several more to go! Proceed with caution if you want to change these stuff!
There is an issue where we can't detect some collisions. This is in my opinion not a bug in the implementation. Our approach needs to change to fix this. Don't know how commonly this happens or whether it will affect regular user experience. Playtesting is required after pockets are implemented and game is operational.

---
## [Omarley7/DTaaS-Bachelor-new-GUI](https://github.com/Omarley7/DTaaS-Bachelor-new-GUI)@[4106db0ebe...](https://github.com/Omarley7/DTaaS-Bachelor-new-GUI/commit/4106db0ebe75c9b45d3144ccdda8036160888285)
#### Friday 2023-05-19 10:43:44 by Mathias Br√¶ndgaard

Add unit tests for Store/AppAccess and Store/UserAccess (#63)

* Add unit tests for Store/AppAccess and Store/UserAccess

* Honestly bullshit codeclimate error.
Would be overly complicated to fix. Even this solution is stupid.
And also updated envUtil to use the same hook, act, assert approach.

* Bullshit l√∏sning

---------

Co-authored-by: Omar <omarg@live.dk>

---
## [revived8895/android_kernel_samsung_exynos8895](https://github.com/revived8895/android_kernel_samsung_exynos8895)@[478f99e111...](https://github.com/revived8895/android_kernel_samsung_exynos8895/commit/478f99e1116590b911f0b1460978196951c62608)
#### Friday 2023-05-19 11:08:43 by Masahiro Yamada

modpost: file2alias: go back to simple devtable lookup

commit ec91e78d378cc5d4b43805a1227d8e04e5dfa17d upstream.

Commit e49ce14150c6 ("modpost: use linker section to generate table.")
was not so cool as we had expected first; it ended up with ugly section
hacks when commit dd2a3acaecd7 ("mod/file2alias: make modpost compile
on darwin again") came in.

Given a certain degree of unknowledge about the link stage of host
programs, I really want to see simple, stupid table lookup so that
this works in the same way regardless of the underlying executable
format.

Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
Acked-by: Mathieu Malaterre <malat@debian.org>
[nc: Omit rpmsg, sdw, fslmc, tbsvc, and typec as they don't exist here
     Add of to avoid backporting two larger patches]
Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
Signed-off-by: Sasha Levin <sashal@kernel.org>

---
## [Offroaders123/NBTify](https://github.com/Offroaders123/NBTify)@[638c71daa4...](https://github.com/Offroaders123/NBTify/commit/638c71daa4a535ef36ce64a0715753b09f41c6af)
#### Friday 2023-05-19 11:16:43 by Offroaders123

Ridiculous Fix

A clever name, haha. While working on bringing these updates over to Dovetail, I discovered a bug with opening unnamed root tag files. Turns out when working on the code for the `SIngle-Definition Configuration Schema`, I accidentally changed the unnamed root tag auto-check step, meaning the `read()` function was only able to open named root files. This showed up as an issue while opening `ridiculous.nbt` into Dovetail, to which I was confused as to how it was having trouble opening the file.

I think this is an example of why I need to implement tests for the library, at least at the file format level. I can have a simple file type for most kinds of formats, and I can check that the reader and writer correctly open and save to and from each format as expected. This issue is a big one, and I essentially only found it in production, or, almost-production. I think it also points out that my auto-detection code could be a little less verbose too, as it kind of hid in the rest of the code there. Or, things like this just tend to happen. I can't plan for every issue I make, so maybe I just have to try my best and deal with it, and double check everything I'm doing. At the same time, I think I can do more than just that. I think a combination of that acceptance, along with some simple tests could be a strong way to go :)

Listening to Wine and Pickles again, 'Inhale'. Now '4s' is starting, and it makes me want to somehow show Elkosaurus Tex to Mike Keneally, I think he'd get a kick out of that project of mine!

---
## [ss220club/Skyrat-tg](https://github.com/ss220club/Skyrat-tg)@[52eb909f42...](https://github.com/ss220club/Skyrat-tg/commit/52eb909f423900340814843d3223a7f3205add35)
#### Friday 2023-05-19 11:19:40 by Tom

Makes Hell Microwaves Not Use Power (#67413) (#21210)

Hey there,

I was informed that the holodeck program Microwave Paradise would draw and suck power out of an APC. Didn't intend for that to happen, and while funny, I don't really want to arm the crew with le epic power sink with very little effort than pressing a button, or warranting this to eventually be locked to "dangerous" programs. So, let's change such that this subtype of microwaves that can not be constructed (only mapped/spawned) doesn't consume any power. I don't know why it drew off the nearest APC or how that works, but this seems to be alright.

It's not possible to deconstruct machinery spawned in at the Holodeck (which I verified while testing this PR), so do not worry about people using this to bypass the power economy for whzhzhzhz purposes.

Co-authored-by: san7890 <the@san7890.com>

---
## [JohnnySpitfire/bobsled_jousting](https://github.com/JohnnySpitfire/bobsled_jousting)@[3b3ed496fa...](https://github.com/JohnnySpitfire/bobsled_jousting/commit/3b3ed496fae23a4bda2eff6869878e7f4ba6b485)
#### Friday 2023-05-19 12:35:48 by Rph1122

Merge pull request #29 from JohnnySpitfire/main

Fuck you im gonna piss on the moon

---
## [RakhithJK/certbot](https://github.com/RakhithJK/certbot)@[208ef4eb94...](https://github.com/RakhithJK/certbot/commit/208ef4eb942c7129dd265632de740ed1fab53c98)
#### Friday 2023-05-19 12:35:50 by Brad Warren

remove CERTBOT_NO_PIN (#9634)

Adrien and I added this is in https://github.com/certbot/certbot/pull/6590 in response to https://github.com/certbot/certbot/issues/6582 which I wrote. I now personally think these tests are way more trouble than they're worth.

In almost all cases, the versions pinned in `tools/requirements.txt` are used. The two exceptions to this that come to mind are users using OS packages and pip. In the former, the version of our dependencies is picked by the OS and do not change much on most systems. As for pip, [we only "support it on a best effort basis"](https://eff-certbot.readthedocs.io/en/stable/install.html#alternative-2-pip).

Even for pip users, I'm not convinced this buys us much other than frequent test failures. We have our tests configured to error on all Python warnings and [we regularly update `tools/requirements.txt`](https://github.com/certbot/certbot/commits/master/tools/requirements.txt). Due to that, assuming our dependencies follow normal conventions, we should have a chance to fix things in response to planned API changes long before they make their way to our users. I do not think it is necessary for our tests to break immediately after an API is deprecated.

I think almost all other failures due to these tests are caused by upstream bugs. In my experience, almost all of them will sort themselves out pretty quickly. I think that responding to those that are not or planned API changes we somehow missed can be addressed when `tools/requirements.txt` is updated or when someone opens an issue. I personally don't think blocking releases or causing our nightly tests to fail is at all worth it here. I think removing this frequent cause of test failures makes things just a little bit easier for Certbot devs without costing us much of anything.

---
## [SamandarKhanAfridi/Arduino-and-NodeMCU_Books_By_SamandarKhanAfridi](https://github.com/SamandarKhanAfridi/Arduino-and-NodeMCU_Books_By_SamandarKhanAfridi)@[a967d3efc0...](https://github.com/SamandarKhanAfridi/Arduino-and-NodeMCU_Books_By_SamandarKhanAfridi/commit/a967d3efc00d3c66c9932b74c85560ca2acbbb81)
#### Friday 2023-05-19 12:58:35 by SamandarKhanAfridi

Readme

---

# Arduino + NodeMCU Books By Samandar Khan Afridi

Welcome to the Arduino + NodeMCU Books repository by Samandar Khan Afridi. This repository is a collection of books aimed at providing a comprehensive guide to Arduino and NodeMCU programming. Whether you're a beginner or an enthusiast, these books will help you build a strong foundation in these popular microcontroller platforms.

## About the Author

Samandar Khan Afridi is a passionate student of B.E. Electrical Engineering at Quaid-e-Awam University of Engineering, Science and Technology, Nawabshah. With a keen interest in the field of electronics and programming, Samandar has authored these books as a means to share his knowledge and experiences in Arduino and NodeMCU development. Through clear explanations, practical examples, and step-by-step instructions, Samandar aims to help readers develop their skills and become proficient in these platforms.

## Repository Contents

This repository contains the following books:

1. **Book 1**: ArduinoUno_SamandarKhanAfridi
2. **Book 2**: NodeMCU_SamandarKhanAfridi

Each book is packed with valuable content, including program sketches, circuit diagrams, and detailed explanations. By following along with the books, you'll learn how to build and program various projects using Arduino and NodeMCU. Whether you're interested in home automation, robotics, or IoT applications, these books will provide you with the necessary knowledge to bring your ideas to life.

## YouTube Channel

Samandar Khan Afridi also maintains a YouTube channel dedicated to sharing insightful videos on topics such as Internet of Things, Electrical Engineering, Programming, and New Technologies. Make sure to subscribe to the channel (https://www.youtube.com/@samandarkhanafridi) to stay updated on the latest tutorials, project demonstrations, and informative videos.


## License

This project is licensed under the [MIT License](LICENSE), allowing you to freely use, modify, and distribute the content of this repository for personal and educational purposes.

---


Thank You!

---
## [newstools/2023-new-york-post](https://github.com/newstools/2023-new-york-post)@[3bdff2c822...](https://github.com/newstools/2023-new-york-post/commit/3bdff2c82273d2a2e68bc6257a104485550da48c)
#### Friday 2023-05-19 14:55:56 by Billy Einkamerer

Created Text For URL [nypost.com/2023/05/19/dear-abby-my-boyfriend-says-hell-take-care-of-me-as-i-battle-cancer-but-im-not-that-into-him/]

---
## [jnutt367/psalms](https://github.com/jnutt367/psalms)@[8697a714ea...](https://github.com/jnutt367/psalms/commit/8697a714ea4e28add2b8b66cb9983e50cdd2c122)
#### Friday 2023-05-19 15:28:53 by Jason Nutt (He/Him) Christian Developer/Creator

Update index.js

For the director of music. With stringed instruments. A psalm. A song.
1 May God be gracious to us and bless us
    and make his face shine on us‚Äî[b]
2 so that your ways may be known on earth,
    your salvation among all nations.

3 May the peoples praise you, God;
    may all the peoples praise you.
4 May the nations be glad and sing for joy,
    for you rule the peoples with equity
    and guide the nations of the earth.
5 May the peoples praise you, God;
    may all the peoples praise you.

6 The land yields its harvest;
    God, our God, blesses us.
7 May God bless us still,
    so that all the ends of the earth will fear him.

---
## [letangphuquy/Sandbox](https://github.com/letangphuquy/Sandbox)@[6fd618b8d4...](https://github.com/letangphuquy/Sandbox/commit/6fd618b8d4a7d3b6e3e908204faf9edbf3912def)
#### Friday 2023-05-19 15:37:40 by Le Tang Phu Quy

Merge branch 'main' of github.com:letangphuquy/Sandbox
Please add a commit message. Fuck you VIm, how do I exit? and save?

---
## [pytorch/pytorch](https://github.com/pytorch/pytorch)@[be79aaf7d2...](https://github.com/pytorch/pytorch/commit/be79aaf7d207c1095147db1f6ec65b207a419f3f)
#### Friday 2023-05-19 15:38:16 by Joel Schlosser

Update base for Update on "(WIP; DO NOT REVIEW) Use python tensor subclass version of NT for PT2"


I'm out next week so I'm dumping some stuff here for whoever is interested. Added some notes inline. Other things:
* Main idea: convert real NT -> fake / meta instance of `NestedTensor` python tensor subclass during tracing and use that throughout the rest of the PT2 stack
* Python tensor subclass only supports contiguous for now
    * Only need `sizes` because of this, and `sizes` is a dim-length list containing int / List[int] items (for ragged dims) OR SymInts for dynamic shapes (will probably only support this case anyway)
* Inference-only for now; ignore Autograd
* Skip functionalization on NTs for now (there's no in-place op support anyway, although we should ideally handle NT <-> T views within functionalization)

Example script:
```python
import torch
from torch.nested import nested_tensor
from torch.nested._nested_tensor import NestedTensor
from torch._inductor import debug

torch._inductor.config.debug = True
torch._dynamo.config.traceable_tensor_subclasses.add(NestedTensor)

device = 'cuda'

def make_tensor(*shape, device=device, dtype=torch.float32):
    return torch.randn(*shape, device=device, dtype=dtype)

torch.manual_seed(1)

def fn(x, x_offsets):
    x_nt = torch._nested_view_from_jagged(x, x_offsets)
    x_nt = x_nt + 69
    x_nt = x_nt * 42
    return x_nt

torch._dynamo.disallow_in_graph(torch.diff)

compiled_fn = torch.compile(fn)

# shape (sum(*), D)
# component shapes: (3, 5), (4, 5), (6, 5)
x = make_tensor(13, 5)
x_offsets = torch.tensor([0, 3, 7, 13], dtype=torch.int64, device=device)

# helps create dynamic graph right away
torch._dynamo.mark_dynamic(x, 0)
torch._dynamo.mark_dynamic(x_offsets, 0)

output = compiled_fn(x, x_offsets)

# shape (sum(*), D)
# component shapes: (2, 5), (6, 5), (4, 5), (5, 5)
y = make_tensor(17, 5)
y_offsets = torch.tensor([0, 2, 8, 12, 17], dtype=torch.int64, device=device)

output2 = compiled_fn(y, y_offsets)

print(output)
print(output2)
```

WARNING: AWFUL HACKS AHEAD. DO NOT REVIEW YET.

cc soumith voznesenskym penguinwu anijain2305 EikanWang jgong5 Guobing-Chen XiaobingSuper zhuhaozhe blzheng Xia-Weiwen wenzhe-nrv jiayisunx peterbell10 desertfire

[ghstack-poisoned]

---
## [SPANDigital/evals](https://github.com/SPANDigital/evals)@[170dfd886c...](https://github.com/SPANDigital/evals/commit/170dfd886c0704588461af075393cc20cfb0480f)
#### Friday 2023-05-19 16:00:54 by Robert Bateman

[Eval] An array of Liar Paradox-based evals (#883)

# Thank you for contributing an eval! ‚ô•Ô∏è

üö® Please make sure your PR follows these guidelines, __failure to follow
the guidelines below will result in the PR being closed automatically__.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access granted. üö®

__PLEASE READ THIS__:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject since GPT-4 is already capable of completing the
task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

## Eval details üìë
### Eval name
logic-liar-paradox

### Eval description

An array of Liar Paradox-based evals, examining the model's proficiency
in navigating linguistic nuances and logical reasoning within
self-referential statements.

### What makes this a useful eval?

This eval is particularly useful because it delves into complex, nuanced
logical concepts and self-referential statements, which have
historically posed challenges for AI models. By exploring various
contexts, alternative logical frameworks, and modifications to
statements, this eval helps assess the model's ability to adapt to
different perspectives, grasp subtleties in language, and engage in
flexible reasoning. The ability to understand and navigate paradoxes is
an essential aspect of human-like reasoning, and improving an AI model's
performance in this area would significantly enhance its overall
usefulness and reliability in real-world applications. Additionally,
showcasing the model's improved proficiency in handling paradoxes would
not only make for a compelling marketing angle (as paradoxes are
understood by a much broader range of people than other difficult tasks
such as pure maths or quantum mechanics) but it would also demonstrate
the progress made in AI's capacity to think and reason more like humans.
It also adds paradox-absorbing crumple zones.

## Criteria for a good eval ‚úÖ

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] **Include at least 15 high quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

- [x] Addresses complex logical reasoning: The eval focuses on AI's
ability to comprehend and navigate paradoxes, self-referential
statements, and context switching, which are important aspects of
human-like reasoning. By testing the model's proficiency in these areas,
we can identify areas for improvement and work towards enhancing AI's
overall capacity to think and reason more like humans.
- [x] Demonstrates adaptability and flexibility: The eval showcases the
model's ability to switch between contexts, alter premises, and engage
with different dimensions of inferred logic. This will help assess the
model's adaptability and flexibility in diverse real-world situations,
making it more reliable and useful.
- [x] Contributes to AI safety and understanding: By identifying the
model's weaknesses and limitations in handling paradoxes and complex
logical constructs, the eval can contribute to AI safety and enable
researchers to better understand the challenges faced by large language
models in these areas.
- [x] Engaging and appealing: An eval that delves into paradoxes and
complex thought exercises is not only intellectually stimulating but
also adds an appealing element to showcase the model's capabilities,
making it more attractive for both researchers and end-users.

### Unique eval value

- [x] Encourages creativity and lateral thinking: The eval, by focusing
on paradoxes and complex logical constructs, encourages both the AI and
its developers to think creatively and approach problem-solving from
unconventional angles. This can lead to the discovery of novel solutions
and a better understanding of the model's capabilities.
- [x] Aligns with human values and expectations: An AI that can
successfully navigate paradoxes and complex logic is more likely to
align with human values and expectations. By addressing these challenges
in the eval, we strive to develop AI systems that understand and respect
the nuances of human thought and communication.
- [x] Addresses a broad range of applications: Improved reasoning and
context-switching abilities can have a significant impact on various AI
applications, including natural language understanding, decision-making,
and problem-solving in domains such as law, philosophy, ethics, and
more.
- [x] Fosters interdisciplinary collaboration: The exploration of
paradoxes and complex logic often draws upon insights from multiple
disciplines, including philosophy, linguistics, psychology, and computer
science. This eval can help foster interdisciplinary collaboration,
leading to richer and more diverse perspectives on AI development and
its potential impact on society.

## Eval structure üèóÔ∏è

Your eval should
- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your yaml is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist üëÄ

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (https://platform.openai.com/docs/usage-policies).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgement

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and high volume of submissions, we will not
be able to accept all submissions and thus not grant everyone who opens
a PR GPT-4 access. We know this is disappointing, but we hope to set the
right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access
granted.

### Submit eval

- [x] I have filled out all required fields in the evals PR form
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data 

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input":[{"role":"system","content":"Is the statement \"This sentence
is true\" a paradox?"}],"ideal":"No, \"This sentence is true\" is not a
paradox; it is a tautology."}
{"input":[{"role":"system","content":"Does the statement \"This sentence
is not true\" create a paradox?"}],"ideal":"Yes, \"This sentence is not
true\" creates a paradox, as it is a variant of the Liar Paradox."}
{"input":[{"role":"system","content":"What is the difference between a
paradox and a tautology?"}],"ideal":"A paradox is a statement that leads
to a self-contradictory or logically unacceptable conclusion, while a
tautology is a statement that is always true by its logical form."}
{"input":[{"role":"system","content":"Can the Liar Paradox be resolved
by assuming that sentences can have both true and false
values?"}],"ideal":"No, the Liar Paradox cannot be resolved by assuming
that sentences can have both true and false values, as this would lead
to a different kind of paradox called the \"Dialetheism Paradox.\""}
{"input":[{"role":"system","content":"Consider the statement \"This
sentence is neither true nor false.\" Is this statement an example of
the Liar Paradox?"}],"ideal":"This statement, \"This sentence is neither
true nor false,\" is not an example of the Liar Paradox, but it is a
similar paradox known as the 'truth-teller paradox' or the 'strengthened
liar paradox.' It creates a paradoxical situation because if the
statement is true, then it is neither true nor false, which contradicts
its truth. If the statement is false, then it is not the case that it is
neither true nor false, which implies that it is either true or false,
again leading to a contradiction. The paradox arises due to
self-reference and the inability to assign a consistent truth value to
the statement."}
  ```
</details>

---
## [SPANDigital/evals](https://github.com/SPANDigital/evals)@[b93700ab49...](https://github.com/SPANDigital/evals/commit/b93700ab496bd112f89821777edc6a22d5972fb2)
#### Friday 2023-05-19 16:00:54 by DunedainStrider

Do math problems related to calculating dates using the Chinese Sexagenary Cycle method. üßÆ (#190)

# Thank you for contributing an eval! ‚ô•Ô∏è

üö® Please make sure your PR follows these guidelines, __failure to follow
the guidelines below will result in the PR being closed automatically__.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access granted. üö®

__PLEASE READ THIS__:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject since GPT-4 is already capable of completing the
task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. We encourage partial PR's with
~5-10 example that we can then run the evals on and share the results
with you so you know how your eval does with GPT-4 before writing all
100 examples.

## Eval details üìë
### Eval name
Do math problems related to calculating dates using the Chinese
Sexagenary Cycle method

### Eval description

The Sexagenary Cycle combines 10 Heavenly Stems (Jia Áî≤, Yi ‰πô, Bing ‰∏ô,
Ding ‰∏Å, Wu Êàä, Ji Â∑±, Geng Â∫ö, Xin Ëæõ, Ren Â£¨, Gui Áô∏) and 12 Earthly Branches
(Zi Â≠ê, Chou ‰∏ë, Yin ÂØÖ, Mao ÂçØ, Chen Ëæ∞, Si Â∑≥, Wu Âçà, Wei Êú™, Shen Áî≥, You ÈÖâ,
Xu Êàå, Hai ‰∫•) to form a 60-unit cycle. To calculate, convert the
Gregorian date to its corresponding Heavenly Stem and Earthly Branch
combination, used for marking specific years, months, and days.

### What makes this a useful eval?

The existing GPT models tend to make errors when performing calculations
related to the Sexagenary Cycle. To address this issue, we have provided
a specialized dataset aimed at improving the model's accuracy in
handling Sexagenary Cycle calculations.

## Criteria for a good eval ‚úÖ

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] Include at least 100 high quality examples (it is okay to only
contribute 5-10 meaningful examples and have us test them with GPT-4
before adding all 100)

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

[2023-03-16 12:46:51,594] [record.py:320] Final report: {'accuracy':
0.65}. Logged to
/tmp/evallogs/230316044112MFPWKX37_gpt-3.5-turbo_sexagenary_cycle_calculation.jsonl
[2023-03-16 12:46:51,594] [oaieval.py:211] Final report:
[2023-03-16 12:46:51,594] [oaieval.py:213] accuracy: 0.65
[2023-03-16 12:46:51,597] [record.py:309] Logged 60 rows of events to
/tmp/evallogs/230316044112MFPWKX37_gpt-3.5-turbo_sexagenary_cycle_calculation.jsonl:
insert_time=2.463ms

## Eval structure üèóÔ∏è

Your eval should
- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your yaml is registered at
`evals/registry/evals/{name}.jsonl`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist üëÄ

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (https://platform.openai.com/docs/usage-policies).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgement

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and high volume of submissions, we will not
be able to accept all submissions and thus not grant everyone who opens
a PR GPT-4 access. We know this is disappointing, but we hope to set the
right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access
granted.

### Submit eval

- [x] I have filled out all required fields in the evals PR form
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data 

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content": "You are a helpful
assistant."}, {"role": "user", "content": "Let's do a math problem
related to calculating dates using the Chinese Sexagenary Cycle
method."}, {"role": "assistant", "content": "Sure, let's do a math
problem using the Chinese Sexagenary Cycle. The Chinese Sexagenary
Cycle, or Stems and Branches, is a system used in China to count years,
months, days, and even hours. It is a 60-year cycle, consisting of 10
Heavenly Stems and 12 Earthly Branches."}, {"role": "user", "content":
"Áî≤ÊàåÁöÑÊ¨°Êó•ÊòØÔºü"}], "ideal": "‰πô‰∫•"}
{"input": [{"role": "system", "content": "You are a helpful
assistant."}, {"role": "user", "content": "Let's do a math problem
related to calculating dates using the Chinese Sexagenary Cycle
method."}, {"role": "assistant", "content": "Sure, let's do a math
problem using the Chinese Sexagenary Cycle. The Chinese Sexagenary
Cycle, or Stems and Branches, is a system used in China to count years,
months, days, and even hours. It is a 60-year cycle, consisting of 10
Heavenly Stems and 12 Earthly Branches."}, {"role": "user", "content":
"‰πô‰∫•ÁöÑÊ¨°Êó•ÊòØÔºü"}], "ideal": "‰∏ôÂ≠ê"}
{"input": [{"role": "system", "content": "You are a helpful
assistant."}, {"role": "user", "content": "Let's do a math problem
related to calculating dates using the Chinese Sexagenary Cycle
method."}, {"role": "assistant", "content": "Sure, let's do a math
problem using the Chinese Sexagenary Cycle. The Chinese Sexagenary
Cycle, or Stems and Branches, is a system used in China to count years,
months, days, and even hours. It is a 60-year cycle, consisting of 10
Heavenly Stems and 12 Earthly Branches."}, {"role": "user", "content":
"Â£¨ÂØÖÁöÑÂêéÊó•ÊòØÔºü"}], "ideal": "Áî≤Ëæ∞"}
{"input": [{"role": "system", "content": "You are a helpful
assistant."}, {"role": "user", "content": "Let's do a math problem
related to calculating dates using the Chinese Sexagenary Cycle
method."}, {"role": "assistant", "content": "Sure, let's do a math
problem using the Chinese Sexagenary Cycle. The Chinese Sexagenary
Cycle, or Stems and Branches, is a system used in China to count years,
months, days, and even hours. It is a 60-year cycle, consisting of 10
Heavenly Stems and 12 Earthly Branches."}, {"role": "user", "content":
"Áô∏ÂçØÁöÑÂêéÊó•ÊòØÔºü"}], "ideal": "‰πôÂ∑≥"}
{"input": [{"role": "system", "content": "You are a helpful
assistant."}, {"role": "user", "content": "Let's do a math problem
related to calculating dates using the Chinese Sexagenary Cycle
method."}, {"role": "assistant", "content": "Sure, let's do a math
problem using the Chinese Sexagenary Cycle. The Chinese Sexagenary
Cycle, or Stems and Branches, is a system used in China to count years,
months, days, and even hours. It is a 60-year cycle, consisting of 10
Heavenly Stems and 12 Earthly Branches."}, {"role": "user", "content":
"Â£¨Â≠êÁöÑÂêéÊó•ÊòØÔºü"}], "ideal": "Áî≤ÂØÖ"}
  ```
</details>

---------

Co-authored-by: dunedainstrider <dunedainstrider@mac16>

---
## [SPANDigital/evals](https://github.com/SPANDigital/evals)@[8e276ea460...](https://github.com/SPANDigital/evals/commit/8e276ea4603155ee616d5cd66aadfddcfbcae0cc)
#### Friday 2023-05-19 16:00:54 by steven-luabase

Eval: Probability Questions Sourced From Actuarial Exam P and University Statistics Courses (#263)

# Thank you for contributing an eval! ‚ô•Ô∏è

üö® Please make sure your PR follows these guidelines, __failure to follow
the guidelines below will result in the PR being closed automatically__.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access granted. üö®

__PLEASE READ THIS__:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject since GPT-4 is already capable of completing the
task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. We encourage partial PR's with
~5-10 example that we can then run the evals on and share the results
with you so you know how your eval does with GPT-4 before writing all
100 examples.

## Eval details üìë
### Eval name
Probability Questions

### Eval description

Tests the model's ability to understand answer probability questions.
Questions are sourced from Society of Actuaries Exam P sample questions
and practice problems/exams from statistics classes at MIT, UPenn,
California State University, Durham University, University of
Connecticut, and other sources. The full list of questions and sources
(in the same order as in the `.jsonl` files) can be found in this Google
[sheet](https://docs.google.com/spreadsheets/d/1TU_4VPhIce9JtLV5gLy619WNibVjiWB-dtiwqkBtCrU/edit?usp=sharing)

### What makes this a useful eval?

Test the model's ability to understand worded probability questions,
bring in concepts such as probability distributions, and then reason
through a correct answer.

## Criteria for a good eval ‚úÖ

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] Include at least 100 high quality examples (it is okay to only
contribute 5-10 meaningful examples and have us test them with GPT-4
before adding all 100)

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

Using the `match` grading criteria, GPT3.5-turbo got an accuracy score
of `{'accuracy': 0.07}`

## Eval structure üèóÔ∏è

Your eval should
- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your yaml is registered at
`evals/registry/evals/{name}.jsonl`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist üëÄ

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (https://platform.openai.com/docs/usage-policies).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgement

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and high volume of submissions, we will not
be able to accept all submissions and thus not grant everyone who opens
a PR GPT-4 access. We know this is disappointing, but we hope to set the
right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access
granted.

### Submit eval

- [x] I have filled out all required fields in the evals PR form
- [x] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data 

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content": "You are a helpful
statistician. Answer the questions with only the numerical answer
rounded to 4 decimal places. Provide no explanation."}, {"role": "user",
"content": "A pair of fair, standard dice are rolled. What is the
probability the sum of the dice is 5"}], "ideal": ["0.1111"]}
{"input": [{"role": "system", "content": "You are a helpful
statistician. Answer the questions with only the numerical answer
rounded to 4 decimal places. Provide no explanation."}, {"role": "user",
"content": "An airplane is built to be able to fly on one engine. If the
plane's two engines operate independently, and each has a 1% chance of
failing in any given four-hour flight, what is the chance the plane will
fail to complete a four-hour flight to Oklahoma due to engine
failure?"}], "ideal": ["0.0001"]}
{"input": [{"role": "system", "content": "You are a helpful
statistician. Answer the questions with only the numerical answer
rounded to 4 decimal places. Provide no explanation."}, {"role": "user",
"content": "A 1-inch-diameter coin is thrown on a table covered with a
grid of lines two inches apart. What is the probability the coin lands
in a square without touching any of the lines of the grid?"}], "ideal":
["0.2500"]}
{"input": [{"role": "system", "content": "You are a helpful
statistician. Answer the questions with only the numerical answer
rounded to 4 decimal places. Provide no explanation."}, {"role": "user",
"content": "Of the 50 students in a certain class, 5 speak French. Two
students of the class will be selected at random. Which of the following
is closest to the probability that neither of the students selected will
speak French?"}], "ideal": ["0.8100"]}
{"input": [{"role": "system", "content": "You are a helpful
statistician. Answer the questions with only the numerical answer
rounded to 4 decimal places. Provide no explanation."}, {"role": "user",
"content": "Of the 10 marbles in a box, 2 are green. A person will
select 2 marbles simultaneously and at random from the box. What is the
probability that neither of the marbles selected will be green?"}],
"ideal": ["0.6222"]}
  ```
</details>

---
## [Xtended-Devices/kernel_xiaomi_daisy](https://github.com/Xtended-Devices/kernel_xiaomi_daisy)@[b0b25a3921...](https://github.com/Xtended-Devices/kernel_xiaomi_daisy/commit/b0b25a392175909a41758bdf7d47970aacfc2b42)
#### Friday 2023-05-19 16:34:46 by Jebaitedneko

[HACK]: base: power: wakeup: create a dummy debugfs entry for trace_marker

ah shit you finally disabled debugfs only to see userspace scream at you for not having trace_marker
this is the only driver which creates a debugfs entry which is essential for battery monitoring (see 1bdb13584fb7b5c6b7b741e4436a4dc4397df26e)
adjust it's init function to create said dummy trace file inside tracing dir
this will suppress the silly userspace errors





Change-Id: I02ecb73d143e7c927ab15113c5d7a64e5b270e84

---
## [MustafaAalabdul/CSE-232](https://github.com/MustafaAalabdul/CSE-232)@[82e3186184...](https://github.com/MustafaAalabdul/CSE-232/commit/82e3186184f0efc155a70708818b507679702036)
#### Friday 2023-05-19 16:39:45 by Mustafa Aalabdulrasul

Project 1

All inputs will be provided through standard input (that is, std::cin). The first two lines of these inputs will each contain a single "keyword". The remaining lines will each contain a full word list. Word lists are one or more words that are separated by commas, with no spaces or any other symbols.
For example:
  Kansas
  Virginia
  Virginia,Wyoming,Vermont
  NewMexico,Kansas,Alabama,Virginia,NewYork,WestVirginia,Arkansas,Virginia,Utah,Virginia
  Alaska
In this case, the keywords are ‚ÄúKansas‚Äù and "Virginia", and then there are three lines of word lists. The word lists will never contain spaces or any characters other than letters (capital or lowercase) and numbers.


For each word list provided, you must output (to standard out, std::cout) which of the two keywords comes first, or ‚ÄúN/A‚Äù if neither one is in the word list at all. You should then output (on the same line) a count of how many times each word appeared, in order. Note that you should NOT count words that are merely a substring of another word.
For the input example above, you should output:
   Virginia 0 1
   Kansas 1 3
   N/A 0 0
There are three lines, one for each word list. In the first word list Virginia appears first (as indicated on the first line of output) and only once. Kansas never appears at all. So the word counts are 0 Kansas and 1 Virginia.
The second line has Virginia appearing three times and Kansas only once, but Kansas appears first so it is the name that begins the line, followed by the two counts. Since a word should not be counted if it is just a substring of another word, ‚ÄúVirginia‚Äù should NOT be counted four times just because it is part of "WestVirginia".
The final word list has neither state name in it, so ‚ÄúN/A‚Äù is printed in the field for which came first, and then zeros are printed for both counts since neither one was actually present.


You should implement this program using four functions, described below, plus the main() function. You may, additionally create any number of extra functions that you believe will help you to efficiently produce the needed output.
We recommend that you implement these required functions in the order described. The first function may be helpful to you in implementing the second function, and the second function will be helpful in implementing the third and fourth functions. All four functions will be tested in unit tests to help you craft them correctly.
Finally, you must implement the main() function to produce the desired output for the program, as described above.
Notes on parameter and return types:
Whenever you are talking about a position in a string, you should use the type size_t to be consistent with the standard library.
When you create a function, if an input is a string that is not changed by the function, you should pass that string as a "const reference". The reference ensures that the whole string does not need to be copied (a time saver for strings!) and the const lest a user know that the string won‚Äôt be altered by the function even though it‚Äôs being passed by reference.
You should almost never return a reference from a stand-alone function. There are rare circumstance where this might be the right thing to do, but usually only under much more advanced use conditions. Likewise you should almost never mark a return type as const.
Function: AtListPosition

The AtListPosition function should take three arguments: a word list (as a string), a word (as a string), and a position. It should return a Boolean value indicating whether or not the provided word begins at the specified position in the word list. Remember, a match that is actually just a part of a longer string should NOT count as having the word at that position of the word list.
Function FindInList

The FindInList function should have two to three parameters, very similar to the previous function: a word list (as a string), a word (as a string), and a start position (which should default to 0 if only two arguments are provided). It should return the first position in the word list where the provided word is found, starting its search from the start position.
Remember, making good use of AtListPosition will likely simplify your implementation of this function.
Function: GetFirstInList

The GetFirstInList function should take three arguments: word list and pointers to two strings, word1 and word2. It should return a regular string equal to the contents of word1 or word2, whichever word appears first in the word list. Clearly FindInList will be very helpful in allowing you to identify which one comes first.
Why are the inputs to this function supposed to be pointers to strings? Is it just to make your life more difficult? Yes, in an sense it is. There are few simple problems where pointers are needed to implement a solution, so we are simply going to require you use pointers in this question so that you can get some (light) experience trying them out.
Function: CountInList

The CountInList function has two parameters: a word list and a word (both strings). This function should return a simple count of how many times the word appears in the word list.

---
## [jnutt367/psalms](https://github.com/jnutt367/psalms)@[32e1c31c49...](https://github.com/jnutt367/psalms/commit/32e1c31c49144e7bf5fa631d3a4f2c3b1f8078d1)
#### Friday 2023-05-19 16:50:07 by Jason Nutt (He/Him) Christian Developer/Creator

Update index.js

Praise the Lord.[a]

Praise God in his sanctuary;
    praise him in his mighty heavens.
2 Praise him for his acts of power;
    praise him for his surpassing greatness.
3 Praise him with the sounding of the trumpet,
    praise him with the harp and lyre,
4 praise him with timbrel and dancing,
    praise him with the strings and pipe,
5 praise him with the clash of cymbals,
    praise him with resounding cymbals.

6 Let everything that has breath praise the Lord.

Praise the Lord.

---
## [michaelfegreus/capstone_vivarium](https://github.com/michaelfegreus/capstone_vivarium)@[bb81d93401...](https://github.com/michaelfegreus/capstone_vivarium/commit/bb81d9340159bc9c43db7f5c09b051fe95567243)
#### Friday 2023-05-19 17:11:09 by trentgarlipp

Oh God i haven't pushed an update to GitHub since February

Damn let's see, I added reflections, all the running particles, water stuff, more fireflies, sound effects for a buncha shit, fixed a bunch of bugs, I DUNNO!

---
## [Pyrtle93/frameworks_base-1](https://github.com/Pyrtle93/frameworks_base-1)@[494f84e894...](https://github.com/Pyrtle93/frameworks_base-1/commit/494f84e8945dd683fd96a821bb75d40c1f0bc289)
#### Friday 2023-05-19 17:39:17 by Kuba Wojciechowski

[SQUASHED] core: Blacklist pixel system feature from Google Photos

    We want to include the P21 experience flag to enable new features,
    however it seems like Google Photos uses it to decide whether to use the
    TPU tflite delegate. There doesn't seem to be any fallback so we need to
    make sure the feature is not exposed to the app so that a normal
    NNAPI/GPU delegate can be used instead.

    Test: Google Photos editor with PIXEL_2021_EXPERIENCE feature in product
    Signed-off-by: Kuba Wojciechowski <nullbytepl@gmail.com>
    Change-Id: I51a02f8347324c7a85f3136b802dce4cc4556ac5

commit 67eb31b3bb43d06fcc7f6fdb2f92eb486451cae6
Author: kondors1995 <normandija1945@gmail.com>
Date:   Thu Jun 9 17:39:25 2022 +0530

    Core: Extend Pixel experience Blacklist For Google Photos

    Turns out having these brakes Original quality backups.
    Since these indicate that the device is pixel 4 with in the turn brakes device spoofing as OG pixel

    Change-Id: I336facff7b55552f094997ade337656461a0ea1d

commit 508a99cde60b73dc3f1e843d569bca31def35988
Author: ReallySnow <reallysnow233@gmail.com>
Date:   Fri Dec 31 16:40:23 2021 +0800

    base: core: Blacklist Pixel 2017 and 2018 exclusive for Google Photos

    * In this way can use PixelPropsUtils to simulate the Pixel XL prop
      method to use the unlimited storage space of Google Photos
    * Thanks nullbytepl for the idea

    Change-Id: I92d472d319373d648365c8c63e301f1a915f8de9

commit aaf07f6ccc89c2747b97bc6dc2ee4cb7bd2c6727
Author: Akash Srivastava <akashniki@gmail.com>
Date:   Sat Aug 20 19:04:32 2022 +0700

    core: Pixel experience Blacklist For Google Photos for Android 13

    * See, in Android 13 pixel_experience_2022_midyear was added, which needs to be blacklisted aswell

    Change-Id: Id36d12afeda3cf6b39d01a0dbe7e3e9058659b8e

commit 9d6e5749a988c9051b1d47c11bb02daa7b1b36fd
Author: spezi77 <spezi7713@gmx.net>
Date:   Mon Jan 31 19:17:34 2022 +0100

    core: Rework the ph0t0s features blacklist

    * Moving the flags to an array feels more like a blacklist :P
    * Converted the flags into fully qualified package names, while at it

    Signed-off-by: spezi77 <spezi7713@gmx.net>
    Change-Id: I4b9e925fc0b8c01204564e18b9e9ee4c7d31c123

commit d7201c0cff326a6374e29aa79c6ce18828f96dc6
Author: Joey Huab <joey@evolution-x.org>
Date:   Tue Feb 15 17:32:11 2022 +0900

    core: Refactor Pixel features

    * Magic Eraser is wonky and hard to
      enable and all this mess isn't really worth
      the trouble so just stick to the older setup.

    * Default Pixel 5 spoof for Photos and only switch
      to Pixel XL when spoof is toggled.

    * We will try to bypass 2021 features and Raven
      props for non-Pixel 2021 devices as apps usage
      requires TPU.

    * Remove P21 experience system feature check

Change-Id: Iffae2ac87ce5428daaf6711414b86212814db7f2

---
## [git-for-windows/git](https://github.com/git-for-windows/git)@[aef5230191...](https://github.com/git-for-windows/git/commit/aef523019152e009705564caf941eafb8a7135ed)
#### Friday 2023-05-19 17:39:30 by Johannes Schindelin

windows: ignore empty `PATH` elements

When looking up an executable via the `_which` function, Git GUI
imitates the `execlp()` strategy where the environment variable `PATH`
is interpreted as a list of paths in which to search.

For historical reasons, stemming from the olden times when it was
uncommon to download a lot of files from the internet into the current
directory, empty elements in this list are treated as if the current
directory had been specified.

Nowadays, of course, this treatment is highly dangerous as the current
directory often contains files that have just been downloaded and not
yet been inspected by the user. Unix/Linux users are essentially
expected to be very, very careful to simply not add empty `PATH`
elements, i.e. not to make use of that feature.

On Windows, however, it is quite common for `PATH` to contain empty
elements by mistake, e.g. as an unintended left-over entry when an
application was installed from the Windows Store and then uninstalled
manually.

While it would probably make most sense to safe-guard not only Windows
users, it seems to be common practice to ignore these empty `PATH`
elements _only_ on Windows, but not on other platforms.

Sadly, this practice is followed inconsistently between different
software projects, where projects with few, if any, Windows-based
contributors tend to be less consistent or even "blissful" about it.
Here is a non-exhaustive list:

Cygwin:

	It specifically "eats" empty paths when converting path lists to
	POSIX: https://github.com/cygwin/cygwin/commit/753702223c7d

	I.e. it follows the common practice.

PowerShell:

	It specifically ignores empty paths when searching the `PATH`.
	The reason for this is apparently so self-evident that it is not
	even mentioned here:
	https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_environment_variables#path-information

	I.e. it follows the common practice.

CMD:

	Oh my, CMD. Let's just forget about it, nobody in their right
	(security) mind takes CMD as inspiration. It is so unsafe by
	default that we even planned on dropping `Git CMD` from Git for
	Windows altogether, and only walked back on that plan when we
	found a super ugly hack, just to keep Git's users secure by
	default:

		https://github.com/git-for-windows/MINGW-packages/commit/82172388bb51

	So CMD chooses to hide behind the battle cry "Works as
	Designed!" that all too often leaves users vulnerable. CMD is
	probably the most prominent project whose lead you want to avoid
	following in matters of security.

Win32 API (`CreateProcess()`)

	Just like CMD, `CreateProcess()` adheres to the original design
	of the path lookup in the name of backward compatibility (see
	https://learn.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessw
	for details):

		If the file name does not contain a directory path, the
		system searches for the executable file in the following
		sequence:

		    1. The directory from which the application loaded.

		    2. The current directory for the parent process.

		    [...]

	I.e. the Win32 API itself chooses backwards compatibility over
	users' safety.

Git LFS:

	There have been not one, not two, but three security advisories
	about Git LFS executing executables from the current directory by
	mistake. As part of one of them, a change was introduced to stop
	treating empty `PATH` elements as equivalent to `.`:
	https://github.com/git-lfs/git-lfs/commit/7cd7bb0a1f0d

	I.e. it follows the common practice.

Go:

	Go does not follow the common practice, and you can think about
	that what you want:
	https://github.com/golang/go/blob/go1.19.3/src/os/exec/lp_windows.go#L114-L135
	https://github.com/golang/go/blob/go1.19.3/src/path/filepath/path_windows.go#L108-L137

Git Credential Manager:

	It tries to imitate Git LFS, but unfortunately misses the empty
	`PATH` element handling. As of time of writing, this is in the
	process of being fixed:
	https://github.com/GitCredentialManager/git-credential-manager/pull/968

So now that we have established that it is a common practice to ignore
empty `PATH` elements on Windows, let's assess this commit's change
using Schneier's Five-Step Process
(https://www.schneier.com/crypto-gram/archives/2002/0415.html#1):

Step 1: What problem does it solve?

	It prevents an entire class of Remote Code Execution exploits via
	Git GUI's `Clone` functionality.

Step 2: How well does it solve that problem?

	Very well. It prevents the attack vector of luring an unsuspecting
	victim into cloning an executable into the worktree root directory
	that Git GUI immediately executes.

Step 3: What other security problems does it cause?

	Maybe non-security problems: If a project (ab-)uses the unsafe
	`PATH` lookup. That would not only be unsafe, though, but
	fragile in the first place because it would break when running
	in a subdirectory. Therefore I would consider this a scenario
	not worth keeping working.

Step 4: What are the costs of this measure?

	Almost nil, except for the time writing up this commit message
	;-)

Step 5: Given the answers to steps two through four, is the security
	measure worth the costs?

	Yes. Keeping Git's users Secure By Default is worth it. It's a
	tiny price to pay compared to the damages even a single
	successful exploit can cost.

So let's follow that common practice in Git GUI, too.

Signed-off-by: Johannes Schindelin <johannes.schindelin@gmx.de>

---
## [peff/git](https://github.com/peff/git)@[a7039ded3e...](https://github.com/peff/git/commit/a7039ded3e434856ec03c54b118924ba2bda76fd)
#### Friday 2023-05-19 17:48:46 by Jeff King

commit: give a hint when a commit message has been abandoned

If we launch an editor for the user to create a commit
message, they may put significant work into doing so.
Typically we try to check common mistakes that could cause
the commit to fail early, so that we die before the user
goes to the trouble.

We may still experience some errors afterwards, though; in
this case, the user is given no hint that their commit
message has been saved. Let's tell them where it is.

Signed-off-by: Jeff King <peff@peff.net>

---
## [openai/evals](https://github.com/openai/evals)@[8e4d43bb5b...](https://github.com/openai/evals/commit/8e4d43bb5b06a725c70a9b2c1eaad38787e737aa)
#### Friday 2023-05-19 17:53:35 by tescao

Human body movement (#360)

# Thank you for contributing an eval! ‚ô•Ô∏è

üö® Please make sure your PR follows these guidelines, __failure to follow
the guidelines below will result in the PR being closed automatically__.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access granted. üö®

__PLEASE READ THIS__:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject since GPT-4 is already capable of completing the
task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. We encourage partial PR's with
~5-10 example that we can then run the evals on and share the results
with you so you know how your eval does with GPT-4 before writing all
100 examples.

## Eval details üìë
### Eval name

Human body movement

### Eval description

An eval to asses the model's understanding of how a human body moves,
e.g. after performing an exercise starting from a known side, which side
does the human end up with?

There are 20 unique samples + 20 samples with the starting side flipped,
as I noticed ChatGPT performed differently when starting side was
changed in the same movement.

### What makes this a useful eval?

The eval test the model's physical reasoning abilities as well as good
knowledge of a human body, which is necessary for being safe and helpful
to users, and could be used in fitness applications, as an aid for
people with visual impairments, generating dance sequences, etc.

## Criteria for a good eval ‚úÖ

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [ ] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [ ] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [ ] Include at least 100 high quality examples (it is okay to only
contribute 5-10 meaningful examples and have us test them with GPT-4
before adding all 100)

If there is anything else that makes your eval worth including, please
document it below.

## Eval structure üèóÔ∏è

Your eval should
- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your yaml is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist üëÄ

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (https://platform.openai.com/docs/usage-policies).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgement

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and high volume of submissions, we will not
be able to accept all submissions and thus not grant everyone who opens
a PR GPT-4 access. We know this is disappointing, but we hope to set the
right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access
granted.

### Submit eval

- [x] I have filled out all required fields in the evals PR form
- [x] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data 

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content": "Answer the question based on
the following description of a movement. Assume average human body
ability."}, {"role": "user", "content": "\nDescription: A woman is
standing on her hands and feet, facing the floor and reaching her hips
towards the ceiling, she lifts her left leg towards the ceiling, then
lowers it and puts it in between her hands. She inhales and twists her
torso pressing her chest against her inner thigh and reaches her arm to
the ceiling.\nQuestion: Which arm does she reach up?\nAnswer with a
single word: 'left' or 'right'."}], "ideal": "left"}
{"input": [{"role": "system", "content": "Answer the question based on
the following description of a movement. Assume average human body
ability."}, {"role": "user", "content": "\nDescription: A woman is
standing on her left leg, she lifts her other leg and presses it into
her chest with both arms. She then grabs the heel of her lifted leg with
her hand and stretches it all the way to the side, still holding the
heel. She remains upright with her chest opened.\nQuestion: Which hand
does she use to hold her leg?\nAnswer with a single word: 'left' or
'right'."}], "ideal": "right"}
{"input": [{"role": "system", "content": "Answer the question based on
the following description of a movement. Assume average human body
ability."}, {"role": "user", "content": "\nDescription: A woman is
holding a reversed plank position, holding her body in a straight line
and facing up. She lifts her left leg off the ground then lifts her hand
off the ground and transitions into a side plank.\nQuestion: Which hand
does she have to lift off the ground to transition into side
plank?\nAnswer with a single word: 'left' or 'right'."}], "ideal":
"left"}
{"input": [{"role": "system", "content": "Answer the question based on
the following description of a movement. Assume average human body
ability."}, {"role": "user", "content": "\nDescription: A man is in a
plank position, holding his body in a straight line and facing the
floor. Bracing his core, he lifts his left leg off the floor until it is
level with his body, then lifts his opposite arm until it is level with
his body, then puts them back on the floor. This is one repetition and
he does eight such repetitions, starting with his left leg and
alternating sides. This is one set. He takes a few seconds to rest then
does the same set again, starting with his right leg this
time.\nQuestion: Which arm does he lift at the last repetition of the
last set?\nAnswer with a single word: 'left' or 'right'."}], "ideal":
"right "}
{"input": [{"role": "system", "content": "Answer the question based on
the following description of a movement. Assume average human body
ability."}, {"role": "user", "content": "\nDescription: A woman stands
straight, she takes a big step back with her left foot, turning toes of
that foot out slightly. She lengthens her torso, opening her chest and
reaching her side towards her front leg until she can grab her leg with
her arm. She reaches the other arm to the sky and holds, lengthening her
body and opening her chest more.\nQuestion: Which arm did she reach
up?\nAnswer with a single word: 'left' or 'right'."}], "ideal": "left"}
  ```
</details>

---------

Co-authored-by: Marina Pchelina <marinapchelina@MarinaucBookPro.hitronhub.home>

---
## [samueljlieber/odoo](https://github.com/samueljlieber/odoo)@[882bd65daa...](https://github.com/samueljlieber/odoo/commit/882bd65daa203cf3a1e368c00999fc1f1de5dcd3)
#### Friday 2023-05-19 18:03:51 by Xavier Morel

[FIX] core: handle recursion error when resolving stored fields

Issue discovered in the uninstall (and reinstall) of sale_project: a
dump has ~100 tasks, when reinstalling `sale_line_id` has to be
initialised, this is done by marking `sale_line_id` on all extant
tasks as to-recompute, which triggers their computation on the next
`flush`.

Because it's a recursive field, `Field.recompute` ensures only one
record at a time gets recomputed (as there could be cross-dependencies
in the recorset which protection would prevent from resolving).

As the field computation runs, it accesses itself, which triggers a
cache miss, which triggers a `_fetch_field` (to get the currently
stored value), this calls `_read`, which flushes the field we're
trying to read.

The problem here is that for efficiency the cache miss will look for
all records in the cache without a value for the
field (`_in_cache_without`) and try to `fetch` on them as well. This
means rather than not doing anything in flush, we're going to
`Field.recompute` on all records except the one selected the first
time around, which repeats the cycle until there is no more additional
record found in `_in_cache_without`, which could trigger the next
round of `recompute`, and the entire thing unwinds, and we probably
perform a ton of unnecessary additional `compute_value`.

Except that doesn't even happen, because the process from one compute
to the next takes 12~13 stack frames, which given the default
recursion limit of 1000 gives a hard limit of 76 fields before hitting
a RecursionError. As this is less than 100, a recursion error [is what
we get](https://runbot.odoo.com/runbot/build/31726625).

In 15.2, this was fixed by only expanding the fetch on non-recursive
fields, pessimizing recursive
fields (5c2511115b14299516fce4aa3737a62faaf5b653). Test-wise this only
impacted mail performances and in a relatively minor manner.

In 16.0, the mail tests actually match already (so that part was
skipped by the cherrypicking) however this impacts the knowledge perf
tests much more significantly e.g. `test_article_creation_multi_roots`
gets +9 queries when creating 10 top-level articles, which is a bit
much.

So use an alternative which is ugly as hell but which I didn't
consider for 15.2 (may want to backport it one day if the current fix
is an issue): catch the recursion error and use the existing
fallback (of fetching just the requested record's field without
expanding the recordset).

This likely makes for a pretty inefficient situation in the original
case as we're certainly going to hit the recursion limit repeatedly,
but that still fixes the issue, and it avoids deoptimising cases which
fall short of the recursion limit (resolving under 60 records or
so).

Plus despite creating giant stacks we might actually get good
efficiency as we're going to hit recursion limits repeatedly but
that's pure python, once we fall below the limit we can resolve
everything at once with a single SQL query (or something along those
lines).

X-original-commit: 9e71094582ec4c9b719431e77538da8f91ffa9e3
Part-of: odoo/odoo#121492

---
## [softcerv/Skyrat-tg](https://github.com/softcerv/Skyrat-tg)@[3ecc9f859d...](https://github.com/softcerv/Skyrat-tg/commit/3ecc9f859dfc0f870500d717e382d52662667996)
#### Friday 2023-05-19 18:26:00 by SkyratBot

[MIRROR] Allows Export of your Preferences JSON File [MDB IGNORE] (#20894)

* Allows Export of your Preferences JSON File (#75014)

## About The Pull Request

Hey there,

This was spoken about in #70492 (specifically
https://github.com/tgstation/tgstation/pull/70492#issuecomment-1278069607),
and I have been waiting for this to be implemented for some time. It
never got implemented, so I decided to code it myself.

Basically, **if the server host doesn't disable it**, you are free to
export your JSONs as a player, right from the stat-panel. It's a pretty
JSON on 515 versions, too!

It's right here:

![image](https://user-images.githubusercontent.com/34697715/235251447-1c977718-51fd-4025-8d89-c60bffc379ec.png)

Here's what the prettified JSON looks like on 515.

![image](https://user-images.githubusercontent.com/34697715/235321061-4a217e26-c082-4bba-b54a-2c780defda0a.png)

There's a cooldown (default to 10 seconds) between exporting your
preferences.

#### Why is this config?

It's because in the past, a server host could always just file-share the
.sav or .json or whatever to the player, but they would have to do the
explicit option of actually bothering to make the files accessible to
the player. In that same line of logic, the server operator will have to
explicitly make the files accessible. This is mostly because I'm not
sure how good `ftp()` is at being a player function and wanted to have
some sort of cap/control somehow in case an exploit vector is detected
or it's just plain spammed by bots, so we'll just leave it up to the
direct providers of this data to elect if they wish to provide the data
or not.
## Why It's Good For The Game

Players don't have to log into Server A to remember what hairstyle they
loved using when they want to swap to Server B! That's amazing actually.
I always forget what ponytail my character has, and it'll be nice to
have the hairstyle in a readily accessible place (after I prettify the
JSON for myself).

It's also more convenient for server hosts to make player data like this
accessible if they really want to, too.

If we ever add an _import_ feature in the future (which would have to be
done with a LOT of care), this will also be useful. I wouldn't advise it
though having taken a precursory look at how much goes into it while
trying to ascertain the scope of this PR.
## Changelog
:cl:
qol: The game now supports export of your preferences into a JSON file!
The verb (export-preferences) should now be available in the OOC tab of
your stat-panel if enabled by server operators.
server: Exporting player preferences is controlled by a configuration
option, 'FORBID_PREFERENCES_EXPORT'. If you do not wish to let clients
access the ftp() function to their own preferences file (probably for
bandwidth reasons?) you should uncomment this or add it to your config
somehow.
config: Server operators are also able to set the cooldown between
requests to download the JSON Preferences file via the
'SECONDS_COOLDOWN_FOR_PREFERENCES_EXPORT' config option.
/:cl:

* Allows Export of your Preferences JSON File

---------

Co-authored-by: san7890 <the@san7890.com>

---
## [softcerv/Skyrat-tg](https://github.com/softcerv/Skyrat-tg)@[96676cc94e...](https://github.com/softcerv/Skyrat-tg/commit/96676cc94e9ab363e8350644a58449af11b614a7)
#### Friday 2023-05-19 18:26:00 by SkyratBot

[MIRROR] Gunpoints now take half a second to activate, make gasp sounds, and briefly immobilize the shooter and target, other small balance changes [MDB IGNORE] (#20882)

* Gunpoints now take half a second to activate, make gasp sounds, and briefly immobilize the shooter and target, other small balance changes (#74036)

## About The Pull Request
This PR messes around with gunpoints a bit, with the purpose of making
them more viable in certain scenarios without making them obnoxious. The
biggest change is that gunpoints now require a 0.5 second do_after()
where neither the shooter nor the target moves, and immobilizes both of
them for 0.75 seconds if point blank, or half that if you're 2 tiles
away. Originally you were supposed to only be able to initiate a
gunpoint from point-blank, but #56601 seems to have removed that
requirement, so we'll run with it and just leave it as advantageous to
gunpoint closer up. The do_after() reinforces that it should be used as
an ambush tactic, and so you can't use it on someone who's actively
fleeing or fighting you.

Getting held up will now make you emit a shocked gasp sound, a la Metal
Gear Solid, which combined with the short immobilize will hopefully make
it more noticeable that someone's pointing a gun at you.

Holdups will now immediately give a 25% bonus to damage and wounds,
instead of having to wait 2.5 seconds to hit the double damage stage.

Finally, right clicking someone that you're holding up will no longer
shoot them. That just feels like good consistency.

## Why It's Good For The Game
Hopefully makes gunpoints a little more viable for when you want to
stick someone who's not expecting it up without them immediately jetting
off. In the future I'd like to ape Baycode and let the gunman have an
action that toggles whether the victim is allowed to move, so you can
order them to move to a second location without instantly shooting them,
but that'll come later.
## Changelog
:cl: Ryll/Shaps
balance: Holding someone at gunpoint now requires both the shooter and
the victim to hold still for half a second before activating, so you
can't hold-up people fleeing or fighting you. After that, it will
briefly immobilize the both of you, 0.75 seconds if adjacent, or half
that if you're two tiles away. Nuke ops are immune to the
immobilization, since they're ready to die anyways.
balance: Holding someone up will immediately apply a 1.25x damage and
wound multiplier, rather than waiting 2.5 seconds to hit 2x.
soundadd: Being held up will now make the victim play a sharp gasp
sound, a la Metal Gear Solid.
qol: Trying to hold someone up that you're already holding up will no
longer shoot them.
/:cl:

---------

Co-authored-by: san7890 <the@ san7890.com>

* Gunpoints now take half a second to activate, make gasp sounds, and briefly immobilize the shooter and target, other small balance changes

---------

Co-authored-by: Ryll Ryll <3589655+Ryll-Ryll@users.noreply.github.com>
Co-authored-by: san7890 <the@ san7890.com>

---
## [dj-34/Skyrat-220](https://github.com/dj-34/Skyrat-220)@[21363d07a5...](https://github.com/dj-34/Skyrat-220/commit/21363d07a5eec9fbce5be2f17cd1693319906d61)
#### Friday 2023-05-19 18:40:43 by SkyratBot

[MIRROR] De-holes holy arrows [MDB IGNORE] (#20985)

* De-holes holy arrows (#75184)

## About The Pull Request

Covers the 2-pixel hole in the holy arrow sprite with 1 alpha pixels to
prevent unintentional missed clicks.

## Why It's Good For The Game

It's annoying and a bad experience to think you clicked on a sprite but
actually landed on a tiny transparent hole and clicked nothing or the
object below the one you wanted.

## Changelog
:cl:
image: Holy arrows are now 15% less holy (You can no longer click on the
2-pixel hole in the arrowhead and unintentionally click the object below
the arrow instead.)
/:cl:

* De-holes holy arrows

---------

Co-authored-by: Thunder12345 <Thunder12345@users.noreply.github.com>

---
## [NewyearnewmeUwu/cmss13](https://github.com/NewyearnewmeUwu/cmss13)@[590bad4061...](https://github.com/NewyearnewmeUwu/cmss13/commit/590bad4061627b75b638c0f7c1fbd3cca84e43c1)
#### Friday 2023-05-19 18:41:07 by sleepynecrons

updates for landing zone sign sprites (#3180)

# About the pull request

Cleans up the palettes on the landing zone sign sprites and gives them a
fresh coat of paint (or blood). Not something most people will notice I
think but it's something I've been wanting to do.


# Explain why it's good for the game

gradients ugly


# Before and After
<details>
<summary>Click to see sprites</summary>


![osudodajs2](https://user-images.githubusercontent.com/106241650/235265980-e622b7da-8f79-4920-ba27-97d704c65550.gif)


![beforenafter](https://user-images.githubusercontent.com/106241650/235266004-0e46a574-9262-445f-98d9-4b19aa53a8fb.png)

</details>


# Changelog

:cl:
imageadd: new sprites for landing zone signs
imagedel: deleted old landing zone signs
/:cl:

---
## [jocca1985/evals](https://github.com/jocca1985/evals)@[ab5f7b2a89...](https://github.com/jocca1985/evals/commit/ab5f7b2a89bcf60e8e93adfb2c70688c6d6ffd44)
#### Friday 2023-05-19 19:14:53 by oscar-king

Counting bigrams in sentences (#302)

# Thank you for contributing an eval! ‚ô•Ô∏è

üö® Please make sure your PR follows these guidelines, __failure to follow
the guidelines below will result in the PR being closed automatically__.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access granted. üö®

__PLEASE READ THIS__:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject since GPT-4 is already capable of completing the
task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. We encourage partial PR's with
~5-10 example that we can then run the evals on and share the results
with you so you know how your eval does with GPT-4 before writing all
100 examples.

## Eval details üìë
### Eval name
Bigram Counting

### Eval description

Tests whether the model is able to count the frequency of bigrams in a
sentence.

### What makes this a useful eval?

This is a very simple task for humans and it's possibly slightly more
'difficult' than counting the occurrences of a single letter.

Bigram frequencies are used in applications ranging from rudimentary NLP
tasks to cryptography.

## Criteria for a good eval ‚úÖ

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] Include at least 100 high quality examples (it is okay to only
contribute 5-10 meaningful examples and have us test them with GPT-4
before adding all 100)

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure üèóÔ∏è

Your eval should
- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your yaml is registered at
`evals/registry/evals/{name}.jsonl`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist üëÄ

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (https://platform.openai.com/docs/usage-policies).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgement

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and high volume of submissions, we will not
be able to accept all submissions and thus not grant everyone who opens
a PR GPT-4 access. We know this is disappointing, but we hope to set the
right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access
granted.

### Submit eval

- [x] I have filled out all required fields in the evals PR form
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data 

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input":[{"role":"system","content":"You will be presented with a
sentence. The task is to count the frequency of the bigram 'ng'. After
reading the sentence tell me the number of times the bigram appeared by
saying 'X' where 'X' is the frequency."},{"role":"user","content":"I'm
worried by the fact that my daughter looks to the local carpet seller as
a role model."}],"ideal":"0"}
{"input":[{"role":"system","content":"You will be presented with a
sentence. The task is to count the frequency of the bigram 'ng'. After
reading the sentence tell me the number of times the bigram appeared by
saying 'X' where 'X' is the frequency."},{"role":"user","content":"He
found rain fascinating yet unpleasant."}],"ideal":"1"}
{"input":[{"role":"system","content":"You will be presented with a
sentence. The task is to count the frequency of the bigram 'ng'. After
reading the sentence tell me the number of times the bigram appeared by
saying 'X' where 'X' is the frequency."},{"role":"user","content":"The
near-death experience brought new ideas to light."}],"ideal":"0"}
{"input":[{"role":"system","content":"You will be presented with a
sentence. The task is to count the frequency of the bigram 'ng'. After
reading the sentence tell me the number of times the bigram appeared by
saying 'X' where 'X' is the
frequency."},{"role":"user","content":"Separation anxiety is what
happens when you can't find your phone."}],"ideal":"0"}
{"input":[{"role":"system","content":"You will be presented with a
sentence. The task is to count the frequency of the bigram 'ng'. After
reading the sentence tell me the number of times the bigram appeared by
saying 'X' where 'X' is the frequency."},{"role":"user","content":"He
realized there had been several deaths on this road, but his concern
rose when he saw the exact number."}],"ideal":"0"}
  ```
</details>

---
## [jocca1985/evals](https://github.com/jocca1985/evals)@[b170a21cf3...](https://github.com/jocca1985/evals/commit/b170a21cf32c47d841f64ec110cfd6796ec3f89a)
#### Friday 2023-05-19 19:14:53 by Sam Ennis

Computer Science Theory (#83)

# Thank you for contributing an eval! ‚ô•Ô∏è

üö® Please make sure your PR follows these guidelines, __failure to follow
the guidelines below will result in the PR being closed automatically__.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access granted. üö®

__PLEASE READ THIS__:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject since GPT-4 is already capable of completing the
task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. We encourage partial PR's with
~5-10 example that we can then run the evals on and share the results
with you so you know how your eval does with GPT-4 before writing all
100 examples.

## Eval details üìë
### Eval name
Computer Science based questions

### Eval description

Testing the models ability to answer multiple choice computer science
questions correctly

### What makes this a useful eval?

Tests whether it has the ability to answer time complexity, binary tree,
algorithmic computer science calculations.

## Criteria for a good eval ‚úÖ

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [X] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [X] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [X] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [ ] Include at least 100 high quality examples (it is okay to only
contribute 5-10 meaningful examples and have us test them with GPT-4
before adding all 100)

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure üèóÔ∏è

Your eval should
- [X] Check that your data is in `evals/registry/data/{name}`
- [X] Check that your yaml is registered at
`evals/registry/evals/{name}.jsonl`
- [X] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist üëÄ

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (https://platform.openai.com/docs/usage-policies).

- [X] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the merged pull request.

- [X] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgement

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and high volume of submissions, we will not
be able to accept all submissions and thus not grant everyone who opens
a PR GPT-4 access. We know this is disappointing, but we hope to set the
right expectation before you open this PR.

- [X] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access
granted.

### Submit eval

- [X] I have filled out all required fields in the evals PR form
- [x] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data 

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input":[{"role":"system","content":"Choose the best multiple choice
answer to this question. Reply ONLY with the single letter of the answer
you have chosen."},{"role":"user","content":"How many children does a
binary tree have? a) 2 b) any number of children c) 0 or 1 or 2 d) 0 or
1"}],"ideal":"c"}
{"input":[{"role":"system","content":"Choose the best multiple choice
answer to this question. Reply ONLY with the single letter of the answer
you have chosen."},{"role":"user","content":"What is/are the
disadvantages of implementing tree using normal arrays? a) difficulty in
knowing children nodes of a node b) difficult in finding the parent of a
node c) have to know the maximum number of nodes possible before
creation of trees d) difficult to implement"}],"ideal":"c"}
{"input":[{"role":"system","content":"Choose the best multiple choice
answer to this question. Reply ONLY with the single letter of the answer
you have chosen."},{"role":"user","content":"What must be the ideal size
of array if the height of tree is ‚Äòl‚Äô? a) (2^l)-1 b) l-1 c) l d)
2l"}],"ideal":"a"}
{"input":[{"role":"system","content":"Choose the best multiple choice
answer to this question. Reply ONLY with the single letter of the answer
you have chosen."},{"role":"user","content":"What are the children for
node ‚Äòw‚Äô of a complete-binary tree in an array representation? a) 2w and
2w+1 b) 2+w and 2-w c) w+1/2 and w/2 d) w-1/2 and w+1/2"}],"ideal":"a"}
{"input":[{"role":"system","content":"Choose the best multiple choice
answer to this question. Reply ONLY with the single letter of the answer
you have chosen."},{"role":"user","content":"What is the parent for a
node ‚Äòw‚Äô of a complete binary tree in an array representation when w is
not 0? a) floor(w-1/2) b) ceil(w-1/2) c) w-1/2 d) w/2"}],"ideal":"a"}
{"input":[{"role":"system","content":"Choose the best multiple choice
answer to this question. Reply ONLY with the single letter of the answer
you have chosen."},{"role":"user","content":"If the tree is not a
complete binary tree then what changes can be made for easy access of
children of a node in the array? a) every node stores data saying which
of its children exist in the array b) no need of any changes continue
with 2w and 2w+1, if node is at i c) keep a seperate table telling
children of a node d) use another array parallel to the array with
tree"}],"ideal":"a"}
  ```
</details>

---
## [jocca1985/evals](https://github.com/jocca1985/evals)@[b5da073c21...](https://github.com/jocca1985/evals/commit/b5da073c215c6453b99269a6dab2dca5454f04dd)
#### Friday 2023-05-19 19:14:53 by somerandomguyontheweb

Add Belarusian lexicon eval (#372)

# Thank you for contributing an eval! ‚ô•Ô∏è

üö® Please make sure your PR follows these guidelines, __failure to follow
the guidelines below will result in the PR being closed automatically__.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access granted. üö®

__PLEASE READ THIS__:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject since GPT-4 is already capable of completing the
task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. We encourage partial PR's with
~5-10 example that we can then run the evals on and share the results
with you so you know how your eval does with GPT-4 before writing all
100 examples.

## Eval details üìë
### Eval name

belarusian-lexicon

### Eval description

Test the model's ability to distinguish between existing and
hallucinated Belarusian words.

### What makes this a useful eval?

While the multilingual capability of recent GPT models is impressive,
there is still room for improvement. Many human languages are lagging
far behind English in terms of the model's ability to answer questions
and produce coherent texts in these languages, and the model's
"knowledge" of their lexicon and grammar is, to some extent,
hallucinated. One example is Belarusian, an East Slavic language spoken
by several million people. In my experience with ChatGPT, when the model
is prompted in Belarusian, its responses are sometimes ungrammatical or
semantically incoherent, and very often they contain made-up words ‚Äì a
possible sign of overgeneralization based on Russian and Ukrainian data,
which are much more
[abundant](https://commoncrawl.github.io/cc-crawl-statistics/plots/languages)
on the web than Belarusian.

This eval contains 150 pairs of single-word prompts: one item in each
pair is a non-word hallucinated by ChatGPT (either totally meaningless
in Belarusian or violating the language's orthographic and phonetic
rules), and another item is an actual Belarusian word with similar
spelling. The model's task is to distinguish between words and
non-words. ChatGPT tends to label most items as existing words,
therefore its accuracy appears to be around 50%, and the negative-class
F measure is very low. Any competent speaker of Belarusian would perform
much better, and a language-specific tool, such as [this spell
checker](https://corpus.by/SpellChecker) or [this grammatical
database](https://bnkorpus.info/grammar.en.html) of Belarusian (also
available for
[download](https://github.com/Belarus/GrammarDB/releases)), would
flawlessly identify non-words.

## Criteria for a good eval ‚úÖ

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] Include at least 100 high quality examples (it is okay to only
contribute 5-10 meaningful examples and have us test them with GPT-4
before adding all 100)

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

This eval an attempt to point out specific deficiencies in the model's
ability to handle a lower-resource language (Belarusian). As such, it
might not only benchmark future refinements of Belarusian language
capability in the GPT models, but also serve as an instructuve example
for other language communities.

## Eval structure üèóÔ∏è

Your eval should
- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your yaml is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist üëÄ

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (https://platform.openai.com/docs/usage-policies).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgement

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and high volume of submissions, we will not
be able to accept all submissions and thus not grant everyone who opens
a PR GPT-4 access. We know this is disappointing, but we hope to set the
right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access
granted.

### Submit eval

- [x] I have filled out all required fields in the evals PR form
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data 

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content": "You will be prompted with a
single word. Does this word exist in Belarusian language? Answer Y or
N."}, {"role": "user", "content": "–∞–±–≤—è–∑–∫–æ—é"}], "ideal": "N"}
{"input": [{"role": "system", "content": "You will be prompted with a
single word. Does this word exist in Belarusian language? Answer Y or
N."}, {"role": "user", "content": "–∞–±–≤—è–∑–∫–∞—é"}], "ideal": "Y"}
{"input": [{"role": "system", "content": "You will be prompted with a
single word. Does this word exist in Belarusian language? Answer Y or
N."}, {"role": "user", "content": "–∞–±–ª–∞—Å—Ü—ñ"}], "ideal": "N"}
{"input": [{"role": "system", "content": "You will be prompted with a
single word. Does this word exist in Belarusian language? Answer Y or
N."}, {"role": "user", "content": "–≤–æ–±–ª–∞—Å—Ü—ñ"}], "ideal": "Y"}
{"input": [{"role": "system", "content": "You will be prompted with a
single word. Does this word exist in Belarusian language? Answer Y or
N."}, {"role": "user", "content": "–∞–±–º—è–Ω—É"}], "ideal": "N"}
{"input": [{"role": "system", "content": "You will be prompted with a
single word. Does this word exist in Belarusian language? Answer Y or
N."}, {"role": "user", "content": "–∞–±–º–µ–Ω—É"}], "ideal": "Y"}
{"input": [{"role": "system", "content": "You will be prompted with a
single word. Does this word exist in Belarusian language? Answer Y or
N."}, {"role": "user", "content": "–∞–±–æ—û—è–∑–∞–∫"}], "ideal": "N"}
{"input": [{"role": "system", "content": "You will be prompted with a
single word. Does this word exist in Belarusian language? Answer Y or
N."}, {"role": "user", "content": "–∞–±–∞–≤—è–∑–∞–∫"}], "ideal": "Y"}
{"input": [{"role": "system", "content": "You will be prompted with a
single word. Does this word exist in Belarusian language? Answer Y or
N."}, {"role": "user", "content": "–∞–¥–Ω–∞—Å—ñ–Ω—å–∫—ñ—Ö"}], "ideal": "N"}
{"input": [{"role": "system", "content": "You will be prompted with a
single word. Does this word exist in Belarusian language? Answer Y or
N."}, {"role": "user", "content": "–∞–¥–Ω—é—Å–µ–Ω—å–∫—ñ—Ö"}], "ideal": "Y"}
  ```
</details>

---
## [JohnFulpWillard/tgstation](https://github.com/JohnFulpWillard/tgstation)@[1a918a2e14...](https://github.com/JohnFulpWillard/tgstation/commit/1a918a2e1411f58e5a90f587a92daebebb9ac395)
#### Friday 2023-05-19 19:38:34 by Jacquerel

Golem Rework (#74197)

This PR implements this design document:
https://hackmd.io/@Y6uzGFDGSXKRaWDNicSiEg/BkRr176st
Put briefly, this will remove every existing golem subtype and
consolidate golems into a single species with cool new sprites.
NOT implemented from that PR is the ability to eat Telecrystals, I
couldn't come up with an appropriate visual that can stack with the
existing ones, but that should be a reasonably trivial add for a future
artist & developer.

New Golems have a food-based mechanic where their hunger decays pretty
quickly and can only be replenished by eating minerals. They start
moving slower as they get hungrier, until eventually they become
completely immobilised and need to be rescued.
Eating different kinds of minerals will visually change your sprite and
give you a special effect in a similar way to old golems, but temporary.
While transformed, you can't eat any other kind of mineral which would
transform you (but can still consume glass).
To see the full list of effects, look at the hackmd above.

In service of these sprites working I have refactored the
`species/offset_features` feature by killing it and delegating that
responsibility to limbs instead. Rather than applying an offset to items
due to your species, it is due to your weird head or arms. This makes
overall more sense to me, but it inflates the code changes in this PR
somewhat.
It doesn't make a lot of sense to atomise unfortunately because that
code also seemed to be entirely unused until I tried to use it in this
PR, so you wouldn't be able to tell if my changes broke anything. I
might make a downstream sad by doing this.

All of the actual numbers in this PR are made up and only loosely
tested, it will need some testmerges to gather feedback about whether it
sucks or not.

Other relevant changes:
I reworked how bioscrambling works based off bodypart bodytypes, to
automatically exclude golem limbs in either direction. There's really no
way to have those work on humans or vice versa. Organs still fly though.

---
## [unrealircd/unrealircd](https://github.com/unrealircd/unrealircd)@[3652940c2c...](https://github.com/unrealircd/unrealircd/commit/3652940c2ca7c8000253e26cfb9fe5c1abaf97bd)
#### Friday 2023-05-19 19:47:43 by Bram Matthys

Add set::anti-flood::<secgroup>::max-channels-per-user setting to override
the default set::max-channels-per-user (also called set::maxchannelsperuser).

This way you can give known-users a higher max-channels-per-user,
or even a special security group for trusted users (that you may
already have given a more lax flood setting and lower lag-penalty
etc. etc. so that fits in nicely)

And yeah this also:
* Makes it both in set and the anti-flood block accept both
  maxchannelsperuser and max-channels-per-user.
* Removes old MAXCHANNELS= in 005, as we already have CHANLIMIT=
This does not:
* Re-announce the 005 CHANLIMIT= if someone transitions from a security
  group with a different max-channels-per-user. We don't do that for
  IRCOps either, and I think no IRCd does that actually...
  To be honest i wonder if sending the limit in 005 is useful at all,
  do client really track this and limit their GUI based on it?? Doubt it!

---
## [ItsSelis/CHOMPStation2](https://github.com/ItsSelis/CHOMPStation2)@[b1f52736ca...](https://github.com/ItsSelis/CHOMPStation2/commit/b1f52736ca4407110979e2c246ae002b89ed86ae)
#### Friday 2023-05-19 19:56:22 by Fluff

Loots, Loots, and More Loots

-Removed the gas in the phoron canisters, and added some chemdispensers in place of the sleeper
-Made the carbinter gun thing useable
-Hopefully made the pirate vessel worth visisting
-Changed the walls of the vox shuttle, adjusted the foes because the giant voxes just stop exsisting, and mercs should die quikly
-Slightly buffed red shuttle down loot.
-Buffed the loot of the blood church

---
## [ItsLJcool/YoshiCrafterEngine-LJ-Optimized](https://github.com/ItsLJcool/YoshiCrafterEngine-LJ-Optimized)@[a6949be499...](https://github.com/ItsLJcool/YoshiCrafterEngine-LJ-Optimized/commit/a6949be49903873489493a1ee06241cc9a7b3948)
#### Friday 2023-05-19 20:15:27 by voiddev

i fixed some shits
- later we use mods folder for now fuck you

---
## [Pickle-Coding/tgstation](https://github.com/Pickle-Coding/tgstation)@[835952ccf4...](https://github.com/Pickle-Coding/tgstation/commit/835952ccf42af58db7238a572d7df6a9b8b2afd7)
#### Friday 2023-05-19 20:24:50 by MrMelbert

Drunk slurring scales based on how drunk you are (#75459)

## About The Pull Request

The strength of the slurring effect drunkness applies on you now scales
based on how drunk you are.

Being "a little" drunk still changes your saymod, and makes you
occasionally slur your words...


![image](https://github.com/tgstation/tgstation/assets/51863163/1b21b359-a1f9-428a-8e10-d2028ac59728)

But being "a lot" drunk kicks it up to 11


![image](https://github.com/tgstation/tgstation/assets/51863163/9d593c80-75ff-4d02-8e7c-e48c738154bb)

Additionally, drunk slurring was separated into "generic slurring" and
"drunk slurring", the former which does not scale but less closely
resembles drunkness. Generic slurring is used in places such as
concussions, so this is an added bonus.

As a result of the split, I had to update mind restoration. Now it heals
all types of slurring, which does include cult slurs.

## Why It's Good For The Game

I, and many other people, always found it very annoying when you became
completely illegible from taking one sip of a drink. This seeks to amend
that by making low levels of drunkness still for the most part be
legible and sane. Average drunkness is roughly the same / equal to the
old slurring effect, while "very drunk" is even more illegible and silly
(which I find funny).

This has the added bonus of separating out "drunk slurring" and "generic
slurring", allowing effects to slur your words without going full ham on
drunkness (burping and "huhh"s).

## Changelog

:cl: Melbert
add: When you are drunk, the strength of your slurring now varies based
on how drunk you are. Being "a little drunk" only rarely slurs your
words, being average drunk is the same as the old effect, while being
very drunk now slurs your words even more.
add: Some non-alcohol sources of slurring, such as concussions, now give
"generic slurring" rather than "drunk slurring", which less resemble
being drunk (ie, no burping).
add: Mind restoration now heals ALL slurring, rather than only drunk
slurring (which includes cult / heretic slurring).
/:cl:

---
## [Rhials/tgstation](https://github.com/Rhials/tgstation)@[2845c985fa...](https://github.com/Rhials/tgstation/commit/2845c985fab04b0de1f7615799a260527af30822)
#### Friday 2023-05-19 20:53:57 by Rhials

Adds a revolutionary conversion stinger (#75002)

<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may
not be viewable. -->
<!-- You can view Contributing.MD for a detailed description of the pull
request process. -->

## About The Pull Request

Adds an antagonist gain stinger for Revolutionaries, created with
inspiration from the obsessed/traitor conversion sounds.


https://user-images.githubusercontent.com/28870487/235028674-170a4f9e-a873-4938-a700-536f005e539f.mp4

Raw audio:


https://cdn.discordapp.com/attachments/440978216484732934/1101964419203862548/revolutionary_tide.ogg

_A distant, hypnotic whistling. The heavy footfalls and clamoring voices
of an approaching crowd. The unstoppable revolutionary tide breaks its
waves upon an unsuspecting station._

I wanted to try and make something that felt like it fit in with the
other antagonist stingers we already have. Let me know what you think!

<!-- Describe The Pull Request. Please be sure every change is
documented or this can delay review and even discourage maintainers from
merging your PR! -->

## Why It's Good For The Game

Gives a bit more flavor, and helps set the mood for the upcoming
bloodbath.

<!-- Argue for the merits of your changes and how they benefit the game,
especially if they are controversial and/or far reaching. If you can't
actually explain WHY what you are doing will improve the game, then it
probably isn't good for the game in the first place. -->

## Changelog

<!-- If your PR modifies aspects of the game that can be concretely
observed by players or admins you should add a changelog. If your change
does NOT meet this description, remove this section. Be sure to properly
mark your PRs to prevent unnecessary GBP loss. You can read up on GBP
and it's effects on PRs in the tgstation guides for contributors. Please
note that maintainers freely reserve the right to remove and add tags
should they deem it appropriate. You can attempt to finagle the system
all you want, but it's best to shoot for clear communication right off
the bat. -->

:cl:
sound: Revolutionaries now have their own stinger that plays upon
becoming that antagonist.
/:cl:

<!-- Both :cl:'s are required for the changelog to work! You can put
your name to the right of the first :cl: if you want to overwrite your
GitHub username as author ingame. -->
<!-- You can use multiple of the same prefix (they're only used for the
icon ingame) and delete the unneeded ones. Despite some of the tags,
changelogs should generally represent how a player might be affected by
the changes rather than a summary of the PR's contents. -->

---
## [TheVekter/tgstation](https://github.com/TheVekter/tgstation)@[b1716732b0...](https://github.com/TheVekter/tgstation/commit/b1716732b058121e86c60700fb9d1d8f4f9a6b3a)
#### Friday 2023-05-19 21:05:11 by Cheshify

The North Star Expeditionary Vessel - A Second Wind (#74371)

## About The Pull Request
A new map for TGstation, in the works! It has 4 fucking Z levels, a
massive expansive maintenance with unique designs, and some unique code
features in the works.

To Do:
- [x] Update the Map to Modern TG
- [x] Local Tests
- [x] Work on Map Optimizations
- [x] Run Live Tests

Fikou has greatly helped with creating an important flavour aspect of
this map, Trek Uniforms on anyone who joins! See the forum thread for
more. This includes the framework for innate station traits, station
traits loaded as long as it's in a map's json

Here's the forum dev thread there are screenshots there.
https://tgstation13.org/phpBB/viewtopic.php?p=657252#p657252

### Mapping March
Ckey to receive rewards: Cheshify

## Why It's Good For The Game
So, this is the North Star. An effort taking multiple mappers and of 9~
months of hard work. This map was not initially designed for TGstation,
but always designed for TGstation code. The process of retooling the map
for TGstation was an absolute joy and I feel like the map definitely has
it's niche as a massive and unique experience for it's players.

I adore this map, it's gorgeous, has a unique aesthetic, and a number of
very funny interactions with multi-Z. The PR comes packed with unique
mechanics for future mappers (innate station traits!), a number of
map-fitting shuttles, and a fun spacefaring uniform gimmick for the
crew.

**This is my second attempt at bringing this map into rotation. It was
initially closed due to concerns about maptick and performance, as I
wasn't willing to push for a map to be added to the repository if it
didn't function to my own standards. I've been informed by a number of
coders far better than I that optimizations are arriving and enroute, so
I think it's time to dust her off and set sail for another journey.**

**Quick Disclaimer: Due to some design decisions disagreed upon by the
headcoder team and myself, the map will not be featuring unique
roundstart uniforms, and despite my design intentions, the innate
station trait features will be shelved for now.**

## Changelog
:cl: Cheshify, Fikou, Blue-Berry, Zytolg, InfiniteGalaxies, Striders,
Sylphet, Riggle, Soal, Andry, Crit, Deranging, and Pumpkin0.
add: Nanotrasen's Newest Exploratory Vessel is now available! Meet the
North Star!
add: More landmines, and a landmine random spawner.
add: energy barriers now have a regenerative subtype, fit for permanent
installations.
code: Raised the number of possible level render to 4, check your
preferences if needed to be reduced.
/:cl:

---------

Co-authored-by: Fikou <23585223+Fikou@users.noreply.github.com>
Co-authored-by: Mothblocks <35135081+Mothblocks@users.noreply.github.com>

---
## [Iajret/Skyrat-tg](https://github.com/Iajret/Skyrat-tg)@[dad84df983...](https://github.com/Iajret/Skyrat-tg/commit/dad84df983a5192877e82200666af3e7b2631552)
#### Friday 2023-05-19 21:41:44 by SkyratBot

[MIRROR] Makes a whole bunch of wooden objects flammable [MDB IGNORE] (#20670)

* Makes a whole bunch of wooden objects flammable (#74827)

## About The Pull Request

This whole PR started because I realized that baseball bats are not
actually flammable which I found weird, then I looked at a whole bunch
of other stuff that really should be flammable but also isn't.

## Why It's Good For The Game

Makes wooden objects behave slightly more consistently? Honestly, most
of these seem like oversights to me.

## Changelog

:cl:
balance: The following structures are now flammable: Picture frame,
fermenting barrel, drying rack, sandals, painting frames, paintings,
spirit board, notice board, dresser, displaycase chassis, wooden
barricade
balance: The following items are now flammable: Baseball bat, rolling
pin, mortar, coffee condiments display, sandals, wooden hatchet, gohei,
popsicle stick, rifle stock
/:cl:

* Makes a whole bunch of wooden objects flammable

---------

Co-authored-by: ChungusGamer666 <82850673+ChungusGamer666@users.noreply.github.com>

---
## [TheWazzzzzup/We-Are-Drunk](https://github.com/TheWazzzzzup/We-Are-Drunk)@[db58644e43...](https://github.com/TheWazzzzzup/We-Are-Drunk/commit/db58644e431a5fcb5be4288eae0e69e394dd1921)
#### Friday 2023-05-19 22:23:33 by EladReuven

HAHAHHAHAA IT FUCKING WORKS

compares ingredients inside Cup to recipes that start with the same base.

yes i know its like a million nested loops but fuck you im tired, ill fix it next push

---
## [jonathan3692bf/witches-of-wubb](https://github.com/jonathan3692bf/witches-of-wubb)@[aa55b1297b...](https://github.com/jonathan3692bf/witches-of-wubb/commit/aa55b1297bc3595facc2e4672e23655e16ccc2cb)
#### Friday 2023-05-19 22:56:00 by Jonathan

Rename music database file
diff --git a/backend/utils/get-clip-from-rfid.ts b/backend/utils/get-clip-from-rfid.ts
index c154d43..74ccb9b 100644
--- a/backend/utils/get-clip-from-rfid.ts
+++ b/backend/utils/get-clip-from-rfid.ts
@@ -10,14 +10,7 @@ export const ClipNameToInfoMap: ClipNameToInfoMapType = {};

 try {
   logger.info('Trying to read RFID CSV file');
-  csv = fs.readFileSync(
-    path.join(
-      process.cwd(),
-      '../src/assets/',
-      'BSS 23 Master Spreadsheet Budget, Inventory, Schedule, ETC - Music Database.csv',
-    ),
-    'utf-8',
-  );
+  csv = fs.readFileSync(path.join(process.cwd(), '../src/assets/', 'Music Database.csv'), 'utf-8');
   const results = Papa.parse(csv, {
     header: true,
     transformHeader: (header) => header.replace(':', ''),
diff --git a/src/assets/BSS 23 Master Spreadsheet Budget, Inventory, Schedule, ETC - Music Database.csv b/src/assets/BSS 23 Master Spreadsheet Budget, Inventory, Schedule, ETC - Music Database.csv
deleted file mode 100644
index b1c9b57..0000000
--- a/src/assets/BSS 23 Master Spreadsheet Budget, Inventory, Schedule, ETC - Music Database.csv
+++ /dev/null
@@ -1,62 +0,0 @@
-RFID,Asset ID,Ingredient Name / Description,Artist,Song Title,Clip Name,Clip Type (e.g. Vocals),Instrument,Key,Major or Minor,Key Numerical,BPM,Icon / Asset Name,Compatible Vox Clips,Compatible Mel Clips,Compatible Bass Clips,Compatible Drum Clips
-,1,,Billie Eilish,Bad Guy,*Bad Guy  vox 9B 135,Vox,Vox,9B,Major,9,135,magic_icon_vocals_2fbe131a-4bb1-47ab-977f-bd0612006090.png,,,,
-,2,,Billie Eilish,Bad Guy,*Bad Guy synth 9B 135bpm,Melody,Synth,9B,Major,9,135,magic_icon_meoldy_aea486d6-d900-4d6a-848e-e259ede48fdd.png,,,,
-,3,,Billie Eilish,Bad Guy,*Bad Guy Bass 9B 135 bpm,Bass,Synth,9B,Major,9,135,magic_icon_bass_342c1a64-2dd6-40ac-b51d-003cabe29068.png,,,,
-,4,,Billie Eilish,Bad Guy,*Bad Guy Drums 9B 135bpm,Drums,Drums (full kit),9B,Major,9,135,magic_icon_drum_5c807703-c0f6-40f2-b58f-34d18c9bba9c.png,,,,
-,5,,Disturbed,Down With the Sickness,*Disturbed - DWTS vox 5B 90,Vox,Vox,5B,Major,5,90,,,,,
-,6,,Disturbed,Down With the Sickness,*DWTS guitar 5B 90bpm,Melody,Electric Guitar,5B,Major,5,90,,,,,
-,7,,Disturbed,Down With the Sickness,*Disturbed DWTS Bass 5B 90bpm,Bass,Bass,5B,Major,5,90,,,,,
-,8,,Disturbed,Down With the Sickness,*DWTS Drums 5B 90,Drums,Vox,5B,Major,5,90,,,,,
-,9,,MGMT,Kids,*MGMT - Kids vox 11B 123,Vox,Vox,11B,Major,11,123,,,,,
-,10,,MGMT,Kids,*MGMT - Kids Synth 11B 123 bpm | 11A,Melody,Synth,11B,Major,11,123,,,,,
-,11,,MGMT,Kids,*MGMT - Kids Synth Bass 11B 123bpm,Bass,Synth,11B,Major,11,123,,,,,
-,12,,MGMT,Kids,*MGMT - Kids Drums 11B 123bpm | 11A,Drums,Drums (standard kit),11B,Major,11,123,,,,,
-,13,,Tha Trickaz ,Little Bombay,*Tha Trickaz - Little Bombay vox 7B 130,Vox,Vox,7B,Major,7,130,,,,,
-,14,,Tha Trickaz ,Little Bombay,*Little Bombay Sitar 7B 130bpm,Melody,Sitar,7B,Major,7,130,,,,,
-,15,,Tha Trickaz ,Little Bombay,*Little Bombay Drums 7B 130bpm,Drums,Drums (standard kit),7B,Major,7,130,,,,,
-,16,,Vanilla Ice,Ice Ice Baby,*Ice Ice vox 10B 116,Vox,Vox,10B,Major,10,116,,,,,
-,17,,Vanilla Ice,Ice Ice Baby,*Ice Ice synth 10B 116 ,Melody,Synth,10B,Major,10,116,,,,,
-,18,,Vanilla Ice,Ice Ice Baby,*Ice Ice bass 10B 116 ,Bass,Bass,10B,Major,10,116,,,,,
-,19,,Vanilla Ice,Ice Ice Baby,*Ice Ice Drums 10B 116,Drums,Drums (standard kit),10B,Major,10,116,,,,,
-,20,,Clozee,Harmony,*Clozee Harmony Vox 4A 109,Vox,Vox,4A,Minor,4,109,,,,,
-,21,,Clozee,Harmony,*Clozee Harmony Guitars 4A 109,Melody,Acoustic Guitar,4A,Minor,4,109,,,,,
-,22,,Clozee,Harmony,*Clozee Harmony Base 4A 109,Bass,Synth,4A,Minor,4,109,,,,,
-,23,,Clozee,Harmony,*Clozee Harmony Drums 4A 109,Drums,Drums (standard kit),4A,Minor,4,109,,,,,
-,24,,Katy Perry,Dark Horse,*KP Dark Horse Vox 3A 132,Vox,Vox,3A,Minor,3,132,magic_icon_vocals_d90a7701-4502-47ca-920c-32088e82b7b0.png,,,,
-,25,,Katy Perry,Dark Horse,*KP Dark Horse Synth 132,Melody,Synth,3A,Minor,3,132,magic_icon_meoldy_aeed6b49-cdbd-4e9b-8e23-b04f2af52a50.png,,,,
-,26,,Katy Perry,Dark Horse,*KP Dark Horse Base 132,Bass,Synth,3A,Minor,3,132,magic_icon_bass_ea915e0c-9354-4e9c-9972-04a1de908890.png,,,,
-,27,,Katy Perry,Dark Horse,*KP Dark Horse Drums 132 | 3A,Drums,Drums (standard kit),3A,Minor,3,132,magic_icon_drum_f83aa38c-5ab9-4b2f-9387-cf17f37ec3e2.png,,,,
-,28,,KSHMR ,Song Of War,*War vox 4A 109,Vox,Vox,4A,Minor,4,109,,,,,
-,29,,KSHMR ,Song Of War,*War guitar 4A 109,Melody,Synth,4A,Minor,4,109,,,,,
-,30,,KSHMR ,Song Of War,*War Base 4A 109,Bass,Synth,4A,Minor,4,109,,,,,
-,31,,KSHMR ,Song Of War,*War Drums 4A 109,Drums,Drums (standard kit),4A,Minor,4,109,,,,,
-,32,,Paramore,Misery Business,*Mizbiz vox 86 3B,Vox,Vox,3B,Major,3,86,,,,,
-,33,,Paramore,Misery Business,*Mizbiz guit 86 3B,Melody,Electric Guitar,3B,Major,3,86,,,,,
-,34,,Paramore,Misery Business,*Mizbiz bass 86 3B,Bass,Bass,3B,Major,3,86,,,,,
-,35,,Paramore,Misery Business,*Mizbiz Drums 86 3B,Drums,Drums (standard kit),3B,Major,3,86,,,,,
-,36,,Evanescence,Bring Me To Life,*BMTL vox 96 9A,Vox,Vox,9A,Minor,9,96,,,,,
-,37,,Evanescence,Bring Me To Life,*BM2L backup vox 96 9A,Melody,"Piano, Vox, Strings",9A,Minor,9,96,,,,,
-,38,,Evanescence,Bring Me To Life,*BMTL Base 96 9A,Bass,Bass,9A,Minor,9,96,,,,,
-,39,,Evanescence,Bring Me To Life,*BMTL Drums 2 96 9A,Drums,Drums (standard kit),9A,Minor,9,96,,,,,
-,40,,Gorillaz,Feel Good Inc,*Feel Good Vox 139 2B,Vox,Vox,2B,Major,2,139,,,,,
-,41,,Gorillaz,Feel Good Inc,*Feel Good Guit 139 2B,Melody,Electric Guitar,2B,Major,2,139,,,,,
-,42,,Gorillaz,Feel Good Inc,*Feel Good Base 139 2B,Bass,Bass,2B,Major,2,139,,,,,
-,43,,Gorillaz,Feel Good Inc,*Feel Good Drums 139 2B,Drums,Drums (standard kit),2B,Major,2,139,,,,,
-,44,,?,?? Babylon,*Babylon Vox 4A 130,Vox,Vox,4A,Minor,4,130,,,,,
-,45,,?,Babylon,*Babylon Oud 130 4A,Melody,Oud,4A,Minor,4,130,,,,,
-,46,,?,Babylon,*Babylon Bass 130 4A,Bass,Bass,4A,Minor,4,130,,,,,
-,47,,?,Babylon,*Babylon Drums 130 4A,Drums,808,4A,Minor,4,130,,,,,
-,48,,Iniko,Jericho,*Jericho Vox  154 bpm 7A,Vox,Vox,7A,Minor,7,154,,,,,
-,49,,Orgy,Blue Monday,*Orgy BM vox 4B 130,Vox,Vox,4B,Major,4,130,,,,,
-,50,,Orgy,Blue Monday,*Orgy BM mel 4B 130,Melody,Electric Guitar,4B,Major,4,130,,,,,
-,51,,Orgy,Blue Monday,*Orgy BM base 4B 130,Bass,Synth,4B,Major,4,130,,,,,
-,52,,Orgy,Blue Monday,*Orgy BM drums 4B 130,Drums,Drums (standard kit),4B,Major,4,130,,,,,
-,53,,Odesza ,Say my name,*Odesza SMN vox 11A 115,Vox,Vox,11A,Minor,11,115,,,,,
-,54,,Odesza ,Say my name,*Odesza SMN mel 11A 115,Melody,Synth,4B,Major,4,,,,,,
-,55,,Odesza ,Say my name,*Odesza SMN bass 11A 115,Bass,Synth,4B,Major,4,,,,,,
-,56,,Odesza ,Say my name,Odesza SMN drums 11A 115,Drums,Drums (standard kit),4B,Major,4,,,,,,
-,,,,,,,,,TBD,,,,,,,
-,,,,,,,,,TBD,,,,,,,
-,,,,,,,,,TBD,,,,,,,
-,,,,,,,,,TBD,,,,,,,
-,,,,,,,,,TBD,,,,,,,
\ No newline at end of file
diff --git a/src/assets/Music Database.csv b/src/assets/Music Database.csv
new file mode 100644
index 0000000..046a6a2
--- /dev/null
+++ b/src/assets/Music Database.csv
@@ -0,0 +1,62 @@
+RFID,Asset ID,Ingredient Name / Description,Artist,Song Title,Clip Name,Clip Type (e.g. Vocals),Instrument,Key,Major or Minor,Key Numerical,BPM,Icon / Asset Name,Compatible Vox Clips,Compatible Mel Clips,Compatible Bass Clips,Compatible Drum Clips
+,1,,Billie Eilish,Bad Guy,Bad Guy  vox 9B 135,Vox,Vox,9B,Major,9,135,magic_icon_vocals_2fbe131a-4bb1-47ab-977f-bd0612006090.png,"[""Ice Ice vox 10B 116 | 1A""]","[""Ice Ice synth 10B 116""]","[""Bad Guy Bass 9B 135 bpm"",""Ice Ice bass 10B 116""]","[""Bad Guy Drums 9B 135bpm"",""Ice Ice Drums 10B 116 | 11A""]"
+,2,,Billie Eilish,Bad Guy,Bad Guy synth 9B 135bpm,Melody,Synth,9B,Major,9,135,magic_icon_meoldy_aea486d6-d900-4d6a-848e-e259ede48fdd.png,"[""Ice Ice vox 10B 116 | 1A""]","[""Ice Ice synth 10B 116""]","[""Ice Ice bass 10B 116""]","[""Bad Guy Drums 9B 135bpm"",""Ice Ice Drums 10B 116 | 11A""]"
+,3,,Billie Eilish,Bad Guy,Bad Guy Bass 9B 135 bpm,Bass,Synth,9B,Major,9,135,magic_icon_bass_342c1a64-2dd6-40ac-b51d-003cabe29068.png,"[""Ice Ice vox 10B 116 | 1A""]","[""Ice Ice synth 10B 116""]","[""Ice Ice bass 10B 116""]","[""Ice Ice Drums 10B 116 | 11A""]"
+,4,,Billie Eilish,Bad Guy,Bad Guy Drums 9B 135bpm,Drums,Drums (full kit),9B,Major,9,135,magic_icon_drum_5c807703-c0f6-40f2-b58f-34d18c9bba9c.png,,"[""DWTS guitar 5B 90bpm""]","[""Disturbed DWTS Bass 5B 90bpm""]","[""DWTS Drums 5B 90""]"
+,5,,Disturbed,Down With the Sickness,Disturbed - DWTS vox 5B 90,Vox,Vox,5B,Major,5,90,,,,"[""Disturbed DWTS Bass 5B 90bpm""]","[""DWTS Drums 5B 90""]"
+,6,,Disturbed,Down With the Sickness,DWTS guitar 5B 90bpm,Melody,Electric Guitar,5B,Major,5,90,,,,,"[""DWTS Drums 5B 90""]"
+,7,,Disturbed,Down With the Sickness,Disturbed DWTS Bass 5B 90bpm,Bass,Bass,5B,Major,5,90,,,,,
+,8,,Disturbed,Down With the Sickness,DWTS Drums 5B 90,Drums,Vox,5B,Major,5,90,,"[""Ice Ice vox 10B 116 | 1A""]","[""MGMT - Kids Synth 11B 123 bpm"",""Ice Ice synth 10B 116""]","[""MGMT - Kids Synth Bass 11B 123bpm"",""Ice Ice bass 10B 116""]","[""MGMT - Kids Drums 11B 123bpm"",""Ice Ice Drums 10B 116 | 11A""]"
+,9,,MGMT,Kids,MGMT - Kids vox 11B 123,Vox,Vox,11B,Major,11,123,,"[""Ice Ice vox 10B 116 | 1A""]","[""Ice Ice synth 10B 116""]","[""MGMT - Kids Synth Bass 11B 123bpm"",""Ice Ice bass 10B 116""]","[""MGMT - Kids Drums 11B 123bpm"",""Ice Ice Drums 10B 116 | 11A""]"
+,10,,MGMT,Kids,MGMT - Kids Synth 11B 123 bpm,Melody,Synth,11B,Major,11,123,,"[""Ice Ice vox 10B 116 | 1A""]","[""Ice Ice synth 10B 116""]","[""Ice Ice bass 10B 116""]","[""MGMT - Kids Drums 11B 123bpm"",""Ice Ice Drums 10B 116 | 11A""]"
+,11,,MGMT,Kids,MGMT - Kids Synth Bass 11B 123bpm,Bass,Synth,11B,Major,11,123,,"[""Ice Ice vox 10B 116 | 1A""]","[""Ice Ice synth 10B 116""]","[""Ice Ice bass 10B 116""]","[""Ice Ice Drums 10B 116 | 11A""]"
+,12,,MGMT,Kids,MGMT - Kids Drums 11B 123bpm,Drums,Drums (standard kit),11B,Major,11,123,,,"[""Little Bombay Sitar 7B 130bpm""]",,"[""Little Bombay Drums 7B 130bpm""]"
+,13,,Tha Trickaz ,Little Bombay,Tha Trickaz - Little Bombay vox 7B 130,Vox,Vox,7B,Major,7,130,,,,,"[""Little Bombay Drums 7B 130bpm""]"
+,14,,Tha Trickaz ,Little Bombay,Little Bombay Sitar 7B 130bpm,Melody,Sitar,7B,Major,7,130,,,,,
+,15,,Tha Trickaz ,Little Bombay,Little Bombay Drums 7B 130bpm,Drums,Drums (standard kit),7B,Major,7,130,,,"[""Ice Ice synth 10B 116""]","[""Ice Ice bass 10B 116""]","[""Ice Ice Drums 10B 116 | 11A""]"
+,16,,Vanilla Ice,Ice Ice Baby,Ice Ice vox 10B 116 | 1A,Vox,Vox,10B,Major,10,116,,,,"[""Ice Ice bass 10B 116""]","[""Ice Ice Drums 10B 116 | 11A""]"
+,17,,Vanilla Ice,Ice Ice Baby,Ice Ice synth 10B 116,Melody,Synth,10B,Major,10,116,,,,,"[""Ice Ice Drums 10B 116 | 11A""]"
+,18,,Vanilla Ice,Ice Ice Baby,Ice Ice bass 10B 116,Bass,Bass,10B,Major,10,116,,,,,
+,19,,Vanilla Ice,Ice Ice Baby,Ice Ice Drums 10B 116 | 11A,Drums,Drums (standard kit),10B,Major,10,116,,"[""War vox 4A 109""]","[""Clozee Harmony Guitars 4A 109 | 4A"",""War guitar 4A 109""]","[""Clozee Harmony Base 4A 109"",""War Base 4A 109""]","[""Clozee Harmony Drums 4A 109"",""War Drums 4A 109""]"
+,20,,Clozee,Harmony,Clozee Harmony Vox 4A 109 | 4A,Vox,Vox,4A,Minor,4,109,,"[""War vox 4A 109""]","[""War guitar 4A 109""]","[""Clozee Harmony Base 4A 109"",""War Base 4A 109""]","[""Clozee Harmony Drums 4A 109"",""War Drums 4A 109""]"
+,21,,Clozee,Harmony,Clozee Harmony Guitars 4A 109 | 4A,Melody,Acoustic Guitar,4A,Minor,4,109,,"[""War vox 4A 109""]","[""War guitar 4A 109""]","[""War Base 4A 109""]","[""Clozee Harmony Drums 4A 109"",""War Drums 4A 109""]"
+,22,,Clozee,Harmony,Clozee Harmony Base 4A 109,Bass,Synth,4A,Minor,4,109,,"[""War vox 4A 109""]","[""War guitar 4A 109""]","[""War Base 4A 109""]","[""War Drums 4A 109""]"
+,23,,Clozee,Harmony,Clozee Harmony Drums 4A 109,Drums,Drums (standard kit),4A,Minor,4,109,,"[""Babylon Vox 4A 130""]","[""KP Dark Horse Synth 132 | 3A"",""Babylon Oud 130""]","[""KP Dark Horse Base 132 | 3B"",""Babylon Bass 130 4A""]","[""KP Dark Horse Drums 132"",""Babylon Drums 130 4A""]"
+,24,,Katy Perry,Dark Horse,KP Dark Horse Vox 3A 132,Vox,Vox,3A,Minor,3,132,magic_icon_vocals_d90a7701-4502-47ca-920c-32088e82b7b0.png,"[""Babylon Vox 4A 130""]","[""Babylon Oud 130""]","[""KP Dark Horse Base 132 | 3B"",""Babylon Bass 130 4A""]","[""KP Dark Horse Drums 132"",""Babylon Drums 130 4A""]"
+,25,,Katy Perry,Dark Horse,KP Dark Horse Synth 132 | 3A,Melody,Synth,3A,Minor,3,132,magic_icon_meoldy_aeed6b49-cdbd-4e9b-8e23-b04f2af52a50.png,"[""Babylon Vox 4A 130""]","[""Babylon Oud 130""]","[""Babylon Bass 130 4A""]","[""KP Dark Horse Drums 132"",""Babylon Drums 130 4A""]"
+,26,,Katy Perry,Dark Horse,KP Dark Horse Base 132 | 3B,Bass,Synth,3A,Minor,3,132,magic_icon_bass_ea915e0c-9354-4e9c-9972-04a1de908890.png,"[""Babylon Vox 4A 130""]","[""Babylon Oud 130""]","[""Babylon Bass 130 4A""]","[""Babylon Drums 130 4A""]"
+,27,,Katy Perry,Dark Horse,KP Dark Horse Drums 132,Drums,Drums (standard kit),3A,Minor,3,132,magic_icon_drum_f83aa38c-5ab9-4b2f-9387-cf17f37ec3e2.png,,"[""War guitar 4A 109""]","[""War Base 4A 109""]","[""War Drums 4A 109""]"
+,28,,KSHMR ,Song Of War,War vox 4A 109,Vox,Vox,4A,Minor,4,109,,,,"[""War Base 4A 109""]","[""War Drums 4A 109""]"
+,29,,KSHMR ,Song Of War,War guitar 4A 109,Melody,Synth,4A,Minor,4,109,,,,,"[""War Drums 4A 109""]"
+,30,,KSHMR ,Song Of War,War Base 4A 109,Bass,Synth,4A,Minor,4,109,,,,,
+,31,,KSHMR ,Song Of War,War Drums 4A 109,Drums,Drums (standard kit),4A,Minor,4,109,,,"[""Mizbiz guit 86""]","[""Mizbiz bass 86""]","[""Mizbiz Drums 86""]"
+,32,,Paramore,Misery Business,Mizbiz vox 86,Vox,Vox,3B,Major,3,86,,,,"[""Mizbiz bass 86""]","[""Mizbiz Drums 86""]"
+,33,,Paramore,Misery Business,Mizbiz guit 86,Melody,Electric Guitar,3B,Major,3,86,,,,,"[""Mizbiz Drums 86""]"
+,34,,Paramore,Misery Business,Mizbiz bass 86,Bass,Bass,3B,Major,3,86,,,,,
+,35,,Paramore,Misery Business,Mizbiz Drums 86,Drums,Drums (standard kit),3B,Major,3,86,,,"[""BM2L backup vox 96""]","[""BMTL Base 96""]","[""BMTL Drums 96""]"
+,36,,Evanescence,Bring Me To Life,BMTL vox 96,Vox,Vox,9A,Minor,9,96,,,,"[""BMTL Base 96""]","[""BMTL Drums 96""]"
+,37,,Evanescence,Bring Me To Life,BM2L backup vox 96,Melody,"Piano, Vox, Strings",9A,Minor,9,96,,,,,"[""BMTL Drums 96""]"
+,38,,Evanescence,Bring Me To Life,BMTL Base 96,Bass,Bass,9A,Minor,9,96,,,,,
+,39,,Evanescence,Bring Me To Life,BMTL Drums 96,Drums,Drums (standard kit),9A,Minor,9,96,,,"[""Feel Good Guit 139""]","[""Feel Good Base 139""]","[""Feel Good Drums 139""]"
+,40,,Gorillaz,Feel Good Inc,Feel Good Vox 139,Vox,Vox,2B,Major,2,139,,,,"[""Feel Good Base 139""]","[""Feel Good Drums 139""]"
+,41,,Gorillaz,Feel Good Inc,Feel Good Guit 139,Melody,Electric Guitar,2B,Major,2,139,,,,,"[""Feel Good Drums 139""]"
+,42,,Gorillaz,Feel Good Inc,Feel Good Base 139,Bass,Bass,2B,Major,2,139,,,,,
+,43,,Gorillaz,Feel Good Inc,Feel Good Drums 139,Drums,Drums (standard kit),2B,Major,2,139,,,"[""Babylon Oud 130""]","[""Babylon Bass 130 4A""]","[""Babylon Drums 130 4A""]"
+,44,,?,?? Babylon,Babylon Vox 4A 130,Vox,Vox,4A,Minor,4,130,,,,"[""Babylon Bass 130 4A""]","[""Babylon Drums 130 4A""]"
+,45,,?,Babylon,Babylon Oud 130,Melody,Oud,4A,Minor,4,130,,,,,"[""Babylon Drums 130 4A""]"
+,46,,?,Babylon,Babylon Bass 130 4A,Bass,Bass,4A,Minor,4,130,,,,,
+,47,,?,Babylon,Babylon Drums 130 4A,Drums,808,4A,Minor,4,130,,,,,
+,48,,Iniko,Jericho,Jericho Vox  154 bpm,Vox,Vox,7A,Minor,7,154,,,"[""Orgy BM mel 4B 130""]","[""Orgy BM base 4B 130""]","[""Orgy BM drums 4B 130""]"
+,49,,Orgy,Blue Monday,Orgy BM vox 4B 130,Vox,Vox,4B,Major,4,130,,,,"[""Orgy BM base 4B 130""]","[""Orgy BM drums 4B 130""]"
+,50,,Orgy,Blue Monday,Orgy BM mel 4B 130,Melody,Electric Guitar,4B,Major,4,130,,,,,"[""Orgy BM drums 4B 130""]"
+,51,,Orgy,Blue Monday,Orgy BM base 4B 130,Bass,Synth,4B,Major,4,130,,,,,
+,52,,Orgy,Blue Monday,Orgy BM drums 4B 130,Drums,Drums (standard kit),4B,Major,4,130,,,,,
+,53,,Odesza ,Say my name,Odesza SMN vox 11A 115,Vox,Vox,11A,Minor,11,115,,,,"[""*Odesza SMN bass 11A 115""]","[""Odesza SMN drums 11A 115""]"
+,54,,Odesza ,Say my name,Odesza SMN mel 11A 115,Melody,Synth,4B,Major,4,,,,,,"[""Odesza SMN drums 11A 115""]"
+,55,,Odesza ,Say my name,Odesza SMN bass 11A 115,Bass,Synth,4B,Major,4,,,,,,
+,56,,Odesza ,Say my name,Odesza SMN drums 11A 115,Drums,Drums (standard kit),4B,Major,4,,,,,,
+,,,,,,,,,TBD,,,,,,,
+,,,,,,,,,TBD,,,,,,,
+,,,,,,,,,TBD,,,,,,,
+,,,,,,,,,TBD,,,,,,,
+,,,,,,,,,TBD,,,,,,,
\ No newline at end of file
diff --git a/src/components/debug.tsx b/src/components/debug.tsx
index b62a92b..8e33dda 100644
--- a/src/components/debug.tsx
+++ b/src/components/debug.tsx
@@ -8,7 +8,7 @@ import { LoggerContext } from '~/contexts/logger-provider';
 import { Dialog, Transition, Switch } from '@headlessui/react';
 import classNames from 'classnames';

-import csv from '~/assets/BSS 23 Master Spreadsheet Budget, Inventory, Schedule, ETC - Music Database.csv';
+import csv from '~/assets/Music Database.csv';
 const RFIDToClipMap: Record<string, any> = {};
 const ClipNameToInfoMap: Record<string, any> = {};
 csv.forEach((row: any) => {

---
## [cychitivav/ros2_documentation](https://github.com/cychitivav/ros2_documentation)@[1be681dc76...](https://github.com/cychitivav/ros2_documentation/commit/1be681dc76d573c3bc20e9b7f943e906af820a32)
#### Friday 2023-05-19 23:28:44 by Chris Lalancette

First pass at the Iron Irwini release notes. (#3395)

* First pass at the Iron Irwini release notes.

That is, add in the full changelog, and also greatly
expand the release notes themselves.

I should point out that the full changelog is necessarily
*not* complete; it only contains information on things that
have already been released.

The release note page is a cut-down version of the full
changelog that just has things that might be interesting
to end users.  What is currently in there was my opinion,
so this list may be expanded or reduced based on thoughts
from other people.

In both cases, we should be able to iteratively add new
items here as they are landed.

Signed-off-by: Chris Lalancette <clalancette@gmail.com>
Co-authored-by: G.A. vd. Hoorn <g.a.vanderhoorn@tudelft.nl>

---
## [newstools/2023-sahara-reporters](https://github.com/newstools/2023-sahara-reporters)@[2f97417bb4...](https://github.com/newstools/2023-sahara-reporters/commit/2f97417bb4b3e29f9065da04c5e6cd8836bea523)
#### Friday 2023-05-19 23:53:06 by Billy Einkamerer

Created Text For URL [saharareporters.com/2023/05/19/nigerian-police-arraign-14-year-old-boy-stabbing-neighbour-death-over-girlfriend]

---

# [<](2023-05-18.md) 2023-05-19 [>](2023-05-20.md)

