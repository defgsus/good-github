# [<](2023-01-09.md) 2023-01-10 [>](2023-01-11.md)

there were a lot of events recorded by [gharchive.org](https://www.gharchive.org/) of which 2,328,921 were push events containing 3,486,598 commit messages that amount to 281,862,327 characters filtered with [words.py@e23d022007...](https://github.com/defgsus/good-github/blob/e23d022007992279f9bcb3a9fd40126629d787e2/src/words.py) to these 28 messages:


## [wetsausages/TCC-Discord](https://github.com/wetsausages/TCC-Discord)@[dedb511324...](https://github.com/wetsausages/TCC-Discord/commit/dedb51132431cc1e34ecd65fc1e4301a29b3312a)
#### Tuesday 2023-01-10 00:01:59 by wetsausages

drop submission rework

- condensed 10 "teammates" fields into 1
- reworked approval button ids to use member primary ids
- holy fuck I hate discord so much

---
## [LoupVaillant/Monocypher](https://github.com/LoupVaillant/Monocypher)@[f9f63dfd1f...](https://github.com/LoupVaillant/Monocypher/commit/f9f63dfd1ff21774d302fea0a245fd741e55e805)
#### Tuesday 2023-01-10 00:45:16 by Loup Vaillant

Add streaming AEAD.

Tests not complete, no documentation yet.

I'm currently rethinking the AEAD API as a whole, and to be honest I'm
so happy with this streaming API that I believe it could replace the
regular API entirely.

One problem with the AEAD API is the sheer number of arguments.
`crypto_lock_aead()` and `crypto_unlock_aead()` currently have 8
arguments, comprising 6 pointers (all of the same type) and 2 sizes.
There are way too many opportunities to swap arguments and break stuff.

The streaming API however is divided into an init phase, which has only
3 arguments, and a read/write phase, which has 7, but "only" 4 pointers
to byte buffers.  Which I don't think we can improve much.  We could try
and use a second struct similar to what we do with Argon2, but with only
7 arguments (compared to Argon2's 15) I don't think we would gain that
much readability.

As for how to use the streaming API for single shot uses, that's obvious
enough:

- Declare the context and call Init.
- Call read/write.
- Wipe the context.

One may argue that everything else (Poly1305, Blake2b, SHA-512, and
HMAC) provide a one-shot API, and we should do so here as well.  There's
just one problem: we don't have one init function, we have _three_.

If we provide a one-shot API, orthogonality would need all 3 variants.
That's 6 functions total (3 locks, 3 unlocks), which is a bit much,
especially since at least one of them is only provided for compatibility
with a standard I don't entirely agree with.  We could of course only
provide only the single one-shot API (like we do right now), but that
leaves such an obvious hole in the API.

Stopping at just the 5 functions we need for everything (streaming,
one-shot, all 3 variants) is very tempting.

See #218

---
## [outreachy/website](https://github.com/outreachy/website)@[ba0b44d3d5...](https://github.com/outreachy/website/commit/ba0b44d3d562b0418be7716f4d057129d159abfe)
#### Tuesday 2023-01-10 02:57:59 by Sage Sharp

HACK: Add hard-coded May 2023 social media and live stream dates

For the May 2023 cohort, we are planning to host two live streams for
mentors, and two live streams for applicants.

I don't have time to figure out a model for these chats. The simple way
would be to add more fields to the RoundPage class. However, it's very
likely we will change chat formats, number of chats, and when they are
held. So for now, I won't make model changes, and I'll just hard-core
them into the applicant and mentor time line snippets.

Note that this will make them appear on the past internship cohort
pages. Oh well? I'll fix this some time in the future. (Sorry future
self!)

---
## [gadget-inc/mobx-quick-tree](https://github.com/gadget-inc/mobx-quick-tree)@[f2b2b630f7...](https://github.com/gadget-inc/mobx-quick-tree/commit/f2b2b630f750bff7275c8df28cf1363199be66d6)
#### Tuesday 2023-01-10 04:05:31 by Harry Brundage

Add class models, a faster API for readonly instances

This introduces a new API for defining models that allows us to construct the read only instances much faster. Without any optimization yet, our primitive benchmark shows a 2.5x speedup for this new API over the existing readonly API:

```
claw ~/C/mobx-quick-tree (class-models) ‚ûú  yarn x spec/bench/cross-framework.ts
yarn run v1.22.10
$ ts-node --transpile-only spec/bench/cross-framework.ts
mobx-state-tree x 4,618 ops/sec ¬±12.62% (80 runs sampled)
mobx-quick-tree types.model x 98,964 ops/sec ¬±3.50% (91 runs sampled)
mobx-quick-tree ClassModel x 261,246 ops/sec ¬±0.22% (92 runs sampled)
Fastest is mobx-quick-tree ClassModel
Slowest is mobx-state-tree
```

The central premise is that `mobx-state-tree`'s API for defining models collects functions that add views and actions in such a way that each view-adder function or action-adder function has to be run once *per* instance. If you have a model like:

```typescript
const Todo = types.model("Todo", {
  name: types.string,
  done: types.boolean
}).actions(self => {
  setDone(done: boolean) {
    self.done = done;
  }
});
```

each time you instantiate a `Todo` with `Todo.create` or `Todo.createReadOnly`, that `self => ({ setDone() {} })` block has to run once to create a new set of actions which close over a new value of self. There's no magic behind the scenes that only runs that function once and re-uses the output between instances -- it's instead re-executed on instantiation every time. NIce API, terrible for performance.

Instead, we should leverage JavaScripts existing mechanisms for defining what is the same about a bunch of objects once instead of over and over: the prototype chain! Classes (which in JS are just sugar over prototypes) allow us to define something like the `setDone` function once on a prototype, and then create an instance which has that as it's prototype, and not need to re-create `setDone` per instance. This whole PR is about defining a class-based API that leverages this built-in performant approach in JS to power read only instances, while still allowing us to generate the observable instances we need sometimes. It's an inversion from the previous approach to MQT: before, we adapted the MST API to give us readonly instances while conforming to the existing API, but now, we define a new API with a higher performance ceiling, and adapt that API to the slower thing under the hood.

The implementation of this is scary to be honest. `types.model` was clearly modelled after classes, so the grain of class definitions and MST type defintions match, but getting it to work at runtime and typetime requires lots of fancy stuff. The first tricky part is the types. I think it's key that a new, class based API for MQT is incrementally adoptable so that we can roll it out over time and build confidence, and that means that the existing `types.model` types and MQT class based types need to interoperate. After much fiddling, I think I accomplished this, but it was hard to get `IType` and `IClassModelType` working in harmony. See the note in `IClassModelType` for more info.

Also tricky is the runtime derivation of the observable class from the readonly class. The decorators give us enough structure to hang off of, but ES2020/TS decorators have two key limitations: they can't muck with properties until they are defined, and TS decorators can't change the type. This matters most for volatiles and async actions.

Let's review the requirements:

 - Async actions in MST and plain old mobx are really several chunks of sync action chained together, which some kind of hook system to ensure that each sync bit is wrapped in mobx action wrapper goodness, and that inbetween while awaiting something, the wrapper isn't active. mobx/MST need this hook point to enforce actions are actually the only ones changing data.
 - We want to define async actions on classes

And then the limitations:

 - The only hook system that the mobx or MST folks have come up with that is ergonomic is having userland code build async actions using generators instead of the normal async/await. This is so they have their hook point for every `yield`, where they can be like "oh, a promise!" and disable the action bits for the duration of the promise, and re-active them when it resolves and they pass the value back in to the caller. Generators allow userland to intercept each call to what would be `await` in both node and the browser.
 - *Inside* the async action you use `yield somePromise`, but calling the action still returns a promise, so you still do `await someNode.someAsyncAction()`. This is to stay as normal as possible outside of MST action bodies and not make the whole system use generators. So, to adapt the generator into a normally typed async function, users need to wrap their generator functions in `flow()`.
 - There's no way to automatically adapt an async function into a generator function for MST. If there was, MST would use it already and not require folks to write generators. This means the code on the MQT class model *has* to be in generator form.
 - TypeScript decorators can't change the type of the property they are decorating, so they can't automatically apply the `flow` expression to a prototype level generator function and get the type turned into a nice promise returning type. If you have a class body like this:

```typescript

class Foo {

  @flow
  *someAsyncAction() {
  }
```

the return type of that function is locked in as a generator, and `@flow` can't change it. It can do stuff to it at *runtime*, but it can't mutate the type time type. That means that `await someFoo.someAsyncAction()` won't typecheck, as TypeScript will be expecting it to return a generator regardless of what runtime trickery the decorator gets up to. Sad.

So, we need to do the adaptation of the generator function into a promise-returning function for nice caller types with some sort of expression. That's what the `flow()` helper from MST does.

 - To assign a `flow(function * () {})` expression to a property on a class, it becomes an "instance property" instead of a prototype property. That is:

```typescript
class Foo {

  someAsyncAction = flow(function * () {
    yield sleep(100)
  });

}
```

desugars into:

```javascript
class Foo {

  constructor() {
    this.someAsyncAction = flow(function * () {
      yield sleep(100)
    });
  }

}
```

It'd be far more performant in general to have this somehow do a `Foo.prototype.whatever = flow(...)`, but alas, thats not how ES6 expression assignments work. This is a major issue for us though, because this desugaring means that there is nothing to look at to get the flow definition at class definition time. For things defined on the prototype, we can get a handle on them easily at class definition time to send them into mobx land for making the observable instance, but, for these things which aren't set until the constructor, we can't see their value until the constructor runs! After much brain wracking I couldn't find a away around this -- I had to go with a major hack which is to actually construct an instance, let the constructor run, and then pull the resulting expression off of the constructed instance to get a handle on the flow implementation to pass into MST. Yikes.

---
## [ChungusGamer666/mojave-sun-13](https://github.com/ChungusGamer666/mojave-sun-13)@[fe5d6c7b56...](https://github.com/ChungusGamer666/mojave-sun-13/commit/fe5d6c7b568d550f403eb892ed47ffaf6b4fd28c)
#### Tuesday 2023-01-10 04:30:12 by Technobug14

Agriculture (#2230)

* Does Stuff

Beginnings of agriculture code, stripped down TG botany a bunch, got rid of scar botany whilst replacing most of it. Also some map edits to change the paths on stuff and add a few spades for farming.

* Some NPK system framework

Removing more TG botany stuff and getting some framework down for NPK. Adds a "nutrient_type" variable to seeds and gives N, P or K as the type to every seed.

* Removes Stuff, More NPK Framework

Still WIP on NPK stuff, removes more basic bitch TG botany stuff, needs a lot more content but in an almost-working state

* Nutrient drain

Nutrients actually get drained properly now. Crop plots output their level of N, P and K when examined. Still need to make something to handle restoring nutrients and figure out a nutrient economy for plant consumption.

* Mostly working, one major bug

This is mostly working now. The NPK now drains according to the seed planted, it replenishes over time, you can now get water from water tiles and the soil will properly adjust the waterlevel variable with the new water types.

HOWEVER, big bug. The way TG handled watering crops is ass. Doesn't delete, stays in the reagent_container of the soil, normally checks for if a reagent_container has water to bypass how full the soil's container is, bad system that sucks. Needs fixing.

* oops

oopsie!!! fucked something!!! forgot to undo a change I made to the code, it's just there to remind me it's not working correctly

* Last minute fixes/bandaids

I HATE TG BOTANY I HATE TG BOTANY I'M LOSING IT

---
## [LegacyGwent/LegacyGwent](https://github.com/LegacyGwent/LegacyGwent)@[540fad4c3c...](https://github.com/LegacyGwent/LegacyGwent/commit/540fad4c3c7df14ca52703c9d97ead9f181f32e3)
#### Tuesday 2023-01-10 06:02:24 by PigeonofWar

fix(description): en translation improve (#356)

* Update en.json

Hi,

Not listing everything here, as some are self explanatory, but have included some where I just wanted to provide a bit of context to my proposed change. A lot of the changes are either minor corrections, consistency changes (to keep the wording same or similar throughout the game), or to further clarify what the card does.

I have used gwent.one as reference, as it contains a database of all beta Gwent cards as they appeared upon the last update, pulled directly from the game. I have of course taken the custom balance changes etc. into account, to keep their new functionality / stats.

This should cover the Neutral cards (Down to Dagon at 21001 / Line 880)

I hope at least some of this is useful. and want to thank you for bringing this project to life and giving me a healthy dose of nostalgia!

12004 Geralt of Rivia: Just to keep the word for the card effects / abilities the same throughout the game, for consistency. Old Gwent used ability, and can see it being used on some custom balance changes and cards as well.

12008 Villentretenmerth: Not sure if coded differently from how it originally worked, but if functioning the same as original Gwent, I added a bit of text to clarify when it happens and that it excludes himself (in case he is the highest or tied for). Please feel free to change to the below if you would want this to be worded exactly as old Gwent, I just think my edit reads a bit clearer. (Old Gwent: After 3 turns, destroy all the other Highest units on turn start. 3 Armor.)

12011 Dandelion: Vainglory: Original included Triss, not sure if just a typo, but may be worth checking if included in the code (sorry, I'm not sure how to do that).

12015 Zoltan: Scoundrel: Not sure if you changed the functionality of this one (which as how it was written, seems to be a nerf, unless Zoltan himself had an increase in Power by 4), but if functionality to old Gwent has not changed, then I updated the wording to match Old Gwent.

12018 Ihuarraquax: Fixed wording to indicate how it worked in Old Gwent, otherwise it indicate that it keeps damaging 3 enemy units by 7 at every turn end, when it only does it once. Might be worth checking code if coded to keep firing ability or only once.

12026 Triss: Telekinesis: Changed from current to starting, as that was how it was in Old Gwent. Not sure if coded as such or a custom change?

12027 Aguara: Again, not sure if custom change or not, but is random Elf in Old Gwent.

14007 Dimeritium Shackles: Was this function changed? It implies to only be able to lock cards, when in Old Gwent it could also unlock (toggling).

14013 Mardroeme: Seems two cards were named Spore, and this one was originally called Mardroeme, so fixed it.

* feat: update language file version

Co-authored-by: neal <46561493+neal2018@users.noreply.github.com>

---
## [BartoszDerenda/dwarves-and-goblins](https://github.com/BartoszDerenda/dwarves-and-goblins)@[95eff93348...](https://github.com/BartoszDerenda/dwarves-and-goblins/commit/95eff93348a64638f9ba6a4fd6840a029d73e8ba)
#### Tuesday 2023-01-10 08:59:41 by BartoszDerenda

push 14

Added some items and placed foundations for further items and effects - added ability_dictionary.
Started theorycrafting difficulty modes - the stat spreads of goblins will be based of off their randomized tactic but itemisation will be random except for last two difficulties (I am planning to implement 4 + separate gamemode unlocked through finishing a challenge run with "???" artifact equipped on hardest difficulty).
Implemented item descriptions for ability_dict (for special abilities layout) and inside items themself (for item frame in equipment layout).
Reworked some things, implemented some abilities from the backlog of my mind and papers.
Added better recursion in game.html for displaying items. Previous attempt was laughably bad lol, anyway bye bye 800ish lines of messy copy-paste code.

NOTE:
Add a mechanic like "scrying" that let's you see enemy's stats and equipment (but not tactic?) - it would be unlocked by a dwarf that reached intelligence of uhhh 150 or something or through equipping an item (Scrying Orb) - upon using the ability, the item would be destroyed.
Same with option to sneak to the enemy camp and poison the opponent or something. Pretty cool mechanic, I think.

I think I need to take a break from this project, I cannot sleep for every 10 minutes in bed, I have to go and scribble some new idea I would want to implement in the game. My desk looks like I am trying to solve a conspiracy theory and I cannot brush my teeth without getting some eureka effect.
I also had a LotR inspired dream, except that it was full of dwarves. Like, we were just dwarves traveling somewhere important, idk. I remember the quiet beers we had at the end of it, mourning our artificer and warlock from our party who died during our journey.

I surely hope my future employer will never have to read this.

---
## [riand01/Dashboard](https://github.com/riand01/Dashboard)@[a0e29700c4...](https://github.com/riand01/Dashboard/commit/a0e29700c41781ddb312e31abd84f4df47bd92bb)
#### Tuesday 2023-01-10 09:00:32 by AronAsk

Merge pull request #7 from riand01/test

Fuck you Carl Axel

---
## [Offroaders123/Menu-Drop-Component](https://github.com/Offroaders123/Menu-Drop-Component)@[ae348678d1...](https://github.com/Offroaders123/Menu-Drop-Component/commit/ae348678d185ab52c41554225780ca673611c3d7)
#### Tuesday 2023-01-10 09:00:39 by Offroaders123

Constructable Stylesheets!

Oh yeah! Nice to have this working now. Rather than loading the styles for the components with a stylesheet linked by the user, now it's included as part of the library's source!

I really like this, as it makes it s the only thing required to fully load the component is to run the script from, wherever essentially, and just by it's URL. You don't have to add any other tags to the head of the page, you don't have to add any polyfills yourself, it just runs.

The only thing that could be debated to be a bit of a drawback is the FOUC, Flash of Unstyled Content, but since everything is lazy-loaded *consistently*, and with the smart things that come in handy thanks to the Custom Elements API, you can rely on different ways to handle that yourself.

I think one way to do that would be with the `window.customElements.whenDefined()` function call, which returns a `Promise` when the given element tag you are checking is defined. This allows you to get a direct callback in your app once 'x' component has fully finished loading. If you do this with all of your components' `Promise`s, then you know exactly when it's safe to fully render the page!

Using this in conjunction with a main `<script type="module"></script>` for your app, then you can simply `await` all of these calls, in the top level, and once they have finished loading, continue the main module process! Of course, if you didn't need to wait for them to finish, you can simply do this for your rendering/display logic, and hide elements as they are loading, accordingly.

I really like this kind of loading idea, where you expect things to not be ready yet. If you do that, then you can prepare for more things on the fly, and it allows it to handle a range of circumstances.

I'm going to try using this design in my web apps from here onwards, I think it can really make your code go a long way :)

I want to go back and try and bring all of my modern code to STE, but I don't know where to start every time I go over there XD. Gonna look into it more, I think ideas like these could really help with how STE is structured.

I definitely want to combine STE with NBTify down the road, that's been one of my goals for a long time now! To get to that point though, I need to step up STE's codebase a bit, and also add SNBT support to NBTify, as I think that's how I want to go about editing NBT. I think the NBT tree view editors with buttons and such look really cool, and they are fairly easy to use, but I think there's something neat about just opening it up as a text file, typing a few things, then saving that with just a keypress. If I made that into it's own mini PWA, I think the Minecraft community would flip their lids! It's definitely something I'd love to have, especially with it working offline, on mobile, and all of the other cool things you get with PWAs. I may have to start a little separate repo for that soon! Maybe it should be it's own thing, rather than being part of STE? I'd probably have both eventually, as I think a lightweight editor specifically for NBT would be nice, and just having it in STE alongside everything else seems really cool. We'll have to see! Lots of cool things ahead :)

Been looking into React and Lit recently too! With all of this fancy TypeScript and module work I've been doing for the last few months now, I feel more equipped to tackle things like that! Next I want to look into how you can get a minimal React/TypeScript setup going, and still be able to publish to GitHub Pages.

So many cool things!!! Gotta go to bed, cya ta' mornin

---
## [RiniChristy/Tableau-Visualizations](https://github.com/RiniChristy/Tableau-Visualizations)@[a319fada78...](https://github.com/RiniChristy/Tableau-Visualizations/commit/a319fada78aacde5da2b6f5b8f15363e88c110e9)
#### Tuesday 2023-01-10 10:11:45 by Rini Christy

Add files via upload

Socially Challenged (SC+ST+OBC Including male & female) Student Percentage By Profession, State & Year [https://public.tableau.com/shared/JXX3XWN3Z?:display_count=n&:origin=viz_share_link]

---
## [m0ha1/Sales-Prediction](https://github.com/m0ha1/Sales-Prediction)@[6de6bb9fe7...](https://github.com/m0ha1/Sales-Prediction/commit/6de6bb9fe71c7cbf027a1950a6cdcf95e2f67b1c)
#### Tuesday 2023-01-10 11:28:06 by m0ha1

Delete README.md

#Sales-Prediction
![alt text](https://searchengineland.com/figz/wp-content/seloads/2014/12/black-friday1-ss-1920.jpg "Black Friday Sales Prediction")

## Table Of Contents
  - [Project Introduction](#project-introduction)
  - [Dataset Description](#dataset-description)
  - [EDA](#eda)
  - [Data Preprocessing](#data-preparation)
  - [Modeling Phase](#modeling-phase)
  - [Evaluation Metric](#evaluation-metric)
  - [Conclusion](#conclusion)



### Dataset Description
The dataset is acquired from an online data analytics hackathon hosted by Analytics Vidhya. The data contained features like age, gender, marital status, categories of products purchased, city demographics, purchase amount etc. The data consists of 12 columns and 537577 records. Our model will be predicting the purchase amount of the products.

###  EDA:
Below are the observations which we have made from the data visualization done as part of the Data Understanding process.
* Approximately, 75% of the number of purchases are made by Male users and rest of the 25% is done by female users. This tells us the Male consumers are the major contributors to the number of sales for the retail store.On average the male gender spends more money on purchase contrary to female, and it is possible to also observe this trend by adding the total value of purchase.
* When we combined Purchase and Marital_Status for analysis, we came to know that Single Men spend the most during the Black Friday. It also tells that Men tend to spend less once they are married. It maybe because of the added responsibilities.
* For Age feature, we observed the consumers who belong to the age group 25-40 tend to spend the most.
* There is an interesting column Stay_In_Current_City_Years, after analyzing this column we came to know the people who have spent 1 year in the city tend to spend the most. This is understandable as, people who have spent more than 4 years in the city are generally well settled and are less interested in buying new things as compared to the people new to the city, who tend to buy more.
* When examining which city the product was purchased to our surprise, even though the city B is majorly responsible for the overall sales income, but when it comes to the above product, it majorly purchased in the city C.

### Data Preparation
* Used LabelEncoder for encoding the categorical columns like Age, Gender and City_Category
* Used get_dummies form Pandas package for converting categorical variable State_In_Current_Years into dummy/indicator variables.
* Filled the missing values in the Product_Category_2 and Product_Category_3

### Modeling Phase
- Splitted dataset into into random train and test subset of ratio 80:20
- Implemented multiple supervised models such as Linear Regressor, Decision Tree Regressor, Random Forest Regressor.

### Evaluation Metric
Root Mean Square Error (RMSE) is a standard way to measure the error of a model in predicting quantitative data. It‚Äôs the square root of the average of squared differences between prediction and actual observation.

### Conclusion
Implanted multiple supervised models such as Linear Regressor,Decision Tree Regressor, Random Forest Regressor Regressor. Out of these supervised models, based on the RMSE scores Random Forest Regressor was the best performer with a score of 3115.

---
## [MadsLeander/rpemotes](https://github.com/MadsLeander/rpemotes)@[45b9259ff8...](https://github.com/MadsLeander/rpemotes/commit/45b9259ff84eea10f91aa0c2b4d122cedf9f7fc9)
#### Tuesday 2023-01-10 11:33:04 by Mads

üö∂‚Äç‚ôÇÔ∏èAdd 11 New Walking Styles (#99) üö∂‚Äç‚ôÇÔ∏è

HUGE thanks to @MadsLeander 

Notes/descriptions of the walking styles:

Bigfoot (move_characters@orleans@core@) - Head hanging slightly forwards, somewhat hurting in left fot, wide with arms as if he's large, walking slow, runs crazy and fast (Used by this character in storymode: https://gta.fandom.com/wiki/Sasquatch_Roleplayer)

Coward (move_m@coward) - Hunched forward when standing still, other wise not diffrent from the default male walk.

Dave (move_characters@dave_n) - Shoulders are higher then normal walk, standing wide when still, left foot hurting when running/jogging (sprint is the default one) (Used by Dave Norton in storymode)

    Femme2 (move_m@femme@) - Shoulders are "swinging", left leg is leaned on when standing still, generally can be best described as a feminine walk for male peds, run and sprint are like the default one (This is one of the avalible walks in GTA Online)

Jimmy (move_characters@jimmy) - Similar to nervous/slow (they are all from the same character afterall), but with out the nervous or slow part (walks normal speed and not tripping with legs when standing still) (Used by Jimmy, the son of Michael in storymode)

Patricia (move_characters@patricia) - Swinging with hips, straight/stiff back, run/sprint is similar to the default female one (Used by Patricia Madrazo in storymode)

Ron (move_characters@ron) - Entire body posture slightly hanging to the left, runs like an idiot, sprint is normal. (Used by Ronald "Ron" Jakowski in storymode)

Swagger2 (move_m@swagger@b) - Confident and somewhat slow walking, moving slightly to the right every so often, run an sprint is normal.

Gangster6 (move_f@gangster@ng) - Slight diffrent in walking speed, posture is noticible diffrent, arms are more straight when standing still.

Veryslow (move_m@leaf_blower) - Head looking down, walking very slowly, running with right arm as if he had a leaf blower, sprint is normal.

Flee5 (move_m@flee@c) - Similar to Flee4, but multiple diffrences like how many times he turns his head to look behind etc.

---
## [petre-symfony/design-patterns-for-fun-and-proficiency-symfonycasts-2022](https://github.com/petre-symfony/design-patterns-for-fun-and-proficiency-symfonycasts-2022)@[6738a92ecd...](https://github.com/petre-symfony/design-patterns-for-fun-and-proficiency-symfonycasts-2022/commit/6738a92ecd866de718caa642cb30bdae3c933c3d)
#### Tuesday 2023-01-10 11:35:45 by petrero

14.4 But now, go into OutputtingXpCalculator add #[AsDecorator()] and pass it XpCalculatorInterface::class, since that's the ID of the service we want to replace

 Donezo! If we try this now:

  php ./bin/console app:game:play
 No errors. An even faster way to prove this is working is by running:

  php ./bin/console debug:container XpCalculatorInterface --show-arguments
 And... check it out! It says that this is an alias for the service OutputtingXpCalculator. So anyone that's autowiring this interface will actually get the OutputtingXpCalculator service. And if you look down here at the arguments, the first argument passed to OutputtingXpCalculator is the real XpCalculator. That's amazing!

 Multiple Decoration
 - All right, the decorator pattern is done. What a cool pattern! One feature of the decorator pattern that we only mentioned is that you can decorate a service as many times as you want. Yep! If we created another class that implemented XpCalculatorInterface and gave it this #AsDecorator() attribute, there would now be two services decorating it. Which service would be on the outside? If you care enough, you could set a priority option on one of the attributes to control that.

 Decoration in the Wild?
 - Where do we see decoration in the wild? The answer to that is... sort of all over! In API Platform, it's common to use decoration to extend core services like the ContextBuilder. And Symfony itself uses decoration pretty commonly to add debugging features while we're in the dev environment. For example, we know that this EventDispatcher class would be used in the prod environment. But in the dev environment - I'll hit t to search for a "TraceableEventDispatcher" - assuming that you have some debugging tools installed, this is the actual class that represents the event_dispatcher service. It decorates the real one!

 I can prove it. Head back to your terminal and run:

  php ./bin/console debug:container event_dispatcher --show-arguments
 Scroll to the top and... check it out! The event_dispatcher service is an alias to debug.event_dispatcher... whose class is TraceableEventDispatcher! And if you scroll down to its arguments, ha! It's passed our DebugEventDispatcherDecorator as an argument. Yup, there are 3 event dispatchers in this case: Symfony's core TraceableEventDispatcher is on the outside, it calls into our DebugEventDispatcherDecorator... and then that ultimately calls the real event dispatcher. Inception!

 Problems Solved by Decorator
 -And what problems does the decorator pattern solve? Simple: it allows us to extend the behavior of an existing class - like XpCalculator - even if that class does not contain any other extension points. This means we can use it to override vendor services when all else fails. The only downside to the decorator pattern is that we can only run code before or after the core method. And the service we want to decorate must implement an interface.

 Okay, team. We're done! There are many more patterns out there in the wild: this was a collection of some of our favorites. If we skipped one or several that you really want to hear about, let us know! Until then, see if you can spot these patterns in the wild and figure out where you can apply them to clean up your own code... and impress your friends.

 Thanks for coding with me, and I'll see you next time!

---
## [yoy0lol/seriouslycasual-epgp-ui](https://github.com/yoy0lol/seriouslycasual-epgp-ui)@[413310a596...](https://github.com/yoy0lol/seriouslycasual-epgp-ui/commit/413310a5963e169cebf544cdca48506324ac679e)
#### Tuesday 2023-01-10 12:20:55 by yoy0lol

Add fucking filters (holy shit this took me way longer than it needed to. Fuck you CSS. Fuck you. Fuck you. Fuck you)

---
## [BRB67/169ctures](https://github.com/BRB67/169ctures)@[e7df6378ca...](https://github.com/BRB67/169ctures/commit/e7df6378caaf9d1e011f205e2941572cdce6406a)
#### Tuesday 2023-01-10 13:48:57 by Sivens Glaude

Thank You LOR4! Peace and Blessings Bro<3K

God is GoOd
liFe is  grEAT

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[3bbc37d50e...](https://github.com/mrakgr/The-Spiral-Language/commit/3bbc37d50e769100715defffe3fdeae93bf38ddf)
#### Tuesday 2023-01-10 16:29:22 by Marko Grdiniƒá

"6:25pm. https://nyaa.si/view/1622655

Subs for Inglis are already out. I guess I'll also get the first ep of High Card. I'll give it a chance.

Just these past few hours, I've been thinking of asking on HN about embedded. I really want to take my career in places where I can promote Spiral.

7:25pm. Hmmm, the chara designs for Inglis' anime give a 80s vibe.

8:25pm. https://youtu.be/qaU34DhiVdM?list=PLQHmK8j6zHB4D_E4Npf4Z32hdn3KxFB5M
19 fill with dread

This track is a masterpiece.

I am thinking and I've decided. In the absence of AI chips, it might be worth going for embedded. Anything else won't give me a chance to make use of Spiral.

1/10/2023

9:55am. It seems I've been writing the year as 2022 on reflex in my past entries. I need to retrain.

No emails as expected. This is horrible. I think I might want to pare down the article to just that last example as the reception is not that great.

I am pissed. What is the point of hoping for AI chips if they are going to treat me like this. I've been thinking about embedded and why not try to go for it seriously? I could do other things, but in other domains my edge would not be as strong. If I look at the CNX Software blog, I see that lot of those new hardware pieces coming out are heterogenous. I could have a large impact programming those in Spiral compared to doing anything else.

10:05am. Since I have I haven't gotten a reply from the PIM guy, I think he is absolutely not interested. What about Tenstorrent? If I don't get a reply by tomorrow, this is probably dead in the water. I'll have to adjust my strategy. Though really, this already quite bad. If they are interested in selling, they sure as hell wouldn't be delaying potential customers.

It is difficult. I really need to make it my strategy to seek out those who could be potentially interested in my work.

10:10am. Right now, I need to chill a little and take a bath. I've been lounging in bed for a long time.

11:50am. Done with the bath. You know what. Forget these crappy AI companies. I do not want to put my faith in them anymore. I should finish the City Of Dawn and look for an embedded job. I want to see if there is anybody in this area who would be interested in skills like mine. If not, and the potential employers all want me to program in raw C, I'll just toss Spiral aside and look for functional jobs. F#, Ocaml, Haskell, whatever. If that fails as well, I'll look into Python/JS and webdev. Those jobs are the most plentiful.

I'll start off by trying to mine HN and Reddit, trying to get employers to come to me, but if that fails I'll switch to being more proactive in applying to startups.

Who knows how long it will take me to find a job, so writing HK can serve as a hobby in the meantime. It will take a while until I am done with the current chapter of Heaven's Key.

12:35pm. https://re-library.com/translations/blade-maiden/volume-7-mount-ooe/chapter-12-hayabusa/

Let me finish this and I will do the chores. Then I will get started on writing for the day.

I have tense nights as I am trying to decide my future. Writing isn't viable as a career path for me. It will have to be programming after all.

1pm. Let me do the chores.

There is no choice. I'll just have to start from the bottom. I only need like 200k before I can switch to trading anyway, so it is no big deal. I can still make it.

One day, this world will surely send me a signal when it is time to pursue AI for real.

1:30pm. Done with chores. Let me start. I keep checking the email every now and then. Let me take a look once more.

...It seems I lost that one backer on the Spiral collective. It is a pity.

Well, thank you for the 108.61 Euro donated so far whoever you are.

You and the guy who contributed 100E up front are those kept the Spiral lang blog alive for 2 extra years. I really would have taken it under if you shadow readers hadn't stepped up.

1:35pm. It is just one bad news after another. Let me write. Truly nothing good happens to me.

5pm. 50.9k. 1.7k so far.

5:05pm. Now Elaina is in the story.

5:20pm. I'll stop here so I can take time to think of the scenes with them. Somehow it will turn out to be Eui and Elaina that are the most active.

As for jobs, I am converging to something.

If my AI goal is to make a GP system on an AI chips, my job goal should be to satisfy my ego with regards to Spiral.

With embedded jobs, if they are forcing me to use raw C, then I can just wipe my hands clean of those. But if they are up for using Spiral, that will allow me to indulge myself and those kinds of jobs would be ideal.

I realize now that I've gotten my programming taste back is that I should separate ego satisfaction and money.

When I am applying to a place, I should always keep in mind whether I am going for money or not. Right now, maybe AI chips are too much, but the embedded space is bigger than them.

5:25pm. I somehow got really good advice when that guy linked me to the CNX blog. I should branch out into embedded jobs. Spiral is the ideal filter for them.

If the world just simply keeps refusing me, at some point I'll cave and look for money related jobs. F#, Typescript, Python. Whatever. Something in a high level language. Definitely not C or C++.

Webdev for all its warts is at least paid well.

5:25pm. Let me commit here. Maybe I'll write a bit more, but I feel like unwinding here."

---
## [OpenVZ/vzkernel](https://github.com/OpenVZ/vzkernel)@[4068407541...](https://github.com/OpenVZ/vzkernel/commit/4068407541378dc108dc2dbe5f697a7a3a0ef4c4)
#### Tuesday 2023-01-10 17:50:55 by Vladimir Davydov

mm: introduce transcendent file cache (tcache)

Transcendent file cache (tcache) is a simple driver for cleancache,
which stores reclaimed pages in memory unmodified. Its purpose it to
adopt pages evicted from a memory cgroup on local pressure, so that they
can be fetched back later without costly disk accesses. It works
similarly to shadow gangs from PCS6 except pages has to be copied on
eviction.

https://jira.sw.ru/browse/PSBM-31757

* Usage

 - Enable:
   # modprobe tcache # only if compiled as a module
   # echo Y > /sys/module/tcache/parameters/enabled

 - Disable:
   # echo N > /sys/module/tcache/parameters/enabled

 - Get number of pages cached:
   # cat /sys/module/tcache/parameters/nr_pages

* Implementation notes

 - Fetching/adding a page to tcache implies looking up a tcache pool
   (corresponds to a super block), tcache node in the pool (corresponds
   to an inode), and a page in the node. Pages of the same node are
   organized into a radix tree protected by a single spin lock,
   similarly to pages in an address_space. Nodes of the same pool are
   kept in several RB trees, each of which protected by its own spin
   lock. The number of RB trees is proportional to the number of CPUs,
   and nodes are distributed among the trees using a hash function. This
   is to minimize contention on the locks protecting the trees. Pools
   are kept in an IDR and looked up locklessly.

 - All tcache pages are linked in per NUMA node LRU lists and reclaimed
   on global pressure by a slab shrinker. Also, if we fail to allocate a
   new page for tcache, we will attempt to reclaim the oldest one
   immediately.

 - Once the tcache module is loaded, it is impossible to disable tcache
   completely due to cleancache limitations. "Disabling" it via the
   corresponding module parameter only forbids populating the cache with
   new pages. Lookups will proceed to tcache anyway.

 - Tcache pages are accounted as file pages.

* F.A.Q.

 - Does copying pages to and from tcache affect performance?

   Yes, it does. Fetching data from tcache advances roughly two times
   slower than from the page cache, because one has to copy data twice.
   Below are times of reading a 512M file from a memory cgroup:

   a) without limits:
      536870912 bytes (537 MB) copied, 0.481623 s, 1.1 GB/s
   b) with 100M limit and tcache enabled:
      536870912 bytes (537 MB) copied, 0.974815 s, 551 MB/s

   However, tcache exists not to allow containers whose working set does
   not fit in their RAM operate as fast as they would if there were no
   memory limits at all. Tcache exists to avoid costly disk operations
   whenever possible. For example, if there is a container which would
   normally thrash due to the memory limit and there is some unused
   memory on the host, it is better to allow the container to use the
   free memory to avoid thrashing, because otherwise it will generate
   disk pressure sensible by other containers.

 - Is there any memory overhead excluding the space used for storing
   data pages?

   Practically, no. All the information about pages is stored directly
   in struct page, and no additional handles are allocated per page.
   Per inode radix trees do consume some additional kernel memory per
   page, but its amount is negligible.

 - Does tcache generate memory pressure at the global level? If yes,
   does it affect containers?

   Yes, it generates global pressure and currently it does affect
   containers. This is similar to the issue we had had in PCS6 before
   shadow gangs and vmscan scheduling hacks were introduced, when there
   was the only LRU list for evicted pages (init_gang). We are planning
   to fix it by backporting low limits for memory cgroups. If a
   container is below its low limit, its memory will not be scanned on
   global pressure unless all containers are below their low limits
   (this is a kind of memory guarantee). We will set low limits for a
   container to be equal to an estimate of its working set size (this
   will be done by a user space daemon). Since tcache resides in the
   root memory cgroup, which does not have any memory guarantees (low
   limit equals 0), it will not press upon containers provided the
   system is properly configured.

 - Why cannot we use low limits instead of hard limits then?

   Low limits are unsafe by design. There is no guarantee that we will
   always be able to reclaim a cgroup back to its low limit. There are
   anonymous and kernel memory, which are sometimes really hard to
   reclaim. We could introduce a separate limit for them (anon+swap),
   but it will never get upstream (we tried).

 - Why is it better than what we have in PCS6?

   Primarily, because the idea of wiring sophisticated vmscan rules into
   the kernel, as we have done in PCS6 (vmscan scheduler) is dubious
   since it makes changing its behavior really painful. There are other
   points too:

   + The PCS6 memory management patch is really intrusive: it has
     sprouted its slimy tentacles all around the mm subsystem (rmap.c,
     memory.c, mlock.c, vmscan.c). We will hardly ever manage to push it
     upstream, so we will most likely have to carry it for good. This
     means each major rebase will turn into a torment. OTOH tcache code
     is isolated in a module and therefore can be easily ported back and
     forth.

   + Thanks to data copying, we can do funny things with the
     transcendent page cache in future, such as compression and
     deduplication. There were plans to implement compressed file cache
     upstream (zcache), but unfortunately it is still not there, and
     nobody seems to care about it. Nevertheless, sooner or later it
     will be introduced (may be, I'll facilitate this process), and we
     will be able to seamlessly switch to it from tcache. Tcache will be
     still useful for testing though.

 - In PCS6 there are per container shadow lists, while you have only the
   global LRU for all tcache pages. Is there any plans to introduce per
   super block or per memory cgroup LRUs?

   I am still unconvinced that we really need it, because it is not
   clear to me what policy we should apply per container on reclaim. It
   smells like one more heuristic, which I am desperately trying to
   avoid. Current design looks simple and sane: there are guarantees for
   containers provided by their limits, and they are competing fairly
   for the rest of the memory used for caches.

 - What about swap cache?

   There are plans to implement a similar driver for frontswap (tswap)
   or backport and use existing zswap. There may be problems with the
   latter though, because it currently does not support reclaim, and it
   will be tricky from the technical point of view to introduce it.

 - Any plans to push tcache upstream?

   No, because its use case looks too narrow to me to be included into
   the vanilla kernel. I am planning to concentrate on zcache instead.

Signed-off-by: Vladimir Davydov <vdavydov@parallels.com>

+++
mm/tcache: restore missing rcu_read_lock() in tcache_detach_page() #PSBM-120802

Looks like rcu_read_lock() was lost in "out:" path of tcache_detach_page()
when tcache was ported to VZ8. As a result, Syzkaller was able to hit
the following warning:

  WARNING: bad unlock balance detected!
  4.18.0-193.6.3.vz8.4.7.syz+debug #1 Tainted: G        W        ---------r-  -
  -------------------------------------
  vcmmd/926 is trying to release lock (rcu_read_lock) at:
  [<ffffffff848ed2e0>] tcache_detach_page+0x530/0x750
  but there are no more locks to release!

  other info that might help us debug this:
  2 locks held by vcmmd/926:
   #0: ffff888036331f30 (&mm->mmap_sem){++++}, at: __do_page_fault+0x157/0x550
   #1: ffff8880567295f8 (&ei->i_mmap_sem){++++}, at: ext4_filemap_fault+0x82/0xc0 [ext4]

  stack backtrace:
  CPU: 0 PID: 926 Comm: vcmmd ve: /
               Tainted: G        W        ---------r-  - 4.18.0-193.6.3.vz8.4.7.syz+debug #1 4.7
  Hardware name: Virtuozzo KVM, BIOS 1.11.0-2.vz7.2 04/01/2014
  Call Trace:
   dump_stack+0xd2/0x148
   print_unlock_imbalance_bug.cold.40+0xc8/0xd4
   lock_release+0x5e3/0x1360
   tcache_detach_page+0x559/0x750
   tcache_cleancache_get_page+0xe9/0x780
   __cleancache_get_page+0x212/0x320
   ext4_mpage_readpages+0x165d/0x1b90 [ext4]
   ext4_readpages+0xd6/0x110 [ext4]
   read_pages+0xff/0x5b0
   __do_page_cache_readahead+0x3fc/0x5b0
   filemap_fault+0x912/0x1b80
   ext4_filemap_fault+0x8a/0xc0 [ext4]
   __do_fault+0x110/0x410
   do_fault+0x622/0x1010
   __handle_mm_fault+0x980/0x1120
   handle_mm_fault+0x17f/0x610
   __do_page_fault+0x25d/0x550
   do_page_fault+0x38/0x290
   do_async_page_fault+0x5b/0xe0
   async_page_fault+0x1e/0x30

Let us restore rcu_read_lock().

https://jira.sw.ru/browse/PSBM-120802
Fix in vz7: 152239c6c3b2 ("mm/tcache: fix rcu_read_lock()/rcu_read_unlock()
imbalance")

Signed-off-by: Evgenii Shatokhin <eshatokhin@virtuozzo.com>
Reviewed-by: Andrey Ryabinin <aryabinin@virtuozzo.com>

vz9 rebase notes:
 * free_unref_page() new arg (page order) has been added - assumed it's
   always 0

(cherry picked from vz8 commit e0868a90331d9ab990f3d4ca802d068fecaa9457)
Signed-off-by: Konstantin Khorenko <khorenko@virtuozzo.com>

https://jira.sw.ru/browse/PSBM-144163
Rebase to RHEL9.1 note:
 * working with pages has been transformed to working with folios,
   so page_cache_get_speculative() -> folio_try_get_rcu()

Rebased-by: Konstantin Khorenko <khorenko@virtuozzo.com>

Feature: mm: transcendent file cache (tcache)

---
## [voira/AVSC-1.0-pc](https://github.com/voira/AVSC-1.0-pc)@[b6f222795e...](https://github.com/voira/AVSC-1.0-pc/commit/b6f222795e78061f4af699e9186156ab76479a7f)
#### Tuesday 2023-01-10 19:02:47 by dogatsahin

changelog 10.01

10.01.23 changelog + sorular:

? waceera smiling eksik, you'll always stay as a kid kƒ±smƒ± i√ßin gerekiyor

+ flashback sonrasƒ± haru kioko boylarƒ± tutmuyor, d√ºzenleme yaptƒ±m ama h√¢l√¢ boylarƒ± tam olmadƒ± gibi (kontrol edelim tekrardan)

? whemond bg ve akademi sƒ±nƒ±f bg eksik

? zuri komple yok

? g√∂z ≈üeritlerini ne yapƒ±caz

+ almasi angry -> almasi annoyed olarak deƒüi≈ütirildi (eldeki sprite o)

? magic circle g√∂rsel cg gerekiyor

- kioko odasƒ±na gireni anlattƒ±ƒüƒ± zaman haru'ya yapƒ±lan zoom kaldƒ±rƒ±ldƒ±

---
## [basil-ladder/basil](https://github.com/basil-ladder/basil)@[2e8f975293...](https://github.com/basil-ladder/basil/commit/2e8f975293d4d88ad7f0090dba1e710bd6cd3544)
#### Tuesday 2023-01-10 19:32:53 by Dennis Waldherr

Fuck you spring, happy to break randomly and not at the start of the app...

---
## [knuxify/eartag](https://github.com/knuxify/eartag)@[062b377cfe...](https://github.com/knuxify/eartag/commit/062b377cfe0fda9b789a42373050a23e1b98a0e8)
#### Tuesday 2023-01-10 20:28:23 by knuxify

meta: revise project description

This description was written back when Ear Tag was initially made.
Back then, it was only able to open one file at a time, and that was
its primary purpose. I made it as a quick tool as I was frustrated with
existing ones (and Picard was crashing my entire DE session - a problem
I did not feel like debugging).

Needless to say, things have changed quite a bit since then. Ear Tag
has fained quite a few new features, and I think it's now become suited
for managing not just singular files, but maybe even small libraries.

This extremely-awkward text has been pasted into various places that
needed a description for the program (thanks for the shoutout, OMG!
Ubuntu!), and it's been giving me second-hand embarrasment. Or maybe
first-hand embarrasment. I was the one who wrote it after all. So,
I decided to fix it. This should hopefully be better (and the new
short description actually follows GNOME's app summary guidelines now).

If I'm already typing out this incredibly long, sentimental and frankly
quite pointless commit message, I'd like to take a moment to apologize
to the creator of Tagger, another libadwaita audio tagging app. I was
completely unaware of its existence when I started working on Ear Tag.
I've seen a few folks confuse the two... sorry about that. Not that
you're ever going to read this anyways. Keep up the good work! I'm
seriously impressed by the double GTK-WinUI sorcery you're doing with
Denaro/Money. It's easily one of the coolest software tricks I've
*ever* seen. And I'm not being smug or ironic here.

---
## [knuxify/eartag](https://github.com/knuxify/eartag)@[aa2d3d4dc4...](https://github.com/knuxify/eartag/commit/aa2d3d4dc4550c9c675c4bfbcd697c652c25ce86)
#### Tuesday 2023-01-10 20:30:20 by knuxify

meta: revise project description

This description was written back when Ear Tag was initially made.
Back then, it was only able to open one file at a time, and that was
its primary purpose. I made it as a quick tool as I was frustrated with
existing ones (and Picard was crashing my entire DE session - a problem
I did not feel like debugging).

Needless to say, things have changed quite a bit since then. Ear Tag
has gained quite a few new features, and I think it's now become suited
for managing not just singular files, but maybe even small libraries.

This extremely-awkward text has been pasted into various places that
needed a description for the program (thanks for the shoutout, OMG!
Ubuntu!), and it's been giving me second-hand embarrasment. Or maybe
first-hand embarrasment. I was the one who wrote it after all. So,
I decided to fix it. This should hopefully be better (and the new
short description actually follows GNOME's app summary guidelines now).

If I'm already typing out this incredibly long, sentimental and frankly
quite pointless commit message, I'd like to take a moment to apologize
to the creator of Tagger, another libadwaita audio tagging app. I was
completely unaware of its existence when I started working on Ear Tag.
I've seen a few folks confuse the two... sorry about that. Not that
you're ever going to read this anyways. Keep up the good work! I'm
seriously impressed by the double GTK-WinUI sorcery you're doing with
Denaro/Money. It's easily one of the coolest software tricks I've
*ever* seen. And I'm not being smug or ironic here.

---
## [tgstation/tgstation](https://github.com/tgstation/tgstation)@[5250b1fcc6...](https://github.com/tgstation/tgstation/commit/5250b1fcc6aca1aa6d6b0f9ec81ce6ad5fe2fa03)
#### Tuesday 2023-01-10 20:59:20 by san7890

Captain's Spare ID Safe Can Only Hold ID Cards (#72584)

## About The Pull Request

I've personally seen this strategy play out the exact same way on more
than one occasion in an higher frequency lately (I've never played as
either side, just witnessed it)- and it always just seems to be an abuse
of a skewed in-game mechanic. So, this PR makes it so that you can only
put IDs into the spare ID safe. Nothing else.
## Why It's Good For The Game

I think this balance change is needed because it really sort of ruins
what I like about nuclear operatives, having to run around and stay
fluid for whatever the nuclear operatives could have, not "HAHA WE WILL
PUT IT IN OUR (NEARLY) IMPENETRABLE SAFE THAT THEY WILL NEED TO USE A C4
DIRECTLY ON AND JUST END UP PLAYING BLOONS TOWER DEFENSE SIX AS WE AWAIT
THOSE RED FUCKS TO ARRIVE". I miss when it would be fun to inject it
into a monkey who could crawl around vents, put it in a disposals loop
around the station to keep the nukies on a wild goose chase, or just
holding your ground in the brig and retreating if they batter you down.
It's just a very OP location in a very OP place with lots of warranted
OP armor for it's intended use case, which is not really being followed
by putting the all-important disk in the safe.

It's just very strong overall due to how protected-from-damage the spare
ID safe is, and I don't really like the fact that this is emerging as a
new "meta gameplay" (even used when there aren't any nuclear
operatives), it just sullies the different variety of ways you can
defend yourself against nuclear operatives when there appears to be
**the clear choice**. I don't like that concept where you can have a
strategy so good that you _shouldn't_ do it.

Also, it's an _ID Safe_. Not a disk safe.
## Changelog
:cl:
balance: Due to materials costing a lot more than ever, Nanotrasen's
Spare ID Safe Supplier have cut down on the space inside of the ID Safe,
meaning you can only cram in things as thin as an ID Card.
/:cl:

---
## [wolfcomp/Dalamud](https://github.com/wolfcomp/Dalamud)@[6e5e6b3b0e...](https://github.com/wolfcomp/Dalamud/commit/6e5e6b3b0e00b77071fac85adec206b9b1c484aa)
#### Tuesday 2023-01-10 21:30:01 by wolfcomp

fix yml again

AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA fuck this and its stupid ass shit with its idiotic non descriptive errors and guides

---
## [keith/bazel](https://github.com/keith/bazel)@[2232c5b445...](https://github.com/keith/bazel/commit/2232c5b445f5264b31b53a698f5f0e726d9be249)
#### Tuesday 2023-01-10 21:30:18 by Christopher Peterson Sauer

Move Boost into C++ Docs; Add Libraries Section

Hi wonderful Bazelers,

This is just a docs change.

Backstory: I'd been looking to make HTTPS requests across platforms from C++. A classic problem if there ever were one, networking being perhaps the most glaring omission in the C++ standard library. Thankfully, this is a problem Bazel can solve well, since most of the problem is the friction of using 3rd party libraries from C++. So, I spun up some build rules to make network requests easy, inspired by collaborating on the boost ones, and set off to add them to the docs.

Along the way, I noticed that the boost rules were in an odd spot: Listed at the language level alongside C++, rather than nested within C++. So I fixed that by nesting Boost inside, added Abseil, and then (hoping you'll forgive my hubris), I'd love to add the rules I just released, since I think they're a solution to a very real need. Perhaps rules for more famous, critical libraries can accumulate there over time, helping Bazel users get set up with the essential tools they need.

Thanks for your consideration!
Chris
(ex-Googler and author of [bazel-compile-commands-extractor](https://github.com/hedronvision/bazel-compile-commands-extractor), also in the docs.)

Closes #16621.

PiperOrigin-RevId: 486106928
Change-Id: I119ccff4f70e66415f8c6ac4930c975e48086bc2

---
## [jgudec/android_kernel_samsung_exynos2200](https://github.com/jgudec/android_kernel_samsung_exynos2200)@[0094ae3711...](https://github.com/jgudec/android_kernel_samsung_exynos2200/commit/0094ae371114944340760c5994595ad872766be4)
#### Tuesday 2023-01-10 22:00:59 by Serge Semin

clk: vc5: Fix 5P49V6901 outputs disabling when enabling FOD

[ Upstream commit c388cc804016cf0f65afdc2362b120aa594ff3e6 ]

We have discovered random glitches during the system boot up procedure.
The problem investigation led us to the weird outcomes: when none of the
Renesas 5P49V6901 ports are explicitly enabled by the kernel driver, the
glitches disappeared. It was a mystery since the SoC external clock
domains were fed with different 5P49V6901 outputs. The driver code didn't
seem like bogus either. We almost despaired to find out a root cause when
the solution has been found for a more modern revision of the chip. It
turned out the 5P49V6901 clock generator stopped its output for a short
period of time during the VC5_OUT_DIV_CONTROL register writing. The same
problem was found for the 5P49V6965 revision of the chip and was
successfully fixed in commit fc336ae622df ("clk: vc5: fix output disabling
when enabling a FOD") by enabling the "bypass_sync" flag hidden inside
"Unused Factory Reserved Register". Even though the 5P49V6901 registers
description and programming guide doesn't provide any intel regarding that
flag, setting it up anyway in the officially unused register completely
eliminated the denoted glitches. Thus let's activate the functionality
submitted in commit fc336ae622df ("clk: vc5: fix output disabling when
enabling a FOD") for the Renesas 5P49V6901 chip too in order to remove the
ports implicit inter-dependency.

Fixes: dbf6b16f5683 ("clk: vc5: Add support for IDT VersaClock 5P49V6901")
Signed-off-by: Serge Semin <Sergey.Semin@baikalelectronics.ru>
Reviewed-by: Luca Ceresoli <luca@lucaceresoli.net>
Link: https://lore.kernel.org/r/20220929225402.9696-2-Sergey.Semin@baikalelectronics.ru
Signed-off-by: Stephen Boyd <sboyd@kernel.org>
Signed-off-by: Sasha Levin <sashal@kernel.org>

---
## [troudbal/squeezelite](https://github.com/troudbal/squeezelite)@[226efa300c...](https://github.com/troudbal/squeezelite/commit/226efa300c4cf037e8486bad635e9deb3104636f)
#### Tuesday 2023-01-10 22:47:53 by Ralph Irving

So, I've made more tests with a simple HTTP server and a client just download data through a simple GET. It's 100% easy to reproduce the issue if the client throttle at say 160kbits/s and a file of ~3.5MB is transferred. The HTTP server confirms (as does tcpdump) that all is transferred in a record time and using TCPview (or netstat) you can see that the connection is in FIN_WAIT_2.

It is all received because the TCPWindow quickly gets massive (a few MB) and so are the kernel's buffers. Obviously, Windows has a half-open socket timer that is started with the first FIN send and that causes the issue 100% time.

By limiting SO_RCVBUF, the TCPWindow cannot open that large as soon as the application does not get data fast enough. Of course, when we'll fill the stream and output buffers, TCPWindow will open because we absorb data super fast, but it will shrink back as soon as we stop pumping data in because we are full.

Now, 4KB is awfully low and I tried to increase it and it was still fine at 65kB, I could see TCPWindow opening and closing. The funny thing is that when you do a getsockopt, system will return 65kB. If you set what you got, the problem disappear as expected. BUT, if don't set anything, then Windows uses some much larger value (although it told you it does not) and then the issues happens.

-philippe44.

Thanks philippe44 for tracking down the cause of this issue.
Increase squeezelite revision to 1419.

---
## [mscalindt/syscfg](https://github.com/mscalindt/syscfg)@[a4bfd55e36...](https://github.com/mscalindt/syscfg/commit/a4bfd55e365aa1af55164cf89ab5ab3a8e86d718)
#### Tuesday 2023-01-10 22:54:26 by Dimitar Yurukov

syscfg: Remove personal comments and such

Since the code is not personal anymore, we should, you know, cut all
opinions and such. Professionalism or something. Yeah, we just pretend
to not debug with printf statements like 'fk', 'wtf', ..., we do not
write "funny" stuff for code that shouldn't activate, et cetera. We
totally don't do that (AND THIS COMMIT MESSAGE IS TOTALLY PROFESSIONAL,
by the way).

Signed-off-by: Dimitar Yurukov <mscalindt@gmail.com>

---
## [formsandlines/formform](https://github.com/formsandlines/formform)@[fe0ef8b54c...](https://github.com/formsandlines/formform/commit/fe0ef8b54ced0553c8042974ae9c7adc6675f446)
#### Tuesday 2023-01-10 23:14:42 by Peter Hofmann

I was dissatisfied with my previous approach to create ‚Äúspecial FORMs‚Äù, so I
started to re-imagine the whole API with a more unified and flexible approach
that follows my FORM-as-data principle more consistently.

Now, there are only 4 primitives in the `expr` module:
- `(‚Ä¶)` or `[‚Ä¶]` for simple FORMs
- `"name"` or `'name` for variables
- `:sym-name` for predefined symbols
- `[:op-name ‚Ä¶]` for predefined operators

Every ‚Äúspecial FORM‚Äù is a predefined operator. Symbols and operators can be
defined using the macros `defoperator` and `defsymbol` by specifying a keyword
as a unique id which the macros will ‚Äúregister‚Äù via generic dispatch in
multimethods. This enables functions to know about these FORMs without having
to add their interpreters, simplifiers or constructors manually. I decided
against using records and protocols here since I find multimethods to be a more
flexible, functional and interop-friendly approach to polymorphism, which
doesn‚Äôt rely on host-specific OOP constructs.

I might get rid of `op-get` though, since the `defoperator` macro will define
methods for it for all parameters of the expression, which may bloat memory
unnecessarily while `op-data` can do the same (albeit a little less efficient).

The bare minimum to define an operator is for the user to define its
interpretation through `interpret-op`. E.g. `:and` can be defined with an
interpretation of `[[x] [y]]` and used like `[:and "red" "green"]`.
Operators can have any shape, but must start with a keyword, so for example
`[:mark-n n x]` might be an operator that generates a FORM with `x` marked `n`
times or `[:sel3-inv [x [y] z]]` might invert a selection to `[[x] y [z]]`.
Variable numbers of parameters are also possible, since we are just working
with normal Clojure functions.

This flexibility enables the user to be very expressive with FORMs and define
their own ‚Äúmacros‚Äù as shortcuts for complex constructions, which can also
be composed and combined at will. They can also define a custom simplification
procedure via `simplify-op` that will then be preferred by the simplifier over
strict interpretation. It can manipulate the environment during simplification
and do all sorts of unsafe and magical stuff, so the user is responsible to
verify the validity and correctness of their approach or just use it for crazy
experiments. Self-equivalent re-entry FORMs, formDNA FORMs and memory FORMs use
this feature to implement their special behavior.

The former ‚Äúexpression‚Äù primitive `[‚Ä¶]` has also been replaced by an operator,
since every FORM or content is considered an expression now (no arbitrary
distinctions anymore!). `[:- ‚Ä¶]` is just called an arrangement and interpreted
as `[[‚Ä¶]]`. It is not required to build an expression and can be used for
grouping and unmarked relations. I also introduced `:*` and `:|` as syntactic
sugar for `(a)(b) ‚Ä¶` and `((a)(b) ‚Ä¶)`, which are ideas from my thoughts on
special FORM syntax. They may or may not be useful, we‚Äôll see.

Construction of operators can be directly as vectors (no metadata needed) or
more safely through `(make :op args‚Ä¶)`, provided the operator is registered
for `make-op`. `(form ‚Ä¶)` is a corresponding constructor for simple FORMs and
`(seq-re :sign nested-exprs‚Ä¶)` constructs self-equivalent re-entry FORMs. In
the REPL, I would use ‚Äújust data‚Äù while in more critical functions/definitions
constructors would be the safer choice, since they can (soon) validate inputs.

I also decided to get rid of `:mn`, since it is just another way to write `:U`
and it is annoying to have to recognize and test both of them in various
functions. If a user wants `:mn`, they can define it as an expression symbol
that gets interpreted as `:U`.

This might be the longest commit ever and I most definitely missed some changes,
but I felt that I needed to document the rewrite of `expr` from a conceptual
side before moving on. The old draft is still around as I still need to adapt
and add many things (and tests), but it will be deleted later.

---

# [<](2023-01-09.md) 2023-01-10 [>](2023-01-11.md)

