# [<](2020-11-17.md) 2020-11-18 [>](2020-11-19.md)

3,212,320 events, 1,546,607 push events, 2,361,507 commit messages, 171,845,496 characters


## [wfleming/dotfiles](https://github.com/wfleming/dotfiles)@[ae12a286d2...](https://github.com/wfleming/dotfiles/commit/ae12a286d2195428379ef9de7bd9b911b1cd5f2d)
#### Wednesday 2020-11-18 00:59:23 by Will Fleming

Drop Cloudflare DNS - use Google instead

I've been noticing very Internet recently, and it appears to
be due to Cloudflare DNS.

Testing with `dig @1.1.1.1 google.com`, I would say ~30-50% of the time
the request times out, or takes several seconds to resolve. Querying via
8.8.8.8 is reliably fast. With 1.1.1.1 as my preferred DNS host in
resolv.conf, `curl https://www.google.com` often takes ~5s. With
8.8.8.8, it's reliably a few hundred ms. So I think what's happening is
that in many cases cloudflare is timing out, and then resolution falls
back to google, which then resolves the address quickly.

This has been going on for at least a couple weeks, I think, and I
finally got annoyed enough to try and figure out what was up (for a
while I just thought our ISP was worse than usual and it was a bandwidth
problem, before I noticed bandwidth-sensitive tasks like video were
fine, it was latency that was the problem).

I confess I'm very surprised at this diagnosis - it's clearly not some
kind of temporary incident, and if Cloudflare's public DNS was fubared
you'd think it might have generated some Internet chatter.  My best
theory right now is that some misconfiguration in a hop along the way
from me to 1.1.1.1 (probably at my ISP) is causing packets to get
mis-routed or dropped or something, so not many people are impacted (and
I'm living in a fairly sparse suburban area, so I might be literally the
only person in the area trying to use Cloudflare DNS).

---
## [ahmetsait/opentk](https://github.com/ahmetsait/opentk)@[615ffa01ca...](https://github.com/ahmetsait/opentk/commit/615ffa01caa40e54a2ecaa8e54196f4dac6d09d5)
#### Wednesday 2020-11-18 01:02:58 by Ahmet Sait

Fix wrong binding code generation on some locales

The reason we set culture info (aka locale) here is because the binding
generator uses locale dependent string operations such as converting characters
to upper/lower case, case insensitive comparisons and float <-> string
conversions. This breaks in all kinds of nasty ways if you try to build the
project in parts of the world where upper case "version" is not "VERSION" but
rather "VERSİON" or lower case "VERSION" is 'versıon'. Obscure culture/language
conventions are among the things you will see that break software or make them
produce garbage output. This is a good examples of it and I suggest you study
it carefully. Theoretically this should be fixed by using overloads of those
string functions that take culture info parameters exclusively. This is
unfeasible however, more on that later.
You see, microsoft engineers thought that making all the relevant functions
such as float.Parse() locale dependent would make lives of programmers easier
since the functions would do the right thing™ by *default*. This is almost
NEVER what you want. Nobody in the right mind would ever think it is reasonable
for people write float.Parse(str, CultureInfo.InvariantCulture) every damn time
you don't want locale to be involved. It could've been an opt-in feature of the
library where you get locale dependent behavior if you _ask for it_ but no.
This shit is the reason your shitty csv/json parser crashes on a poor soul
living in some part of the world where comma instead of dot is used for decimal
numbers. This type of bullshit is the reason Visual Studio auto-complete used
to not show you "Invariant" when you enter "inv" because you happen to have a
tr-TR locale set on your computer. This right here is the reason some garbage
Asp.Net web page shows your purchase date in some retarded american format
because the server happens to be in USA.
Much can be said about how degenerate this global state dependent spooky action
at distance kind of nonsense is, to the point where you can convince anyone
that die-hard pure functional haskell fans were right all along. Things are
made worse by the fact that string interpolation and implicit string conversion
makes searching the problematic code rather inconceivable, and this cancerous
functionality is encouraged by the features integrated directly into the
language. But the badness doesn't stop here. The people behind this glorious
bullshit were smart enough to make CultureInfo.CurrentCulture thread local
(which btw only prevents data races and retains all the disgusting ugliness a
global state can have), but not smart enough to make child threads inherit the
locale from its parent. Prior to .Net 4.5 every new thread would have its
locale reset to whatever the OS current is, which broke things even if you've
set CurrentCulture in the main thread but forgot to set it for each and every
thread you (or worse, a library you use) spawned!
At some point they must have realized how fucked up this whole situation is,
which resulted in an attempt to fix it by introducing _another_ property called
DefaultThreadCurrentCulture which determines what locale a new thread would get
initialized to. Don't be fooled into believing that this finally does solve
things sanely, as this is completely broken crap simply because it is an
application-wide global variable meaning that any thread at any time can change
it to facilitate subsequent threads they spawn to have a certain locale, except
of course it is not possible to do such thing in a multi-threaded environment
as you can not be sure if it changed just before you spawn a thread.
Unsurprisingly, the official docs for DefaultThreadCurrentCulture doesn't even
mention whether it is thread safe to mess with it as to keep you excited on
your coding journey.
So in order to avoid this utterly spectacular incompetence, we assign every
culture info setting to InvariantCulture and hope that no library under the sun
touches these abominations like CurrentCulture and its variants.

---
## [Mantaro/MantaroBot](https://github.com/Mantaro/MantaroBot)@[2f7f1ceb26...](https://github.com/Mantaro/MantaroBot/commit/2f7f1ceb26fb705064a9ef120f58b88f3aeee609)
#### Wednesday 2020-11-18 02:04:29 by kodehawa

Fix(removetrack): fix removetrack not working at all for various reasons

Removing a single track worked. That's it.
Issues fixed:
- Removing the last track would remove the last element - 1
(so if the list had 15 elements, it'd remove element N° 14, not even counting index, so it removed the index 13)
- Removing the first track would try to remove element -1
- Removing a range would appear to work, but since the element of the ArrayList would
shift by one every call, it removed every index shifted by one all the time.

In short, this entire command didn't work at all, for FOUR years, and
nobody reported it until today, end of 2020. This command git blame'd to
about early 2017. I'm lost as to how little people use music on this bot to
even be worth keeping at this point

/rant

I still love you all. But holy shit :P

Signed-off-by: kodehawa <david.alejandro.rubio@gmail.com>

---
## [PieZu/PieZu.github.io](https://github.com/PieZu/PieZu.github.io)@[9c82703b56...](https://github.com/PieZu/PieZu.github.io/commit/9c82703b56c09c5f240d21d75053f3f72ca10036)
#### Wednesday 2020-11-18 02:49:26 by PieZu

fixed encryption test suite

omg the intricate little bugs took me so long to find and fix and stuff.... i think the main problem was that the variable 'key' was being scoped to the parameters in an anonymous function in the .then,,, I must say it is rather confusing when it works perfectly in developer tools but not in code. Also I wrote a little custom encoder to just use some pastable characters because that also lead to problems.. yeah...
the code is now really ugly and messy and i understood it before but now i dont really but im too scared to touch it for now. At least it works (i think) :p

---
## [island-troll-tribes/island-troll-tribes](https://github.com/island-troll-tribes/island-troll-tribes)@[92ed1f2206...](https://github.com/island-troll-tribes/island-troll-tribes/commit/92ed1f22066135035feb277705b32c12724f68ef)
#### Wednesday 2020-11-18 02:56:40 by Marc Szilagyi

Removed Ded'Jellow and God'Jellow from the proper names pool. (#643)

$changelog: Removed kinjello references in Priest & Master Healer proper name.

It has reached my hearing that some people aren't happy at all seeing kinjello having a reference in priest name.
Those names have been added by me in a context where the player base was meme-ing at kinjello perfomance on priest, sometime he would crappy move and die, sometime he would actually do good play and turn up a fight. His behavior being impredictable, I decided to add those name just for meme-ing, the community back then didn't seem to complain, atleast not to the point where I had to revert it.

---
## [facebookresearch/flashlight](https://github.com/facebookresearch/flashlight)@[14888c51d1...](https://github.com/facebookresearch/flashlight/commit/14888c51d174519278712dd0bc8d4bb29f074b4f)
#### Wednesday 2020-11-18 05:56:42 by Jacob Kahn

Move flashlight to C++14 (#267)

Summary:
Pull Request resolved: https://github.com/facebookresearch/flashlight/pull/267

Upgrade to C++ 14.

We've been talking about this for some time; I think it's time to make the transition.

To be honest, moving to C++17 may not be a bad step in the near future, but making incremental changes will make this transition easier.

For now, this change only removes backports for `make_unique` and various `type_traits`, and leaves other things as they are for now.

### General Thoughts
- Staying >= 4 years behind the standard (2020 - 2014), to me, is extremely reasonable
- ArrayFire already requires C++14 to build from source
- gcc >= 5 has solid support for C++14 already, and that's our compiler recommendation as is since we use some "advanced" C++11 features.
- PyTorch has a C++14 minimum for its C++ API to build from source, so this is consistent with other competing frameworks frameworks

### What's new in C++14?
A light summary here — there are a wealth of new features that make life better:
- `std::make_unique<T>` (enough said)
- Removal of a bunch of awful type trait backports
  - `std::remove_const_t` and friends
  - `decay_t`!
- `auto` as a return type for functions
- `auto` lambda params!
```
auto fun = [](auto v) { return v + 1; };
```
- Move capture rather than reference in a persistent pointer!
```
auto _myFoo = std::make_unique<Foo>();
auto fun = [myFoo = std::move(_myFoo)]() { ... }
```
- Compile time literals for a bunch of stuff (datetime, string)
```
using namespace std::chrono_literals;
auto week = 168h;
```

Reviewed By: tlikhomanenko

Differential Revision: D25037733

fbshipit-source-id: 9d88d39922e544e6a5bde2ce5f5bafb9f319acca

---
## [genixo/Galaxy-Educational-Services](https://github.com/genixo/Galaxy-Educational-Services)@[3ab7bd3be2...](https://github.com/genixo/Galaxy-Educational-Services/commit/3ab7bd3be241008b97ba865032582b4846b0b5d8)
#### Wednesday 2020-11-18 06:34:50 by genixo

Create Benefits of pursuing BBA Course

You may be wondering what to do after BBA? You may feel that there is no scope for BBA. But this is not true, every course has its value and every degree programme has its own importance.

Just read this article till the end you will get your answers

Bachelor of Business Administration
BBA is most preferred and pursued next to engineering and medical courses by many students after the completion of 12th. There is always a rat race to join medical and engineering soon after the completion of 12th. There may be many reasons for this as the students will undergo a lot of stress. They get confused due to various factors like parent’s force, peer pressure, suggestions from different sources, friendship and many more. But students should be very cautious about choosing their career. They should not go with the flow and land in trouble.

So, it is suggested to have a glance of this article before deciding to join any undergraduate programmes.


What is BBA?
Bachelor of Business administration (BBA) is the undergraduate course that provides broad knowledge about the functional aspect of an organization.

BBA is a 3-year degree programme which trains the students on managerial skills required in the field of management. The students of today have many opportunities to explore numerous options available in BBA. The students can easily build their career in the management field by joining BBA.

The BBA programme can be opted by students of all the streams: science, commerce and arts. The BBA programme offers the students with the relevant knowledge and training in management skills and leadership skills. These skills prepare them to handle the managerial roles and entrepreneurship with ease.


Benefits of doing a BBA programme
The students can get a lot of benefits by opting BBA programmes. The students can develop themselves at both levels; professionally and personally. Professionally, the BBA programme offers a good step towards career growth.

The best-performing students can adorn many managerial levels in the organizations. They will also be promoted to decision making positions in a short time.

At the personal level, the students will develop many qualities like leadership, entrepreneurship, negotiation skills, management skills, analytical skills etc. These qualities ensure the holistic development of the BBA students.

Apart from this there are many other benefits that the BBA programme offers, they are:

The BBA programme acts as a gateway to a number of job opportunities in different sectors like Marketing, Education, Finance, Sales, Government etc. You name it you have it.
The BBA programme gives an in-depth knowledge of business to the students. The BBA programme shapes the students into successful entrepreneurs by teaching them the tactics of observation, judgement, risk-taking abilities and decision-making capacity.
The BBA course trains the students with different qualities like entrepreneurial qualities, leadership qualities and management skills.
The BBA programme acts as a strong base for pursuing MBA courses. The BBA students will be learning all the aspects of the management at their BBA course duration. The BBA course gives a basic understanding of the management topics and it becomes easy for BBA students to join MBA and perform better.
The BBA programmes provide an opportunity for the students to work as interns in many organizations. BBA students get better exposure to the work culture of the organizations. The BBA programme empowers the students with better business knowledge of the organizations.
The BBA programme helps the students to build stronger business acumen and makes them competent to take splendid decisions that will benefit the organization’s success rates
The BBA course helps the students to develop out of box thinking capacities and makes them unique and stands out of the crowd.
The students pursuing a BBA programme will be equipped with practical skills with a better knowledge of global ideas and prepare them for future workspaces.

Some of the Specializations of BBA
As time passes the industry trend also changes accordingly. The advancement in new technologies, new strategies, new business ideas, new ventures have given room to more specializations and new subjects.

BBA has also developed its wings into different specializations. The changing trend in the industry has created new job opportunities for skilled professionals in different sectors. The industry today looks for specialists who are talented and capable to do multitasking and the demand is more for talented multi-tasking professionals.

BBA which was once only limited to a few subjects has changed its dimensions today. Due to the demand of the industry, the BBA programmes have introduced many specializations that are relevant to the industry. The students can choose from a variety of specializations according to their interests.

Some of the specializations that are offered by BBA programmes are:

BBA Global Aviation
BBA Logistics & Supply Chain Management
BBA Strategic Finance
BBA Business Analytics
BBA Entrepreneurship
BBA Aviation Management
BBA Finance and Accountancy
BBA Travel and Tourism Management
BBA Hospitality and Event Management
BBA Finance and International Business
BBA Global
The students can choose their desired specializations and build their careers in management with the BBA degree in hand. As it has already mentioned BBA has spread its wings into different sectors with unique specializations. The students can study their interested subjects and land in best careers.

Job Roles Available after BBA
The BBA students can have thousands of job openings soon after the completion of their BBA degree. The BBA is a versatile degree and the BBA students can find a job at almost all the fields across nations with no barriers attached.

Some of the job roles that are available after the BBA programme are:


Accountant
Accountants are professionals who are good in numbers. They are required in all the businesses irrespective of they are small or large. It may be a small provision shop owner or an owner of huge supermarkets, everyone needs an accountant to look after their earnings daily. The accountants are responsible to prepare financial documents and ensure that the tax operations go smoothly


Financial Advisor
Financial Advisors are responsible to look after the financial health of the companies and people. The financial advisors guide the people and the companies to manage and allocate the money generated and make their businesses successful. They also help people to make smart decisions on investments and help them to become financially stable individuals.


Marketer
The marketers plan and coordinate the marketing efforts of the businesses. They are required to promote the products and create the demand in the market. They create marketing strategies for their products and try to generate demand for that product. They are also required to oversee the development of the product and monitor the marketing trends within the business targeted markets.


Commodities Trader
The commodities traders buy and sell commodity contracts on behalf of the companies. They procure the raw materials for the company and sell the finished product to the markets. The commodity trader is essential to maintain a proper balance between the buying and selling of the goods and raw materials and also should take care of the finished products.


Human Resources Executives
As the name itself denotes that it is related to man-power. The human resource executives are responsible to hire the new employees for the organizations.

They are required to screen the candidates according to the requirement for a job role. They are responsible to schedule and conduct the interview sessions for the right candidates. They are also required to judge the candidates based on different parameters like communication skills, attitude, technical capability, dedication. They are also required to formulate the employment policies, maintain employment records, address employee grievance redressals in the organizations.


Loan Officer
The loan officers are required in banks and financial institutions. They are responsible to approve or deny the loans for the people and businesses. They are responsible to evaluate the eligibility of the people and business. They are responsible to maintain accurate records for the loans given to the people and ensure that the complete loan is recovered during the specified loan repayment period.


Real Estate Agent
The real estate agents help people to buy and sell properties. The real-estate brokers are required to pass the licensing exams to start their careers.

They can practice individually or can work under licensed companies like 99acres.com, No Broker.com, Magic Bricks.com etc. The BBA can act as the base to become a real estate agent. The real estate agents are required to have in-depth knowledge of the market rates according to the locations. They are required to provide accurate information for both buyers and sellers.


Manager
The managers are responsible to keep the things to run smoothly in an organization. They are required to perform almost all the daily operations irrespective of the organizations they are hired.

No matter if it is a small retail shop or a large production facility. They are responsible to oversee all the tasks that are performed by the organization and ensure that the workflow is smooth without any blockages


Stock Brokers
The Stock Brokers mainly work in share markets i.e. BSE and NSE. Their main role of these stock brokers is to buy and sell the shares of the different organizations that are listed in the share markets.

Many organizations sell their shares in the open share markets for generating liquid cash. So, that the normal public can buy those shares and generate revenue for the organizations. This ensures a money flow in the markets and ensures that the country’s economy is strong. The stockbrokers are required to monitor the shares daily and ensure that proper money flow is maintained in the country’s markets.


Entrepreneur
Entrepreneurs are the individuals who organize and operate their own businesses. The individuals who come with their own ventures and businesses are termed as entrepreneurs. The BBA degree can provide a perfect base for the people who are interested to start their own ventures.

The entrepreneurs come with innovative ideas and develop new businesses in the market. With the advent of the internet, we are witnessing a huge raise in entrepreneurs in the last decade. So, if you are interested to be the boss of your own, then you can choose to become an entrepreneur by joining BBA programmes

Concluding Words
As it is already mentioned that every degree has its importance and no degree is considered as a waste. It is up to the students how to use their chosen degrees for their growth. The interested and dedicated students can easily land in best job opportunities and can see a fruitful career irrespective of their degrees. Similarly, the BBA programme is also unique. The BBA degree provides a proper base for many career opportunities. The interested students who join BBA courses can have many job opportunities and can have a good career growth. They can land in many challenging roles after the BBA programme and can prove themselves to reach the high levels in their careers. Further, the BBA programme not only helps the students to grow professionally but also personally.

---
## [coozoo/qtjsondiff](https://github.com/coozoo/qtjsondiff)@[669578047f...](https://github.com/coozoo/qtjsondiff/commit/669578047fb620c132996e708be120dd63d8cc7c)
#### Wednesday 2020-11-18 07:20:31 by coozoo

Whole tree collapse/expand to single selection

aded just two items yeah did it in a ugly way but it's damn easier just
few copy paste actions sorry :)

---
## [kutemeikito/android_kernel_xiaomi_ginkgo](https://github.com/kutemeikito/android_kernel_xiaomi_ginkgo)@[93b5a3333a...](https://github.com/kutemeikito/android_kernel_xiaomi_ginkgo/commit/93b5a3333aaf5df72ff144abf71368e16a409d34)
#### Wednesday 2020-11-18 09:35:13 by Christian Brauner

BACKPORT: signal: add pidfd_send_signal() syscall

The kill() syscall operates on process identifiers (pid). After a process
has exited its pid can be reused by another process. If a caller sends a
signal to a reused pid it will end up signaling the wrong process. This
issue has often surfaced and there has been a push to address this problem [1].

This patch uses file descriptors (fd) from proc/<pid> as stable handles on
struct pid. Even if a pid is recycled the handle will not change. The fd
can be used to send signals to the process it refers to.
Thus, the new syscall pidfd_send_signal() is introduced to solve this
problem. Instead of pids it operates on process fds (pidfd).

/* prototype and argument /*
long pidfd_send_signal(int pidfd, int sig, siginfo_t *info, unsigned int flags);

/* syscall number 424 */
The syscall number was chosen to be 424 to align with Arnd's rework in his
y2038 to minimize merge conflicts (cf. [25]).

In addition to the pidfd and signal argument it takes an additional
siginfo_t and flags argument. If the siginfo_t argument is NULL then
pidfd_send_signal() is equivalent to kill(<positive-pid>, <signal>). If it
is not NULL pidfd_send_signal() is equivalent to rt_sigqueueinfo().
The flags argument is added to allow for future extensions of this syscall.
It currently needs to be passed as 0. Failing to do so will cause EINVAL.

/* pidfd_send_signal() replaces multiple pid-based syscalls */
The pidfd_send_signal() syscall currently takes on the job of
rt_sigqueueinfo(2) and parts of the functionality of kill(2), Namely, when a
positive pid is passed to kill(2). It will however be possible to also
replace tgkill(2) and rt_tgsigqueueinfo(2) if this syscall is extended.

/* sending signals to threads (tid) and process groups (pgid) */
Specifically, the pidfd_send_signal() syscall does currently not operate on
process groups or threads. This is left for future extensions.
In order to extend the syscall to allow sending signal to threads and
process groups appropriately named flags (e.g. PIDFD_TYPE_PGID, and
PIDFD_TYPE_TID) should be added. This implies that the flags argument will
determine what is signaled and not the file descriptor itself. Put in other
words, grouping in this api is a property of the flags argument not a
property of the file descriptor (cf. [13]). Clarification for this has been
requested by Eric (cf. [19]).
When appropriate extensions through the flags argument are added then
pidfd_send_signal() can additionally replace the part of kill(2) which
operates on process groups as well as the tgkill(2) and
rt_tgsigqueueinfo(2) syscalls.
How such an extension could be implemented has been very roughly sketched
in [14], [15], and [16]. However, this should not be taken as a commitment
to a particular implementation. There might be better ways to do it.
Right now this is intentionally left out to keep this patchset as simple as
possible (cf. [4]).

/* naming */
The syscall had various names throughout iterations of this patchset:
- procfd_signal()
- procfd_send_signal()
- taskfd_send_signal()
In the last round of reviews it was pointed out that given that if the
flags argument decides the scope of the signal instead of different types
of fds it might make sense to either settle for "procfd_" or "pidfd_" as
prefix. The community was willing to accept either (cf. [17] and [18]).
Given that one developer expressed strong preference for the "pidfd_"
prefix (cf. [13]) and with other developers less opinionated about the name
we should settle for "pidfd_" to avoid further bikeshedding.

The  "_send_signal" suffix was chosen to reflect the fact that the syscall
takes on the job of multiple syscalls. It is therefore intentional that the
name is not reminiscent of neither kill(2) nor rt_sigqueueinfo(2). Not the
fomer because it might imply that pidfd_send_signal() is a replacement for
kill(2), and not the latter because it is a hassle to remember the correct
spelling - especially for non-native speakers - and because it is not
descriptive enough of what the syscall actually does. The name
"pidfd_send_signal" makes it very clear that its job is to send signals.

/* zombies */
Zombies can be signaled just as any other process. No special error will be
reported since a zombie state is an unreliable state (cf. [3]). However,
this can be added as an extension through the @flags argument if the need
ever arises.

/* cross-namespace signals */
The patch currently enforces that the signaler and signalee either are in
the same pid namespace or that the signaler's pid namespace is an ancestor
of the signalee's pid namespace. This is done for the sake of simplicity
and because it is unclear to what values certain members of struct
siginfo_t would need to be set to (cf. [5], [6]).

/* compat syscalls */
It became clear that we would like to avoid adding compat syscalls
(cf. [7]).  The compat syscall handling is now done in kernel/signal.c
itself by adding __copy_siginfo_from_user_generic() which lets us avoid
compat syscalls (cf. [8]). It should be noted that the addition of
__copy_siginfo_from_user_any() is caused by a bug in the original
implementation of rt_sigqueueinfo(2) (cf. 12).
With upcoming rework for syscall handling things might improve
significantly (cf. [11]) and __copy_siginfo_from_user_any() will not gain
any additional callers.

/* testing */
This patch was tested on x64 and x86.

/* userspace usage */
An asciinema recording for the basic functionality can be found under [9].
With this patch a process can be killed via:

 #define _GNU_SOURCE
 #include <errno.h>
 #include <fcntl.h>
 #include <signal.h>
 #include <stdio.h>
 #include <stdlib.h>
 #include <string.h>
 #include <sys/stat.h>
 #include <sys/syscall.h>
 #include <sys/types.h>
 #include <unistd.h>

 static inline int do_pidfd_send_signal(int pidfd, int sig, siginfo_t *info,
                                         unsigned int flags)
 {
 #ifdef __NR_pidfd_send_signal
         return syscall(__NR_pidfd_send_signal, pidfd, sig, info, flags);
 #else
         return -ENOSYS;
 #endif
 }

 int main(int argc, char *argv[])
 {
         int fd, ret, saved_errno, sig;

         if (argc < 3)
                 exit(EXIT_FAILURE);

         fd = open(argv[1], O_DIRECTORY | O_CLOEXEC);
         if (fd < 0) {
                 printf("%s - Failed to open \"%s\"\n", strerror(errno), argv[1]);
                 exit(EXIT_FAILURE);
         }

         sig = atoi(argv[2]);

         printf("Sending signal %d to process %s\n", sig, argv[1]);
         ret = do_pidfd_send_signal(fd, sig, NULL, 0);

         saved_errno = errno;
         close(fd);
         errno = saved_errno;

         if (ret < 0) {
                 printf("%s - Failed to send signal %d to process %s\n",
                        strerror(errno), sig, argv[1]);
                 exit(EXIT_FAILURE);
         }

         exit(EXIT_SUCCESS);
 }

/* Q&A
 * Given that it seems the same questions get asked again by people who are
 * late to the party it makes sense to add a Q&A section to the commit
 * message so it's hopefully easier to avoid duplicate threads.
 *
 * For the sake of progress please consider these arguments settled unless
 * there is a new point that desperately needs to be addressed. Please make
 * sure to check the links to the threads in this commit message whether
 * this has not already been covered.
 */
Q-01: (Florian Weimer [20], Andrew Morton [21])
      What happens when the target process has exited?
A-01: Sending the signal will fail with ESRCH (cf. [22]).

Q-02:  (Andrew Morton [21])
       Is the task_struct pinned by the fd?
A-02:  No. A reference to struct pid is kept. struct pid - as far as I
       understand - was created exactly for the reason to not require to
       pin struct task_struct (cf. [22]).

Q-03: (Andrew Morton [21])
      Does the entire procfs directory remain visible? Just one entry
      within it?
A-03: The same thing that happens right now when you hold a file descriptor
      to /proc/<pid> open (cf. [22]).

Q-04: (Andrew Morton [21])
      Does the pid remain reserved?
A-04: No. This patchset guarantees a stable handle not that pids are not
      recycled (cf. [22]).

Q-05: (Andrew Morton [21])
      Do attempts to signal that fd return errors?
A-05: See {Q,A}-01.

Q-06: (Andrew Morton [22])
      Is there a cleaner way of obtaining the fd? Another syscall perhaps.
A-06: Userspace can already trivially retrieve file descriptors from procfs
      so this is something that we will need to support anyway. Hence,
      there's no immediate need to add another syscalls just to make
      pidfd_send_signal() not dependent on the presence of procfs. However,
      adding a syscalls to get such file descriptors is planned for a
      future patchset (cf. [22]).

Q-07: (Andrew Morton [21] and others)
      This fd-for-a-process sounds like a handy thing and people may well
      think up other uses for it in the future, probably unrelated to
      signals. Are the code and the interface designed to permit such
      future applications?
A-07: Yes (cf. [22]).

Q-08: (Andrew Morton [21] and others)
      Now I think about it, why a new syscall? This thing is looking
      rather like an ioctl?
A-08: This has been extensively discussed. It was agreed that a syscall is
      preferred for a variety or reasons. Here are just a few taken from
      prior threads. Syscalls are safer than ioctl()s especially when
      signaling to fds. Processes are a core kernel concept so a syscall
      seems more appropriate. The layout of the syscall with its four
      arguments would require the addition of a custom struct for the
      ioctl() thereby causing at least the same amount or even more
      complexity for userspace than a simple syscall. The new syscall will
      replace multiple other pid-based syscalls (see description above).
      The file-descriptors-for-processes concept introduced with this
      syscall will be extended with other syscalls in the future. See also
      [22], [23] and various other threads already linked in here.

Q-09: (Florian Weimer [24])
      What happens if you use the new interface with an O_PATH descriptor?
A-09:
      pidfds opened as O_PATH fds cannot be used to send signals to a
      process (cf. [2]). Signaling processes through pidfds is the
      equivalent of writing to a file. Thus, this is not an operation that
      operates "purely at the file descriptor level" as required by the
      open(2) manpage. See also [4].

/* References */
[1]:  https://lore.kernel.org/lkml/20181029221037.87724-1-dancol@google.com/
[2]:  https://lore.kernel.org/lkml/874lbtjvtd.fsf@oldenburg2.str.redhat.com/
[3]:  https://lore.kernel.org/lkml/20181204132604.aspfupwjgjx6fhva@brauner.io/
[4]:  https://lore.kernel.org/lkml/20181203180224.fkvw4kajtbvru2ku@brauner.io/
[5]:  https://lore.kernel.org/lkml/20181121213946.GA10795@mail.hallyn.com/
[6]:  https://lore.kernel.org/lkml/20181120103111.etlqp7zop34v6nv4@brauner.io/
[7]:  https://lore.kernel.org/lkml/36323361-90BD-41AF-AB5B-EE0D7BA02C21@amacapital.net/
[8]:  https://lore.kernel.org/lkml/87tvjxp8pc.fsf@xmission.com/
[9]:  https://asciinema.org/a/IQjuCHew6bnq1cr78yuMv16cy
[11]: https://lore.kernel.org/lkml/F53D6D38-3521-4C20-9034-5AF447DF62FF@amacapital.net/
[12]: https://lore.kernel.org/lkml/87zhtjn8ck.fsf@xmission.com/
[13]: https://lore.kernel.org/lkml/871s6u9z6u.fsf@xmission.com/
[14]: https://lore.kernel.org/lkml/20181206231742.xxi4ghn24z4h2qki@brauner.io/
[15]: https://lore.kernel.org/lkml/20181207003124.GA11160@mail.hallyn.com/
[16]: https://lore.kernel.org/lkml/20181207015423.4miorx43l3qhppfz@brauner.io/
[17]: https://lore.kernel.org/lkml/CAGXu5jL8PciZAXvOvCeCU3wKUEB_dU-O3q0tDw4uB_ojMvDEew@mail.gmail.com/
[18]: https://lore.kernel.org/lkml/20181206222746.GB9224@mail.hallyn.com/
[19]: https://lore.kernel.org/lkml/20181208054059.19813-1-christian@brauner.io/
[20]: https://lore.kernel.org/lkml/8736rebl9s.fsf@oldenburg.str.redhat.com/
[21]: https://lore.kernel.org/lkml/20181228152012.dbf0508c2508138efc5f2bbe@linux-foundation.org/
[22]: https://lore.kernel.org/lkml/20181228233725.722tdfgijxcssg76@brauner.io/
[23]: https://lwn.net/Articles/773459/
[24]: https://lore.kernel.org/lkml/8736rebl9s.fsf@oldenburg.str.redhat.com/
[25]: https://lore.kernel.org/lkml/CAK8P3a0ej9NcJM8wXNPbcGUyOUZYX+VLoDFdbenW3s3114oQZw@mail.gmail.com/

Cc: "Eric W. Biederman" <ebiederm@xmission.com>
Cc: Jann Horn <jannh@google.com>
Cc: Andy Lutomirsky <luto@kernel.org>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Oleg Nesterov <oleg@redhat.com>
Cc: Al Viro <viro@zeniv.linux.org.uk>
Cc: Florian Weimer <fweimer@redhat.com>
Signed-off-by: Christian Brauner <christian@brauner.io>
Reviewed-by: Tycho Andersen <tycho@tycho.ws>
Reviewed-by: Kees Cook <keescook@chromium.org>
Reviewed-by: David Howells <dhowells@redhat.com>
Acked-by: Arnd Bergmann <arnd@arndb.de>
Acked-by: Thomas Gleixner <tglx@linutronix.de>
Acked-by: Serge Hallyn <serge@hallyn.com>
Acked-by: Aleksa Sarai <cyphar@cyphar.com>

(cherry picked from commit 3eb39f47934f9d5a3027fe00d906a45fe3a15fad)

Conflicts:
        arch/x86/entry/syscalls/syscall_32.tbl - trivial manual merge
        arch/x86/entry/syscalls/syscall_64.tbl - trivial manual merge
        include/linux/proc_fs.h - trivial manual merge
        include/linux/syscalls.h - trivial manual merge
        include/uapi/asm-generic/unistd.h - trivial manual merge
        kernel/signal.c - struct kernel_siginfo does not exist in 4.14
        kernel/sys_ni.c - cond_syscall is used instead of COND_SYSCALL
        arch/x86/entry/syscalls/syscall_32.tbl
        arch/x86/entry/syscalls/syscall_64.tbl

(1. manual merges because of 4.14 differences
 2. change prepare_kill_siginfo() to use struct siginfo instead of
kernel_siginfo
 3. use copy_from_user() instead of copy_siginfo_from_user() in copy_siginfo_from_user_any()
 4. replaced COND_SYSCALL with cond_syscall
 5. Removed __ia32_sys_pidfd_send_signal in arch/x86/entry/syscalls/syscall_32.tbl.
 6. Replaced __x64_sys_pidfd_send_signal with sys_pidfd_send_signal in arch/x86/entry/syscalls/syscall_64.tbl.)

Bug: 135608568
Test: test program using syscall(__NR_pidfd_send_signal,..) to send SIGKILL
Change-Id: I34da11c63ac8cafb0353d9af24c820cef519ec27
Signed-off-by: Suren Baghdasaryan <surenb@google.com>
(cherry picked from commit c8b9b2c5cca36e3bbc567a1f030ee10a795b409d)
(cherry picked from commit bc2aae56cbc3337606ffab64182cb47269961f61)
(cherry picked from commit 14ab996549cf2910bd4ecaacbed3628cfc7e5ca1)
Signed-off-by: Edwiin Kusuma Jaya <kutemeikito0905@gmail.com>

---
## [kutemeikito/android_kernel_xiaomi_ginkgo](https://github.com/kutemeikito/android_kernel_xiaomi_ginkgo)@[8f5fc73052...](https://github.com/kutemeikito/android_kernel_xiaomi_ginkgo/commit/8f5fc730523aa612aece76755859579585410c16)
#### Wednesday 2020-11-18 10:53:25 by Alexander Potapenko

BACKPORT: mm: security: introduce init_on_alloc=1 and init_on_free=1 boot options

Upstream commit 6471384af2a6530696fc0203bafe4de41a23c9ef.

Patch series "add init_on_alloc/init_on_free boot options", v10.

Provide init_on_alloc and init_on_free boot options.

These are aimed at preventing possible information leaks and making the
control-flow bugs that depend on uninitialized values more deterministic.

Enabling either of the options guarantees that the memory returned by the
page allocator and SL[AU]B is initialized with zeroes.  SLOB allocator
isn't supported at the moment, as its emulation of kmem caches complicates
handling of SLAB_TYPESAFE_BY_RCU caches correctly.

Enabling init_on_free also guarantees that pages and heap objects are
initialized right after they're freed, so it won't be possible to access
stale data by using a dangling pointer.

As suggested by Michal Hocko, right now we don't let the heap users to
disable initialization for certain allocations.  There's not enough
evidence that doing so can speed up real-life cases, and introducing ways
to opt-out may result in things going out of control.

This patch (of 2):

The new options are needed to prevent possible information leaks and make
control-flow bugs that depend on uninitialized values more deterministic.

This is expected to be on-by-default on Android and Chrome OS.  And it
gives the opportunity for anyone else to use it under distros too via the
boot args.  (The init_on_free feature is regularly requested by folks
where memory forensics is included in their threat models.)

init_on_alloc=1 makes the kernel initialize newly allocated pages and heap
objects with zeroes.  Initialization is done at allocation time at the
places where checks for __GFP_ZERO are performed.

init_on_free=1 makes the kernel initialize freed pages and heap objects
with zeroes upon their deletion.  This helps to ensure sensitive data
doesn't leak via use-after-free accesses.

Both init_on_alloc=1 and init_on_free=1 guarantee that the allocator
returns zeroed memory.  The two exceptions are slab caches with
constructors and SLAB_TYPESAFE_BY_RCU flag.  Those are never
zero-initialized to preserve their semantics.

Both init_on_alloc and init_on_free default to zero, but those defaults
can be overridden with CONFIG_INIT_ON_ALLOC_DEFAULT_ON and
CONFIG_INIT_ON_FREE_DEFAULT_ON.

If either SLUB poisoning or page poisoning is enabled, those options take
precedence over init_on_alloc and init_on_free: initialization is only
applied to unpoisoned allocations.

Slowdown for the new features compared to init_on_free=0, init_on_alloc=0:

hackbench, init_on_free=1:  +7.62% sys time (st.err 0.74%)
hackbench, init_on_alloc=1: +7.75% sys time (st.err 2.14%)

Linux build with -j12, init_on_free=1:  +8.38% wall time (st.err 0.39%)
Linux build with -j12, init_on_free=1:  +24.42% sys time (st.err 0.52%)
Linux build with -j12, init_on_alloc=1: -0.13% wall time (st.err 0.42%)
Linux build with -j12, init_on_alloc=1: +0.57% sys time (st.err 0.40%)

The slowdown for init_on_free=0, init_on_alloc=0 compared to the baseline
is within the standard error.

The new features are also going to pave the way for hardware memory
tagging (e.g.  arm64's MTE), which will require both on_alloc and on_free
hooks to set the tags for heap objects.  With MTE, tagging will have the
same cost as memory initialization.

Although init_on_free is rather costly, there are paranoid use-cases where
in-memory data lifetime is desired to be minimized.  There are various
arguments for/against the realism of the associated threat models, but
given that we'll need the infrastructure for MTE anyway, and there are
people who want wipe-on-free behavior no matter what the performance cost,
it seems reasonable to include it in this series.

[glider@google.com: v8]
  Link: http://lkml.kernel.org/r/20190626121943.131390-2-glider@google.com
[glider@google.com: v9]
  Link: http://lkml.kernel.org/r/20190627130316.254309-2-glider@google.com
[glider@google.com: v10]
  Link: http://lkml.kernel.org/r/20190628093131.199499-2-glider@google.com
Link: http://lkml.kernel.org/r/20190617151050.92663-2-glider@google.com
Signed-off-by: Alexander Potapenko <glider@google.com>
Acked-by: Kees Cook <keescook@chromium.org>
Acked-by: Michal Hocko <mhocko@suse.cz>		[page and dmapool parts
Acked-by: James Morris <jamorris@linux.microsoft.com>]
Cc: Christoph Lameter <cl@linux.com>
Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
Cc: "Serge E. Hallyn" <serge@hallyn.com>
Cc: Nick Desaulniers <ndesaulniers@google.com>
Cc: Kostya Serebryany <kcc@google.com>
Cc: Dmitry Vyukov <dvyukov@google.com>
Cc: Sandeep Patil <sspatil@android.com>
Cc: Laura Abbott <labbott@redhat.com>
Cc: Randy Dunlap <rdunlap@infradead.org>
Cc: Jann Horn <jannh@google.com>
Cc: Mark Rutland <mark.rutland@arm.com>
Cc: Marco Elver <elver@google.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

Removed the drivers/infiniband/core/uverbs_ioctl.c part, which is not in
android-common 4.14 kernel.

Change-Id: I6b5482fcafae89615e1d79879191fb6ce50d56cf
Bug: 138435492
Test: Boot cuttlefish with and without
Test:   CONFIG_INIT_ON_ALLOC_DEFAULT_ON/CONFIG_INIT_ON_FREE_DEFAULT_ON
Test: Boot an ARM64 mobile device with and without
Test:   CONFIG_INIT_ON_ALLOC_DEFAULT_ON/CONFIG_INIT_ON_FREE_DEFAULT_ON
Signed-off-by: Alexander Potapenko <glider@google.com>
(cherry picked from commit 8a4e1fcd4b5899935bf2375e7f23af39b95aaede)
(cherry picked from commit d995564220bfeb91ca6fcfe0cb1a769bc89a918a)
(cherry picked from commit ac7d8fe375d0b940f43e6b39f0415de509ae48f3)
Signed-off-by: Edwiin Kusuma Jaya <kutemeikito0905@gmail.com>

---
## [DerxwnaKapsyla/Pokemon-Essentials](https://github.com/DerxwnaKapsyla/Pokemon-Essentials)@[d87acf4b6d...](https://github.com/DerxwnaKapsyla/Pokemon-Essentials/commit/d87acf4b6ddae115fb7a384fbbdc01f6d12b28ec)
#### Wednesday 2020-11-18 11:51:35 by Derxwna Kapsyla

Bunch of porting changes

We stray further from God's light with each update, but fuck it.

---
## [destial/Mercury](https://github.com/destial/Mercury)@[f7a43c06d7...](https://github.com/destial/Mercury/commit/f7a43c06d78b76cb5ddfb22ce4eb71ce2995f18d)
#### Wednesday 2020-11-18 13:12:11 by destial

removed disguises because that was a fuckin pain in the ass and glitchy a fuck and this will be the last commit and release

pce out yo, just came to fix issues.

---
## [m-ou-se/rust](https://github.com/m-ou-se/rust)@[f7fb2a989e...](https://github.com/m-ou-se/rust/commit/f7fb2a989e58de289e16fdd1e3a4e3689469306c)
#### Wednesday 2020-11-18 13:51:48 by Mara Bos

Rollup merge of #79039 - thomcc:weakly-relaxing, r=Amanieu

Tighten the bounds on atomic Ordering in std::sys::unix::weak::Weak

This moves reading this from multiple SeqCst reads to Relaxed read + Acquire fence if we are actually going to use the data.

Would love to avoid the Acquire fence, but doing so would need Ordering::Consume, which neither Rust, nor LLVM supports (a shame, since this fence is hardly free on ARM, which is what I was hoping to improve).

r? `@Amanieu` (Sorry for always picking you, but I know a lot of people wouldn't feel comfortable reviewing atomic ordering changes)

---
## [LucasVChaves/NmapPipes](https://github.com/LucasVChaves/NmapPipes)@[735c61a3c8...](https://github.com/LucasVChaves/NmapPipes/commit/735c61a3c8d835e8a112d7e2d285b4ca555e3dca)
#### Wednesday 2020-11-18 14:53:05 by Lucas

Some minor changes and some hacker shit so i can brag to my friends

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[0c198f6cd3...](https://github.com/mrakgr/The-Spiral-Language/commit/0c198f6cd32032cef00bde9c7d657c5d90ecba75)
#### Wednesday 2020-11-18 15:50:20 by Marko Grdinić

"9:35am. I remember as a kid once I finished a game and it started getting boring, I'd try out various cheats. It never made it fun again.

With BG is similar, except I am so obsessed with it now that this is what is making it fun.

I really have no idea what to think about Spell Revisions.

9:55am. I am explode if I keep thinking about it for any longer. But with the latest changes I do not think solo play is viable - at least it would not be if not for that basilisk zone that gives you >25k free exp.

10am. You know, maybe the real question I should be asking myself is - in settings with magic, what is the point in even having fighters and other non-magic using classes?

When I get down to it, BG is not actually that good at magic - the best game that I've had the pleasure of experiencing with a mage is Dungeon Crawl Stone Soup.

In BG, you can walk until you see the enemy, cast fireball, and by the time you finish casting the melee guys have already caught up to you. In DCSS you can cast it a few times and kill him before he walks up to you and then scram before his friends get there. In BG to get the same effect, you have to use invis and hurl fireballs from out of line of sight.

I want to dig deeper into it, but is there a point in playing when all I am doing is AI abuse?

Right now I seem to be stuck in a loop of replaying the early parts of BG without being able to find a release.

10:05am. Abuse is right, but better AI is also right.

So the ideal game is the one that continually gets better along with you.

I really like Spell Revision the idea of buffing summons, but I do not know how to feel about it nerfing sleep so heavily and making Blindness a level 8 spell with a much shorter duration.

10:15am. Let me chill for a while. I do not feel like starting right away.

My sleep last night was not that good, I want to purge my BG thoughts out of my system. I've more or less tried everything but playing a thief by now.

10:20am. The way to purge these thoughts is to decide what my hopes are. When I started playing BG, I really wanted to master mages that I did not as a kid. But now...I'll put it on a backburner until I decide. Just this kind of thinking is a source of fun for me now.

11:15am. It is good that I did not start as the breakfast was early.

Right now my obsession is at its peak, so let me go outside for a bit and do the chores for a while. The weather cleared up finally.

11:20am. All this tripping down the memory lane has reminded me of a certain idea I had as a kid. It might be worth cultivating at this point. I'll think about it.

1:35pm. Done with chores. Less than a week of winter preparation left.

Let me cool down for a while.

2pm. Every day is a first step.

Let me make one. Today I will focus solely on module loading.

It is time to elaborate it.

2:45pm. I have some ideas and new principles in my mind, but before I talk about it, let me step away from the screen for half an hour. I want to sleep on this for a while and want to do it away from the screen.

After I do that, I'll write down my ideas and start work on them.

I'll start with the typechecker lazification and then redo the entire schema loading and validation process. I am going to change how it works. I'll get rid of that concurrent loading function as it makes everything non-composable.

Let me commit here."

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[00ceb82a6c...](https://github.com/mrakgr/The-Spiral-Language/commit/00ceb82a6c95f18856aa29a54bf7856c6793a7ae)
#### Wednesday 2020-11-18 15:50:20 by Marko Grdinić

"3pm. Ok, let me do this thing. I've thought things through. First I will do the typechecker stream change.

Then I will...

```fs
type ResultMap<'a> = Map<string,Result<'a,string>>
let load (m : ValidatedSchema ResultMap) text project_dir =
    let m = Map.remove project_dir m
    let waiting = MVar(Set.empty)
    let finished = MVar(m)
    let rec loop text project_dir =
        match Map.tryFind project_dir m with
        | Some _ -> Job.unit()
        | None ->
            MVar.modifyFun (fun waiting ->
                if Set.contains project_dir waiting then waiting, Job.unit()
                else
                    let process_packages = function
                        | Ok x -> Seq.Con.iterJob (snd >> loop None) x.packages
                        | Error _ -> Job.unit()
                    Set.add project_dir waiting,
                    match text with
                    | None ->
                        load_from_file project_dir >>= fun x ->
                        Job.start (MVar.mutateFun (Map.add project_dir x) finished) >>=.
                        process_packages x
                    | Some text -> Job.delay <| fun () ->
                        let x = load_from_string project_dir text
                        Job.start (MVar.mutateFun (Map.add project_dir x) finished) >>=.
                        process_packages x
                ) waiting >>= Job.Ignore
    loop text project_dir >>=. MVar.take finished
```

I'll make this just a regular load.

The way it works now, packages have to be loaded and validated concurrently.

I somehow managed to do this bit of concurrency. But suppose I want to extend the above so I can load them modules as well.

```fs
                | FileHierarchy.File(r',(r,a),is_top_down,_) ->
                    try let x = FileInfo(Path.Combine(prefix,a + (if is_top_down then ".spi" else ".spir")))
                        if x.Exists then
                            links.Add (r, "file:///" + x.FullName)
                            actions.Add (r, RenameFile {|filePath=x.FullName; target=null|})
                            actions.Add (r, DeleteFile {|range=r'; filePath=x.FullName|})
                        else
                            errors.Add (r, "File does not exist.")
                            actions.Add (r, CreateFile {|filePath=x.FullName|})
                        Some(File(x.FullName,a))
                    with e -> errors.Add (r, e.Message); None
```

Instead of just checking whether a file exists here, why don't I load it as well?

If I tried doing that, I'd end up in trouble pretty quickly. Because now I have to reason out how to deal with the data structure containing the files.

It would not be enough to just load the module from this. Obviously, I'd need some kind of map, and I'd look whether the file is in it first, and if it is not, then I'd just do the module load. Rather than concurrency, making sure that no extraneous disk loads are being done is the main priority.

3:15pm. The way I imagine it, I could make it all a recursive block

```
let rec load_module_from_disk path = ...
and module_changed path text = ...
and load_package_from_disk path = ...
and package_changed path text = ...
and validate_package schema = ...
```

Both packages and modules should be a part of the state and the above should essentially just be the fold function that works over the graph.

One idea that looks good at a glance is to make the state an MVar, but that would not work...

...Yeah, no. I went through this before. Having promises in the schema map would be very annoying. It is much easier to just do things sequentially.

When I made the package loads concurrently, I did have a little voice telling me that I am optimizing a thing I should not be. Now I am paying for it. I wanted the exp, but I should have just relied on my wisdom.

3:25pm. I am have to redo it with a focus on simplicity.

I am going to greatly simplify the whole process of dealing with schemas and modules even if it means that the user will have to bear some start up lag.

But still, why should I bother optimizing this? Is loading even a 10k files that big of a deal?

And if I really want to get some speedup, I can go with the idea of doing the loads concurrently.

Not fully concurrent like in that `load` function right now, but based on the idea that I had before it and discarded - when I have modules a,b,c that need loading, there is no reason not to do just that part concurrently and wait on the results.

I can much easily deal with that technique than full concurrency. Even though it would be less performant, it would be fully composable.

...I like that.

3:30pm. This is going to be the final push. After I do this redesign the compilation pipeline will essentially be complete. All the hard parts will have been done.

Sure I'll have to do the prepass and the rest, but those won't be hard. Just drawing upon the promises is the extent of the complexity of that.

3:40pm. I am contrasting the difficulties I am having with loading packages and modules concurrently with the eventual concurrent compilation of join points.

Join will be easy to compile concurrently for the simple reason that I can prepare for their concurrently compilation ahead of time. I can separate out the join points and tag them. That would allow me to put all of them on their own threads.

4:20pm. Lunch was unusually early today. Let me resume.

```fs
let load (m : ValidatedSchema ResultMap) text project_dir =
    let m = Map.remove project_dir m
    let waiting = MVar(Set.empty)
    let finished = MVar(m)
    let rec loop text project_dir =
        match Map.tryFind project_dir m with
        | Some _ -> Job.unit()
        | None ->
            MVar.modifyFun (fun waiting ->
                if Set.contains project_dir waiting then waiting, Job.unit()
                else
                    let process_packages = function
                        | Ok x -> Seq.Con.iterJob (snd >> loop None) x.packages
                        | Error _ -> Job.unit()
                    Set.add project_dir waiting,
                    match text with
                    | None ->
                        load_from_file project_dir >>= fun x ->
                        Job.start (MVar.mutateFun (Map.add project_dir x) finished) >>=.
                        process_packages x
                    | Some text -> Job.delay <| fun () ->
                        let x = load_from_string project_dir text
                        Job.start (MVar.mutateFun (Map.add project_dir x) finished) >>=.
                        process_packages x
                ) waiting >>= Job.Ignore
    loop text project_dir >>=. MVar.take finished
```

Let me paste this again. I am trying to wrap my head around `MVar`s and the more I think about them, the more they seem like soing I should avoid. This piece of code is very complicated.

The way I am using nested `MVar` modifications is not something that makes me happy. Though I did it in this case, it is really hard to reason about in general. I've been thinking of using them for join point compilation, but I've changed my mind. I really should be using servers period.

4:25pm. Had I been doing this again, I would have opted for a different way than `MVar`s. I have a method that uses only a single channel in mind, but I am not going to get a chance to use it as I am going to replace the above with something sequential that I can compose with module loading.

4:30pm. Forget about that. Let me at least do something for the day.

Let me do that TC change. I want to get at least that burden out of the way.

```fs
                    // Doing the memoization like this has the disadvantage of always focing the evaluation of the previous
                    // streams' first item, but on the plus side will reuse old state.
```

Now this comment no longer applies. It won't force the evaluation of the first because the stream it gets will always be fulfilled to begin with.

```fs
    let rec loop r =
        {new TypecheckerStream with
            member _.Run(res) =
                let r = r()
                let r' =
                    r >>=* fun old_results ->
                    top_env >>= fun top_env ->
                    res >>- fun res ->
                    run (cons_fulfilled old_results) top_env 0 res.bundles
                let a = Stream.mapFun (fun (_,x,_) -> x) r'
                a, loop (fun () -> if Promise.Now.isFulfilled r' then r' else r)
            }
    loop (fun () -> Stream.nil)
```

Here it is. It is actually rather easy.

4:40pm.

```fs
            | _ ->
                let x = Infer.infer package_id module_id env (bundle_top b)
                let _,_,env as s = b,x,Infer.union x.top_env_additions env
                Cons(s,promise_thunk (fun () -> run old_results env (i+1) bs))
```

Now I am thinking - won't this always force evaluation of at least one item every time the server is tugged.

I think it will, but I'll just leave with it. I did the change that I needed.

Let me commit this. Actually, let me try it out. I should make sure it still works.

Afterwards I will be taking a wrecking ball to the previous servers.

I am going to first interleave module and package loading. Once I make sure that works, I will start work on adding the package stream to the mix after that.

Yeah, it is good.

Now let commit."

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[258227824d...](https://github.com/mrakgr/The-Spiral-Language/commit/258227824dcfdf8dcbcea635709badc20e20c82b)
#### Wednesday 2020-11-18 17:28:01 by Marko Grdinić

"4:55pm. It is time to start wrecking stuff. Since I am not exactly sure how to fit all that I've previosly done into the new context, let me start by opening a new module.

5pm.

```fs
module Spiral.Supervisor

open Spiral.ServerUtils
open Spiral.StreamServer

type SupervisorState = {
    modules : Map<string, TokenizerStream>
    schemas : Map<string, ValidatedSchema>
    }
```

Every great old thing has a humble new beginning.

Let me go with this. One thing I am going to do in package files is make module errors informative. I'll highlight them directly in the project file.

I should aim for that level of integration, even though I should leave that in particular for later.

Right now I am thinking - what if the package file has a missing file error and then the user adds that file through a different channel.

In other words, I want the changes to the modules to trigger the revalidation of the package file...

Should I go for that?

Or should I go for something rough and simple, like the user having to trigger the revalidation manually?

5:05pm. Actually, let me go for the later. Trying to take account for all kinds of possible changes is too much of a chore.

Let me do the minimum viable and then I'll do spit and polish after that.

I want to get this out the door, not put in luxury features.

Maybe I will have adding files trigger the project file reevaluation if the project has errors to begin with. That is the ticket!

```fs
type SupervisorState = {
    modules : Map<string, TokenizerStream>
    schemas : Map<string, ValidatedSchema>
    }
```

Let me go with this. As the first step, I'll focus just on filling this up.

5:15pm.

```fs
                    try let x = FileInfo(Path.Combine(prefix,a + (if is_top_down then ".spi" else ".spir")))
                        if x.Exists then
                            links.Add (r, "file:///" + x.FullName)
                            actions.Add (r, RenameFile {|filePath=x.FullName; target=null|})
                            actions.Add (r, DeleteFile {|range=r'; filePath=x.FullName|})
                        else
                            errors.Add (r, "File does not exist.")
                            actions.Add (r, CreateFile {|filePath=x.FullName|})
                        Some(File(x.FullName,a))
```

I know what I've said, but the though of weaving the supervisor state through this does not make me happy.

Instead I am leaning more towards just taking the file hierarchy here and loading the missing modules based on it.

5:25pm. Ah, let me take a break. I might as well read Hagure Idol.

5:35pm. Ok, good. Now focus me. I am going to have to weave the state into this after all.

Let me do it.

```fs
let schema project_dir (x : Schema) (s : SupervisorState) =
    let mutable modules = s.modules
```

Let me do it like this.

5:45pm.

```fs
modules : Map<string, TokenizerStream>
```

Er, this is...what exactly am I supposed to use here for a file? A tokenizer stream? An array of lines?

`TokRes * TokenizerStream`?

Hmmm...how about I make a stream that is a combination of the tokenizer and the parser stream? That seems like the easiest way to go.

5:50pm. No. I am on the wrong track after all.

I should leave `scheme` mostly unchanged and I should not be weaving state through it. Instead let me change the file hierarchy a little.

```fs
| File of path: string * name: string * exists: bool
```

If the file is present in the map, but the hierarchy flag does not match I will just remove it in a later pass.

6pm. Modified the schema to take note of the exists flag.

```fs
type SupervisorState = {
    modules : Map<string, TokenizerStream * ParserRes Hopac.Promise * ParserStream>
    schemas : Map<string, ValidatedSchema>
    }
```

Now I am wracking my brain for what to put in the modules spot.

Should I just make that new diff stream? Let me do it.

```fs
type ModuleStream = abstract member Run : TokReq -> ParserRes Promise * ModuleStream
let module' is_top_down =
    let rec loop (tokenizer : TokenizerStream, parser : ParserStream) =
        {new ModuleStream with
            member _.Run(req) =
                let x,tok = tokenizer.Run(req)
                let x,par = parser.Run(x)
                x,loop (tok,par)
                }
    loop (tokenizer, parser is_top_down)
```

Let me go with this.

6:20pm. Let me call it a day here as I've gone fully distracted and want to move to playtime.

Tomorrow I am going to deal with module loading."

---
## [stellaraf/site](https://github.com/stellaraf/site)@[0b8fef75f4...](https://github.com/stellaraf/site/commit/0b8fef75f427bb7e9f897b314f62b0fa466294cb)
#### Wednesday 2020-11-18 19:37:22 by checktheroads

beat the shit out of error handling because fuck you

---
## [EvilMcJerkface/pilosa](https://github.com/EvilMcJerkface/pilosa)@[c133ce0376...](https://github.com/EvilMcJerkface/pilosa/commit/c133ce037661422d51c949664b399d8be5d8d2c4)
#### Wednesday 2020-11-18 19:59:13 by Seebs

Make containers copy-on-write

This patch replaces a lot of circumstances in which containers
were being copied with circumstances in which they are shared,
using copy-on-write semantics.

To achieve this, we emulate somewhat the design of go's
native `append` function. Operations on a container may optionally
yield a new container. A container can be marked "frozen",
after which no operation should ever write to it in any way;
that applies both to the container itself and the backing store
it refers to, if any. So for instance, instead of:

	c.arrayToBitmap()

we now write:

	c = c.arrayToBitmap()

Operations which need to modify a container in any way
need to be able to return a new container, which is a modified
copy of the previous container. This applies to operations
like add/remove, but also to things like unmapping memory-mapped
storage, or changing a container's type.

Bitmaps do not support the same copy-on-write semantics,
currently, but "copying" a bitmap and sharing the containers
instead of duplicating them is *much* cheaper than copying
the containers.

Bitmaps do support a .Freeze method, which currently copies
the previous bitmap, making a new one with the same container
pointers, and freezes the individual containers. Use this
if you need a writeable copy of a bitmap -- the resulting
bitmap can safely have its set of containers modified, and
bitmap operators that would want to modify the containers
will use copy-on-write for that.

The primary motivation of this is to reduce the cost of the
row cache used by fragments. As a secondary issue, the row cache
is no longer updated on writes -- that update was actually a
race condition waiting to happen. Rather, writes to a row
invalidate the cache entry for that row. The row cache is
created by creating a new bitmap, and freezing the relevant
containers from the fragment's storage. In the case where
nothing is being written, the row cache grows to contain
bitmaps containing all those containers, but never copies
any containers. If nothing's being read, the row cache is
never created, and the containers are in general not getting
frozen. The only circumstance where copies have to happen is
when things are read (and thus stored in the row cache) and
later modified. In that case, each read freezes objects, and
the first write to a container after it's been frozen will
create a new copy.

We drop the enterprise/b btree implementation, because we
don't really need it anymore -- we now provide that
implementation by default in the open source product anyway.

Along with this, there's a lot of other changes which
improve support for nil containers, as a cheaper representation
for empty containers. Operations which we know will provide
an empty container can always short-circuit and just yield
a nil *Container. Similarly, operations which would provide
a full container can return a single shared full container
object (which is frozen). The higher-level (non type-specific)
container ops are now using that logic to short-circuit
operations for empty and full containers. (For instance,
difference of anything minus an empty container is the
original thing, union of anything and empty is the original
thing, and so on.)

The Containers interface adds "Update" and "UpdateEvery"
methods, based in part on the "Put" interface provided
by the underlying btree implementation; Update performs
a possible update in-place of a container for a given
key, bypassing the need to replicate the search for that
key in the container. UpdateEvery loops through all the
containers.

Containers do not strictly guarantee that they won't
return nil `*Container` objects. However, the container
iterators won't return those -- empty containers aren't
interesting. Some tests are updated to reflect this.

Some of the container internals, like N(), or the isArray()
and related functions, accept nil container pointers. Some,
like Thaw(), do not. For the array(), bitmap(), and runs()
methods, roaringparanoia enables an explicit panic on a nil
container explaining the problem, but the intent is that those
should never be called unless you already know you have the
right kind of container, so by default they don't perform
the extra checks. In most cases, this is already covered
because a nil container is empty, and there's no operation
we can perform that requires us to inspect the contents of
an empty container. This is passing a fair amount of testing,
but the testing may not be comprehensive enough.

The overall impact of this is pretty trivial performance-wise.
In our default roaring/ benchmarks, a few things get a few
percent faster, or slower. The advantage is that, with
read-heavy workloads, the row cache no longer eats up incredible
amounts of memory.

For a smallish test case, pilosa's memory usage (RES in top) after
startup was ~2.5GB. Without this patch, simply reading every
row a few times got memory usage to about 9GB, which seemed
reasonably stable. With this patch, memory usage went to about
3GB. This will be less noticeable in mixed read/write loads,
but it should be consistently significantly lower.

In addition to dropping things from the rowCache on modifications,
we also stopped performing a full count on a modified row when
not using a cache of a kind that would use that count, and don't
repopulate the rowCache regardless. We don't want every write
to imply a corresponding read after it.

There's a lot of room for possible future optimizations in
terms of things like in-place operations, and some of the
row/rowSegment code is a little suspicious to me, but I don't
think it should be *worse* in any cases.

---
## [pkeducation/web](https://github.com/pkeducation/web)@[bc392d179c...](https://github.com/pkeducation/web/commit/bc392d179c21ff35162f020488dc4d4cec556d71)
#### Wednesday 2020-11-18 21:46:33 by ggulgulia

PKW-012: fixed with super ugly hacks, god please keep feeding me and my family<2

---
## [llvm/llvm-project](https://github.com/llvm/llvm-project)@[96d40df71e...](https://github.com/llvm/llvm-project/commit/96d40df71ecee07c69aea512f6c04fc4fbe6acfb)
#### Wednesday 2020-11-18 21:52:38 by Fangrui Song

MCExpr::evaluateAsRelocatableImpl : allow evaluation of non-VK_None MCSymbolRefExpr when MCAsmLayout is available

https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;h=4acf8c78e659833be8be047ba2f8561386a11d4b
(1994) introduced this behavior:
if a fixup symbol is equated to an expression with an undefined symbol, convert
the fixup to be against the target symbol. glibc relies on this behavior to perform
assembly level indirection

```
asm("memcpy = __GI_memcpy"); // from sysdeps/generic/symbol-hacks.h

...
  // call memcpy@PLT
  // The relocation references __GI_memcpy in GNU as, but memcpy in MC (without the patch)
  memcpy (...);
```

(1) It complements `extern __typeof(memcpy) memcpy asm("__GI_memcpy");` The frontend asm label does not redirect synthesized memcpy in the middle-end. (See D88712 for details)
(2) `asm("memcpy = __GI_memcpy");` is in every translation unit, but the memcpy declaration may not be visible in the translation unit where memcpy is synthesized.

MC already redirects `memcpy = __GI_memcpy; call memcpy` but not `memcpy = __GI_memcpy; call memcpy@plt`.
This patch fixes the latter by allowing MCExpr::evaluateAsRelocatableImpl to
evaluate a non-VK_None MCSymbolRefExpr, which is only done after the layout is available.

GNU as allows `memcpy = __GI_memcpy+1; call memcpy@PLT` which seems nonsensical, so we don't allow it.

`MC/PowerPC/pr38945.s` `NUMBER = 0x6ffffff9; cmpwi 8,NUMBER@l` requires the
`symbol@l` form in AsmMatcher, so evaluation needs to be deferred. This is the
place whether future simplification may be possible.

Note, if we suppress the VM_None evaluation when MCAsmLayout is nullptr, we may
lose the `invalid reassignment of non-absolute variable` diagnostic
(`ARM/thumb_set-diagnostics.s` and `MC/AsmParser/variables-invalid.s`).
We know that this diagnostic is troublesome in some cases
(https://github.com/ClangBuiltLinux/linux/issues/1008), so we can consider
making simplification in the future.

Reviewed By: jyknight

Differential Revision: https://reviews.llvm.org/D88625

---
## [AhmadJ2/Comp-2021-HM1](https://github.com/AhmadJ2/Comp-2021-HM1)@[edf8e7e95a...](https://github.com/AhmadJ2/Comp-2021-HM1/commit/edf8e7e95aa90c27d7e0841c79e0e1bc8b5f559d)
#### Wednesday 2020-11-18 22:32:49 by AhmadJ2

Merge pull request #15 from AhmadJ2/Muhammads

oh oh fuck you AHMAD

---
## [dackst/nayuta](https://github.com/dackst/nayuta)@[89657e2487...](https://github.com/dackst/nayuta/commit/89657e24875b0b951b9378ecccdef8ae89ac0758)
#### Wednesday 2020-11-18 23:56:03 by D

fix mishy bug

HOLY SHIT for the longest time I thought something was wrong in the script files

through trial and error I discovered it was solved with the original arb files.
When I noticed Mensa had two names while browsing one of them in a hex editor
("Mensa" and "Mrs. Mensa") I remembered the multiple entries for Mishy

these names that can't be safely edited really should be skipped by the dumper/inserter,
but whatever man

---

# [<](2020-11-17.md) 2020-11-18 [>](2020-11-19.md)

