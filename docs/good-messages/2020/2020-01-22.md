# [<](2020-01-21.md) 2020-01-22 [>](2020-01-23.md)

2,070,381 events, 1,049,757 push events, 1,648,186 commit messages, 118,129,712 characters


## [chris-morgan/overture](https://github.com/chris-morgan/overture)@[9503cfbcb8...](https://github.com/chris-morgan/overture/commit/9503cfbcb8f43891ed58c10b1f2c36ac89c6a8a1)
#### Wednesday 2020-01-22 00:33:32 by Chris Morgan

Router: ditch useHash in favour of more baseUrl

All browsers that we now care about support the History API, including
the popstate event. (IE supports it from 10 on, and we only care about
IE 11 now.) Due to this, we no longer need the hashchange fallback, and
so by tweaking how baseUrl works, to make it purely a prefix (thus, for
https: URLs, including the origin), we can drop useHash altogether.

useHash used to *almost* work on the file: protocol if you didn’t
include “#/” in the URL when you loaded the page—it’d simply think you
were on a very strange URL, and you might be able to recover from it.
Now, the router will fail to initialise. I consider this to be an
acceptable pain, when the alternative is greater complexity and
unnecessary bytes served (I’d prefer that the production bundle didn’t
support the 'file:' protocol at all, but our build toolchain isn’t in a
suitable shape to support that yet).

The rest of this commit message justifies removing the exeption
suppression around the history.pushState/history.replaceState calls.

I removed it because I don’t like seemingly-unnecessary exception
handling, and I haven’t had any trouble with it in Firefox in quite some
years. All situations where the spec says it may produce an exception,
we should care about; so I prefer also to stop masking such things. See
https://html.spec.whatwg.org/multipage/history.html#dom-history-pushstate
for the algorithm for history.pushState and history.replaceState. Let’s
look at the possible cases:

> 2. If document is not fully active, throw a "SecurityError"
>    DOMException.

I don’t believe there are any situations in which our document will not
be fully active.

> 5. Let serializedData be StructuredSerializeForStorage(data).
>    Rethrow any exceptions.

We always pass null for data, which serializes trivially according to
that algorithm.

> 7. If url is not null, then:
>
>    1. Parse url, relative to the relevant settings object of this
>       History object.
>
>    2. If that fails, then throw a "SecurityError" DOMException.

Provided baseUrl is set properly and the getUrlForEncodedState function
returns a sane value, this won’t be triggered. If it is triggered, it’s
a bug that we don’t *want* suppressed.

>    4. Compare newURL to document's URL. If any component of these two
>       URL records differ other than the path, query, and fragment
>       components, then throw a "SecurityError" DOMException.

If something causes us to be trying to change the scheme, host name or
port, something’s badly wrong, and we don’t want to suppress it.

>    5. If the origin of newURL is not same origin with the origin of
>       document, and either the path or query components of the two URL
>       records compared in the previous step differ, throw a
>       "SecurityError" DOMException. (This prevents sandboxed content
>       from spoofing other pages on the same origin.)

The main time this affects us is when serving from the file: scheme,
where the origin is probably an opaque origin that internally contains
the full path name. This is why you can, on file: URLs, modify the hash,
but not the path or query string. And again, if we’re somehow doing
something wrong with this, we don’t *want* to suppress it.

In summary: the try/catch around history.pushState and
history.replaceState is undesirable unless it’s for working around
innocuous browser bugs, and I have no evidence that such bugs yet exist.

---
## [TheC0deF0x/d2xstock](https://github.com/TheC0deF0x/d2xstock)@[866258d042...](https://github.com/TheC0deF0x/d2xstock/commit/866258d0421fe0ffb865994de8839b770e802a01)
#### Wednesday 2020-01-22 00:47:51 by Ivan Meler

ologk.h: because fuck you

Kanged from daddy Meler

---
## [miik2/3rd_CITM_GameJam_NewIgnore](https://github.com/miik2/3rd_CITM_GameJam_NewIgnore)@[3348be6743...](https://github.com/miik2/3rd_CITM_GameJam_NewIgnore/commit/3348be6743af3839640447e223070cfe7f1a1394)
#### Wednesday 2020-01-22 02:19:17 by Carles Homs

Dani, stop editing my fucking prefabs

I'm so fucking tired of merging shit holy shit.

---
## [emmettgb/Lathe.jl](https://github.com/emmettgb/Lathe.jl)@[3a3382c05d...](https://github.com/emmettgb/Lathe.jl/commit/3a3382c05db4589ca11553fb4bfa7c155e1b4593)
#### Wednesday 2020-01-22 03:43:19 by Emmett Boudreau

Updated URL to lathe.ai

Happy to report, Lathe has a new home, at a domain we were really happy with.
It was very expensive, but it was definitely worth it. Thank you all for making such a thing possible, I love it.

---
## [danejur/AniDroid](https://github.com/danejur/AniDroid)@[63623f0e39...](https://github.com/danejur/AniDroid/commit/63623f0e39feaa353b019aa583ea46f5fa85fccc)
#### Wednesday 2020-01-22 05:16:57 by Dane Juras

finally fixed the stupid date picker bug HOLY SHIT

---
## [youtangai/criu](https://github.com/youtangai/criu)@[e098b119f3...](https://github.com/youtangai/criu/commit/e098b119f3480418c43431beb04f700d1e87f19f)
#### Wednesday 2020-01-22 05:29:41 by Pavel Emelyanov

test, unix: Exhaustive testing of states (v2)

By exhaustive testing I understand a test suite that generates as much
states to try to C/R as possible by trying all the possible sequences
of system calls. Since such a generation, if done on all the Linux API
we support in CRIU, would produce bazillions of process, I propose to
start with something simple.

As a starting point -- unix stream sockets with abstract names that
can be created and used by a single process :)

The script generates situations in which unix sockets can get into by
using a pre-defined set of system calls. In this patch the syscalls
are socket, listen, bind, accept, connect and send. Also the nummber
of system calls to use (i.e. -- the depth of the tree) is limited by
the --depth option.

There are three things that can be done with a generated 'state':

I) Generate :) and show

Generation is done by recursively doing everything that is possible
(and makes sence) in a given state. To reduce the size of the tree
some meaningless branches are cut, e.g. creating a socket and closing
it right after that, creating two similar sockets one-by-one and some
more.

Shown on the screen is a cryptic string, e.g. 'SA-CX-MX_SBL one,
describing the sockets in the state. This is how it can be decoded:

 - sockets are delimited with _
 - first goes type (S -- stream, D --datagram)
 - next goes name state (A -- no name, B with name, X socket is not in
   FD table, i.e. closed or not yet accepted)
 - next may go letter L meaning that the socket is listening
 - -Cx -- socket is connected and x is the peer's name state
 - -Ixyz -- socket has incoming connections queue and xyz are the
   connect()-ors name states
 - -Mxyz -- socket has messages and xyz is senders' name states

The example above means, that we have two sockets:

 - SA-CX-MX: stream, with no name, connected to a dead one and with a
   message from a dead one
 - SBL: stream, with name, listening

Next printed is the sequence of system calls to get into it, e.g. this
is how to get into the state above:

	socket(S) = 1
	bind(1, $name-1)
	listen(1)
	socket(S) = 2
	connect(2, $name-1)
	accept(1) = 3
	send(2, $message-0)
	send(3, $message-0)
	close(3)

Program has created a stream socket, bound it, listened it, then
created another stream socket, connected to the 1st one, then accepted
the connection sent two messages vice-versa and closed the accepted
end, so the 1st socket left connected to the dead socket with a
message from it.

II) Run the state

This is when test actually creates a process that does the syscalls
required to get into the generated state (and hopefully gets into it).

III) Check C/R of the state

This is the trickiest part when it comes to the R step -- it's not
clear how to validate that the state restored is correct. But if only
trying to dump the state -- it's just calling criu dump. As images dir
the state string description is used.

One may choose only to generate the states with --gen option. One may
choose only to run the states with --run option. The latter is useful
to verify that the states generator is actually producing valid
states. If no options given, the state is also dump-ed (restore is to
come later).

For now the usage experience is like this:

- Going --depth 10 --gen (i.e. just generating all possibles states
  that are acheivable with 10 syscalls) produces 44 unique states for
  0.01 seconds. The generated result covers some static tests we have
  in zdtm :)  More generation stats is like this:
   --depth 15 : 1.1 sec   / 72 states
   --depth 18 : 13.2 sec  / 89 states
   --depth 20 : 1 m 8 sec / 101 state

- Running and trying with criu is checked with --depth 9. Criu fails
  to dump the state SA-CX-MX_SBL (shown above) with the error

  Error (criu/sk-queue.c:151): recvmsg fail: error: Connection reset by peer

Nearest plans:

1. Add generators for on-disk sockets names (now oly abstract).
   Here an interesting case is when names overlap and one socket gets
   a name of another, but isn't accessible by it

2. Add datagram sockets.
   Here it'd be fun to look at how many-to-one connections are
   generated and checked.

3. Add socketpair()-s.

Farther plans:

1. Cut the tree better to allow for deeper tree scan.

2. Add restore.

3. Add SCM-s

4. Have the exhaustive testing for other resources.

Changes since v1:

* Added DGRAM sockets :)

  Dgram sockets are trickier that STREAM, as they can reconnect from
  one peer to another. Thus just limiting the tree depth results in
  wierd states when socket just changes peer. In the v1 of this patch
  new sockets were added to the state only when old ones reported that
  there's nothing that can be done with them. This limited the amount
  of stupid branches, but this strategy doesn't work with dgram due to
  reconnect. Due to this, change #2:

* Added the --sockets NR option to limit the amount of sockets.

  This allowed to throw new sockets into the state on each step, which
  made a lot of interesting states for DGRAM ones.

* Added the 'restore' stage and checks after it.

  After the process is restore the script performs as much checks as
  possible having the expected state description in memory. The checks
  verify that the values below get from real sockets match the
  expectations in generated state:

   - socket itself
   - name
   - listen state
   - pending connections
   - messages in queue (sender is not checked)
   - connectivity

  The latter is checked last, after all queues should be empty, by
  sending control messages with socket.recv() method.

* Added --keep option to run all tests even if one of them fails.

  And print nice summary at the end.

So far the test found several issues:

- Dump doesn't work for half-closed connection with unread messages
- Pending half-closed connection is not restored
- Socket name is not restored
- Message is not restored

New TODO:

- Check listen state is still possible to accept connections (?)
- Add socketpair()s
- Add on-disk names
- Add SCM-s
- Exhaustive script for other resources

Signed-off-by: Pavel Emelyanov <xemul@virtuozzo.com>
Signed-off-by: Andrei Vagin <avagin@virtuozzo.com>

---
## [SciCrunch/sparc-curation](https://github.com/SciCrunch/sparc-curation)@[2074f504b7...](https://github.com/SciCrunch/sparc-curation/commit/2074f504b7ca313d19275d53d70f6ec70c7cc159)
#### Wednesday 2020-01-22 06:10:45 by Tom Gillespie

use namedtuple they said, it will improve readability they said

WHAT THEY DIDN'T MENTION IS THAT IT WILL DESTROY ALL YOUR HOPES AND DREAMS
of being able to pickle and unpickle those tuples if they are
constructed dynamically, and you can't use any cute tricks with type
either, maybe a metaclass would work, but at this point I don't care anymore

parallel export is now mostly safe to use with google sheets enabled,
the implementation of Integrator is still a hideous mess, but at least
it is a bit faster, this is probably the last section of the code that
needs to be completely ripped out and redisigned, the lifters are an
awful design decision, there is violation of encapsulation everywhere,
nasty action at a distance effects even making attempts not to mutate
things, all centered on the abomanation that is Integrator.pipeline

IntegrtorSafe is an awful hack to avoid calling Integrator.setup which
is most likely what was causing a reup of all services in subprocesses

quite a bit of mess is left from hunting down the fact that big grids
attached to Sheet objects were causing joblib to only run a single job
at a time, still not sure of the actual underlying cause, but we have
smaller grids now as a result

---
## [thoshiai/pgsql-ivm](https://github.com/thoshiai/pgsql-ivm)@[1cff1b95ab...](https://github.com/thoshiai/pgsql-ivm/commit/1cff1b95ab6ddae32faa3efe0d95a820dbfdc164)
#### Wednesday 2020-01-22 06:52:55 by Tom Lane

Represent Lists as expansible arrays, not chains of cons-cells.

Originally, Postgres Lists were a more or less exact reimplementation of
Lisp lists, which consist of chains of separately-allocated cons cells,
each having a value and a next-cell link.  We'd hacked that once before
(commit d0b4399d8) to add a separate List header, but the data was still
in cons cells.  That makes some operations -- notably list_nth() -- O(N),
and it's bulky because of the next-cell pointers and per-cell palloc
overhead, and it's very cache-unfriendly if the cons cells end up
scattered around rather than being adjacent.

In this rewrite, we still have List headers, but the data is in a
resizable array of values, with no next-cell links.  Now we need at
most two palloc's per List, and often only one, since we can allocate
some values in the same palloc call as the List header.  (Of course,
extending an existing List may require repalloc's to enlarge the array.
But this involves just O(log N) allocations not O(N).)

Of course this is not without downsides.  The key difficulty is that
addition or deletion of a list entry may now cause other entries to
move, which it did not before.

For example, that breaks foreach() and sister macros, which historically
used a pointer to the current cons-cell as loop state.  We can repair
those macros transparently by making their actual loop state be an
integer list index; the exposed "ListCell *" pointer is no longer state
carried across loop iterations, but is just a derived value.  (In
practice, modern compilers can optimize things back to having just one
loop state value, at least for simple cases with inline loop bodies.)
In principle, this is a semantics change for cases where the loop body
inserts or deletes list entries ahead of the current loop index; but
I found no such cases in the Postgres code.

The change is not at all transparent for code that doesn't use foreach()
but chases lists "by hand" using lnext().  The largest share of such
code in the backend is in loops that were maintaining "prev" and "next"
variables in addition to the current-cell pointer, in order to delete
list cells efficiently using list_delete_cell().  However, we no longer
need a previous-cell pointer to delete a list cell efficiently.  Keeping
a next-cell pointer doesn't work, as explained above, but we can improve
matters by changing such code to use a regular foreach() loop and then
using the new macro foreach_delete_current() to delete the current cell.
(This macro knows how to update the associated foreach loop's state so
that no cells will be missed in the traversal.)

There remains a nontrivial risk of code assuming that a ListCell *
pointer will remain good over an operation that could now move the list
contents.  To help catch such errors, list.c can be compiled with a new
define symbol DEBUG_LIST_MEMORY_USAGE that forcibly moves list contents
whenever that could possibly happen.  This makes list operations
significantly more expensive so it's not normally turned on (though it
is on by default if USE_VALGRIND is on).

There are two notable API differences from the previous code:

* lnext() now requires the List's header pointer in addition to the
current cell's address.

* list_delete_cell() no longer requires a previous-cell argument.

These changes are somewhat unfortunate, but on the other hand code using
either function needs inspection to see if it is assuming anything
it shouldn't, so it's not all bad.

Programmers should be aware of these significant performance changes:

* list_nth() and related functions are now O(1); so there's no
major access-speed difference between a list and an array.

* Inserting or deleting a list element now takes time proportional to
the distance to the end of the list, due to moving the array elements.
(However, it typically *doesn't* require palloc or pfree, so except in
long lists it's probably still faster than before.)  Notably, lcons()
used to be about the same cost as lappend(), but that's no longer true
if the list is long.  Code that uses lcons() and list_delete_first()
to maintain a stack might usefully be rewritten to push and pop at the
end of the list rather than the beginning.

* There are now list_insert_nth...() and list_delete_nth...() functions
that add or remove a list cell identified by index.  These have the
data-movement penalty explained above, but there's no search penalty.

* list_concat() and variants now copy the second list's data into
storage belonging to the first list, so there is no longer any
sharing of cells between the input lists.  The second argument is
now declared "const List *" to reflect that it isn't changed.

This patch just does the minimum needed to get the new implementation
in place and fix bugs exposed by the regression tests.  As suggested
by the foregoing, there's a fair amount of followup work remaining to
do.

Also, the ENABLE_LIST_COMPAT macros are finally removed in this
commit.  Code using those should have been gone a dozen years ago.

Patch by me; thanks to David Rowley, Jesper Pedersen, and others
for review.

Discussion: https://postgr.es/m/11587.1550975080@sss.pgh.pa.us

---
## [little-dude/xain-fl](https://github.com/little-dude/xain-fl)@[b286b3fa50...](https://github.com/little-dude/xain-fl/commit/b286b3fa506d2387754ef3100fc5ea3f49135d70)
#### Wednesday 2020-01-22 09:20:51 by Corentin Henry

XP-456: replace the CLI arguments with a config file

References
==========

https://xainag.atlassian.net/browse/XP-456
https://xainag.atlassian.net/browse/DO-58

Rationale
=========

The CLI is getting complex so it is worth loading the configuration
from a file instead.

Implementation details
======================

TOML
----

We decided to use TOML for the following reasons:

  - it is human friendly, ie easy to read and write
  - our configuration has a pretty flat structure which makes TOML
    quite adapted
  - it is well specified and has lots of implementation
  - it is well known

The other options we considered:

  - INI: it is quite frequent in the Python ecosystem to use INI for
    config files, and the standard library even provides support for
    this. However, INI is not as powerful as TOML and does not have a
    specification
  - JSON: it is very popular but is not human friendly. For instance,
    it does not support comments, is very verbose, and breaks
    easily (if a trailing comma is forgotten at the end of a list for
    instance)
  - YAML: another popular choice, but is in my opinion more complex
    than TOML.

Validation
----------

We use the third-party `schema` library to validate the
configuration. It provides a convenient way to:

- declare a schema to validate our config
- leverage third-party libraries to validate some inputs (we use the
  `idna` library to validate hostnames)
- define our own validators
- transform data after it has been validated: this can be useful to
  turn a relative path into an absolute one for example
- provide user friendly error message when the configuration is
  invalid

The `Config` class
------------------

By default, the `schema` library returns a dictionary containing a
valid configuration, but that is not convenient to manipulate in
Python. Therefore, we dynamically create a `Config` class from the
configuration schema, and instantiate a `Config` object from the data
returned by the `schema` validator.

Package re-organization
-----------------------

We moved the command line and config file logic into its own `config`
sub-package, and moved the former `xain_fl.cli.main` entrypoint into
the `xain_fl.__main__` module.

Docker infrastructure
---------------------

- Cache the xain_fl dependencies. This considerably reduces
  "edit->build-> debug" cycle, since installing the dependencies takes
  about 30 minutes.
- Move all the docker related files into the `docker/` directory

Current limitations and future work
-----------------------------------

1. The documentation generated for the `ServerConfig`,
   `AiConfig` and `StorageConfig`  classes is wrong. Each attribute is
   documented as "Alias for field number X". This can be fixed by
   having `create_class_from_schema()` setting the `__doc__` attribute
   for each attribute. However, we won't be able to automatically
   document the type of each attribute.

2. When the configuration contains an invalid value, the error message
   we generate does not contain the invalid value in question. I think
   it is possible to enable this in the future but haven't really
   looked into it.

---
## [newstools/2020-national-daily-nigeria](https://github.com/newstools/2020-national-daily-nigeria)@[80b2da18dc...](https://github.com/newstools/2020-national-daily-nigeria/commit/80b2da18dcc1871796dc439028df592f01695512)
#### Wednesday 2020-01-22 09:22:36 by NewsTools

Created Text For URL [nationaldailyng.com/how-true-love-brought-23-year-old-hausa-boy-together-with-46-yr-old-american-woman/]

---
## [SpiNNakerManchester/PACMAN](https://github.com/SpiNNakerManchester/PACMAN)@[7ed54e55bb...](https://github.com/SpiNNakerManchester/PACMAN/commit/7ed54e55bba630f3a22aca539d7817a84bde6e73)
#### Wednesday 2020-01-22 09:30:20 by Andrew Rowley

Don't you just love the magic python lets you get away with?

---
## [AdminOfThis/Frequent](https://github.com/AdminOfThis/Frequent)@[b123603d50...](https://github.com/AdminOfThis/Frequent/commit/b123603d50271b1058ea3259fdacf7363bbd9807)
#### Wednesday 2020-01-22 09:50:23 by AdminOfThis

Fixed Lags, fuck you you fucking maps, arrays is my new best friend

---
## [roll-wg/roll-turnon-rfc8138](https://github.com/roll-wg/roll-turnon-rfc8138)@[7ef089ded6...](https://github.com/roll-wg/roll-turnon-rfc8138/commit/7ef089ded67a190dac6fa532046dd6bb6ac43e30)
#### Wednesday 2020-01-22 10:27:56 by Pascal Thubert

Hello Rahul

Many thanks for your review!

Li created a new repo within the ROLL github, you’ll find it under https://github.com/roll-wg
Please see below:

Overall the document is very much to the point and I do not have any major comments.
Following are my comments for the draft(-02):

1. Section 5
"It results whether a parent supports RFC 8138 is not known by the child with the current level of specifications, and a child cannot favor a parent based on a particular support."
I think the purpose of this sentence is to let know that one cannot use T flag as a way to know that the parent supports 8138 or not. But I am not sure of this. Do you think this can be rephrased?

<Pascal>
You’re correct. What about replacing with:
“
A parent propagates the "T" flag as set whether it supports
RFC 8138 or not. The setting of the "T" flag can thus not be
used as an indication of the support by the sender, and a child
cannot favor a parent based on it.

“
</Pascal>

2. A 6LR may be 8138 + this draft compliant and may want to initiate "a local instance" in which case the 'T' flag needs to be set/unset. I believe the 6LR could use the knowledge of Global Instance to handle this. But again, may be there is no relation here, and it is completely the choice of the Instance root (in this case the given 6LR) to decide this. I just wanted to say it loud, to check if there is anything missing!

<Pascal>
Great question, and yes. Each root is responsible to set the “T” flag based on its own knowledge and needs, true for local and global RPL Instances.

If the OF support mandates RFC 8138 then that will work. If the 6LR/root knows that all participants support RFC 8138 that will work as well. Once we have the capability draft and the 6LR/root found that all the members of the DODAG have the capability, that will work.
What if the 6LR knows none of that? This question affects in particular the DAO projection work. A projected path may cross over multiple DODAGS so it cannot inherit from one.

Also I gave a new look at the transition scenarios. We say that a node that does not support RFC 8138 can act as a leaf if the 6LR un-compresses the packets before delivery. Same question, how does it know? As it goes, useofrplinfo says that external targets are not expected to support RFC 8138 since it is a RPL thing. So acting as a RUL, we know things work.

Till the capability work comes in we need a separate source of knowledge (config, management) for a 6LR to know if 1) it can form a local instance with the “T” flag set and 2) to deliver packets to a RAL in compressed form.

I suggest to mod the section on leaf as follows:
“
    A node that does not support <xref target='RFC8138'/> can interoperate with a
    node that supports this specification in a network with RFC 8138 compression
    turned off. But it cannot forward compressed packets and therefore it cannot
    act as a router in a network with RFC 8138 compression turned on. It may
    remain connected to that network as a leaf and generate uncompressed packets.
    The leaf can receive packets if they are delivered by the parent 6LR in the
    uncompressed form. This requires a knowledge by the 6LR that the leaf does
    not support RFC 8138.
    A RPL-Unaware-Leaf (RUL) <xref target='I-D.ietf-roll-useofrplinfo'/>
      is an external target and by default is not expected to support RFC 8138. “

</Pascal>

3. Section 5
"But the node is also free to refrain from joining an Instance when a parameter is not suitable."
Refrain from joining an instance is not the same as "join as a leaf". A node that joins as a leaf, still is joining the instance. A node may join as a leaf when a parameter is not suitable. (It is possible that I have completely misunderstood the statement here).

<Pascal>
Yes that sentence is not that useful. It says that the node may decide not to join at all. Which is true but not a scientific breakthrough.
I’d rather indicate the following
“
   [ietf-roll-useofrplinfo] indicates that the node may also
   join as a RUL, in which case it refrains from participating to RPL and depends on the
   6LR to ensure connectivity regardless on the way the RPL network is operated.

“
</Pascal>

4. Section 5.3
"instances operate as ships-in-the-night"
ships-in-the-night? I didn't find any explanation in the given ref. After searching online, I think I understand :-), better to put in simple terms.
<Pascal>
What about
“
The two RPL Instances operate independently as specified
   in <xref target='RFC6550'/>.
“
</Pascal>

Nits:
1. "network is rebooted with implicitely"
implicitely -> implicitly

ok

2. "in an homogeneous network" -> "in a homogeneous ..."

Ok

3. "but MAY still joins as a leaf" -> "but MAY still join as a leaf"
Ok

4. ". when it finally" -> ". When it finally" .... Better would be to rephrase
... "The root migrates to new OCP when it finally sets the "T" flag."

<Pascal>
I’d wish to indicate clearly that they go together. What about:
“
The root sets the "T" flag at the time it migrates to the new OCP.
“
</Pascal>

5. "distribute the uncompresses"
uncompresses -> uncompressed

ok

6. Instance 'I' is used capital in some cases, 'i' in other cases for exact similar context.

<Pascal>
Should use “RPL Instance” every time as RFC 6550 does.
</Pascal>

7. The term "turn on" is used in a few places... For e.g., in security considerations, "Turning the "T" flag on before...." ... Can we use ON in caps here to specify the meaning appropriately?
<Pascal>
Unsure. Do we need to define “turning on”?
</Pascal>

Thanks,
Rahul

________________________________________
From: Roll <roll-bounces@ietf.org> on behalf of Ines Robles <mariainesrobles=40googlemail.com@dmarc.ietf.org>
Sent: Friday, January 17, 2020 10:39 AM
To: roll <roll@ietf.org>
Subject: [Roll] Request for review draft-ietf-roll-turnon-rfc8138-02

Dear all,

We kindly request reviews for the draft draft-ietf-roll-turnon-rfc8138-02 , we understand that it is ready for Last Call.

Thank you in advance,

Ines and Dominique

---
## [TheTrueTom/GLINCS-KiCAD-Libraries](https://github.com/TheTrueTom/GLINCS-KiCAD-Libraries)@[573a0e70c5...](https://github.com/TheTrueTom/GLINCS-KiCAD-Libraries/commit/573a0e70c5ac2a8dfc576eb4409549d2aeba0676)
#### Wednesday 2020-01-22 13:45:19 by chalumeau

add new components for andra cards and fuck your dog.

Very deep.

---
## [trollbreeder/trollstation](https://github.com/trollbreeder/trollstation)@[564d44803c...](https://github.com/trollbreeder/trollstation/commit/564d44803c1decf0ffd1c842d8c65cbdf8e306b6)
#### Wednesday 2020-01-22 14:09:14 by trollbreeder

Update README.md

fuck you byond why do you act like this

---
## [JosDUisterhout/wwi](https://github.com/JosDUisterhout/wwi)@[1886263298...](https://github.com/JosDUisterhout/wwi/commit/1886263298ca498b7e7f42a185480fbb8dcc5061)
#### Wednesday 2020-01-22 14:30:25 by Jos

What the fuck did you just fucking say about me, you little bitch?

What the fuck did you just fucking say about me, you little bitch? I'll have you know I graduated top of my class in the Navy Seals, and I've been involved in numerous secret raids on Al-Quaeda, and I have over 300 confirmed kills. I am trained in gorilla warfare and I'm the top sniper in the entire US armed forces. You are nothing to me but just another target. I will wipe you the fuck out with precision the likes of which has never been seen before on this Earth, mark my fucking words. You think you can get away with saying that shit to me over the Internet? Think again, fucker. As we speak I am contacting my secret network of spies across the USA and your IP is being traced right now so you better prepare for the storm, maggot. The storm that wipes out the pathetic little thing you call your life. You're fucking dead, kid. I can be anywhere, anytime, and I can kill you in over seven hundred ways, and that's just with my bare hands. Not only am I extensively trained in unarmed combat, but I have access to the entire arsenal of the United States Marine Corps and I will use it to its full extent to wipe your miserable ass off the face of the continent, you little shit. If only you could have known what unholy retribution your little "clever" comment was about to bring down upon you, maybe you would have held your fucking tongue. But you couldn't, you didn't, and now you're paying the price, you goddamn idiot. I will shit fury all over you and you will drown in it. You're fucking dead, kiddo.

---
## [TheKins/MetaDoom](https://github.com/TheKins/MetaDoom)@[dcf2d0840d...](https://github.com/TheKins/MetaDoom/commit/dcf2d0840d7199e566066c04ef7e53753ac653dc)
#### Wednesday 2020-01-22 15:00:07 by The Kins

Holy shit, progress! Hell Guard near-final sprites

---
## [Mickyan/tgstation](https://github.com/Mickyan/tgstation)@[044fd3f7ad...](https://github.com/Mickyan/tgstation/commit/044fd3f7adec122551e745dfc4493c4c07e0c32b)
#### Wednesday 2020-01-22 15:30:50 by Rob Bailey

TGUI-next Nanite Interface Overhaul + Dropdown component (#47972)

* Nanite TGUI-Next + Dropdown

nanite remote

program hub and better remote

fuck it let's make a dropdown component, time to die

DROPDOWN WORKING HOLY SHIT

more dropdown work

cleanup + fixes

new timer system

nanite work

jj

functional dropdown + final structure for backend, more refactor needed

dropdown being insane

oh my god dropdown actually works correctly for once

massive backend refactor

small fix + docs

dropdown optimizations + width

wip nanite cloud control

forgot it

cloud controller

bunch of work

final chamber console

nanite remotes

rebuild

small tweaks

rebuild after rebase

* fixes

* big refactor to useFrontend, use standard style

* whoops

* small changes

* rebuild

* small fixes and tweaks + documentation on dropdown and collapsible

* small tweak to programmer ui

* Cosmetic

---
## [rokibhasansagar/aosp_common_kernels](https://github.com/rokibhasansagar/aosp_common_kernels)@[fa1f270d36...](https://github.com/rokibhasansagar/aosp_common_kernels/commit/fa1f270d36bd089c791225f8dfa53d554d132fef)
#### Wednesday 2020-01-22 16:28:44 by Douglas Anderson

serial: core: Allow processing sysrq at port unlock time

[ Upstream commit d6e1935819db0c91ce4a5af82466f3ab50d17346 ]

Right now serial drivers process sysrq keys deep in their character
receiving code.  This means that they've already grabbed their
port->lock spinlock.  This can end up getting in the way if we've go
to do serial stuff (especially kgdb) in response to the sysrq.

Serial drivers have various hacks in them to handle this.  Looking at
'8250_port.c' you can see that the console_write() skips locking if
we're in the sysrq handler.  Looking at 'msm_serial.c' you can see
that the port lock is dropped around uart_handle_sysrq_char().

It turns out that these hacks aren't exactly perfect.  If you have
lockdep turned on and use something like the 8250_port hack you'll get
a splat that looks like:

  WARNING: possible circular locking dependency detected
  [...] is trying to acquire lock:
  ... (console_owner){-.-.}, at: console_unlock+0x2e0/0x5e4

  but task is already holding lock:
  ... (&port_lock_key){-.-.}, at: serial8250_handle_irq+0x30/0xe4

  which lock already depends on the new lock.

  the existing dependency chain (in reverse order) is:

  -> #1 (&port_lock_key){-.-.}:
         _raw_spin_lock_irqsave+0x58/0x70
         serial8250_console_write+0xa8/0x250
         univ8250_console_write+0x40/0x4c
         console_unlock+0x528/0x5e4
         register_console+0x2c4/0x3b0
         uart_add_one_port+0x350/0x478
         serial8250_register_8250_port+0x350/0x3a8
         dw8250_probe+0x67c/0x754
         platform_drv_probe+0x58/0xa4
         really_probe+0x150/0x294
         driver_probe_device+0xac/0xe8
         __driver_attach+0x98/0xd0
         bus_for_each_dev+0x84/0xc8
         driver_attach+0x2c/0x34
         bus_add_driver+0xf0/0x1ec
         driver_register+0xb4/0x100
         __platform_driver_register+0x60/0x6c
         dw8250_platform_driver_init+0x20/0x28
	 ...

  -> #0 (console_owner){-.-.}:
         lock_acquire+0x1e8/0x214
         console_unlock+0x35c/0x5e4
         vprintk_emit+0x230/0x274
         vprintk_default+0x7c/0x84
         vprintk_func+0x190/0x1bc
         printk+0x80/0xa0
         __handle_sysrq+0x104/0x21c
         handle_sysrq+0x30/0x3c
         serial8250_read_char+0x15c/0x18c
         serial8250_rx_chars+0x34/0x74
         serial8250_handle_irq+0x9c/0xe4
         dw8250_handle_irq+0x98/0xcc
         serial8250_interrupt+0x50/0xe8
         ...

  other info that might help us debug this:

   Possible unsafe locking scenario:

         CPU0                    CPU1
         ----                    ----
    lock(&port_lock_key);
                                 lock(console_owner);
                                 lock(&port_lock_key);
    lock(console_owner);

   *** DEADLOCK ***

The hack used in 'msm_serial.c' doesn't cause the above splats but it
seems a bit ugly to unlock / lock our spinlock deep in our irq
handler.

It seems like we could defer processing the sysrq until the end of the
interrupt handler right after we've unlocked the port.  With this
scheme if a whole batch of sysrq characters comes in one irq then we
won't handle them all, but that seems like it should be a fine
compromise.

Signed-off-by: Douglas Anderson <dianders@chromium.org>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Signed-off-by: Sasha Levin <sashal@kernel.org>
Signed-off-by: Lee Jones <lee.jones@linaro.org>
Change-Id: I9c3a80ff237aba9c770a39fa8ffa06d932af12ce

---
## [putermuter/s4sinterface-server](https://github.com/putermuter/s4sinterface-server)@[f851d1e857...](https://github.com/putermuter/s4sinterface-server/commit/f851d1e857955c8d42af83adcde633b55c084e5b)
#### Wednesday 2020-01-22 17:02:55 by putermuter

Initial code commit.

This server code kinda sucks atm but I think it is better to let more
experienced people improve it.

---
## [locutus2/Stockfish](https://github.com/locutus2/Stockfish)@[9afa03b80e...](https://github.com/locutus2/Stockfish/commit/9afa03b80ea4610729427ee8287a5bbadba03e02)
#### Wednesday 2020-01-22 18:35:15 by noobpwnftw

7-pieces Syzygy tablebase support

This is the first patch teaching Stockfish how to use the 7-pieces
Syzygy tablebase currently calculated by Bujun Guo (@noobpwnftw) and
Ronald de Man (@syzygy1). The 7-pieces database are so big that they
required a change in the internal format of the files (technically,
some DTZ values are 16 bits long, so this had to be stored as wide
integers in the Huffman tree).

Here are the estimated file size for the 7-pieces Syzygy files,
compared to the 151G of the 6-pieces Syzygy:

```
7.1T    ./7men_testing/4v3_pawnful (ongoing, 120 of 325 sets remaining)
2.4T    ./7men_testing/4v3_pawnless
2.3T    ./7men_testing/5v2_pawnful
660G    ./7men_testing/5v2_pawnless
117G    ./7men_testing/6v1_pawnful
87G     ./7men_testing/6v1_pawnless
```
Some pointers to download or recalculate the tables:

Location of original files, by Bujun Guo:
ftp://ftp.chessdb.cn/pub/syzygy/

Mirrors:
http://tablebase.sesse.net/ (partial)
http://tablebase.lichess.ovh/tables/standard/7/

Generator code:
https://github.com/syzygy1/tb/

Closes https://github.com/official-stockfish/Stockfish/pull/1707

Bench: 5591925 (No functional change if SyzygyTB is not used)

----------------------

Comment by Leonardo Ljubičić (@DragonMist)

This is an amazing achievement, generating and being able to use 7 men syzygy
on the fly. Thank you for your efforts @noobpwnftw !! Looking forward how this
will work in real life, and expecting some trade off between gaining perfect
play and slow disc Access, but once the disc speed and space is not a problem,
I expect 7 men to yield something like 30 elo at least.

-----------------------

Comment by Michael Byrne (@MichaelB7)

This definitely has a bright future. I turned off the 50 move rule (ala ICCF
new rules) for the following position:  `[d]8/8/1b6/8/4N2r/1k6/7B/R1K5 w - - 0 1`
This position is a 451 ply win for white (sans the 50 move rule, this position
was identified by the generator as the longest cursed win for white in KRBN v KRB).

Now Stockfish finds it instantly (as it should), nice work 👊👍 .
```
dep score	    nodes	    time
  7	+132.79 	4339    	0:00.00	Rb1+ Kc4 Nd6+ Kc5 Bg1+ Kxd6 Rxb6+ Kc7 Be3 Rh2 Bd4
  6	+132.79 	1652    	0:00.00	Rb1+ Kc4 Nd2+ Kd5 Rxb6 Rxh2 Nf3 Rf2
  5	+132.79 	589      	0:00.00	Rb1+ Kc4 Rxb6 Rxh2 Nf6 Rh1+ Kb2
  4	+132.79 	308      	0:00.00	Rb1+ Kc4 Nd6+ Kc3 Rxb6 Rxh2
  3	+132.79 	88        	0:00.00	Rb1+ Ka4 Nc3+ Ka5 Ra1+ Kb4 Ra4+ Kxc3 Rxh4
  2	+132.79 	54        	0:00.00	Rb1+ Ka4 Nc3+ Ka5 Ra1+ Kb4
  1	+132.7
```

---
## [ipld/go-ipld-prime](https://github.com/ipld/go-ipld-prime)@[ce917dd435...](https://github.com/ipld/go-ipld-prime/commit/ce917dd435c1e6fe21f1c71613fdc47d24a140fc)
#### Wednesday 2020-01-22 18:38:31 by Eric Myhre

I need to start admitting some research code.

It's been, broadly speaking, "tricky" to plan out and design some of
this project.  It's been doubly tricky to do it while understanding
the holistic performance implications of the detailed choices.
And while "premature optimization, evil", etcetera... I've gone
through the performance rodeo in this vincinity at least once before
(in the form of the refmt libraries): and resultingly, I'm going to
claim a slightly-better-than-zero intuition for what's premature and
what's utterly critical to keep track of as early as possible lest
ye be doomed to a rewrite after learning things the hard way.

(Arguably, half this codebase **is** the rewrite after learning things
the hard way.  But I digress.)

So: to combat this "trickiness", I've started writing a lot of
"research" code and experimental benchmarks.
This is still certainly fraught with peril -- in fact, one of the
major things I've learned overall is just *how* dangerously misleading
microbenchmarks can be (and to combat this, I've now started regularly
reading the assembler output to make sure the optimizer is doing
exactly what I think it is, neither more nor less) -- but it's much
more informative than *not* doing it, and trying to suss out the mess
later once you've built a whole system.

And that's what it's time to start committing.
(I should've started a while ago, honestly.)

This "rsrch" directory will get some more content momentarily in
coming commits, because there's a *lot* of stuff on my localhost.
Some of it was so preliminary I'm not going to bother to preserve it;
a lot of things are potentially pretty interesting, as educational
and archeological material, if nothing else: those I'm going to commit.

(It's possible all this will end up `git rm` again at some time in the
future, too.  But honestly, it's darn hard to remember "why didn't
you just do X?" sometimes.  Notes need to get committed *somewhere*,
at least briefly enough that it's possible to dig them out again.)

So!  To start: here are some research benchmarks into what strongly-
natively-typed builders might look like in our codegen outputs.

These are from about Oct 13th, as best I can suss localhost mtimes.
I think most of these concepts are ones I'm (frustratingly) backing
away from now, because I've learned a *lot* more about performance
in the meanwhile, and I don't think these are gonna do well.
But the worked exploration into ergonomics is still potentially
interesting and worth review!

Signed-off-by: Eric Myhre <hash@exultant.us>

---
## [ipld/go-ipld-prime](https://github.com/ipld/go-ipld-prime)@[38aa8b7cb0...](https://github.com/ipld/go-ipld-prime/commit/38aa8b7cb0b336e7ab20483dc6c90ba8da51cc29)
#### Wednesday 2020-01-22 18:38:31 by Eric Myhre

In which I reverse engineered "inline pointers".

As you can see from the directory name ("multihoisting"), when I began
exploring this topic, I didn't know they were called that.  :/
This thus turned out to very much be one of those occasions where
knowing the *right two words* to put into a search engine would've
saved a fairly enormous number of hours.  Once I finally found the
right term, some perfectly lovely documentation appeared.  But alas.

(Like the previous commits, this stuff is coming from a while ago;
roughly Oct 25.  It uncovers a lot of stuff that gets us much closer to
being able to make correct and performant designs to minimize and
amortize the number of allocations that will be required to make our
node trees work in codegen (though with that said, there will also
still be plenty of details in need of refinement after this, too).)

Still working on a "HACKME_memorylayout.md" doc, which will appear
in the codegen directories in the near future and contain a summary
of these learnings and how they balance against other design concerns.

Meanwhile, a couple of other notes in their rough form:

- basically, don't use non-pointer methods.
	- turns out value receivers tend to mean "copy it", and pointer receivers *don't* mean "heap alloc it" (they just mean "consider escape, maybe").
		- so overall you're tying the compilers hands when you use a value receiver, and you're *not* when you use a pointer receiver.
- taking pointers to things already being passed around in pointer form or already having heap-escaped seems to be free.
	- it might demand something become heap alloc if it wasn't already...
		- but this turns out to be fairly amortizable.
		- because if you write nearly-everthing to be pointers, then, there you go.
	- and if you're lucky and something is shortlived (provably doesn't escape), then even whole stacks of ptr-receiver methods will still probably inline and collapse to no heap action.
		- the analysis on this seems to reach much further than i thought it would.
		- `-gcflags '-m -m'` was extremely revealing on this point.
- tl;dr:
	- more pointers not less in all functions and passing;
	- but do have one struct that's the Place of Residence of the data without pointers.
	- this pair of choices probably leads to the best outcomes.
- hokay so.  applied to topic: two sets of embeds.
	- builders might as well have their own big slab of embed too.
		- logically nonsense to embed them, but incredibly rare you're not gonna use the memory, so!

And a couple important incantations, which can help understand
What's Really Going On Here in a bunch of ways:

- `-gcflags '-S'` -- gives you assembler dump
- `-gcflags '-m'` -- gives you escape analysis (minimally informative and hard to read)
- `-gcflags '-m -m'` -- gives you radically more escape analysis, in stack-form (actually useful!!)
- `-gcflags '-l'` -- disables inlining!

I learned about the '-m -m' thing by grepping the Go compiler source,
incidentally.  It's a wildly under-documented feature.
No joke: I encountered it via doing a `grep "Debug['m']` in go/src;
there is currently no mention of it in `go tool compile -d help`.
Once I found the magic string, and could submit it to search engines,
I started to find a few other blogs which mention it... but I'd
seen none of them (and had not found queries that turned them up)
until having this critical knowledge already in-hand.  >:I
So chalking up another score for "the right words would've been nice".

Performance work is fun!

---
## [CrashCringle12/Simply-Love-SM5](https://github.com/CrashCringle12/Simply-Love-SM5)@[b5f6ba6652...](https://github.com/CrashCringle12/Simply-Love-SM5/commit/b5f6ba665235c585196f85ddfac96ab1aa3b9934)
#### Wednesday 2020-01-22 20:28:52 by Dan Guzek

make Simply Love Options more modular

Simply Love started to seriously support more than just English starting with v4.8.0.  At that time, one of the testers (Jose or HeySora, I think) found that the Simply Love Options screen did not fully update to use a new language until SM was restarted.

I did not have time to fix it then, so v4.8 shipped with the note:

-------------
Please note that immediately after switching the language (for example, from English to Español), it may be necessary to restart to StepMania for all in-game text to be properly translated. This is probably a bug, but thankfully you should only need to change the language once.
-------------

Then I forgot about it for a while.

I looked into it today and realized pretty quickly that my SL_CustomPrefs table in ./Scripts/99 SL-ThemePrefs.lua was only being evaluated once, at SM init.

This commit makes SL's use of _fallback's ThemePrefs system more modular by wrapping the existing code in functions.

I added some inline comments and updated the main README.md.

---
## [AngelGryph/NTotSC](https://github.com/AngelGryph/NTotSC)@[9d592860dd...](https://github.com/AngelGryph/NTotSC/commit/9d592860dd5abf7bb7462f2444a9a2601cd04abd)
#### Wednesday 2020-01-22 20:36:28 by Gitjas

update to v3.2.0

Changes:
	-Completed and revised Italian version by ilot
	-Completed and revised Polish version by Roberciiik
	-Map Note to Fire Leaf Forest added (entrance to pass to Cloud Peak)
	-Map Note added to AR80PB.are (Entrance to Cave)
	-description of Shocking Flail adjusted to real stats
	-Draagis' staff should have correct damage effect
	-all keys tagged as keys so they fit into the key chain
	-Nadalin recognizes whether he brought PC to island before (should not give his first dialogue every time after quest is finished)
	-AR9001.are: trap at desk should be removable/reachable
	-AR25PB.are: removed original fire slamander references, also from dialogues (replaced with mod ones)
	-journal entry for elven bow will also be added if PC gets quest without any of the items already in inventory
	-assigned fighting script to Demon Knights (should not stand idle)
	-nerved fire slamander fight: for level PC lower 4 or game difficulty lower NORMAL, number of fire slamander will be halved.
	-nerved fire slamanders: less HP, no immunity to nonmagical weapons, less damage
	-Lesser Tanar'ri nerved: lower XP, immunity to slashing, crishing, piercing set to 0, nerfed Tanar'ri spell script.
	-fight with Lesser Tanar'ri nerved: number of Lesser Tanar'ri depending in game difficulty
	-removed elven chain mail +1 from Haebal
	-Haebal cre nerfed and corrected: is now mage with legal stats
	-Hasdar cre nerfed: has now legal amount of HP
	-nerved Knights of the Grave: reduced HP, nerved undroppable flame blade
	-monster count in AR02PB reduced depending on game difficulty. For INSANE, all monsters will still be there.
	-DSotSC ressources: Holy Water effect should work on undead, Holy Water can be bought in almost all Temples.
	-put a note into the readme that Will is a rather silent NPC.
	-German version: corrected description of Studded Leather of Resistance
	-German version: effects description of Armor of Black Swan corrected

---
## [elBukkit/dynmap](https://github.com/elBukkit/dynmap)@[3928985d34...](https://github.com/elBukkit/dynmap/commit/3928985d34ad72ebcfc7ab0cf0808e11db0a94d7)
#### Wednesday 2020-01-22 21:56:27 by Aaron-Mann

Create README.md

I was checking out the Repository for your plugin (which I love using on my server) when I noticed that you did not have a "readme" file. I have created a draft readme file for the repo, with all information taken form documentation on CurseForge. Hope this can help you out!

---
## [mamedev/mame](https://github.com/mamedev/mame)@[819af3ced9...](https://github.com/mamedev/mame/commit/819af3ced97dcfbd561cb3015b5bb02787e9a657)
#### Wednesday 2020-01-22 22:23:17 by Firehawke

Late January Apple II update. (#6208)

* New working software list additions
-----------------------------------

apple2_flop_orig: Wizardry: Proving Grounds of the Mad Overlord (Version 2.1), Wizardry II: The Knight of Diamonds (Version PV3S2V1/10-MAR-82), Wiziprint (Version 2.1), Amazon, Lords of Karma, Xyphus, Chess (Odesta) (Version 7.0) [4am, Firehawke]

* New working software list additions
-----------------------------------

apple2_flop_clcracked: What's My Logic? (Version 1.0) (cleanly cracked) [4am, Firehawke]

apple2_flop_orig: Rambo: First Blood Part II, New World, Quest for the Scarlet Letter, Cuban Fantasy, Neuromancer, The Dark Heart of Uukrul, The Breckenridge Caper of 1798, Amnesia, Gold Rush! (Version 1.0M), Questprobe featuring The Hulk (Version 2.3/127) [4am, Firehawke]

* New working software list additions
-----------------------------------

apple2_flop_orig: Horizon V, Crown of Arthain, Diamond Mine, The Abyssal Zone  [4am, Firehawke]

apple2_flop_clcracked: Diascriptive Reading I (cleanly cracked), Air Navigation Trainer (cleanly cracked) [4am, Firehawke]

---
## [ShadeAware/switchbladesrcool](https://github.com/ShadeAware/switchbladesrcool)@[1c4f37b5bf...](https://github.com/ShadeAware/switchbladesrcool/commit/1c4f37b5bfd0fecaea6d7c6d7795eab5d1af20a7)
#### Wednesday 2020-01-22 22:51:00 by ShadeAware

MAKING THE CODE LESS SHIT THANS TO ARTUR AND SUN WUKONG

WHY DID IT TAKE ME SO LONG TO DO THIS THEY LITERALLY SPOONFED ME THE INFORMATION GOD IM SO FUCKING STUPID AND RETARD GOD I FUCKING I FHUHDHJUGDFJTUFUGFUG7F7BGFJKDOKDIVFUBHFB

---
## [Spencerstf/Civilian-Industries](https://github.com/Spencerstf/Civilian-Industries)@[25178a23c9...](https://github.com/Spencerstf/Civilian-Industries/commit/25178a23c9c3ccd6e6aee24c75024c848e7b1ee4)
#### Wednesday 2020-01-22 23:32:57 by Spencer

Goods Begone Update

Save Compatibility is pretty much impossible due to the performance overhauls in this patch. Sorry. Eventually I'll get better at future-proofing, but there was a need for quite the overhaul for performance's sake. I'm slowly getting better at programming though, and the dream of a patch-safe update is still alive and strong.

Code Revamped for better late game performance.
Certain changes may potentially cause desync in multiplayer. They, for all intents and purposes, shouldn't, but noting this here for my future self to come back and laugh at if it happens.The performance gain is enough for this to be worth it.

Goods removed.
Grand Station no longer imports or exports cargo.
Militia Stations now only requests resources from their local Trade Station, OR adjacent planet trade stations if theirs is destroyed.
They will never search beyond that point.
Trade Stations have increased capacity and resource generation.
You now start with a Trade Station on your home planet.
-All these changes basically mean that your trade network can splinter, but survive. You still need to have a few cargo ships arrive on a planet in the first place, but afterwards, they'll be able to (somewhat) defend themselves with local shipments to their militia bases.
-They will attempt to ferry resources between stations (and, in fact, will do so much better than before), but won't attempt to do so across the entire galaxy anymore.

Every resource is now tied to a tech type.
Each Outpost and Patrol Post will roll one random ship (or turret, if outpost) type that uses the respective resource's tech.
Expect a much, much larger variety in units now. No more uniform ship style, your civies will simply use what they can find.

Current barracks renamed to Patrol Posts.
Patrol Posts can only be built around mines and are limited by the mine count on each planet.
Each planet will attempt to fully cover all wormholes and mines on its planet over time, but they will prioritize threatened planets first.

The AI will now launch periodic Exogalactic attacks meant to raid various trade stations. They will attempt to do so in time with waves sent by the ai for coordinated strikes.
These are INCREDIBLY painful, so be prepared.

Mark level for ships & turrets now properly scale with player mark level.

Patrol Post mobile forces will no longer attempt to aid you in fights you have an overwhelming advantage in, unless they have nothing else they think they can currently be doing.

AI Ship targeting priority updated so they will no longer focus cargo ships over absolutely everything else.

Outpost/Patrol Posts have had increased defensive stats to make up for them no longer marking up.

Units will now take increasingly higher amounts of resoures to build as they reach their capacity.

---

# [<](2020-01-21.md) 2020-01-22 [>](2020-01-23.md)

