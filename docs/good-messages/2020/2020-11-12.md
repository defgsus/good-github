# [<](2020-11-11.md) 2020-11-12 [>](2020-11-13.md)

2,924,620 events, 1,539,487 push events, 2,349,400 commit messages, 166,876,882 characters


## [CliMA/ClimateMachine.jl](https://github.com/CliMA/ClimateMachine.jl)@[f82b25684a...](https://github.com/CliMA/ClimateMachine.jl/commit/f82b25684a7143a26c2be0dc8c8df160659f79fe)
#### Thursday 2020-11-12 00:53:20 by bors[bot]

Merge #1716

1716: Experimental CartesianField abstractions for plotting and simple analysis, plus two new Ocean tutorials r=glwagner a=glwagner

### Description

This PR adds an experimental `CartesianDomain` and `CartesianField` abstraction, plus two new ocean tutorials.

Eventually we would use `CartesianDomain` to idealized rectangular domains with both regular and stretched elements, and `CartesianDomain` will manage the construction of the `DiscontinuousSpectralElementGrid`.

However, in the spirit of incremental changes, the current constructor for `CartesianDomain` does the opposite, by inverting the data in `DiscontinuousSpectralElementGrid` assuming an underlying Cartesian structure to build a Cartesian abstraction.

Usage is illustrated in the tutorials, which produce these animations:

![geostrophic_adjustment](https://user-images.githubusercontent.com/15271942/98382723-8efabb80-2019-11eb-9ed9-0d23752da478.gif)

![radiating_eddy](https://user-images.githubusercontent.com/15271942/98382740-9326d900-2019-11eb-96b9-380da42cbc39.gif)

# `CartesianDomain` usage

Currently we can't build a `DiscontinuousSpectralElementGrid` all that easily outside of the `DriverConfiguration` / `SolverConfiguration` interface. So my example asumes one has a `SolverConfiguration` object in hand. Then we'd write

```julia
julia> domain = CartesianDomain(solver_configuration.dg.grid, Ne)
CartesianDomain{Float64, ClimateMachine.Mesh.Grids.DiscontinuousSpectralElementGrid}:
    Np = 4, Ne = (x = 100, y = 1, z = 1)
    x = (0.00e+00, 1.00e+06), y = (0.00e+00, 1.00e+06), z = (-4.00e+02, 0.00e+00)
    Lx = 1.00e+06, Ly = 1.00e+06, Lz = 4.00e+02
```

where `Ne` is a tuple corresponding to the number of elements in each Cartesian direction `x, y, z`.

# `CartesianField` usage

`CartesianField` provides a Cartesian `view` into data in `MPIStateArray`. The current interface (which hopefully will be improved) is

```
julia> u = CartesianField(domain, solver_configuration.Q, 1);
```

where `domain::CartesianDomain` and `1` is the index of the field in `solver_configuration.solver.Q.realdata`. `CartesianField` keeps track of `CartesianField.domain` and `CartesianField.elements` is an `Array{RectangularElement, 3}`:

```julia
julia> u.elements
100×1×1 Array{ClimateMachine.Ocean.CartesianDomains.RectangularElement... # goes on
```

which is indexed into via

```julia
julia> u[1, 1, 1]
RectangularElement{SubArray} with data ∈ [-1.29e-05, 7.50e-06]
    x ∈ [0.00e+00, 1.00e+04]
    y ∈ [0.00e+00, 1.00e+06]
    z ∈ [-4.00e+02, 0.00e+00]
```

which have properties `x, y, z, data`:

```julia
julia> u[1, 1, 1].x
5-element view(::Array{Float64,4}, :, 1, 1, 1) with eltype Float64:
     0.0
  1726.731646460114
  5000.0
  8273.268353539885
 10000.0

julia> u[1, 1, 1].data
5×5×5 view(reshape(view(::Array{Float64,3}, :, 1, 1:100), 5, 5, 5, 100), :, :, :, 1) with eltype Float64:
# much output...
```

Note that `CartesianField` does not assume ~~anything~~ too much about the structure of `MPIStateArray.realdata` (except that data is stored in an array with indices `(node, field, element)`), but uses a linear coordinate to sort elements:

https://github.com/CliMA/ClimateMachine.jl/blob/c7a48d20604b6ef0148aec0b273126471d58fd53/src/Ocean/CartesianDomains/cartesian_field.jl#L57-L75

However, we do assume that all coordinates are 1D, despite that in the underlying `DiscontinuousSpectralElement` grid the nodal coordinates can differ by factors close to machine precision.

# Key function: `assemble`

Using this abstraction we are `assemble` the elements of a field into 

https://github.com/CliMA/ClimateMachine.jl/blob/860a801baff7edd0fdcc9328a8374b217ca7c8b7/src/Ocean/CartesianDomains/rectangular_element.jl#L88-L103

which in the wild looks like

```julia
julia> assembly = assemble(u)
RectangularElement{Array} with data ∈ [-1.93e-03, 1.82e-03]
    x ∈ [0.00e+00, 1.00e+06]
    y ∈ [0.00e+00, 1.00e+06]
    z ∈ [-4.00e+02, 0.00e+00]
```

which, crucially, averages data on shared nodes and returns a giant `RectangularElement` with all the data. This is necessary for creating visualizations using tools like `Plots.contourf`, for example.

When adapting this object for `CuArray`, we will have to provide an option specifying whether to transfer data before `assemble`ing or to perform all computations on the GPU.  @christophernhill has mentioned we would also like a function that does the same thing but avoids averaging. Perhaps extending `cat` for `RectangularElement`s will work for this.

This abstraction may require more development to work with memory-distributed problems. I don't think its crucial that this abstraction works for memory-distributed problems, because its mostly useful for quick visualization needed for fast turnover while designing experiments, producing tutorials, and post-processing data.

If the tutorials are to run without external dependencies, we'd have to depend on `Plots`.

Note: the tutorials in this PR depend on #1703 .

- [x] Code follows the [style guidelines](https://clima.github.io/ClimateMachine.jl/latest/DevDocs/CodeStyle/) OR N/A.
- [x] Unit tests are included OR N/A.
- [x] Code is exercised in an integration test OR N/A.
- [x] Documentation has been added/updated OR N/A.


Co-authored-by: Gregory Wagner <wagner.greg@gmail.com>

---
## [rifath33/SuperArray](https://github.com/rifath33/SuperArray)@[0a1d4f3577...](https://github.com/rifath33/SuperArray/commit/0a1d4f3577e6059ab87ba9c4272a0c2abf77bdc0)
#### Thursday 2020-11-12 01:26:09 by rifath33

Oh my god. After 5 hours of frustration I was finally able to fix this issue that has been KILLING me. You don't know how happy I am. I can now confidently say that things should be able to sail smooth from here on out.

---
## [TorannD/TMagic](https://github.com/TorannD/TMagic)@[d99a1b3f96...](https://github.com/TorannD/TMagic/commit/d99a1b3f96e15ceecf29eb718b1a5d86478c5124)
#### Thursday 2020-11-12 01:34:33 by TorannD

v2.5.4.0 update - shaman

New:
 o Dark Robes - Art improvements and redesign by Aledroid
	- Renamed to "Mage Robe"
	- Stats tweaked to reduce physical and environmental protection
	- Replaces the ability XP gain penalty of -25% to a bonus +10%
 o Added custom weapon defs for 31 mods thanks to fluffysnowcap

 o New Magic class - Shaman: utilizes a variety of offensive, defensive and support abilities through their connection with spirit and elemental energies
  - Totems: creates totems of lightning, earth, and healing to provide temporary AoE support
  - Enrage: uses emotions as fuel to greatly augment physical combat power
  - Hex: place a hex on targets (friend or foe) that establishes a link between the shaman and hexed spirits; additional curses can be applied to all hexed targets:
	* Pain Hex: applies a minor injury that causes extreme pain
	* Mental Assault Hex: can cause various mental breaks
	* Critical Fail Hex: hexed targets suffer from extremely bad luck which can result in shooting allies, tripping over their own weapon, and other unlucky results
  - Chain Lightning: creates a bolt of lightning that bounces to nearby enemy targets
  - Spirit Wolves: summons a howling pack of wolves to charge a position
  - Spirit Animal: calls for the Shamans spirit animal
	* Bear: defensive and steadfast, the spirit bear will taunt enemies and soak damage with it's thick hideous
	* Mongoose: crafty and agile, the mongoose can deliver lethal surprise attacks
	* Crow: augments the wisdom and spirit connections of the shaman

Tweaks:
 o Shadow trait penalty to shooting accuracy reduced from -25 -> -5; global learning speed, social skills, and research reduced to compensate
 o Reduced difficulty of Elemental Assault by 25%
 o Core classes using custom class defs will still appear under the core class mod options
 o Light Lance will no longer hit friendly pawns within 2 cells of the caster
 o Updates for valid weapon requirements for abilities is cached every second to improve performance
 o Reverse time will lose some of it's power each time it removes a illnesses or injury, effectively limiting the number of hediffs it will remove for each application
 o Commander orders now take a small amount of time to issue

Bug fixes:
 o Fixed a bug where Cantrip skills had a cap of 3 levels instead of 15
 o AI should no longer use abilities on prisoners
 o Fixed a bug that was preventing disabling shot from upgrading skills if the ability was at level 3
 o Fixed a bug when Dragon Strike attempted to kick an invalid target

---
## [fuglore/PD2-Hyper-Heisting](https://github.com/fuglore/PD2-Hyper-Heisting)@[187f6f8631...](https://github.com/fuglore/PD2-Hyper-Heisting/commit/187f6f86318d13fb16bbd034bb8192009b0bee3a)
#### Thursday 2020-11-12 01:46:27 by Fuglore

i dont want to jinx it but i think i got it

-fixed blah blah blah blah fuck you

---
## [cryptoseb/cryptoseb.pw](https://github.com/cryptoseb/cryptoseb.pw)@[827d32eb44...](https://github.com/cryptoseb/cryptoseb.pw/commit/827d32eb443b1b6d2f94c3c2648b2fc5f7835b55)
#### Thursday 2020-11-12 05:34:45 by Crypto | Seb

Update index.html

Made some big edits. Decided that I didn't want it to be a one-page website (because it looked really ugly). Also decided that the stupid circular corner menu I had was terrible and got rid of it. It has been replaced with a munch nicer menu that fits the theme better. I'm now trying to add some SVG Social Icons into the footer and have them link to my accounts. It's not going well, haha. I've given up for tonight.

---
## [CluckeyMcCormick/fictional-guacamole](https://github.com/CluckeyMcCormick/fictional-guacamole)@[7e20770fb0...](https://github.com/CluckeyMcCormick/fictional-guacamole/commit/7e20770fb0f53a3673965f051c6ced003f972d4a)
#### Thursday 2020-11-12 05:34:57 by frick-nedrickson

Build and change a NavigationMesh on the fly

This game/prototype is a city builder. It was a critical lynchpin,
then, that we be able to add terrain or delete terrain from the scene
and have the NavigationMesh update appropriately.

This is not possible in vanilla Godot 3.2.3. However, with the Godot
Navigation Lite plugin, it's possible to do EXACTLY this!

To test out this capability, I've added a new test scene:
DynamicNavMeshTest. This scene is almost a duplicate of
PawnPathingTest, but features controls for adding and removing
buildings on the fly (and a different building cycle). Whenever a
building is added or deleted, we rebake the DetourNavigationMesh.

We'll need to keep an eye on that as time goes on. If we end up with
a big map, there might be a big performance impact for adding a new
building. Or maybe there won't be? Hard to say...

Also, I tweaked House and Hut - rather than the "hiding corners" being
given in cardinals (i.e Northwest, Southeast), they are now given in
relative directional positions - i.e. Back Right, Front Left. I did
this since I was GENUINELY having a lot of trouble deducing what the
values actually meant (since I tend to use North-South as a reference
for camera movement).

I also reduced the Hut's cartoonishly tall roof. It was funny but it
was getting in the way of testing.

---
## [ToxxyTheTrash/SimplyDarkFuchsiaDarkness](https://github.com/ToxxyTheTrash/SimplyDarkFuchsiaDarkness)@[d30f823202...](https://github.com/ToxxyTheTrash/SimplyDarkFuchsiaDarkness/commit/d30f823202ca0b72c014f64e5e8028fe1465cad5)
#### Thursday 2020-11-12 06:56:35 by ToxxyTheTrash

goddamn channel structure change

fuck yourself discord fucking sick of your useless class changes

---
## [Dmitriy-Lunyov-2004/BaseWindow](https://github.com/Dmitriy-Lunyov-2004/BaseWindow)@[decfb2584b...](https://github.com/Dmitriy-Lunyov-2004/BaseWindow/commit/decfb2584b97bbd413faa41da441cbfb8aa988b2)
#### Thursday 2020-11-12 10:13:07 by Dmitriy_Lunyov_2004

Some commit

I don't no what I've done !!! fuck you !!!

---
## [tannerhelland/PhotoDemon](https://github.com/tannerhelland/PhotoDemon)@[c9a960189d...](https://github.com/tannerhelland/PhotoDemon/commit/c9a960189d7eef09923ec1f9c7d99ee5a5fb4f71)
#### Thursday 2020-11-12 14:29:45 by Tanner

Improve startup performance on Win 10 (?)

For some time, I've had random sessions where PD takes an inordinantly long time to show its splash screen.  After a particularly bad bout immediately following the latest Win 10 feature update, I broke down and did some profiling.

The culprit?  GdipCreateFontFamilyFromName!  This is the first function call (in a chain of calls) required to set up a GDI+ font.  I have no idea why its performance is so variable, but I just had the idea to "cheat" and simply create a GDI font, then use a different GDI+ pattern to initialize a GDI+ front from a GDI DC with a GDI font already selected into it.  (A GDI+ font is required because we're painting onto a 32-bpp surface with variable transparency.  Antialiasing under GDI is unreliable on 32-bpp targets with non-solid alpha channels.)

Performance went from an average of several hundred ms for the original function, to < 10 ms for the new one, despite it being way more involved and requiring interop between GDI and GDI+!

Oh well.  If decades of Windows development have taught me anything, it's to never assume the shorter approach is also the faster one.

I don't know if any other users have experienced this issue, but I'm getting much more reliable (and shorter!) startup times after this change, so hopefully others will benefit too.

---
## [Rivaldosetiawan135/git-scm.com](https://github.com/Rivaldosetiawan135/git-scm.com)@[849b1c410e...](https://github.com/Rivaldosetiawan135/git-scm.com/commit/849b1c410e72ae7376d320ab7d7c4620cfe3f795)
#### Thursday 2020-11-12 15:14:01 by Rivaldosetiawan135

ARCHITECTURE.md.arc

# git-scm.com architecture

This document describes the general setup and architecture that runs the
git-scm.com site. The idea is to document all the moving parts that
_aren't_ checked in to this repository. That may help new people joining
the project to help out, as well provide some continuity in case the
maintainer is hit by a bus.

## Content

Though the site is a rails app, it can _mostly_ be thought of a serving
static content. It's just that we suck in that static content and
pre-process it using nightly scheduled jobs. We never write anything to
the database on behalf of user requests.

The content is a mix of:

  - actual static content in this repository

  - community book content brought in from https://github.com/progit;
    see the `lib/tasks/book2.rake` file.

  - manpages from releases of the git project, imported and formatted
    via asciidoctor; see the `lib/tasks/index.rake` task.


## Heroku

The app itself is served by Heroku. The app name is `git-scm` (so you
can visit it directly as https://git-scm.herokuapp.com). The site is
owned by the git-scm.com team. If you want to be involved in managing
uptime/deploys/etc, you'll need a Heroku account and request to be added
to that team. The git-scm team receives credits from Heroku so that the
hosting is free.

We use a few Heroku add-ons:

  - Bonsai elasticsearch (see below)

  - Heroku Postgres as the database

  - Heroku Redis for rails caching

  - Heroku scheduler for cron jobs

The nightly scheduled jobs are:

  - `rake downloads` (pick up newly released git versions)

  - `rake preindex` (pull in and format manpages for released git
    versions)

  - `rake remote_genbook2` (pull in and format progit2 book content,
    including translations)

It should be safe to run any of those jobs more frequently. E.g., if you
know there's a new Git release out, then:

    heroku run rake preindex
    heroku run rake downloads

will get it on the site without waiting for the nightly run.

Merges to the `master` branch on GitHub auto-deploy to Heroku, so unless
you're doing something tricky you generally shouldn't need to manually
deploy.

Note that some of the formatting of manpages and book content happens
when they are imported by the rake tasks. So after fixing some
formatting and deploying, the rake jobs may need to be re-run with a
special flag to re-import (see the individual tasks for details).


## Cloudflare

We get enough requests that it's easy to overwhelm the single Heroku
dyno. So we have Cloudflare sitting in front of it, aggressively caching
everything. That also should make the site faster to serve to regions
far away from Heroku's servers.

The Cloudflare setup is mostly pretty simple:

 - they serve DNS for the whole domain (that's where they insert the CDN
   magic)

 - Cloudflare provides `https://` support to the user. Obviously the
   site is totally open and doesn't have any sensitive data, so this is
   really more about integrity. The certificate is generated by
   Cloudflare (and requires SNI on the browser side).

 - the Cloudflare connection to Heroku is passed over TLS; they provide an
   "internal" certificate that we ask Heroku to use, so the connection
   is secured between the two (again, mostly for integrity)

 - the most exotic config is that we use "page rules" to mark the whole
   site to be cached aggressively, regardless of any caching headers
   sent from Heroku. This is a bit of a hack, but there's very little on
   the site that can't be cached (which is perhaps a sign that the rails
   setup needs to be tweaked to send more reasonable caching headers,
   but this has been simple and effective so far).

   There are a few special page rules to lift this caching for cases
   where we do server-side logic (e.g.,
   https://github.com/git/git-scm.com/issues/1129#issuecomment-363067019"),
   but the long-term goal is to push that logic onto the client side as
   much as possible.

Both domains (c.f., the section on [DNS](#DNS) below) are owned by a
Cloudflare "Team", and membership of that team is required to
administrate the domains. Similar to the Heroku setup, you can ask to
join this team if you wish to help out. The information about the team
setup is in escrow with the Git PLC at Software Freedom Conservancy.
Cloudflare provides the project with enough credits that it doesn't cost
anything (though we're not using very many features, so it's possible
that a free account would be sufficient, too).

## Bonsai Elasticsearch

The search functionality on the site is served by an elasticsearch
cluster. The index can be populated by running `rake search_index`
(manpages) and `rake search_index_book` (book) on Heroku (we only index
the manpages and book). This perhaps should be run nightly, or at least
after pulling in new content, but it currently isn't done automatically.

The elasticsearch cluster is provided by Bonsai via their Heroku plugin.
Our needs are larger than their free tier provides, but we receive
credits from them that provide the service for free.


## DNS

The actual DNS service is provided by Cloudflare (see above). The domain
itself is registered with Gandi, and is owned by the project via
Software Freedom Conservancy. Funds for the registration are provided
from the Git project's Conservancy funds, and both the Git PLC and
Conservancy have credentials to modify the setup.

Note that we own both git-scm.com and git-scm.org; the latter redirects
to the former.


## Manual Intervention

The site mostly just runs without intervention:

  - code merged to `master` is auto-deployed

  - new git versions are detected daily and manpages and download links
    updated

  - book updates (including translations) are picked up daily

There are a few tasks that still need to be handled by a human:

  - new images added to the book have to be copied manually from
    progit/progit2

  - new languages for book translations need to be added to
    `lib/tasks/book2.rake`

  - forced re-imports of content (e.g., a formatting fix to imported
    manpages) must be triggered manually
   -arc

---
## [DavidTheMe/Repository](https://github.com/DavidTheMe/Repository)@[cb6de2b261...](https://github.com/DavidTheMe/Repository/commit/cb6de2b26130f4e3732dafd1802e3a3e6ac58307)
#### Thursday 2020-11-12 15:21:29 by DavidTheMe

fuck you covid!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

---
## [m-ou-se/rust](https://github.com/m-ou-se/rust)@[a3b0c14ca9...](https://github.com/m-ou-se/rust/commit/a3b0c14ca92c7834598832c4a8583f93933e2845)
#### Thursday 2020-11-12 16:06:26 by Mara Bos

Rollup merge of #78950 - khyperia:spirv-asm, r=Amanieu

Add asm register information for SPIR-V

As discussed in [zulip](https://rust-lang.zulipchat.com/#narrow/stream/182449-t-compiler.2Fhelp/topic/Defining.20asm!.20for.20new.20architecture), we at [rust-gpu](https://github.com/EmbarkStudios/rust-gpu) would like to support `asm!` for our SPIR-V backend. However, we cannot do so purely without frontend support: [this match](https://github.com/rust-lang/rust/blob/d4ea0b3e46a0303d5802b632e88ba1ba84d9d16f/compiler/rustc_target/src/asm/mod.rs#L185) fails and so `asm!` is not supported ([error reported here](https://github.com/rust-lang/rust/blob/d4ea0b3e46a0303d5802b632e88ba1ba84d9d16f/compiler/rustc_ast_lowering/src/expr.rs#L1095)). To resolve this, we need to stub out register information for SPIR-V to support getting the `asm!` content all the way to [`AsmBuilderMethods::codegen_inline_asm`](https://doc.rust-lang.org/nightly/nightly-rustc/rustc_codegen_ssa/traits/trait.AsmBuilderMethods.html#tymethod.codegen_inline_asm), at which point the rust-gpu backend can do all the parsing and codegen that is needed.

This is a pretty weird PR - adding support for a backend that isn't in-tree feels pretty gross to me, but I don't see an easy way around this. `@Amanieu` said I should submit it anyway, so, here we are! Let me know if this needs to go through a more formal process (MCP?) and what I should do to help this along.

I based this off the [wasm asm PR](https://github.com/rust-lang/rust/pull/78684), which unfortunately this PR conflicts with that one quite a bit, sorry for any merge conflict pain :(

---

Some open questions:

- What do we call the register class? Some context, SPIR-V is an SSA-based IR, there are "instructions" that create IDs (referred to as `<id>` in the spec), which can be referenced by other instructions. So, `reg` isn't exactly accurate, they're SSA IDs, not re-assignable registers.
- What happens when a SPIR-V register gets to the LLVM backend? Right now it's a `bug!`, but should that be a `sess.fatal()`? I'm not sure if it's even possible to reach that point, maybe there's a check that prevents the `spirv` target from even reaching that codepath.

---
## [hipe/downtownfun](https://github.com/hipe/downtownfun)@[f9a390ef75...](https://github.com/hipe/downtownfun/commit/f9a390ef75f59073a4eaff8792e8f21506a950ed)
#### Thursday 2020-11-12 17:25:28 by Mark Meves

refactor: no more RECEIVE_DIFF_LINES hack ((1375))

Discussion: When we originally constructed our API for the result
signatures of our three canonic edit functions (update, create, delete),
we did so with a KISS-ism that now, with the benefit of hindsight, seems
to have been a bit overzealous:

the three canonic edit functions (update, create, delete) produced
results consisting directly of the entities they involved:

For CREATE, the result was the created entity; for DELETE, the result
was the deleted entity; and for UPDATE the result was at two-tuple
of the “before” and “after” entity.

This convention met our requirements at the time and hummed along nicely
for a few years. But trouble brewed when we started trying to simplify
and unify things around single-file collections: It became more and more
convenient to want there to be a *returned* patch file representing the
change to make.

Up until now, we had a hackish work-around as a way of getting the diff
lines back from the storage adapter: they called a callback that was
attached to the `opn` function (something that itself is on the chopping
block for being too hacky).

Our newest solution is that the result value from these three functions
is a *custom structure* that has fields for the participating entities
AND things like the diff lines (if it’s a single-file format).

There are by-products of this change that we expected to see more of in
this commit that we aren’t seeing. (Where do patches get applied in
production? Do they?)

There is also a tension that is introduced: we want the diff lines to
be accessible for testing, but “in production” we want them to
“just work”. In a subsequent commit we’ll try to confront this tension
with approaches like using the “shell/kernel” architecture some of which
still remains in our SA architecture…

Other disjoint comments/observations:
- Our only real life workhorse directory-based storage adapter (eno)
  is insulated from a lot of this change because it doesn’t even
  implement two of the three canonic edit functions - it gets it work
  done mostly thru the more sophisticated and modern “batch update”
  function…
- An asymmetry is discovered where some of the CUD implementations
  bundle their own “emit edited” emitter and others don’t

(times)
  11-11 09:20  refactor for the patch thing
        11:25  zz
        13:00  wake & resume
        15:38  break for run then zumba
  11-12 03:00  try again: what am i doing
        06:28  all green!?. zz shortly after
        12:22  now
.

---
## [m-ou-se/rust](https://github.com/m-ou-se/rust)@[76fa5f25ab...](https://github.com/m-ou-se/rust/commit/76fa5f25abc02d1e3d97c105a24ecaed619deaf6)
#### Thursday 2020-11-12 18:46:17 by Mara Bos

Rollup merge of #78950 - khyperia:spirv-asm, r=Amanieu

Add asm register information for SPIR-V

As discussed in [zulip](https://rust-lang.zulipchat.com/#narrow/stream/182449-t-compiler.2Fhelp/topic/Defining.20asm!.20for.20new.20architecture), we at [rust-gpu](https://github.com/EmbarkStudios/rust-gpu) would like to support `asm!` for our SPIR-V backend. However, we cannot do so purely without frontend support: [this match](https://github.com/rust-lang/rust/blob/d4ea0b3e46a0303d5802b632e88ba1ba84d9d16f/compiler/rustc_target/src/asm/mod.rs#L185) fails and so `asm!` is not supported ([error reported here](https://github.com/rust-lang/rust/blob/d4ea0b3e46a0303d5802b632e88ba1ba84d9d16f/compiler/rustc_ast_lowering/src/expr.rs#L1095)). To resolve this, we need to stub out register information for SPIR-V to support getting the `asm!` content all the way to [`AsmBuilderMethods::codegen_inline_asm`](https://doc.rust-lang.org/nightly/nightly-rustc/rustc_codegen_ssa/traits/trait.AsmBuilderMethods.html#tymethod.codegen_inline_asm), at which point the rust-gpu backend can do all the parsing and codegen that is needed.

This is a pretty weird PR - adding support for a backend that isn't in-tree feels pretty gross to me, but I don't see an easy way around this. ``@Amanieu`` said I should submit it anyway, so, here we are! Let me know if this needs to go through a more formal process (MCP?) and what I should do to help this along.

I based this off the [wasm asm PR](https://github.com/rust-lang/rust/pull/78684), which unfortunately this PR conflicts with that one quite a bit, sorry for any merge conflict pain :(

---

Some open questions:

- What do we call the register class? Some context, SPIR-V is an SSA-based IR, there are "instructions" that create IDs (referred to as `<id>` in the spec), which can be referenced by other instructions. So, `reg` isn't exactly accurate, they're SSA IDs, not re-assignable registers.
- What happens when a SPIR-V register gets to the LLVM backend? Right now it's a `bug!`, but should that be a `sess.fatal()`? I'm not sure if it's even possible to reach that point, maybe there's a check that prevents the `spirv` target from even reaching that codepath.

---
## [Alanii/NewHestia](https://github.com/Alanii/NewHestia)@[d335f16eea...](https://github.com/Alanii/NewHestia/commit/d335f16eea44c135ca67e3e02e83aadfa852af2a)
#### Thursday 2020-11-12 20:30:52 by bearrrrrrrr

fixes RCD door having wrong access in CE room (#267)

* fixes RCD door having wrong access in CE room

* fuck you travis

---
## [cockroachdb/cockroach](https://github.com/cockroachdb/cockroach)@[b10b4d7121...](https://github.com/cockroachdb/cockroach/commit/b10b4d71218be5d59b9b7207a02d422b788ff244)
#### Thursday 2020-11-12 20:34:17 by craig[bot]

Merge #56373 #56437 #56533

56373: hlc: introduce synthetic flag on timestamps r=nvanbenschoten a=nvanbenschoten

Informs #52745.
Informs #36431.

This commit introduces an 8-bit `flags` field on the hlc timestamp struct. The flags are used to provide details about the timestamp and its meaning. They do not affect the sort order of Timestamps.

The commit then introduces the first flag: SYNTHETIC. As discussed in #52745, a synthetic timestamp is defined as a timestamp that makes no claim about the value of clocks in the system. While standard timestamps are pulled from HLC clocks and indicate that some node in the system has a clock with a reading equal to or above its value, a synthetic timestamp makes no such indication. By avoiding a connection to "real time", synthetic timestamps can be used to write values at a future time and to indicate that observed timestamps do not apply to such writes for the purposes of tracking causality between the write and its observers. Observed timestamps will be a critical part of implementing non-blocking transactions (#52745) and fixing the interaction between observed timestamps and transaction refreshing (#36431).

The original plan was to reserve the high-order bit in the logical portion of a timestamp as a "synthetic bit". This is how I began implementing things, but was turned off for a few reasons. First, it was fairly subtle and seemed too easy to get wrong. Using a separate field is more explicit and avoids a class of bugs. Second, I began to have serious concerns about how the synthetic bit would impact timestamp ordering. Every timestamp comparison would need to mask out the bit or risk being incorrect. This was even true of the LSM custom comparator. This seemed difficult to get right and seemed particularly concerning since we're planning on marking only some of a transaction's committed values as synthetic to fix #36431, so if we weren't careful, we could get atomicity violations. There were also minor backwards compatibility concerns.

But a separate field is more expensive in theory, so we need to be careful. However, it turns out that a separate field is mostly free in each case that we care about. In memory, the separate field is effectively free because the Timestamp struct was previously 12 bytes but was always padded out to 16 bytes when included as a field in any other struct. This means that the flags field is replacing existing padding. Over the wire, the field will not be included when zero and will use a varint encoding when not zero, so again, it is mostly free. In the engine key encoding, the field is also not included when zero, and takes up only 1 byte when non-zero, so it is mostly free.

----

First three commits from #56477.

@sumeerbhola I'm hoping you can take a look at the engine-level changes in the `introduce synthetic flag on timestamps` commit (4th commit as of the time of writing). I think the key encoding added here makes sense, but want to make sure you're on board. One possible concern is that we introduce a new 13-byte suffix, which means that combined with a 4-byte sequence number (see https://github.com/cockroachdb/cockroach/issues/41720#issuecomment-548780872), we'd collide with the 17 byte `engineKeyVersionLockTableLen`.

@tbg do you mind being the primary reviewer here? I think you know the most about the motivations for this change and will have a good sense of whether this is the best way to introduce additional state on timestamps.

56437: cli, ui: dismiss release notes signup banner per environment variable r=knz,dhartunian a=nkodali

Previously, the signup banner could only be dismissed manually.
For internal testing purposes, this banner is unnecessary. This
change provides a way to dismiss the signup banner upon start of
a cluster via the cli by setting the environment variable
COCKROACH_UI_RELEASE_NOTES_SIGNUP_DISMISSED=true.

Resolves #46998

Release note: none

56533: backupccl: add feature flag support for BACKUP, RESTORE r=otan a=angelapwen

Follow-up to the RFC at #55778. This addresses the SRE use case mentioned in #51643 — instead of moving forward with a global denylist as the RFC indicated, we are prototyping feature flags via cluster settings to turn on/off requested features. The first part of the prototype will be done on `BACKUP` and `RESTORE` commands.

See [this doc](https://docs.google.com/document/d/1nZSdcK7YprL0P4TAuseY-mvlYnd82IaJ_ptAQDoWB6o/edit?) for further details. 

Note that the logic test under `ccl/backupccl/testdata/backup-restore/feature-flags` can be tested with the command `make test PKG=./pkg/ccl/backupccl TESTS='TestBackupRestoreDataDriven'`

— Commit message below — 

Adds a cluster setting to toggle a feature flag for the BACKUP and
RESTORE commands off and on; as well as a broad category for
Bulk IO commands. Currently disabling the cluster setting for Bulk
IO will only disable BACKUP and RESTORE jobs, but other types may
be included in this category in the future..

The feature is being introduced to address a Cockroach Cloud SRE
use case: needing  to disable certain categories of features in
case of cluster failure.

Release note (enterprise change): Adds cluster settings to enable/
disable the BACKUP and RESTORE commands. If a user attempts to use
these features while they are disabled, an error indicating that
the database administrator has disabled the feature is surfaced.

Example usage for the database administrator:
SET CLUSTER SETTING feature.bulkio.backup.enabled = FALSE;
SET CLUSTER SETTING feature.bulkio.backup.enabled = TRUE;
SET CLUSTER SETTING feature.bulkio.restore.enabled = FALSE;
SET CLUSTER SETTING feature.bulkio.restore.enabled = TRUE;
SET CLUSTER SETTING feature.bulkio.enabled = FALSE;
SET CLUSTER SETTING feature.bulkio.enabled = TRUE;

Co-authored-by: Nathan VanBenschoten <nvanbenschoten@gmail.com>
Co-authored-by: Namrata Kodali <namrata@cockroachlabs.com>
Co-authored-by: angelapwen <angelaw@cockroachlabs.com>

---
## [Erlite/glua-net-monitor](https://github.com/Erlite/glua-net-monitor)@[a7c3b3c07c...](https://github.com/Erlite/glua-net-monitor/commit/a7c3b3c07c8f9a95f84e7233e1a8e52ed70a02b0)
#### Thursday 2020-11-12 21:03:27 by Erlite

Add support for deprecated umsg library (fuck you)

---
## [jpmorganchase/modular](https://github.com/jpmorganchase/modular)@[1b34e70e28...](https://github.com/jpmorganchase/modular/commit/1b34e70e2848b73641f3d3efd48e5d541f633667)
#### Thursday 2020-11-12 22:03:13 by Sunil Pai

refactor: update dependencies + self host repository. (#132)

* refactor

This PR is a refactor of the codebase, but without changing (much) functionality. It may seem like a lot, but that's exaggerated by the fact that a lot of it is just moved round. Here are the details - 

- This updates `react-scripts`/`@craco/craco` to support `create-react-app@4.0.0`. As part of that, I've also disabled the in-browser linting experience (https://github.com/gsoft-inc/craco/issues/205). *This is temporary*. I'll enable it when it's fixed on craco's side, but that shouldn't block this PR. This should fix https://github.com/jpmorganchase/modular/issues/125. 
- The refactor is mainly around making this repository self-hosted (https://github.com/jpmorganchase/modular/issues/120). The steps taken to achieve that were: 
  - e2e-tests were split up and inlined into `modular-scripts` / `create-modular-react-app`, as applicable. This also enabled removing verdaccio and associated complexity.
  - `cra-template-modular-typescript` was inlined into `modular-scripts`; this has the benfit of preventing one waterfall step when adding a new app to a project. 
  - We had a bug where we needed at least one app named `app` for all tests to run, I fixed that. We still need at least one app, but it can be named whatever. (I've named it `modular-site`, and we can use it for experiments, and maybe hosting documentation). In the future we dhsould fix it so it doesn't need any at all, but that's an edge case. 
- I've removed `modular-scripts/src/getModularViewMap`, and will instead implement `modular-views.macro` (https://github.com/jpmorganchase/modular/issues/59). I'm working on it right now, but it shouldn't block this PR. 

### caveats 

- I need to implement and write tests for the views macro, as mentioned above. 
- While this runs all tests on CI, it skips one test, the one that starts up a server and tests whether the app works as expected. This is because it still leaves hanging processes, and will eat up our github-actions minutes. Working on fixing it, it's a weird one. (probably related to https://github.com/jpmorganchase/modular/issues/54)
- I haven't verified builds yet, will do so. (EDIT: done, looks fine)
- I need to simplify the root configurations for babel/eslint so that it uses the `modular` configs. It's not critical to this PR so I figured it could wait. 
- all tests take about 550s on my 2015 macbook pro. That kinda sucks. A lot of the time is literally just fetching dependencies and installing. We should setup caches for our build, and further use cached versions of dependencies when installing. This is less of a problem now that the repo is public, but still. (EDIT: now under 4 minutes, not bad.)

---

# [<](2020-11-11.md) 2020-11-12 [>](2020-11-13.md)

