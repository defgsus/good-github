# [<](2020-11-12.md) 2020-11-13 [>](2020-11-14.md)

182,595 events, 98,795 push events, 150,383 commit messages, 11,036,262 characters


## [zopac/freemanatee-client](https://github.com/zopac/freemanatee-client)@[a5a7c4f8bf...](https://github.com/zopac/freemanatee-client/commit/a5a7c4f8bf7cb47d1acc1096a1edd781f2c49145)
#### Friday 2020-11-13 22:17:21 by yeah

remove the hwid fuck you im tired of getting dms

die

---
## [chrisbobbe/zulip-mobile](https://github.com/chrisbobbe/zulip-mobile)@[2691ed6de4...](https://github.com/chrisbobbe/zulip-mobile/commit/2691ed6de425e42146f65b5d61cc08f3298eac51)
#### Friday 2020-11-13 22:18:48 by Greg Price

outbox [nfc]: Send based on `display_recipient`, not `narrow`.

This was the last place we were using the `narrow` property on
outbox messages, so taking it out will mean we can remove that
property in the next commit.  Which is good because (a) the `Narrow`
type is a great big mess, and the fewer different parts of the code
are using it, the fewer need to be migrated to a cleaned-up version
of it; and (b) it was never an appropriate type to use to describe a
single message's destination.

I don't love the "display recipient" values either, but their
structure is at least less wild than Narrow, and their semantic
range is an appropriate match for "where this individual message
is sent".  And whenever we decide it's that type's turn to get
straightened out, this usage should fit in nicely to be swept up
with all the others, because it comes right after a check of the
display_recipient's friend the `type: 'stream' | 'private'` field.

This commit makes a small change in the data we send to the server
for sending a PM:
 * The old code would leave out the self user, except on self-PMs.
 * This new code will always include the self user.

Both conventions are found in different areas of the server and
webapp.  The new one here matches the display_recipient the server
sends on PMs, and is simpler.  In any event the server doesn't
care, and that's a deliberate API choice: we want to be sure to
make easy things easy when writing bots, and allowing a range of
natural ways to say who to send a message to is a key part of that.

Concretely in the server implementation, since earliest times it
drops dupes and does its own normalization whether to include the
sender, so it's essentially always lived up to that plan.  The
relevant logic lives today (as of zulip/zulip@620e9cbf7) in the
function get_recipient_from_user_profiles; and though it's moved
around and been refactored, its logic is essentially unchanged since
zulip/zulip@f851d9437, in 2012 a few months after Zulip began.

---
## [pankajerma/UsBoomBikes](https://github.com/pankajerma/UsBoomBikes)@[82029de287...](https://github.com/pankajerma/UsBoomBikes/commit/82029de28752c1dc95c3b92e4e4c210129d482b4)
#### Friday 2020-11-13 22:24:52 by pankaj verma

Add files via upload

Assignment-based Subjective Questions:
1.From your analysis of the categorical variables from the dataset, what could you infer about their effect on the dependent variable?
Answer: The plots above shows the relationship between categorical variables and a Target variable.
• Bike Rentals are more during the Fall season and then in summer
• Bike Rentals are more in the year 2019 compared to 2018
• Bike Rentals are more in partly cloudy weather
• Bike Rentals are more on Saturday,wednesday and thursday
2.Why is it important to use drop_first=True during dummy variable creation? Answer:
3.Looking at the pair-plot among the numerical variables, which one has the highest correlation with the target variable?
Answer: Bike rentals are more correlated to temperature.
4. How did you validate the assumptions of Linear Regression after building the model on the training set?
Answer: We arrived at a very decent model for the the demand for shared bikes with the significant variables. We can see that temperature variable is having the highest coefficient 0.4914, which means if the temperature increases by one unit the number of bike rentals increases by 0.4914 units.Similary we can see coefficients of other variables in the equation for best fitted line.We also see there are some variables with negative coefficients, A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease. We have spring, mist cloudy , light snow variables with negative coefficient. The coefficient value signifies how much the mean of the dependent variable changes given a one- unit shift in the independent variable while holding other variables in the model constant.¶
 more dummy features make it harder for the algorithm to fit or even worse make it
 easier to overfit. To avoid over fitting of the model and to avoid the redundant values.

5. Based on the final model, which are the top 3 features contributing significantly towards explaining the demand of the shared bikes?
Answer: A US bike-sharing provider BoomBikes can focus more on Temperature
We can see demand for bikes was more in 2019 than 2018, so just focus as there is increase in 2019 and might be facing dips in their revenues due to the ongoing Corona pandemic and by the time it reduces the things will be better. Can focus more on Summer & Winter season, August, September month, Weekends, Working days as they have good influence on bike rentals. We can see spring season has negative coefficients and negatively correlated to bike rentals. So we can give some offers there to increase the demand Now seeing to weathers it variable, we have got negative coefficients for Mist +cloudy and Lights now weather... And yes we can give offers
General Subjective Questions: 1.Explain the linear regression algorithm in detail.
 Answer: Linear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting. Different regression models differ based on – the kind of relationship between dependent and independent variables, they are considering and the number of independent variables being

 used.
 Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x). So, this regression technique finds out a linear relationship between x (input) and y(output). Hence, the name is Linear Regression.
In the figure above, X (input) is the work experience and Y (output) is the salary of a person. The regression line is the best fit line for our model.
Hypothesis function for Linear Regression :
 2.Explain the Anscombe’s quartet in detail.
Answer: Statistics have long been used to describe data in general terms. For example, things like variance and standard deviation allow us to understand how much variation there was in some data without having to look at every data point individually. They give us a rough idea as to how consistent data is. However, knowing variance alone does not give you the full picture as to what the data truly is in its native form. Statistics are great for describing general trends and aspects of data, but statistics alone can't fully depict any data set. Francis Anscombe realized this in 1973 and created several data sets, all with several identical statistical properties, to illustrate it. These data sets, collectively known as “Anscombe's Quartet

3.What is Pearson’s R?
Answer: Correlation is a technique for investigating the relationship between two quantitative, continuous variables, for example, age and blood pressure. Pearson's correlation coefficient (r) is a measure of the strength of the association between the two variables. The first step in studying the relationship between two continuous variables is to draw a scatter plot of the variables to check for linearity. The correlation coefficient should not be calculated if the relationship is not linear. For correlation only purposes, it does not really matter on which axis the variables are plotted. However, conventionally, the independent (or explanatory) variable is plotted on the x-axis (horizontally) and the dependent (or response) variable is plotted on the y- axis (vertically).The nearer the scatter of points is to a straight line, the higher the strength of association between the variables. Also, it does not matter what measurement units are used.
4. What is scaling? Why is scaling performed? What is the difference between normalized scaling and standardized scaling?
Answer
Normalization is good to use when you know that the distribution of your data does not follow a Gaussian distribution. This can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors and Neural Networks. Standardization, on the other hand, can be helpful in cases where the data follows a Gaussian distribution. However, this does not have to be necessarily true. Also, unlike normalization, standardization does not have a bounding range. So, even if you have
outliers in your data, they will not be affected by standardization.
5.You might have observed that sometimes the value of VIF is infinite. Why does this
happen? Answer
 : It is a step of Data Pre Processing which is applied to independent variables or features
 of data. It basically helps to normalize the data within a particular range. Sometimes, it also
 helps in speeding up the calculations in an algorithm.
 : VIF is an index that provides a measure of how much the variance of an estimated
 regression coefficient increases due to collinearity. In order to determine VIF, we fit a
 regression model between the independent variables. A large value of VIF indicates that there
 is a correlation between the variables. If the VIF is 4, this means that the variance of the model
 coefficient is inflated by a factor of 4 due to the presence of multicollinearity. This would mean
 that that standard error of this coefficient is inflated by a factor of 2 (square root of variance is
 the standard deviation). The standard error of the coefficient determines the confidence
 interval of the model coefficients. If the standard error is large, then the confidence intervals

 may be large, and the model coefficient may come out to be non-significant due to the
 presence of multicollinearity. A general rule of thumb is that if VIF > 10 then there is
 multicollinearity. Note that this is a rough rule of thumb, in some cases we might choose to live
 with high VIF values if it does not affect our model results such as when we are fitting a
 quadratic or cubic model or depending on the sample size a large value of VIF may not
 necessarily indicate a poor model.
6.What is a Q-Q plot? Explain the use and importance of a Q-Q plot in linear regression?
Answer:As the name suggests, the Q-Q plot is a graphical plotting of the quantiles of two distributions with respect to each other. In other words, you plot quantiles against quantiles.Whenever you interpret a Q-Q plot, you should concentrate on the ‘y = x’ line. You also call it the 45-degree line in statistics. It entails that each of your distributions has the same quantiles. In case you witness a deviation from this line, one of the distributions could be skewed when compared to the other.

---

# [<](2020-11-12.md) 2020-11-13 [>](2020-11-14.md)

