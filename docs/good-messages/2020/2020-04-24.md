# [<](2020-04-23.md) 2020-04-24 [>](2020-04-25.md)

2,506,498 events, 1,283,985 push events, 2,061,145 commit messages, 153,204,808 characters


## [iampatterson/skDooley](https://github.com/iampatterson/skDooley)@[6ac8ee283e...](https://github.com/iampatterson/skDooley/commit/6ac8ee283e42d183324ec348352b7b4002244015)
#### Friday 2020-04-24 00:08:54 by Michael Patterson

Add files via upload

This is the baseline code that I used.  It is kinda ugly but it works ok for me.  I hope that this helps.  Please reach out if you have any questions.  I took the idea from this website. 

https://towardsdatascience.com/bring-your-jupyter-notebook-to-life-with-interactive-widgets-bc12e03f0916

---
## [DareCarrington/myPrograms](https://github.com/DareCarrington/myPrograms)@[d83e4bba30...](https://github.com/DareCarrington/myPrograms/commit/d83e4bba30fc5e1ced1d99eaa80454ee445aa91f)
#### Friday 2020-04-24 00:26:40 by DareCarrington

Add files via upload

first program i made in python, was made for my girlfriend of 3-1/2 years. Hope she loves it! Program was inspired by the file named life moto.

---
## [OJ/metasploit-payloads](https://github.com/OJ/metasploit-payloads)@[3fd732f373...](https://github.com/OJ/metasploit-payloads/commit/3fd732f373fa9bfc2f8bc988f58a71e82bdc6d36)
#### Friday 2020-04-24 02:32:41 by OJ

Fix mimikatz to build clean again

I am sad. Like.. really sad. I'm sad for so many reasons. For nearly
7 years I've worked on this god forsaken source, and for many of those
7 years I have had the ext_server_mimikatz project configured to have
warning level 3, and warnings as errors. While making changes to the
build systems in the last week or so, I've even rebuilt this on updated
toolsets on multiple platforms.

Despite all this, one thing slipped through the cracks. I have NO idea
why this warning wasn't shown in th past. Also.. how did this ever
work!? Why is it that it's only rearing its ugly head now? I honestly
don't know. Based on the code that I've had to fix in this PR, there's
no reason why this should build without warnings on any machine. Yet, it
does. It builds clean on my Windows 10 desktop with VS2013/2017/2019.
Same on most of my other virtual machines. For some reason it only
failed on this one VM after I had to fight to reproduce it when Brent
hand an issue.

The issue here was that a `string` type was being constructed from an
iterator over a `wstring` type, and hence there was an implicit
character conversion from `wchar_t` to `char`. This SHOULD be a warning,
because clearly that's not a good thing. BUT HERE WE ARE.

Anyway, we're proxying via the `_bstr_t` type now to avoid having to do
horrible manual character conversions. Given that we're in C++ land
already there's no point in working any harder. Also, this extension is
probably going to go away soon anyway, so a temporary fix that does the
job is good enough.

RIP my morning. I won't be getting that back.

---
## [stevemanion/nz-covid19-travel-data](https://github.com/stevemanion/nz-covid19-travel-data)@[1a44ac1fae...](https://github.com/stevemanion/nz-covid19-travel-data/commit/1a44ac1fae508f055d6ba7216a1069647d3de07c)
#### Friday 2020-04-24 03:16:49 by stevemanion

Added lists for New Zealand female and male first names (1,564 and 1,172 respectively). The intention is to use these names as easy to remember alias ids that are unique, so when discussing a particular case it can be refered to by a human name (easier than numbers/codes). These two lists have been placed in a folder called meta, which should be used to store data that has been prepared in advance for input into other data generation scripts (such as a name id assigning script). How they are to be assigned is yet to be decided, however if there is a concern there is not enough (since there are only 2,736), aspects like DHB could also be concatenated - e.g. Jim-AK or Jim-BP (Jim from Auckland and Jim from Bay of Plenty).

The two lists were derived from the 'Baby Name Popularity Over Time' list from the NZ Department of Internal Affairs, which is a list of common New Zealand names registered at birth dating back to the 1900s to now. The list was separated into two lists by gender, then a distinct and shuffle operation performed. Lastly the license for using this list is a Creative Commons 4.0.

---
## [Slmnj/criterion_kernel_hammerhead](https://github.com/Slmnj/criterion_kernel_hammerhead)@[1e625ee9d8...](https://github.com/Slmnj/criterion_kernel_hammerhead/commit/1e625ee9d804862b8cd376443b1a38a004a90270)
#### Friday 2020-04-24 03:18:51 by Francisco Franco

msm: thermal: work faster with more thrust

Last commit was not enough, it mitigated most of the issues, but some users
were still having weird shits because temperature wasn't going down as fast
as it should. So now queue it every fucking 100ms in a dedicated high prio
workqueue. It's my last stance!

Signed-off-by: Francisco Franco <franciscofranco.1990@gmail.com>

---
## [raspbian-packages/git](https://github.com/raspbian-packages/git)@[7aeb55c24c...](https://github.com/raspbian-packages/git/commit/7aeb55c24c2546d8cfcc3657774e6a061e42129d)
#### Friday 2020-04-24 03:38:55 by Jeff King

credential: refuse to operate when missing host or protocol

The credential helper protocol was designed to be very flexible: the
fields it takes as input are treated as a pattern, and any missing
fields are taken as wildcards. This allows unusual things like:

  echo protocol=https | git credential reject

to delete all stored https credentials (assuming the helpers themselves
treat the input that way). But when helpers are invoked automatically by
Git, this flexibility works against us. If for whatever reason we don't
have a "host" field, then we'd match _any_ host. When you're filling a
credential to send to a remote server, this is almost certainly not what
you want.

Prevent this at the layer that writes to the credential helper. Add a
check to the credential API that the host and protocol are always passed
in, and add an assertion to the credential_write function that speaks
credential helper protocol to be doubly sure.

There are a few ways this can be triggered in practice:

  - the "git credential" command passes along arbitrary credential
    parameters it reads from stdin.

  - until the previous patch, when the host field of a URL is empty, we
    would leave it unset (rather than setting it to the empty string)

  - a URL like "example.com/foo.git" is treated by curl as if "http://"
    was present, but our parser sees it as a non-URL and leaves all
    fields unset

  - the recent fix for URLs with embedded newlines blanks the URL but
    otherwise continues. Rather than having the desired effect of
    looking up no credential at all, many helpers will return _any_
    credential

Our earlier test for an embedded newline didn't catch this because it
only checked that the credential was cleared, but didn't configure an
actual helper. Configuring the "verbatim" helper in the test would show
that it is invoked (it's obviously a silly helper which doesn't look at
its input, but the point is that it shouldn't be run at all). Since
we're switching this case to die(), we don't need to bother with a
helper. We can see the new behavior just by checking that the operation
fails.

We'll add new tests covering partial input as well (these can be
triggered through various means with url-parsing, but it's simpler to
just check them directly, as we know we are covered even if the url
parser changes behavior in the future).

[jn: changed to die() instead of logging and showing a manual
 username/password prompt]

Reported-by: Carlo Arenas <carenas@gmail.com>
Signed-off-by: Jeff King <peff@peff.net>
Signed-off-by: Jonathan Nieder <jrnieder@gmail.com>
(cherry picked from commit 8ba8ed568e2a3b75ee84c49ddffb026fde1a0a91)
Signed-off-by: Jonathan Nieder <jrnieder@gmail.com>

Gbp-Pq: Name 15-CVE-2020-11008-4-credential-refuse-to-operate-when-missing-host-or-pro.patch

---
## [Akkynwa/bootcamp](https://github.com/Akkynwa/bootcamp)@[f0db880d1b...](https://github.com/Akkynwa/bootcamp/commit/f0db880d1b8e568bebf453bf10f0cffba213bf61)
#### Friday 2020-04-24 04:47:34 by Akkynwa

Update book excerpt.txt

<h2>How can I make my camera-work profitable</h2>
<p> What It's All About

<ul>
<li>Whence come the thousands of photographs used every month by newspapers and magazines?</li>

<li>More than that, whence do the photographs come which are used by makers of calendars, postcards, for advertisements, and for illustrating books, stories and articles?</li>
</ul>
---------------------------------</p>
<blockquote>
<p>This little book is a practical, up-to-the-minute answer to the question: <h4>"How can I make my camera-work profitable?"</h4> </p>

<cite>A. H. Beardsley, 
Publisher, Photo-Era Magazine.</cite> </blockqoute>
----------------------------------

<p>At first thought, the answer is,<strong> "From professional photographers and publisher-photo-services." </strong> But professional photographers do not produce one-third of the photographs used, and publisher-photo-services are supplied by that same large number of camerists that supply publications with most of their prints.

No one can deny that the greatest number of prints published are bought from amateur photographers in towns no larger than the average, and sometimes smaller.

The camerist does not have to get in an air-ship and fly to Africa in order to produce photographs that will sell. Read what Waldon Fawcett says, himself a success at selling his photographs:

"The photographer is apt to think that all his ambitions would be realised if only he could journey to foreign shores or to distant corners of our country; or if he could attend the spectacular events that focus the attention of the world now and then. <em>This is a delusion.</em> The real triumph is that of the photographer who utilises the material ready at hand in his own district, be it large or small."[end]

And more, a person does not have to be an expert photographer in order to succeed at the work. Here is what one prominent writer says about it:

"The requirements of the field are well within the capabilities of even the beginner in photography, viz.; the ability to make good negatives and good prints, the ability to recognise news-value, and a methodical plan to find the market where the prints will find acceptance. The man or woman who can meet these requirements should be fairly successful from the beginning, and will open up quickly new avenues of special work and profit."

In short, ability to make metaphors, create lovely heroines or such is not at all necessary to the successful selling of photographs to publications.

Is the field overcrowded? <em>No</em> If there were ten times as many persons engaged in the work they could all keep themselves busy.

The field—how wide is it? Get out your map of the world. The field for <em>making</em> photographs extends from the top margin to the bottom, and from the left to the right. The field for <em>selling</em> photographs—which is more to the point—extends over about five thousand publications which use prints; not to speak of a few score of other markets.

<h3>The markets may be classified briefly:</h3>

<ol>
<li>Newspapers</li>
<li>Magazines</li>
<li>Postcard-makers</li>
<li>Calendar-makers</li>
<li>Art-study producers</li>
<li>Illustrations for books</li>
<li>Illustrations for articles</li>
<li>Prints for advertising.</li>
</ol>

And there are more, of more specialised branches.</p>

<p>And how does it pay? Please note: <em>"A certain magazine once paid $100 for four prints of sundials. An amateur, who happened to be on the spot with a kodak, made over $200 out of a head-on railroad-collision. A New York professional netted $125 from the newspaper-use of a wedding-party, of considerable local prominence, which was leaving the church after the ceremony." One amateur "realised $300 a year for two or three years from a lucky snapshot of eight pet rabbits in a row."

A set of South-Pole photographs brought $3,000 from Leslie's and $1,000 more from the International Feature Service.</em> These all, though, are very exceptional instances. The average print sells for about three dollars. But there is absolutely nothing in the world to hinder a wide-awake person with a camera from making from several hundred to over $3,000 a year from his prints. If he becomes a specialist he may earn as high as $5,000 or even more.

No discrimination is made between press-photographers.<strong>The person wins who <"delivers the goods."</strong></p>

<p> However, I do not mean that the instances of $200 or so for prints should be taken as the prices ordinarily paid. I do not maintain that there is a fortune awaiting the man with the camera; but I do say there are unlimited possibilities for salable photographs and almost an unlimited number of markets for them. But there are not "barrels of money" in it, for all. A person may add appreciably to his income for having sold photographs; and having developed the trade to a high degree, he may cash cheques to the amount of $5,000 or more a year. But not every one. Just some. And it isn't like the log and the falling off it. It's work—hard work—[emphasis]hard work.[end]

Success at selling press-photographs does not depend on the size of the town you live in, the cost or manufacture of your apparatus, or on your literary ability. <em>It depends on you and your worship of the homaged gods of success if you would sell photographs.</em> The gift of these gods is the ability to make good.</p>

--------------------------------------
<h1>An excerpt from the book</h1> <em>"Making Your Camera Pay,</em> <p>" by Frederick C. Davis. Copyright 1922, Robert M. McBride & Company, New York. Full book available online at Project Gutenberg <a href= "https://www.gutenberg.org/files/35709/35709-h/35709-h.htm)" > Gutenberg </a></p>

---
## [peterjtalen/Pokemon_Super_Crystal](https://github.com/peterjtalen/Pokemon_Super_Crystal)@[8b894a82aa...](https://github.com/peterjtalen/Pokemon_Super_Crystal/commit/8b894a82aa7994ef1858a32d250eb7ae5e56f9e8)
#### Friday 2020-04-24 05:23:08 by Peter

removed Lovely Kiss from Poliwag line cuz its actually insanely fucking OP out of this realm

---
## [aws/aws-cdk](https://github.com/aws/aws-cdk)@[9566cca8c7...](https://github.com/aws/aws-cdk/commit/9566cca8c77b99922e8214567b87fa5680fe06ef)
#### Friday 2020-04-24 09:09:27 by Rico Huijbers

fix(cli): can't bootstrap environment not in app

It used to be that if we had an `--app` argument, we would always glob
arguments to `cdk bootstrap <ENV>` through the environments of stacks
in the app.

This makes it super hard/annoying to run `cdk bootstrap
aws://1234/us-somewhere` in a CI/CD project; you have to add a stack
there first and compile before you're allowed to do that, which is
kinda silly.

Change behavior to only glob environment from the environments in the
app if it looks like the user is supplying a glob (if it contains `*`).

If the user is supplying a concrete environment name, just use it
directly.

Also in this commit:

- refactor: lots of places where we were passing around a pair
of `(account, region)`. Replace those by passing a `cxapi.Environment`
instead (most of the changes in this PR).
- refactor: the old and new bootstrapping experience had a lot of
copy/pasta between them. Refactored to make them share code.
- (prerelease) feat: add a version check to the bootstrapping operation,
so that users won't accidentally downgrade a bootstrap stack to an older
version (This happened to 2 devs already, and is an easy mistake to
make. Protect against it.)

---
## [morbidrsa/btrfs-progs](https://github.com/morbidrsa/btrfs-progs)@[c003709191...](https://github.com/morbidrsa/btrfs-progs/commit/c0037091917af0e32e49e90ec4a53748205e2c80)
#### Friday 2020-04-24 09:14:33 by Qu Wenruo

btrfs-progs: print-tree: Use BFS as default traversal method

When debugging tree nodes with higher level, default DFS is not that
reader friendly:

  file tree key (262 ROOT_ITEM 16)
  node 33800192 level 2 items 4 free 117 generation 16 owner 262
  fs uuid 2d66d111-6850-4ca1-ae73-03f50adde41c
  chunk uuid 11141e63-2534-4d04-a0bd-c0531a8f5b88
  	key (256 INODE_ITEM 0) block 33771520 gen 15
  	key (330 EXTENT_DATA 0) block 33325056 gen 11
  	key (438 EXTENT_DATA 0) block 33652736 gen 15
  	key (654 EXTENT_DATA 0) block 33644544 gen 15
  node 33771520 level 1 items 59 free 62 generation 15 owner 256
  fs uuid 2d66d111-6850-4ca1-ae73-03f50adde41c
  chunk uuid 11141e63-2534-4d04-a0bd-c0531a8f5b88
  	key (256 INODE_ITEM 0) block 33787904 gen 15
  	key (256 DIR_ITEM 273597024) block 33124352 gen 9
  	[...]
  leaf 33787904 items 30 free space 1868 generation 15 owner 256
  fs uuid 2d66d111-6850-4ca1-ae73-03f50adde41c
  chunk uuid 11141e63-2534-4d04-a0bd-c0531a8f5b88
  	item 0 key (256 INODE_ITEM 0) itemoff 3835 itemsize 160
  		generation 6 transid 15 size 12954 nbytes 0
  		block group 0 mode 40755 links 1 uid 0 gid 0 rdev 0
  		sequence 528 flags 0x0(none)
  		atime 1565071339.446118888 (2019-08-06 14:02:19)
  		ctime 1565071339.449452222 (2019-08-06 14:02:19)
  		mtime 1565071339.449452222 (2019-08-06 14:02:19)
  		otime 1565071338.89452221 (2019-08-06 14:02:18)
  	item 1 key (256 INODE_REF 256) itemoff 3823 itemsize 12
  		index 0 namelen 2 name: ..
  	item 2 key (256 DIR_ITEM 2487323) itemoff 3781 itemsize 42
  		location key (487 INODE_ITEM 0) type FILE
  		transid 7 data_len 0 name_len 12
  		name: file_reg_115
  	[...]
  leaf 33124352 items 31 free space 1873 generation 9 owner 256
  	[...]

However such DFS will show the leaves before nodes. If tracing things
like drop_progress, we want to see nodes first then leaves.

So change default behavior to BFS to life of developers easier.

This affects 'btrfs inspect-internal dump-tree' output, the traversal
order can be selected by --dfs or --bfs options.

Signed-off-by: Qu Wenruo <wqu@suse.com>
Signed-off-by: David Sterba <dsterba@suse.com>

---
## [jan-warchol/ansible-workstation-setup](https://github.com/jan-warchol/ansible-workstation-setup)@[2cbdeccf56...](https://github.com/jan-warchol/ansible-workstation-setup/commit/2cbdeccf560ea07dacf92687d6ff81c4a4143d4c)
#### Friday 2020-04-24 09:44:36 by Jan Warchoł

Get rid of stupid snap idiotism GRRR

Obnoxious snap insists on polluting my home dir with annoying `snap`
folder: https://bugs.launchpad.net/ubuntu/+source/snapd/+bug/1575053

If that's the case, I'm ditching snap altogether. Be gone from my
machine!

---
## [newstools/2020-news-24](https://github.com/newstools/2020-news-24)@[e395c2e55b...](https://github.com/newstools/2020-news-24/commit/e395c2e55b62fe5001fab04d873f897f43a86e71)
#### Friday 2020-04-24 13:20:52 by NewsTools

Created Text For URL [www.news24.com/SouthAfrica/Life/nurse-strangled-his-doctor-girlfriend-after-thinking-she-gave-him-covid-19-20200403]

---
## [yogstation13/Yogstation](https://github.com/yogstation13/Yogstation)@[bf810f49c2...](https://github.com/yogstation13/Yogstation/commit/bf810f49c28c48835ae1f37acf3bbbb542b22182)
#### Friday 2020-04-24 14:29:55 by monster860

C++ Monstermos - Putting the 99% LAG FREE in 99% LAG FREE (#7981)

* c++ monstermos

fuck

Fixes the server hemorrhaging memory due to extools not decrementing ref counts

Increases defauilt tank pressure

make space cold or some shit

floor tile rips

Fixes code assuming that the heat capacity is nonzero

:facepalm:

Fixes crash

fixes some bugs

fuck *facepalm*

the fastening

removes Del() in favor of an internal c++ hook

Fixes vent-pump math

* Fix the invisible gases bug

* Linux support

* fix the deploy.sh

* Uses newer BYOND 513 because older one is probably missing an important pattern (it segfaulted on pattern search)

* Updates windows dll to match linux version and cleans up unused BYOND code

---
## [fredericd/Koha](https://github.com/fredericd/Koha)@[3e5eb8aacf...](https://github.com/fredericd/Koha/commit/3e5eb8aacf39cab5bac519f9b173ba5a6c34abf3)
#### Friday 2020-04-24 14:31:24 by Jonathan Druart

Bug 24123: Fix import of UTF-8 encoded MARC21 MARCXML using bulkmarcimport (elastic only)

If elastic is used as search engine, the bulkmarcimport.pl will not
handle correctly UTF-8 encoded MARCXML

Koha::SearchEngine::Search->new uses a require statement to load the correct Search module.
This is done l.257 of bulkmarcimport.pl:
  257 my $searcher = Koha::SearchEngine::Search->new

Koha::SearchEngine::Elasticsearch::Search will `use MARC::File::XML`, and so resets the arguments set before:
  216     $MARC::File::XML::_load_args{BinaryEncoding} = 'utf-8';

  220     $MARC::File::XML::_load_args{RecordFormat} = $recordformat;

An easy (but dirty) fix could be to move the declaration of my $searcher before in the script.
The tricky (but correct) fix would be to remove the long standing "ugly hack follows" comment.

This patch is the easy, and dirty, fix

Test plan:
Use the command line tool to import MARXCML records that contains unicode characters into Koha

Something like `misc/migration_tools/bulkmarcimport.pl -biblios -file record.marcxml -m=MARCXML`

Without this patch you will notice that unicode characters will not be displayed correctly

Signed-off-by: Michal Denar <black23@gmail.com>
Signed-off-by: Tomas Cohen Arazi <tomascohen@theke.io>
Signed-off-by: Martin Renvoize <martin.renvoize@ptfs-europe.com>

Signed-off-by: Joy Nelson <joy@bywatersolutions.com>
(cherry picked from commit b11946bc377ec2c6474f9dc2192fda8188c86888)

Signed-off-by: Lucas Gass <lucas@bywatersolutions.com>

---
## [nicholasmartin/documentation](https://github.com/nicholasmartin/documentation)@[2e1e80cbf7...](https://github.com/nicholasmartin/documentation/commit/2e1e80cbf71ea847bf6cf233d0fdbb5bcb853621)
#### Friday 2020-04-24 14:48:20 by Nick Martin

Minor update to running prysm.h install command

Following a chat in Discord as I experienced a slight confusion following the setup guide:

SalohcinToday at 9:53 PM
Hi I'm following this guide https://docs.prylabs.network/docs/install/windows/ and after running the line in step 4, windows comes up with the following:

Starting Prysm beacon-chain --clear-db --min-sync-peers 7
2020/04/24 21:49:18 maxprocs: Leaving GOMAXPROCS=12: CPU quota undefined
time="2020-04-24 21:49:18" level=warning msg="Using default mainnet config" prefix=flags
time="2020-04-24 21:49:18" level=warning msg="This will delete your beacon chain data base stored in your data directory. Your database backups will not be removed - do you want to proceed? (Y/N)" prefix=node
>> n

I tried saying 'Y' but then the installer just exits, but now I tried with 'N' and it continues. Is that weird or am I not getting it?
Installing Prysm on Windows · Prysm 'Topaz' Testnet
Prysm can be installed on Windows systems using the Prysm build script. This page includes instructions for performing this process.

Ocaa/GrumsToday at 9:58 PM
@Salohcin the flag --clear-db shouldn't be in the command. This is only if your beacon chain db is corrupt or after a major update of the prysm client that you'll need to use this flag

SalohcinToday at 9:59 PM
Ah okay, so maybe it shouldn't be in the install guide?

Ocaa/GrumsToday at 9:59 PM
--clear-db will erase the whole sync of your node from the beacon chain, and you don't want to restart the sync from the beginning each time you restart your node

SalohcinToday at 9:59 PM
Yeah that would be a waste :slight_smile:

Ocaa/GrumsToday at 10:00 PM
@Salohcin I think so yeah. That's a mistake in the doc I think @celeste

---
## [brauner/linux](https://github.com/brauner/linux)@[ea6c7fab42...](https://github.com/brauner/linux/commit/ea6c7fab4204d230fcd25f6357024b396c2c9462)
#### Friday 2020-04-24 16:09:30 by Christian Brauner

loopfs: implement loopfs

This implements loopfs, a loop device filesystem. It takes inspiration
from the binderfs filesystem I implemented about two years ago and with
which we had overall good experiences so far. Parts of it are also
based on [3] but it's mostly a new, imho cleaner approach.

Loopfs allows to create private loop devices instances to applications
for various use-cases. It covers the use-case that was expressed on-list
and in-person to get programmatic access to private loop devices for
image building in sandboxes. An illustration for this is provided in
[4].

Also loopfs is intended to provide loop devices to privileged and
unprivileged containers which has been a frequent request from various
major tools (Chromium, Kubernetes, LXD, Moby/Docker, systemd). I'm
providing a non-exhaustive list of issues and requests (cf. [5]) around
this feature mainly to illustrate that I'm not making the use-cases up.
Currently none of this can be done safely since handing a loop device
from the host into a container means that the container can see anything
that the host is doing with that loop device and what other containers
are doing with that device too. And (bind-)mounting devtmpfs inside of
containers is not secure at all so also not an option (though sometimes
done out of despair apparently).

The workloads people run in containers are supposed to be indiscernible
from workloads run on the host and the tools inside of the container are
supposed to not be required to be aware that they are running inside a
container apart from containerization tools themselves. This is
especially true when running older distros in containers that did exist
before containers were as ubiquitous as they are today. With loopfs user
can call mount -o loop and in a correctly setup container things work
the same way they would on the host. The filesystem representation
allows us to do this in a very simple way. At container setup, a
container manager can mount a private instance of loopfs somehwere, e.g.
at /dev/loopfs and then bind-mount or symlink /dev/loopfs/loop-control
to /dev/loop-control, pre allocate and symlink the number of standard
devices into their standard location and have a service file or rules in
place that symlink additionally allocated loop devices through losetup
into place as well.
With the new syscall interception logic this is also possible for
unprivileged containers. In these cases when a user calls mount -o loop
<image> <mountpoint> it will be possible to completely setup the loop
device in the container. The final mount syscall is handled through
syscall interception which we already implemented and released in
earlier kernels (see [1] and [2]) and is actively used in production
workloads. The mount is often rewritten to a fuse binary to provide safe
access for unprivileged containers.

Loopfs also allows the creation of hidden/detached dynamic loop devices
and associated mounts which also was a often issued request. With the
old mount api this can be achieved by creating a temporary loopfs and
stashing a file descriptor to the mount point and the loop-control
device and immediately unmounting the loopfs instance.  With the new
mount api a detached mount can be created directly (i.e. a mount not
visible anywhere in the filesystem). New loop devices can then be
allocated and configured. They can be mounted through
/proc/self/<fd>/<nr> with the old mount api or by using the fd directly
with the new mount api. Combined with a mount namespace this allows for
fully auto-cleaned up loop devices on program crash. This ties back to
various use-cases and is illustrated in [4].

The filesystem representation requires the standard boilerplate
filesystem code we know from other tiny filesystems. And all of
the loopfs code is hidden under a config option that defaults to false.
This specifically means, that none of the code even exists when users do
not have any use-case for loopfs.
In addition, the loopfs code does not alter how loop devices behave at
all, i.e. there are no changes to any existing workloads and I've taken
care to ifdef all loopfs specific things out.

Each loopfs mount is a separate instance. As such loop devices created
in one instance are independent of loop devices created in another
instance. This specifically entails that loop devices are only visible
in the loopfs instance they belong to.

The number of loop devices available in loopfs instances are
hierarchically limited through /proc/sys/user/max_loop_devices via the
ucount infrastructure (Thanks to David Rheinsberg for pointing out that
missing piece.). An administrator could e.g. set
echo 3 > /proc/sys/user/max_loop_devices at which point any loopfs
instance mounted by uid x can only create 3 loop devices no matter how
many loopfs instances they mount. This limit applies hierarchically to
all user namespaces.

In addition, loopfs has a "max" mount option which allows to set a limit
on the number of loop devices for a given loopfs instance. This is
mainly to cover use-cases where a single loopfs mount is shared as a
bind-mount between multiple parties that are prevented from creating
other loopfs mounts and is equivalent to the semantics of the binderfs
and devpts "max" mount option.

Note that in __loop_clr_fd() we now need not just check whether bdev is
valid but also whether bdev->bd_disk is valid. This wasn't necessary
before because in order to call LOOP_CLR_FD the loop device would need
to be open and thus bdev->bd_disk was guaranteed to be allocated. For
loopfs loop devices we allow callers to simply unlink them just as we do
for binderfs binder devices and we do also need to account for the case
where a loopfs superblock is shutdown while backing files might still be
associated with some loop devices. In such cases no bd_disk device will
be attached to bdev. This is not in itself noteworthy it's more about
documenting the "why" of the added bdev->bd_disk check for posterity.

[1]: 6a21cc50f0c7 ("seccomp: add a return code to trap to userspace")
[2]: fb3c5386b382 ("seccomp: add SECCOMP_USER_NOTIF_FLAG_CONTINUE")
[3]: https://lore.kernel.org/lkml/1401227936-15698-1-git-send-email-seth.forshee@canonical.com
[4]: https://gist.github.com/brauner/dcaf15e6977cc1bfadfb3965f126c02f
[5]: https://github.com/kubernetes-sigs/kind/issues/1333
     https://github.com/kubernetes-sigs/kind/issues/1248
     https://lists.freedesktop.org/archives/systemd-devel/2017-August/039453.html
     https://chromium.googlesource.com/chromiumos/docs/+/master/containers_and_vms.md#loop-mount
     https://gitlab.com/gitlab-com/support-forum/issues/3732
     https://github.com/moby/moby/issues/27886
     https://twitter.com/_AkihiroSuda_/status/1249664478267854848
     https://serverfault.com/questions/701384/loop-device-in-a-linux-container
     https://discuss.linuxcontainers.org/t/providing-access-to-loop-and-other-devices-in-containers/1352
     https://discuss.concourse-ci.org/t/exposing-dev-loop-devices-in-privileged-mode/813
Cc: Jens Axboe <axboe@kernel.dk>
Cc: Steve Barber <smbarber@google.com>
Cc: Filipe Brandenburger <filbranden@gmail.com>
Cc: Kees Cook <keescook@chromium.org>
Cc: Benjamin Elder <bentheelder@google.com>
Cc: Seth Forshee <seth.forshee@canonical.com>
Cc: Stéphane Graber <stgraber@ubuntu.com>
Cc: Tom Gundersen <teg@jklm.no>
Cc: Tejun Heo <tj@kernel.org>
Cc: Christian Kellner <ckellner@redhat.com>
Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Cc: "David S. Miller" <davem@davemloft.net>
Cc: Dylan Reid <dgreid@google.com>
Cc: David Rheinsberg <david.rheinsberg@gmail.com>
Cc: Akihiro Suda <suda.kyoto@gmail.com>
Cc: Dmitry Vyukov <dvyukov@google.com>
Cc: "Rafael J. Wysocki" <rafael@kernel.org>
Reviewed-by: Serge Hallyn <serge@hallyn.com>
Signed-off-by: Christian Brauner <christian.brauner@ubuntu.com>
---
/* v2 */
- David Rheinsberg <david.rheinsberg@gmail.com> /
  Christian Brauner <christian.brauner@ubuntu.com>:
  - Correctly cleanup loop devices that are in-use after the loopfs
    instance has been shut down. This is important for some use-cases
    that David pointed out where they effectively create a loopfs
    instance, allocate devices and drop unnecessary references to it.
- Christian Brauner <christian.brauner@ubuntu.com>:
  - Replace lo_loopfs_i inode member in struct loop_device with a custom
    struct lo_info pointer which is only allocated for loopfs loop
    devices.

/* v3 */
- Christian Brauner <christian.brauner@ubuntu.com>:
  - Fix loopfs_access() to not care about non-loopfs devices.
  - Stash refcounted sbinfo in lo_info to simplify retrieval of user
    namespace. This way each loopfs instance just takes a single
    reference for each to the user namespace that is dropped when the
    last loop device is removed. This puts us on the safe side. (Thanks
    to Serge for making me aware of this issue.
- David Rheinsberg <david.rheinsberg@gmail.com> /
  Serge Hallyn <serge@hallyn.com>:
  - Remove "max" mount option.

---
## [yoyobatty/HippieStation](https://github.com/yoyobatty/HippieStation)@[ff93bd2c2c...](https://github.com/yoyobatty/HippieStation/commit/ff93bd2c2c14adf2ae24ecafb494c27cb985694f)
#### Friday 2020-04-24 16:27:53 by karmaisblackandbluepilled

Half Life sound effects, HEV Suit and scientist changes (#12726)

* FORGET ABOUT FREEMAN

* Ah, Freeman, it's good to see you

* Help me, Gordon!

* Look Gordon, ropes!

* Modular Dongs

* I hate coding

* i forgot to press save

* Poonis rartus

* We've boosted the anti-mass spectrometer

---
## [Toshimonster/discordian-mrip](https://github.com/Toshimonster/discordian-mrip)@[4515223d8f...](https://github.com/Toshimonster/discordian-mrip/commit/4515223d8f1de12b190b043ec764bc3b4c66089e)
#### Friday 2020-04-24 16:38:34 by Toshimonster

Epic Fix after sqlite3 is a fucking pain in the arse postergsql or whatever is so much better I want to die now

---
## [Flinesoft/BartyCrouch](https://github.com/Flinesoft/BartyCrouch)@[6003368b33...](https://github.com/Flinesoft/BartyCrouch/commit/6003368b33d1fd2b91b3aaa0cd9d2e56b30ae710)
#### Friday 2020-04-24 16:59:22 by Cihat Gündüz

Remove magic of gathering of new translation via comment

I remember I added this feature to improve the user experience when working
with the default behavior of Interface Builder, but I don't remember the details.
Also this feature was never documented or tested, so I think it can be removed.

Fingers crossed that there will be no side effects and no one is relying on this.

---
## [stebomurkn420/kernel_google_b4s4](https://github.com/stebomurkn420/kernel_google_b4s4)@[cf9f829523...](https://github.com/stebomurkn420/kernel_google_b4s4/commit/cf9f829523c09272ddddad7decc0e4f15b4976bb)
#### Friday 2020-04-24 18:12:14 by Christian Brauner

BACKPORT: signal: add pidfd_send_signal() syscall

The kill() syscall operates on process identifiers (pid). After a process
has exited its pid can be reused by another process. If a caller sends a
signal to a reused pid it will end up signaling the wrong process. This
issue has often surfaced and there has been a push to address this problem [1].

This patch uses file descriptors (fd) from proc/<pid> as stable handles on
struct pid. Even if a pid is recycled the handle will not change. The fd
can be used to send signals to the process it refers to.
Thus, the new syscall pidfd_send_signal() is introduced to solve this
problem. Instead of pids it operates on process fds (pidfd).

/* prototype and argument /*
long pidfd_send_signal(int pidfd, int sig, siginfo_t *info, unsigned int flags);

/* syscall number 424 */
The syscall number was chosen to be 424 to align with Arnd's rework in his
y2038 to minimize merge conflicts (cf. [25]).

In addition to the pidfd and signal argument it takes an additional
siginfo_t and flags argument. If the siginfo_t argument is NULL then
pidfd_send_signal() is equivalent to kill(<positive-pid>, <signal>). If it
is not NULL pidfd_send_signal() is equivalent to rt_sigqueueinfo().
The flags argument is added to allow for future extensions of this syscall.
It currently needs to be passed as 0. Failing to do so will cause EINVAL.

/* pidfd_send_signal() replaces multiple pid-based syscalls */
The pidfd_send_signal() syscall currently takes on the job of
rt_sigqueueinfo(2) and parts of the functionality of kill(2), Namely, when a
positive pid is passed to kill(2). It will however be possible to also
replace tgkill(2) and rt_tgsigqueueinfo(2) if this syscall is extended.

/* sending signals to threads (tid) and process groups (pgid) */
Specifically, the pidfd_send_signal() syscall does currently not operate on
process groups or threads. This is left for future extensions.
In order to extend the syscall to allow sending signal to threads and
process groups appropriately named flags (e.g. PIDFD_TYPE_PGID, and
PIDFD_TYPE_TID) should be added. This implies that the flags argument will
determine what is signaled and not the file descriptor itself. Put in other
words, grouping in this api is a property of the flags argument not a
property of the file descriptor (cf. [13]). Clarification for this has been
requested by Eric (cf. [19]).
When appropriate extensions through the flags argument are added then
pidfd_send_signal() can additionally replace the part of kill(2) which
operates on process groups as well as the tgkill(2) and
rt_tgsigqueueinfo(2) syscalls.
How such an extension could be implemented has been very roughly sketched
in [14], [15], and [16]. However, this should not be taken as a commitment
to a particular implementation. There might be better ways to do it.
Right now this is intentionally left out to keep this patchset as simple as
possible (cf. [4]).

/* naming */
The syscall had various names throughout iterations of this patchset:
- procfd_signal()
- procfd_send_signal()
- taskfd_send_signal()
In the last round of reviews it was pointed out that given that if the
flags argument decides the scope of the signal instead of different types
of fds it might make sense to either settle for "procfd_" or "pidfd_" as
prefix. The community was willing to accept either (cf. [17] and [18]).
Given that one developer expressed strong preference for the "pidfd_"
prefix (cf. [13]) and with other developers less opinionated about the name
we should settle for "pidfd_" to avoid further bikeshedding.

The  "_send_signal" suffix was chosen to reflect the fact that the syscall
takes on the job of multiple syscalls. It is therefore intentional that the
name is not reminiscent of neither kill(2) nor rt_sigqueueinfo(2). Not the
fomer because it might imply that pidfd_send_signal() is a replacement for
kill(2), and not the latter because it is a hassle to remember the correct
spelling - especially for non-native speakers - and because it is not
descriptive enough of what the syscall actually does. The name
"pidfd_send_signal" makes it very clear that its job is to send signals.

/* zombies */
Zombies can be signaled just as any other process. No special error will be
reported since a zombie state is an unreliable state (cf. [3]). However,
this can be added as an extension through the @flags argument if the need
ever arises.

/* cross-namespace signals */
The patch currently enforces that the signaler and signalee either are in
the same pid namespace or that the signaler's pid namespace is an ancestor
of the signalee's pid namespace. This is done for the sake of simplicity
and because it is unclear to what values certain members of struct
siginfo_t would need to be set to (cf. [5], [6]).

/* compat syscalls */
It became clear that we would like to avoid adding compat syscalls
(cf. [7]).  The compat syscall handling is now done in kernel/signal.c
itself by adding __copy_siginfo_from_user_generic() which lets us avoid
compat syscalls (cf. [8]). It should be noted that the addition of
__copy_siginfo_from_user_any() is caused by a bug in the original
implementation of rt_sigqueueinfo(2) (cf. 12).
With upcoming rework for syscall handling things might improve
significantly (cf. [11]) and __copy_siginfo_from_user_any() will not gain
any additional callers.

/* testing */
This patch was tested on x64 and x86.

/* userspace usage */
An asciinema recording for the basic functionality can be found under [9].
With this patch a process can be killed via:

 #define _GNU_SOURCE
 #include <errno.h>
 #include <fcntl.h>
 #include <signal.h>
 #include <stdio.h>
 #include <stdlib.h>
 #include <string.h>
 #include <sys/stat.h>
 #include <sys/syscall.h>
 #include <sys/types.h>
 #include <unistd.h>

 static inline int do_pidfd_send_signal(int pidfd, int sig, siginfo_t *info,
                                         unsigned int flags)
 {
 #ifdef __NR_pidfd_send_signal
         return syscall(__NR_pidfd_send_signal, pidfd, sig, info, flags);
 #else
         return -ENOSYS;
 #endif
 }

 int main(int argc, char *argv[])
 {
         int fd, ret, saved_errno, sig;

         if (argc < 3)
                 exit(EXIT_FAILURE);

         fd = open(argv[1], O_DIRECTORY | O_CLOEXEC);
         if (fd < 0) {
                 printf("%s - Failed to open \"%s\"\n", strerror(errno), argv[1]);
                 exit(EXIT_FAILURE);
         }

         sig = atoi(argv[2]);

         printf("Sending signal %d to process %s\n", sig, argv[1]);
         ret = do_pidfd_send_signal(fd, sig, NULL, 0);

         saved_errno = errno;
         close(fd);
         errno = saved_errno;

         if (ret < 0) {
                 printf("%s - Failed to send signal %d to process %s\n",
                        strerror(errno), sig, argv[1]);
                 exit(EXIT_FAILURE);
         }

         exit(EXIT_SUCCESS);
 }

/* Q&A
 * Given that it seems the same questions get asked again by people who are
 * late to the party it makes sense to add a Q&A section to the commit
 * message so it's hopefully easier to avoid duplicate threads.
 *
 * For the sake of progress please consider these arguments settled unless
 * there is a new point that desperately needs to be addressed. Please make
 * sure to check the links to the threads in this commit message whether
 * this has not already been covered.
 */
Q-01: (Florian Weimer [20], Andrew Morton [21])
      What happens when the target process has exited?
A-01: Sending the signal will fail with ESRCH (cf. [22]).

Q-02:  (Andrew Morton [21])
       Is the task_struct pinned by the fd?
A-02:  No. A reference to struct pid is kept. struct pid - as far as I
       understand - was created exactly for the reason to not require to
       pin struct task_struct (cf. [22]).

Q-03: (Andrew Morton [21])
      Does the entire procfs directory remain visible? Just one entry
      within it?
A-03: The same thing that happens right now when you hold a file descriptor
      to /proc/<pid> open (cf. [22]).

Q-04: (Andrew Morton [21])
      Does the pid remain reserved?
A-04: No. This patchset guarantees a stable handle not that pids are not
      recycled (cf. [22]).

Q-05: (Andrew Morton [21])
      Do attempts to signal that fd return errors?
A-05: See {Q,A}-01.

Q-06: (Andrew Morton [22])
      Is there a cleaner way of obtaining the fd? Another syscall perhaps.
A-06: Userspace can already trivially retrieve file descriptors from procfs
      so this is something that we will need to support anyway. Hence,
      there's no immediate need to add another syscalls just to make
      pidfd_send_signal() not dependent on the presence of procfs. However,
      adding a syscalls to get such file descriptors is planned for a
      future patchset (cf. [22]).

Q-07: (Andrew Morton [21] and others)
      This fd-for-a-process sounds like a handy thing and people may well
      think up other uses for it in the future, probably unrelated to
      signals. Are the code and the interface designed to permit such
      future applications?
A-07: Yes (cf. [22]).

Q-08: (Andrew Morton [21] and others)
      Now I think about it, why a new syscall? This thing is looking
      rather like an ioctl?
A-08: This has been extensively discussed. It was agreed that a syscall is
      preferred for a variety or reasons. Here are just a few taken from
      prior threads. Syscalls are safer than ioctl()s especially when
      signaling to fds. Processes are a core kernel concept so a syscall
      seems more appropriate. The layout of the syscall with its four
      arguments would require the addition of a custom struct for the
      ioctl() thereby causing at least the same amount or even more
      complexity for userspace than a simple syscall. The new syscall will
      replace multiple other pid-based syscalls (see description above).
      The file-descriptors-for-processes concept introduced with this
      syscall will be extended with other syscalls in the future. See also
      [22], [23] and various other threads already linked in here.

Q-09: (Florian Weimer [24])
      What happens if you use the new interface with an O_PATH descriptor?
A-09:
      pidfds opened as O_PATH fds cannot be used to send signals to a
      process (cf. [2]). Signaling processes through pidfds is the
      equivalent of writing to a file. Thus, this is not an operation that
      operates "purely at the file descriptor level" as required by the
      open(2) manpage. See also [4].

/* References */
[1]:  https://lore.kernel.org/lkml/20181029221037.87724-1-dancol@google.com/
[2]:  https://lore.kernel.org/lkml/874lbtjvtd.fsf@oldenburg2.str.redhat.com/
[3]:  https://lore.kernel.org/lkml/20181204132604.aspfupwjgjx6fhva@brauner.io/
[4]:  https://lore.kernel.org/lkml/20181203180224.fkvw4kajtbvru2ku@brauner.io/
[5]:  https://lore.kernel.org/lkml/20181121213946.GA10795@mail.hallyn.com/
[6]:  https://lore.kernel.org/lkml/20181120103111.etlqp7zop34v6nv4@brauner.io/
[7]:  https://lore.kernel.org/lkml/36323361-90BD-41AF-AB5B-EE0D7BA02C21@amacapital.net/
[8]:  https://lore.kernel.org/lkml/87tvjxp8pc.fsf@xmission.com/
[9]:  https://asciinema.org/a/IQjuCHew6bnq1cr78yuMv16cy
[11]: https://lore.kernel.org/lkml/F53D6D38-3521-4C20-9034-5AF447DF62FF@amacapital.net/
[12]: https://lore.kernel.org/lkml/87zhtjn8ck.fsf@xmission.com/
[13]: https://lore.kernel.org/lkml/871s6u9z6u.fsf@xmission.com/
[14]: https://lore.kernel.org/lkml/20181206231742.xxi4ghn24z4h2qki@brauner.io/
[15]: https://lore.kernel.org/lkml/20181207003124.GA11160@mail.hallyn.com/
[16]: https://lore.kernel.org/lkml/20181207015423.4miorx43l3qhppfz@brauner.io/
[17]: https://lore.kernel.org/lkml/CAGXu5jL8PciZAXvOvCeCU3wKUEB_dU-O3q0tDw4uB_ojMvDEew@mail.gmail.com/
[18]: https://lore.kernel.org/lkml/20181206222746.GB9224@mail.hallyn.com/
[19]: https://lore.kernel.org/lkml/20181208054059.19813-1-christian@brauner.io/
[20]: https://lore.kernel.org/lkml/8736rebl9s.fsf@oldenburg.str.redhat.com/
[21]: https://lore.kernel.org/lkml/20181228152012.dbf0508c2508138efc5f2bbe@linux-foundation.org/
[22]: https://lore.kernel.org/lkml/20181228233725.722tdfgijxcssg76@brauner.io/
[23]: https://lwn.net/Articles/773459/
[24]: https://lore.kernel.org/lkml/8736rebl9s.fsf@oldenburg.str.redhat.com/
[25]: https://lore.kernel.org/lkml/CAK8P3a0ej9NcJM8wXNPbcGUyOUZYX+VLoDFdbenW3s3114oQZw@mail.gmail.com/

Cc: "Eric W. Biederman" <ebiederm@xmission.com>
Cc: Jann Horn <jannh@google.com>
Cc: Andy Lutomirsky <luto@kernel.org>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Oleg Nesterov <oleg@redhat.com>
Cc: Al Viro <viro@zeniv.linux.org.uk>
Cc: Florian Weimer <fweimer@redhat.com>
Signed-off-by: Christian Brauner <christian@brauner.io>
Reviewed-by: Tycho Andersen <tycho@tycho.ws>
Reviewed-by: Kees Cook <keescook@chromium.org>
Reviewed-by: David Howells <dhowells@redhat.com>
Acked-by: Arnd Bergmann <arnd@arndb.de>
Acked-by: Thomas Gleixner <tglx@linutronix.de>
Acked-by: Serge Hallyn <serge@hallyn.com>
Acked-by: Aleksa Sarai <cyphar@cyphar.com>

(cherry picked from commit 3eb39f47934f9d5a3027fe00d906a45fe3a15fad)

Conflicts:
        arch/x86/entry/syscalls/syscall_32.tbl - trivial manual merge
        arch/x86/entry/syscalls/syscall_64.tbl - trivial manual merge
        include/linux/proc_fs.h - trivial manual merge
        include/linux/syscalls.h - trivial manual merge
        include/uapi/asm-generic/unistd.h - trivial manual merge
        kernel/signal.c - struct kernel_siginfo does not exist in 4.9
        kernel/sys_ni.c - cond_syscall is used instead of COND_SYSCALL
        arch/x86/entry/syscalls/syscall_32.tbl
        arch/x86/entry/syscalls/syscall_64.tbl

(1. manual merges because of 4.9 differences
 2. change prepare_kill_siginfo() to use struct siginfo instead of
kernel_siginfo
 3. exclude kill() changes to avoid struct kernel_siginfo usage
 4. exclude copy_siginfo_from_user_any() to avoid struct kernel_siginfo usage
 5. use copy_from_user() instead of copy_siginfo_from_user() in copy_siginfo_from_user_any()
 6. replaced COND_SYSCALL with cond_syscall
 7. Removed __ia32_sys_pidfd_send_signal in arch/x86/entry/syscalls/syscall_32.tbl.
 8. Replaced __x64_sys_pidfd_send_signal with sys_pidfd_send_signal in arch/x86/entry/syscalls/syscall_64.tbl.)

Bug: 135608568
Test: test program using syscall(__NR_pidfd_send_signal,..) to send SIGKILL
Change-Id: I00f1c618b2e9dbafae4d4113ad4d8a1a44b6957c
Signed-off-by: Suren Baghdasaryan <surenb@google.com>

---
## [AbhishekBasu-14/Python_3_Beginner](https://github.com/AbhishekBasu-14/Python_3_Beginner)@[9b70077ee6...](https://github.com/AbhishekBasu-14/Python_3_Beginner/commit/9b70077ee6783b968064860f625c01bbc8db3f9e)
#### Friday 2020-04-24 19:40:15 by Abhishek Basu

Chef and his cake

Chef’s girlfriend's birthday is near, so he wants to surprise her by making a special cake for her. Chef knows that his girlfriend likes cherries on the cake, so he puts cherries on the top of the cake, but he was not satisfied. Therefore, he decided to replace some of the cherries to make a beautiful pattern. However, Chef has a lot of other work to do so he decided to ask for your help.

The cherries are of two colors red and green. Now Chef wants the cherries to be placed in such a way that each cherry of one color must be adjacent to only cherries of the other color, two cherries are adjacent if they share a side. Now Chef has asked for your help in making that pattern on the cake.

You can replace any cherry of given color with the other color. But there is a cost for each replacement: if you replace a red cherry with a green one, the cost is 5 units and if you replace a green cherry with a red one, the cost is 3 units.

Help your friend Chef by making the cake special with minimum cost.

---
## [certbot/certbot](https://github.com/certbot/certbot)@[01dc981a09...](https://github.com/certbot/certbot/commit/01dc981a0923ccd5eb3267a737360dc2f1906602)
#### Friday 2020-04-24 21:13:13 by Brad Warren

Merge pull request #7948 from certbot/snap-build-squashed

Despite this PR (only) being ~200 lines containing mostly code copied from another repo, there is a lot going on here. For the sake of making it both easier to review and to remember some of these things in the future by referring back to this PR, I've documented a lot of noteworthy things with section headers below. With that said, it's probably not necessary to read each section unless you're interested in that topic.

The most noteworthy thing for the reviewer is **this PR should be merged and not squashed** to preserve authorship. To merge this code, once we're happy with this PR, I'll probably open a new PR squashing any commits I make in response in review comments back into a single commit to try to keep history somewhat clean. To help prevent this PR from being accidentally squashed, I'm making this a draft PR for now.

### Git history of https://github.com/basak/certbot-snap-build

I think it is worth preserving the git history of https://github.com/basak/certbot-snap-build that this PR is based on in this repo to help us track why things were done a certain way. To do this while keeping our git history somewhat clean, I took the approach described at https://stackoverflow.com/questions/1425892/how-do-you-merge-two-git-repositories/21495718#21495718 to move all history of https://github.com/basak/certbot-snap-build into a `snap` directory. I then squashed all commits so that sequential commits from the same author are one commit. I probably could have reordered commits to try and squash things a little more, but I personally don't think it's worth the trouble. Finally, I merged this rewritten history into this branch of the Certbot repo.

The contents of the `snap` directory are identical to the current contents of https://github.com/basak/certbot-snap-build before my final commit in this PR which makes the changes to make things work in this repo.

### Travis stages

This is described in general at https://docs.travis-ci.com/user/build-stages/, but I don't think we should deploy the snap if any of our tests are failing. To accomplish this, I created a "Snap" stage that builds, tests, and deploys the snap which is only executed after a "Test" stage that contains all of our other tests. The "Snap" stage will not run until the "Test" stage completes successfully.

### snap/local

This directory is ignored by `snapcraft` which I think makes it a good place to store `snap` specific scripts like `build_and_install.sh`.

See https://bugs.launchpad.net/snapcraft/+bug/1792203 for more info.

### Why remove certbot-compatibility-test from apacheconftest toxenvs?

Because it's not used. In theory, it could go in its own PR, but it'll create merge conflicts with this one so I'd personally prefer to include this simple change in this PR as well.

### Checklist for landing this PR

- [x] Squash all of my commits into one commit
- [x] Update the release instructions to have to move the snap to the beta channel
- [x] Shut down Robie's nightly builds probably by updating his repo to say that the code has moved here and deleting everything

---
## [viverosm/GRAD521_DMPMarcosViveros_2020](https://github.com/viverosm/GRAD521_DMPMarcosViveros_2020)@[812297aa55...](https://github.com/viverosm/GRAD521_DMPMarcosViveros_2020/commit/812297aa55ae50d2f0d33c826c29f6eea460e7f4)
#### Friday 2020-04-24 21:46:16 by Marcos Viveros-Cespedes

Update DMP for the research project: Gender, Masculinity, and Education

1.	Research context and research questions:

This study will examine perceptions of gender and masculinity in self-identified male students enrolled in XXXXXX at XXXXXX University. Being the instructor of XXXXX and my previous experience conducting research about the experiences of college male students in Women, Gender, and Sexuality Studies courses, have informed my current research interest in studying how male students in XXXX perceive masculinity; what factors impact these perceptions; how students make sense of different concepts of masculinity; and how students’ understanding of these concepts impact the formation of their future career as (potential)educators. XXXXX is a social justice-oriented course where students are exposed to the learning and critical discussions of gender issues, race, and other topics. Therefore, I believe it is crucial and pertinent to study how male students perceive gender and how they make sense of masculinity in order to explore ways to promote gender equality in this particular educational setting. My research will be informed based on the following questions: 

a)	How do self-identified male students in a multicultural education class use discourse to represent their gender and masculinity in course assignments? 
b)	How do students in XXXX who self-identify as male perceive their own masculinities?
c)	What key factors (i.e.; media, social life, etc.) affect perceptions of masculinity in
students who identify as male in XXXXX?
d)	How do self-identified male students perceive their own gender identities in relation to
social constructions of masculinity and what roles do they see such identities and
performativities playing in their future careers as professional educators?

2.	Type of Data
Data for this project will include written course assignments. XXXX is taught every term and an average of 25 students give consent to use their assignments as part of a larger research project whose objective is to redesign XXXXX. I anticipate having access to around 150 written assignments by winter term 2021 which is when I plan to start analyzing my data. Assignments include:  
a)	Weekly reflection questions (posted on Canvas): Students need to complete two or three questions based on the readings assigned each week.
b)	Exit cards: At the end of every class, students have to answer one or two questions a piece of paper. Usually questions include: “what made you feel uncomfortable during today’s class”? “what was your Aha moment in today’s class”?
c)	Cultural identity wheel: During week two, students participate in an activity where they have to reflect on their cultural identities. Part of this activity includes completing a cultural identity wheel with their gender, race, sexual orientation, age, college major, hobbies, and so on.
d)	Analytic memos: Students have to write three memos over the course of term whenever they sense an important connection to course content that warrants further exploration.  For this assignment students are welcome (and encouraged) to incorporate their own experiences with one or more of the weeks readings for this course.

3.	Data set. 
I do not have a data set yet. I am in the process of organizing the data that I have so far and here I where I need support in this class. For now, I have around 20 students who gave consent to use their assignments, which mean I will have access to approximately 60 course assignments to organize in a data set.

---
## [microsoft/terminal](https://github.com/microsoft/terminal)@[98ac196cec...](https://github.com/microsoft/terminal/commit/98ac196cec88a0d85ae5eeb0cb96916fbb750220)
#### Friday 2020-04-24 22:14:48 by Michael Niksa

Lock when changing selection endpoint on wheel/auto-scroll (#5551)

Takes the lock inside two routines in `TermControl` that were changing
the selection endpoint while a rendering frame was still drawing,
resulting in several variants of graphical glitches from double-struck
selection boxes to duplicated line text.

## References
- Introduced with #5185

## PR Checklist
* [x] Closes #5471 
* [x] Already signed life away to company.
* [x] Manual tests passed since it's visual.
* [x] No extra doc besides the comments.
* [x] Am core contributor: Roar.

The renderer base and specific renderer engine do a lot of work to
remember the previous selection and compensate for scrolling regions and
deltas between frames. However, all that work doesn't quite match up
when the endpoints are changed out from under it. Unfortunately,
`TermControl` doesn't have a robust history of locking correctly in step
with the renderer nor does the renderer's `IRenderData` currently
provide any way of 'snapping' state at the beginning of a frame so it
could work without a full lock. So the solution for now is for the
methods that scroll the display in `TermControl` to take the lock that
is shared with the renderer's frame painter so they can't change out of
sync.

## Validation Steps Performed
- Opened terminal with Powershell core.
  Did ls a bunch of times.
  Clicked to make selection and held mouse button while wheeling around.
- Opened terminal with Powershell core.;
  Did ls a bunch of times.
  Clicked to make selection and dragged mouse outside the window to make
  auto scroll happen.
- Opened terminal with Powershell core.
  Did ls a bunch of times.
  Clicked to make selection and released. Wheeled around like a crazy
  person to make sure I didn't regress that.

---
## [openmaraude/APITaxi_front](https://github.com/openmaraude/APITaxi_front)@[05c8a27423...](https://github.com/openmaraude/APITaxi_front/commit/05c8a274238d8ea063479bed95474f0ee41e5d6e)
#### Friday 2020-04-24 22:29:30 by Julien Castets

WIP

I'm tired. The models API is so badly designed it is literally
impossible to create unittests without mocking everything, even if you
allow yourself to do a lot of ugly hacks. We need to rewrite completely
APITaxi_models, remove the fucking logic from __init__ method to put it
in a separate library, and stop having 50 dependencies just to create a
fucking object.

---

# [<](2020-04-23.md) 2020-04-24 [>](2020-04-25.md)

