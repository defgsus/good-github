# [<](2020-01-22.md) 2020-01-23 [>](2020-01-24.md)

1,948,569 events, 995,320 push events, 1,598,713 commit messages, 123,774,825 characters


## [newstools/2020-the-star@d0ef484112...](https://github.com/newstools/2020-the-star/commit/d0ef484112bb4982528480e136e08beff3aa67c3)
##### 2020-01-23 01:48:12 by NewsTools

Created Text For URL [www.the-star.co.ke/counties/central/2020-01-22-estranged-lover-kills-girlfriend-with-her-mothers-kitchen-knife/]

---
## [NetBSD/src@73b59bc81e...](https://github.com/NetBSD/src/commit/73b59bc81e94681ffdbd5f8d50abc5a06e16207a)
##### 2020-01-23 03:06:42 by martin

Pull up following revision(s) (requested by maxv in ticket #817):

	sys/net/npf/npf_inet.c: revision 1.38-1.44
	sys/net/npf/npf_handler.c: revision 1.38-1.39
	sys/net/npf/npf_alg_icmp.c: revision 1.26
	sys/net/npf/npf.h: revision 1.56
	sys/net/npf/npf_sendpkt.c: revision 1.17-1.18

Declare NPC_FMTERR, and use it to kick malformed packets. Several sanity
checks are added in IPv6; after we see the first IPPROTO_FRAGMENT header,
we are allowed to fail to advance, otherwise we kick the packet.
Sent on tech-net@ a few days ago, no response, but I'm committing it now
anyway.

Switch nptr to uint8_t, and use nbuf_ensure_contig. Makes us use fewer
magic values.

Remove dead branches, 'npc' can't be NULL (and it is dereferenced
earlier).

Fix two consecutive mistakes.

The first mistake was npf_inet.c rev1.37:
        "Don't reassemble ipv6 fragments, instead treat the first fragment
        as a regular packet (subject to filtering rules), and pass
        subsequent fragments in the same group unconditionally."

Doing this was entirely wrong, because then a packet just had to push
the L4 payload in a secondary fragment, and NPF wouldn't apply rules on
it - meaning any IPv6 packet could bypass >=L4 filtering. This mistake
was supposed to be a fix for the second mistake.

The second mistake was that ip6_reass_packet (in npf_reassembly) was
getting called with npc->npc_hlen. But npc_hlen pointed to the last
encountered header in the IPv6 chain, which was not necessarily the
fragment header. So ip6_reass_packet was given garbage, and would fail,
resulting in the packet getting kicked. So basically IPv6 was broken by
NPF.

The first mistake is reverted, and the second one is fixed by doing:
-                       hlen = sizeof(struct ip6_frag);
+                       hlen = 0;

Now the iteration stops on the fragment header, and the call to
ip6_reass_packet is valid.

My npf_inet.c rev1.38 is partially reverted: we don't need to worry
about failing properly to advance; once the packet is reassembled
npf_cache_ip gets called again, and this time the whole chain should be
there.

Tested with a simple UDPv6 server - send a 3000-byte-sized buffer, the
packet gets correctly reassembled by NPF now.

Mmh, put back the RFC6946 check (about dummy fragments), otherwise NPF
is not happy in npf_reassembly, because NPC_IPFRAG is again returned after
the packet was reassembled.

I'm wondering whether it would not be better to just remove the fragment
header in frag6_input directly.

Fix the "return-rst" rule on IPv6 packets.
The scopes needed to be set on the addresses before invoking ip6_output,
because ip6_output needs them. The reason they are not here already is
because pfil_run_hooks (in ip6_input) is called _before_ the kernel
initializes the scopes.

Until now ip6_output was always failing, and the IPv6-TCP-RST packet was
never actually sent.

Perhaps it would be better to have the kernel initialize the scopes
before invoking pfil_run_hooks, but several things will need to be fixed
in several places.

Tested with a simple TCPv6 server. Until now the client would block
waiting for an answer that never came; now it receives an RST right away
and closes the connection, as expected.
I believe that the same problem exists in the "return-icmp" rules, but I
can't investigate this right now (some problems with wireshark).

Fix the IPv6 payload computation in npf_tcpsaw. It was incorrect, and this
caused the "return-rst" rules to send back an RST with the wrong ACK when
the received SYN had an IPv6 option.

Set the scopes before calling icmp6_error(). This fixes a bug similar to
the one I fixed in rev1.17: since the scopes were not set the packet was
never actually sent.

Tested with wireshark, now the ICMPv6 reply is correctly sent, as
expected.

Don't read the L4 payload after IPPROTO_AH when handling IPv6 packets.
AH must be considered as the payload, otherwise a

        block all
        pass in proto ah from any
        pass out proto ah from any

configuration will actually block everything, because NPF checks the
protocol against the one found after AH, and not AH itself.

In addition it may have been a problem for stateful connections; an AH
packet sent by an attacker with an incorrect authentication and a correct
TCP/UDP/whatever payload from an active connection could manage to change
NPF's FSM state, which would perhaps have altered the legitimate
connection with the authenticated remote IPsec host.

Note that IPv4 already doesn't go beyond AH, which is the correct
behavior.

Add XXX (we don't handle IPv6 Jumbograms), and whitespace.

---
## [mrakgr/The-Spiral-Language@e0aa352796...](https://github.com/mrakgr/The-Spiral-Language/commit/e0aa3527961f2d591c059140f001d3531f6d4437)
##### 2020-01-23 08:54:09 by Marko Grdinić

"9am. I am up. I actually woke up earlier, but have been indulging myself in my imagination.

If there is a direction I want to change, it would be to take my imagination more seriously.

Deep down, I've been too laid back and skeptical.

This is reflected in the last 5 years. Spiral since its inception was always an expression of both my belief and skepticism in ML. But I did not channel this skepticism properly. A really common pattern in my explorations is that I would figure out some big optimization like KFAC, Zap, that cumulative eligibility trace update, and then find that they are local minima in terms of design. Even minor architectural changes break them.

In the end, I can only count of plain old backprop.

And starting from 2015, ever since the discrete optimization course, I did not really understand why anything other that point optimizations were necessary. Even now I do not have an absolute view I could point to, but nonetheless the hints are everywhere that diversity is the key to uncertainty estimation.

Back in 2015, I thought that there would be something smarter than multiple random inits, but I guess not.

9:10am. This time I really want to do so much more.

And conversely, this is the last time I will ever work on a language. I swear it. V0.2 is the last time I will ever put so much effort into this because honestly, I had enough. I do not want to end up in a situation where in 2030 I both still a pure human and still fiddling with this donkey shit.

Programs are crystallizations of understanding, so I am going to finish it here.

9:35pm. Ok, enough slacking. Let me see whether I can get some work done. I need to start work on partial evaluation. Just two more years of this and then I am done for good.

When v0.2 is done, I will have no more refactoring or compilation speed issues anymore. It needs to be done.

9:50am. Yeah, it is going to be hard going to start. Right now rather than programming I am posting on /sci/. For the past few months my frequency of posting has been way up. From once a year on average to a few times per week.

...Ah, let me chill for a while longer and then I will start."

---
## [ProtoDump/kernel_xiaomi_santoni@98320508ff...](https://github.com/ProtoDump/kernel_xiaomi_santoni/commit/98320508ffe0ea2ff3bdc09a9adf35979613f7f3)
##### 2020-01-23 10:40:05 by Paul E. McKenney

fs/sync: Make sync() satisfy many requests with one invocation

Dave Jones reported RCU stalls, overly long hrtimer interrupts, and
amazingly long NMI handlers from a trinity-induced workload involving
lots of concurrent sync() calls (https://lkml.org/lkml/2013/7/23/369).
There are any number of things that one might do to make sync() behave
better under high levels of contention, but it is also the case that
multiple concurrent sync() system calls can be satisfied by a single
sys_sync() invocation.

Given that this situation is reminiscent of rcu_barrier(), this commit
applies the rcu_barrier() approach to sys_sync().  This approach uses
a global mutex and a sequence counter.  The mutex is held across the
sync() operation, which eliminates contention between concurrent sync()
operations.  The counter is incremented at the beginning and end of
each sync() operation, so that it is odd while a sync() operation is in
progress and even otherwise, just like sequence locks.

The code that used to be in sys_sync() is now in do_sync(), and sys_sync()
now handles the concurrency.  The sys_sync() function first takes a
snapshot of the counter, then acquires the mutex, and then takes another
snapshot of the counter.  If the values of the two snapshots indicate that
a full do_sync() executed during the mutex acquisition, the sys_sync()
function releases the mutex and returns ("Our work is done!").  Otherwise,
sys_sync() increments the counter, invokes do_sync(), and increments
the counter again.

This approach allows a single call to do_sync() to satisfy an arbitrarily
large number of sync() system calls, which should eliminate issues due
to large numbers of concurrent invocations of the sync() system call.

Changes since v1 (https://lkml.org/lkml/2013/7/24/683):

o	Add a pair of memory barriers to keep the increments from
	bleeding into the do_sync() code.  (The failure probability
	is insanely low, but when you have several hundred million
	devices running Linux, you can expect several hundred instances
	of one-in-a-million failures.)

o	Actually CC some people who have experience in this area.

Reported-by: Dave Jones <davej@redhat.com>
Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Cc: Alexander Viro <viro@zeniv.linux.org.uk>
Cc: Christoph Hellwig <hch@lst.de>
Cc: Jan Kara <jack@suse.cz>
Cc: Curt Wohlgemuth <curtw@google.com>
Cc: Jens Axboe <jaxboe@fusionio.com>
Cc: linux-fsdevel@vger.kernel.org

Signed-off-by: Paul Reioux <reioux@gmail.com>

---
## [mrakgr/The-Spiral-Language@481b3ed0bf...](https://github.com/mrakgr/The-Spiral-Language/commit/481b3ed0bf13fc1005816dbce5aa8701e0c3b531)
##### 2020-01-23 11:25:06 by Marko Grdinić

"10:15am. Let me finally start this thing.

First of all - types.

```
and TypedData =
    | TyList of TypedData list
    | TyKeyword of KeywordTag * TypedData []
    | TyFunction of Expr * StackSize * EnvTerm
    | TyRecFunction of Expr * StackSize * EnvTerm
    | TyObject of ObjectDict * EnvTerm
    | TyMap of MapTerm

    | TyT of ConsedTy
    | TyV of TyTag
    | TyBox of TypedData * ConsedTy
    | TyLit of Value
```

I need to make this into something sensible. I already said I would removing consing and replace it reference memoization.

10:20am. The pevaller is a big piece to deal with, so let me do it slowly, one at a time.

Focus me. Let me just do the types and then I'll take a proper break.

10:40am.

```
module Spiral.PartEval

open Spiral.Prepass

type Env<'a,'b> = {type' : StackSize * 'a []; value : StackSize * 'b []}

type LayoutType =
    | LayoutStack
    | LayoutHeap
    | LayoutHeapMutable

type Ty =
    | PairT of Ty * Ty
    | KeywordT of KeywordTag * Ty []
    | FunctionT of Expr * StackSize * Env<Ty, Ty>
    | RecordT of Map<KeywordTag, Ty>
    | PrimT of Parsing.PrimitiveType

    | LayoutT of LayoutType * Data
    | ArrayT of Ty
    | RuntimeFunctionT of Ty * Ty
    | MacroT of Data

and Data =
    | TyPair of Data * Data
    | TyKeyword of KeywordTag * Data []
    | TyFunction of Expr * Env<Ty, Data>
    | TyRecord of Map<KeywordTag, Data>
    | TyLit of Tokenize.Value

    | TyV of int * Ty
    | TyRef of int // For use in join points, layout types and macros
```

I am missing union types here, but apart from that this is excellent. This time I do not even need recursive functions. They will all be there in the ...

Ah, I just realized. It is not just renaming that I have to watch out for cycles, but when returning from regular join points as well. And in dynamize too.

And in destructure. Pretty much every function that iterates over the Data and Ty now has to do memoization by reference.

11am. Right now I am thinking how I am going to handle that.

...There is no way getting around it. I am going to have to ditch the elegant memoize and take care of the troublesome cases by hand.

11:05am. Forget about this. Let me do the types for the codegen.

11:35am. Ah, fuck. I am still thinking about the recursive memoizer. I am trying to find a way to simplify it, but I can't come up with anything.

Without a doubt, having cycles really makes things more difficult.

```
let keyword_env = string_to_keyword "env:" // For join points keys. It is assumed that they will never be printed.
let keyword_apply = string_to_keyword "apply:"
let keyword_key_value = string_to_keyword "key:value:"
let keyword_key_state_value = string_to_keyword "key:state:value:"
let keyword_text = string_to_keyword "text:"
let keyword_variable = string_to_keyword "variable:"
let keyword_literal = string_to_keyword "literal:"
let keyword_type = string_to_keyword "type:"
```

What is all this. Nevermind, I will remove this.

11:40am.

```
let typed_data_to_consed' call_data =
    let dict = Dictionary(HashIdentity.Reference)
    let call_args = ResizeArray(64)
    let rec f x =
        memoize dict (function
            | TyList l -> List.map f l |> ctylist
            | TyKeyword(a,b) -> (a,Array.map f b) |> ctykeyword
            | TyFunction(a,b,c) -> (a,b,Array.map f c) |> ctyfunction
            | TyRecFunction(a,b,c) -> (a,b,Array.map f c) |> ctyrecfunction
            | TyObject(a,b) -> (a,Array.map f b) |> ctyobject
            | TyMap l -> Map.map (fun _ -> f) l |> ctymap
            | TyV(T(_,ty) as t) -> call_args.Add t; CTyV (call_args.Count-1, ty)
            | TyBox(a,b) -> (f a, b) |> CTyBox
            | TyLit x -> CTyLit x
            | TyT x -> CTyT x
            ) x
    let x = f call_data
    call_args.ToArray(),x
```

As expected the very first function I have to do is this one.

Ok, I will handle it.

But I feel a bit bad about removing consed annotations.

I am going to do a little trick.

12pm.

```
        | TyFunction(b,c) ->
            let v_ar = Array.zeroCreate (snd c.value).Length
            let r = TyFunction(b,{c with value=fst c.value, v_ar})
            Array.iter (fu)
```

Holy shit, this is even more annoying than I thought it would be.

```
        | TyFunction(a,b,c,d,e) ->
            let e' = Array.zeroCreate e.Length
            let r = TyFunction(a,b,c,d,e')
            Array.iteri (fun i x -> e'.[i] <- f x) e
            r
```

Let me do it like this.

12:20pm.

```
// Memoizing map for cyclical structure
let inline memoize_rec (dict : Dictionary<_,_>) (e : _ []) ret f x =
    match dict.TryGetValue x with
    | true, v -> v
    | _ ->
        let e' = Array.zeroCreate e.Length
        let r = ret e'
        dict.Add(x,r)
        Array.iteri (fun i x -> e'.[i] <- f x) e
        r
```

```
/// Unlike v0.1 and previously, the functions can now have cycles so that needs to be taken care of during memoization.
let typed_data_to_renamed' call_data =
    let dict = Dictionary(HashIdentity.Reference)
    let call_args = ResizeArray(64)
    let rec f x =
        let memoize f = memoize dict f x
        let memoize_rec e ret f = memoize_rec dict e ret f x
        match x with
        | TyPair(a,b) -> memoize (fun _ -> TyPair(f a, f b))
        | TyKeyword(a,b) -> memoize (fun _ -> TyKeyword(a, Array.map f b))
        | TyFunction(a,b,c,d,e) -> memoize_rec e (fun e' -> TyFunction(a,b,c,d,e')) f
        | TyRecord l -> memoize (fun _ -> TyRecord(Map.map (fun _ -> f) l))
        | TyV(T(_,ty) as t) -> memoize (fun _ -> call_args.Add t; TyV(T(call_args.Count-1, ty)))
        | TyLit x -> memoize (fun _ -> TyLit x)
        | TyRef _ -> failwith "Compiler error"
    let x = f call_data
    call_args.ToArray(),x
```

This is so annoying, but I am into it. I wish I did not have to use `T` in `TyV`, but it will do.

...And I haven't done what this things asks which is use TyRef.

I've been thinking about the join point returns and have done the thing correctly as a result. Whops.

12:25pm. Forget it, I really need that break here."

---
## [mrakgr/The-Spiral-Language@2408e7f21a...](https://github.com/mrakgr/The-Spiral-Language/commit/2408e7f21a047a4215f5b5c3b6580c3cdbcd2b94)
##### 2020-01-23 15:08:37 by Marko Grdinić

"3:05pm. Damn this took a while. To make matters worse, it was not like I was doing anything in particular.

This is not like the time I was immersed in reading the last few weeks. Right now that I am in this programming mindset I can't really enjoy fiction as I usually would.

And yet, I do not feel like programming either. So it is the same as usual for me.

I'll get into it once I start.

First off, let me do the two main functions `ty_to_data` and `data_to_ty`. Then I will do those consing functions again, this time properly.

```
let rec destructure tyv_or_tyt x =
    let inline f x = destructure tyv_or_tyt x
    match x with
    | ListT x -> TyList(List.map f x.node)
    | KeywordT(C(a,l)) -> TyKeyword(a,Array.map f l)
    | FunctionT(C(a,b,l)) -> TyFunction(a,b,Array.map f l)
    | RecFunctionT(C(a,b,l)) -> TyRecFunction(a,b,Array.map f l)
    | ObjectT(C(a,l)) -> TyObject(a,Array.map f l)
    | MapT l -> TyMap(Map.map (fun _ -> f) l.node)
    | x -> tyv_or_tyt x

let rec tyv = function
    | ListT x -> TyList(List.map tyv x.node)
    | KeywordT(C(a,l)) -> TyKeyword(a,Array.map tyv l)
    | FunctionT(C(a,b,l)) -> TyFunction(a,b,Array.map tyv l)
    | RecFunctionT(C(a,b,l)) -> TyRecFunction(a,b,Array.map tyv l)
    | ObjectT(C(a,l)) -> TyObject(a,Array.map tyv l)
    | MapT l -> TyMap(Map.map (fun _ -> tyv) l.node)
    | LayoutT(C (_,_,true)) | UnionT _ | RecUnionT _ | MacroT _ | TermCastedFunctionT _ | PrimT _ as ty -> TyV(T(tag(), ty))
    | ArrayT(_,l) as ty -> if type_is_unit l then TyT ty else TyV(T(tag(), ty))
    | LayoutT _ as ty -> TyT ty

let rec tyt = function
    | ListT x -> TyList(List.map tyt x.node)
    | KeywordT(C(a,l)) -> TyKeyword(a,Array.map tyt l)
    | FunctionT(C(a,b,l)) -> TyFunction(a,b,Array.map tyt l)
    | RecFunctionT(C(a,b,l)) -> TyRecFunction(a,b,Array.map tyt l)
    | ObjectT(C(a,l)) -> TyObject(a,Array.map tyt l)
    | MapT l -> TyMap(Map.map (fun _ -> tyt) l.node)
    | ArrayT _ | LayoutT _ | UnionT _ | RecUnionT _ | MacroT _ | TermCastedFunctionT _ | PrimT _ as ty -> TyT ty
```

Did I forget to remove `destructure` or did I leave it in on purpose? I can't remember.

3:10pm. Focus me focus. Just do these functions. I'll think about the rest later.

This won't be done that easily. It will take me a while to get into the swing of things and go through all of this.

3:20pm.

```
let ty_to_data i t =
    let d = Dictionary(HashIdentity.Reference)
    let rec f = function
        | PairT(a,b) -> TyPair(f a, f b)
        | KeywordT(a,b) -> TyKeyword(a,Array.map f b)
        | FunctionT(a,b,c,d,e) -> TyFunction(a,b,c,d,Array.map f e)
```

Oh, this is already an interesting case. It might seem straightforward - one might say that I just need to memoize here, but...

The issue here is that I actually need to ignore references in the parallel parts I only have to memoize nested references.

Something like `join x,x` where `x` is a recursive function should not return the same thing everywhere.

3:35pm.

```
    | LayoutT(C (_,_,true)) | UnionT _ | RecUnionT _ | MacroT _ | TermCastedFunctionT _ | PrimT _ as ty -> TyV(T(tag(), ty))
    | ArrayT(_,l) as ty -> if type_is_unit l then TyT ty else TyV(T(tag(), ty))
    | LayoutT _ as ty -> TyT ty
```

Previously I had this checking whether something is a unit. This time I have no need for this sort of confusion at all.

3:40pm.

```
let ty_to_data i x =
    let m = Dictionary(HashIdentity.Reference)
    let rec f x =
        match x with
        | PairT(a,b) -> TyPair(f a, f b)
        | KeywordT(a,b) -> TyKeyword(a,Array.map f b)
        | FunctionT(a,b,c,d,e) ->
            match m.TryGetValue x with
            | true, v -> v
            | _ ->
                let e' = Array.zeroCreate e.Length
                let r = TyFunction(a,b,c,d,e')
                m.Add(x,r)
                Array.iteri (fun i x -> e'.[i] <- f x) e
                m.Remove(x) |> ignore // Non-nested mapping should not share vars
                r
        | RecordT l -> TyRecord(Map.map (fun k -> f) l)
        | PrimT _ | LayoutT _ | ArrayT _ | RuntimeFunctionT _ | MacroT _ -> let r = TyV(T(!i,x)) in i := !i+1; r
    f x
```

Here is the first of the bunch. This will do nicely.

What else is there? Let me go to the next one.

3:50pm.

```
open Spiral.Tokenize
open Spiral.Parsing
let value_to_ty = function
    | LitUInt8 _ -> PrimT UInt8T
    | LitUInt16 _ -> PrimT UInt16T
    | LitUInt32 _ -> PrimT UInt32T
    | LitUInt64 _ -> PrimT UInt64T
    | LitInt8 _ -> PrimT Int8T
    | LitInt16 _ -> PrimT Int16T
    | LitInt32 _ -> PrimT Int32T
    | LitInt64 _ -> PrimT Int64T
    | LitFloat32 _ -> PrimT Float32T
    | LitFloat64 _ -> PrimT Float64T
    | LitBool _ -> PrimT BoolT
    | LitString _ -> PrimT StringT
    | LitChar _ -> PrimT CharT
```

This advice of not putting types all in one module is really not working for me.

Can't I do selective imports of types?

Also that reminds me, in module open I've forgotten all about types.

Maybe later it might be good to add `open type` to the language?

4:05pm. Of, I am completely distracted.

```
open Spiral.Tokenize
open Spiral.Parsing
let value_to_ty = function
    | LitUInt8 _ -> PrimT UInt8T
    | LitUInt16 _ -> PrimT UInt16T
    | LitUInt32 _ -> PrimT UInt32T
    | LitUInt64 _ -> PrimT UInt64T
    | LitInt8 _ -> PrimT Int8T
    | LitInt16 _ -> PrimT Int16T
    | LitInt32 _ -> PrimT Int32T
    | LitInt64 _ -> PrimT Int64T
    | LitFloat32 _ -> PrimT Float32T
    | LitFloat64 _ -> PrimT Float64T
    | LitBool _ -> PrimT BoolT
    | LitString _ -> PrimT StringT
    | LitChar _ -> PrimT CharT

let data_to_ty x =
    let m = Dictionary(HashIdentity.Reference)
    let rec f x =
        let memoize f = memoize m f x
        let memoize_rec e ret f = memoize_rec m e ret f x
        match x with
        | TyPair(a,b) -> memoize (fun _ -> PairT(f a, f b))
        | TyKeyword(a,b) -> memoize (fun _ -> KeywordT(a, Array.map f b))
        | TyFunction(a,b,c,d,e) -> memoize_rec e (fun e' -> FunctionT(a,b,c,d,e')) f
        | TyRecord l -> memoize (fun _ -> RecordT(Map.map (fun _ -> f) l))
        | TyV(T(_,ty) as t) -> ty
        | TyLit x -> value_to_ty x
        | TyRef _ -> failwith "Compiler error"
    f x
```

Well, I did do this, but now I am asking questions such as 'how do I rename type variables in module open'.

Just like with keywords, I am going to have to assign tags to every nominal type just to make sure there is no confusion.

Agh. Let me take a little break here."

---
## [hanzohasashi33/Competetive_programming@8714fc57cf...](https://github.com/hanzohasashi33/Competetive_programming/commit/8714fc57cfe413add1027ee00d85ea08d3305f1f)
##### 2020-01-23 16:37:51 by Prasanna Venkatesh

Create Xor_Segment.py

All submissions for this problem are available.Xenon loves XORs and thus he has given his friend Subash a challenge to xor all values from L to R inclusive.
That is L⊕(L+1)⊕(L+2).....R=Z
Subash is on a date with his new girlfriend, will you be his helping hand to find Z?

---
## [Anskiy/jetsoftime@67d17b84aa...](https://github.com/Anskiy/jetsoftime/commit/67d17b84aaac93abfd94215d1b53eaaddb98916f)
##### 2020-01-23 17:28:54 by DevAnj2

Updated patch

Changelog:

-Fixed blue palette glitch with the courtiers at the Ocean Palace.

-Made Robo Tackle get bonus damage from Crisis Arm.

-Buffed the base power of Crono's Life to 16.

-Buffed the base power of Lucca's Flare to 50, the same as Luminaire.

-Buffed the base power of Magus' Dark Matter to 42, Flare's old base power.

-Made Magus learn 2 techs if found at Guardia Castle, 3 techs if found at Frog's Burrow, the Dactyl Nest, or Proto Dome.

-Buffed Magus(the boss)' HP to 6000, raised his physical defense to 153.

-Buffed Azala's HP to 2000.

-Buffed the base power of GreenDream's revive to 10.

-Buffed the TP of Goons to 25.

-Buffed the TP of Tubsters to 30.

-Nerfed the magic defense of Lavos Core's central bit to 35, so casters have a less bad time facing it.

---
## [trollbreeder/trollstation@327fbea568...](https://github.com/trollbreeder/trollstation/commit/327fbea568c84343df260e892024a25450af385d)
##### 2020-01-23 17:42:27 by trollbreeder

And god said, LET THERE BE LIGHT! In the brig.

Adds lighting fixtures to brig: how i missed this, i have no fucking clue.
May do stupid shit idk there's exclamation marks on the folders but nothing on the files

---
## [mmihaeladraghici/talks@e8d43a35ab...](https://github.com/mmihaeladraghici/talks/commit/e8d43a35ab07485ed661a739816804c481671018)
##### 2020-01-23 17:56:06 by mmihaeladraghici

Product Managers, to pair or not to pair?

Product Managers, to pair or not to pair?
Speaker : Mihaela Draghici
Available : first day, second day, third day
Length : 45 minutes
Language : English

Description
Just as, for engineers, pair programming means two engineers working together, PM pairing refers to two Product Managers working together as part of the same product team. 

However, there are little resources available regarding pairing for Product Managers. That's because it's not too common.

What does pairing really mean for PMs? How is it different from pair programming? Why is it great? Why does it suck? When is it good to pair? And more than that, how to make the most of it when you do pair?
 
I aim to share my lessons learned and tips & tricks about pairing for PMs (from own experience), to give you more insights on this topic.

Speaker Bio
A Romanian, with a British passport, living in Lisbon. Marketing girl, turned tech girl, building products that deliver happiness. Strong advocate for gender equality and inclusive work environments in tech industries.

Links
Company: https://www.linkedin.com/company/volkswagen-digital-solutions/
GitHub: https://github.com/mmihaeladraghici/
Photo: https://pbs.twimg.com/profile_images/1271157175/mihaela-draghici1_400x400.jpg
Extra Information
The purpose of this talk is to offer more information regarding pairing practices for Product Managers to to help:

those who have not heard of pairing for PMs, learn more about it;
those who have heard about it but have not considered pairing in their product teams: start considering it and weigh options around benefits for their products/business;
those who have tried it: open a conversation about advantages/disadvantages and exchange knowledge.
I have over 10 years of international work experience in digital marketing and product management. I have contributed to both small and large scale product initiatives to bring business value and worked closely with engineering teams, UX designers, localisation specialists as well as business stakeholders across regions. I am passionate about what I do, the products I've built and the people I work with. Since I have learned a lot throughout my career and benefited from great colleagues and mentors, I am looking to share my knowledge and give back to the community through talks, events & mentoring.

Some references to myself and my work:

https://www.facebook.com/GirlsinTechLondon/
https://www.youtube.com/watch?v=VSHNdMvXlUY
https://www.eventbrite.co.uk/e/getting-into-tech-tech-spectrum-panel-for-graduates-tickets-50451371410#
https://issuu.com/businesswomanclub/docs/april_digital_business_women_emagaz/60
https://www.eventbrite.co.uk/e/in-common-women-at-work-tickets-65778833261#
https://www.linkedin.com/pulse/10-things-i-love-being-product-manager-mihaela-draghici
https://performancein.com/news/2019/06/18/awin-thinktankuk-2019-and-future-proofing-affiliate-industry/

---

# [<](2020-01-22.md) 2020-01-23 [>](2020-01-24.md)

