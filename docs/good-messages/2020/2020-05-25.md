# [<](2020-05-24.md) 2020-05-25 [>](2020-05-26.md)

2,366,961 events, 1,197,416 push events, 1,862,108 commit messages, 121,307,341 characters


## [holybrunneis/stalmid.uno](https://github.com/holybrunneis/stalmid.uno)@[f00b0a56b8...](https://github.com/holybrunneis/stalmid.uno/commit/f00b0a56b8e69bbbe63da9aa4d2ccd81b1169b9b)
#### Monday 2020-05-25 05:16:27 by holybrunneis

do stupid fuckin url shit cus i am a big stupid idiot -donovan

---
## [nfagerlund/dw-free](https://github.com/nfagerlund/dw-free)@[5daf45a0b9...](https://github.com/nfagerlund/dw-free/commit/5daf45a0b96e10138c49b84b71919a81c5be8ef5)
#### Monday 2020-05-25 06:16:48 by Nick Fagerlund

[2650] Improved image shrinking, part three

We currently constrain the size of images in entry and comment content. But the
REASON we do this is so that people can casually post medium-sized images
and not stress about annoying their friends and readers; the beginning and end
of it is to make it easier to post on DW.

There's another set of user behaviors that's basically the OPPOSITE of casually
posting a medium image, where people express themselves by doing weird intricate
HTML shit no modern site would allow. It's part of DW's fandom-centric culture,
so we'd rather not interfere with it or make it harder.

This commit uses some extra javascript to try and guess which images are part of
a complex hunk of decorative / narrative markup, and changes the CSS to leave
said images alone (under the assumption that the author knows what they're
trying to accomplish and doesn't need any "help").

And while I'm at it, it also removes the "zoom in" cursor from images that are
already actual size and thus don't need to zoom. (That part uses an ultra-modern
API with stringent browser requirements, because 1. it's kind of just a vanity
thing, and 2. it has to update on window resize, but any tangible performance
cost is unacceptable, so if we can't do it for nearly-free then we shouldn't do
it at all. Native ResizeObserver is nearly-free, polyfills ain't.)

---
## [sug0/horizon](https://github.com/sug0/horizon)@[3f1c8b647e...](https://github.com/sug0/horizon/commit/3f1c8b647e041fce8cee6824b73e162f889e8ca2)
#### Monday 2020-05-25 06:50:31 by Tiago Carvalho

trying to use this package from discord but it fails so fuck you going to sleep

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[66b5908a0a...](https://github.com/mrakgr/The-Spiral-Language/commit/66b5908a0a0f806d851890d7280828375396ba5d)
#### Monday 2020-05-25 07:06:30 by Marko Grdinić

"7:50am. I am back and so has my mind returned to battle readiness. I've been thinking about my idea of propagating lazy values and decided against it after all.

I am going to go with intermediate nodes, but rather than what I talked about yesterday (ref count 2 nodes,) what I will do are attention modulated switches. One thing I am going to have to figure out is how to get `DistinctByKey` to use reference equality.

8am. Ah, let me try just that particular thing now.

```fsharp
Observable.single 1
|> Observable.distinctKeyCompare id
        {new Collections.Generic.IEqualityComparer<_> with
            member _.Equals(a,b) = a = b
            member _.GetHashCode(x) = hash x
            }
```

Yeah, as expected there is a way to get that functionality. It is no problem at all.

```
Collections.HashIdentity.Reference
```

Ah, I never realized it before, but this is literally an `IEqualityComparer`.

```
        Observable.single 1
        |> Observable.distinctKeyCompare id Collections.HashIdentity.Structural
```

So I can just swap this for the reference comparer wherever I need it. Great.

8:10am. This is great. Just last night I've been thinking how great it would be if I could pass `HashIdentity.Reference` into `Distinct` and as it turns out that is possible.

This is what I meant by reactive combinators being a neverending parade of joy.

8:15am. Now let me talk about those attention modulated switches.

As one could guess I am going to have the editor send me info on which file the user is editing. That is the attention part.

I meant to use lazy values to get efficiency, but what occurred to me is that lazy values would make it really difficult to abort the computation as it is going on. I want typechecking to switch on new info and file changes.

For me to have missed this while I was awake yesterday, I really must have been out of it. I even planned this, but forgot about it in the interim.

Reactive combinators are so great - there are just so many opportunities for abstraction and good design, and proving one's skill.

8:20am. The next thing on my list is something I should have done earlier. Let me open an issue for the spell checker.

8:40am. Er, I opened an PR for the reactive typo. There has been some activity there. I've committed myself to fixing the `switchMap` and `choose` after I finish the GUI examples.

Now the spellchecker.

8:50am. https://github.com/bartosz-antosik/vscode-spellright/issues/
Issue spell checking a "large" document

Somebody already did it. Issue 351.

Ok.

8:55am. Let me take a break here. Machimaho and that Looking Up To Magical Girls TL thread are waiting for me. Last night I was too tired to read them and went to bed at 8pm.

Let me slack here for a while, and then I will go into it full force. If possible it would be good if I could finish the ZeroMQ examples by the end of the month."

---
## [devksingh4/notus](https://github.com/devksingh4/notus)@[79de0bd760...](https://github.com/devksingh4/notus/commit/79de0bd76028e429e3910d8aba1d987a77b0b53c)
#### Monday 2020-05-25 07:09:34 by Jacob Levine

to whoever made me do occlusions, fuck you

you know who you are

Signed-off-by: Jacob Levine <jacoblevine18@gmail.com>

---
## [devksingh4/notus](https://github.com/devksingh4/notus)@[4f8a631974...](https://github.com/devksingh4/notus/commit/4f8a631974bc718accedbb5be931fd2d38ffb0c2)
#### Monday 2020-05-25 07:09:34 by Jacob Levine

stupid ai bc others didn't implement it

will be improved after the deadline. next time, let's actually
talk about schedules first and get this shit implemented before
1am the night of lol

Signed-off-by: Jacob Levine <jacoblevine18@gmail.com>

---
## [YashdalfTheGray/bingo](https://github.com/YashdalfTheGray/bingo)@[0fff729573...](https://github.com/YashdalfTheGray/bingo/commit/0fff729573371998d5015a7ec18772540adaeee9)
#### Monday 2020-05-25 07:48:11 by Yash Kulshrestha

removed all the stupid ass eslint-typescript bullshit, it's just trash

---
## [NixOS/nixpkgs](https://github.com/NixOS/nixpkgs)@[8cc8fa19d9...](https://github.com/NixOS/nixpkgs/commit/8cc8fa19d954b46a250e701dc205c3e945605946)
#### Monday 2020-05-25 09:05:24 by Emily

nixos/acme: change default keyType to ec256

Previously, the NixOS ACME module defaulted to using P-384 for
TLS certificates. I believe that this is a mistake, and that we
should use P-256 instead, despite it being theoretically
cryptographically weaker.

The security margin of a 256-bit elliptic curve cipher is substantial;
beyond a certain level, more bits in the key serve more to slow things
down than add meaningful protection. It's much more likely that ECDSA
will be broken entirely, or some fatal flaw will be found in the NIST
curves that makes them all insecure, than that the security margin
will be reduced enough to put P-256 at risk but not P-384. It's also
inconsistent to target a curve with a 192-bit security margin when our
recommended nginx TLS configuration allows 128-bit AES. [This Stack
Exchange answer][pornin] by cryptographer Thomas Pornin conveys the
general attitude among experts:

> Use P-256 to minimize trouble. If you feel that your manhood is
> threatened by using a 256-bit curve where a 384-bit curve is
> available, then use P-384: it will increases your computational and
> network costs (a factor of about 3 for CPU, a few extra dozen bytes
> on the network) but this is likely to be negligible in practice (in a
> SSL-powered Web server, the heavy cost is in "Web", not "SSL").

[pornin]: https://security.stackexchange.com/a/78624

While the NIST curves have many flaws (see [SafeCurves][safecurves]),
P-256 and P-384 are no different in this respect; SafeCurves gives
them the same rating. The only NIST curve Bernstein [thinks better of,
P-521][bernstein] (see "Other standard primes"), isn't usable for Web
PKI (it's [not supported by BoringSSL by default][boringssl] and hence
[doesn't work in Chromium/Chrome][chromium], and Let's Encrypt [don't
support it either][letsencrypt]).

[safecurves]: https://safecurves.cr.yp.to/
[bernstein]: https://blog.cr.yp.to/20140323-ecdsa.html
[boringssl]: https://boringssl.googlesource.com/boringssl/+/e9fc3e547e557492316932b62881c3386973ceb2
[chromium]: https://bugs.chromium.org/p/chromium/issues/detail?id=478225
[letsencrypt]: https://letsencrypt.org/docs/integration-guide/#supported-key-algorithms

So there's no real benefit to using P-384; what's the cost? In the
Stack Exchange answer I linked, Pornin estimates a factor of 3×
CPU usage, which wouldn't be so bad; unfortunately, this is wildly
optimistic in practice, as P-256 is much more common and therefore
much better optimized. [This GitHub comment][openssl] measures the
performance differential for raw Diffie-Hellman operations with OpenSSL
1.1.1 at a whopping 14× (even P-521 fares better!); [Caddy disables
P-384 by default][caddy] due to Go's [lack of accelerated assembly
implementations][crypto/elliptic] for it, and the difference there seems
even more extreme: [this golang-nuts post][golang-nuts] measures the key
generation performance differential at 275×. It's unlikely to be the
bottleneck for anyone, but I still feel kind of bad for anyone having
lego generate hundreds of certificates and sign challenges with them
with performance like that...

[openssl]: https://github.com/mozilla/server-side-tls/issues/190#issuecomment-421831599
[caddy]: https://github.com/caddyserver/caddy/blob/2cab475ba516fa725d012f53ca417c3e039607de/modules/caddytls/values.go#L113-L124
[crypto/elliptic]: https://github.com/golang/go/tree/2910c5b4a01a573ebc97744890a07c1a3122c67a/src/crypto/elliptic
[golang-nuts]: https://groups.google.com/forum/#!topic/golang-nuts/nlnJkBMMyzk

In conclusion, there's no real reason to use P-384 in general: if you
don't care about Web PKI compatibility and want to use a nicer curve,
then Ed25519 or P-521 are better options; if you're a NIST-fearing
paranoiac, you should use good old RSA; but if you're a normal person
running a web server, then you're best served by just using P-256. Right
now, NixOS makes an arbitrary decision between two equally-mediocre
curves that just so happens to slow down ECDH key agreement for every
TLS connection by over an order of magnitude; this commit fixes that.

Unfortunately, it seems like existing P-384 certificates won't get
migrated automatically on renewal without manual intervention, but
that's a more general problem with the existing ACME module (see #81634;
I know @yegortimoshenko is working on this). To migrate your
certificates manually, run:

    $ sudo find /var/lib/acme/.lego/certificates -type f -delete
    $ sudo find /var/lib/acme -name '*.pem' -delete
    $ sudo systemctl restart 'acme-*.service' nginx.service

(No warranty. If it breaks, you get to keep both pieces. But it worked
for me.)

(cherry picked from commit 62e34d1c87ee8436bfa8ceaeac07ea3855fabd43)

---
## [haasn/libplacebo](https://github.com/haasn/libplacebo)@[6076fcafa1...](https://github.com/haasn/libplacebo/commit/6076fcafa19552c55fbed331adc5418723892827)
#### Monday 2020-05-25 09:38:54 by Niklas Haas

vulkan: add pNext chain boilerplate for physical device features

We now "officially" support enabling arbitrary extra device features,
including both features request by the user and features needed by us.

It's about time for me to write the shitty boilerplate to link and
memdup chains and stuff. Using generated code to get the sizeof()
unknown structs, because how the heck else would you copy over a pNext
chain while only modifying the values you care about?

Still using shitty hacks for the features whitelisting. I hope they
never change the structure of these arrays as just being a list of
VkBool32 values. (But in theory we could just generate code for this, in
the worst case....)

---
## [sszigeti/Stalkerlike](https://github.com/sszigeti/Stalkerlike)@[e166e10c3f...](https://github.com/sszigeti/Stalkerlike/commit/e166e10c3f0830267f8c571ae00d4d49e3f40491)
#### Monday 2020-05-25 15:18:50 by Sandor Szigeti

Manual recovery after git merge DISASTER

Git wasn't able to merge my feature branch back into master. Unless my evil twin has modified the master branch without my approval and knowledge, I fail to understand why git had to randomly rewrite my code, destroying it.
After some failed manual merge attempts I've deleted master and copied the files over from the feature branch, and hope that it will work. Is the Universe telling me to fuck off and die already?

---
## [savonet/liquidsoap](https://github.com/savonet/liquidsoap)@[27f948606a...](https://github.com/savonet/liquidsoap/commit/27f948606a0908356f50f1a8247fa67b87d8a96c)
#### Monday 2020-05-25 16:36:58 by Samuel Mimram

Compute kinds by unification in order to get rid of types during evaluation. (#1202)

Remove all types at execution.

The typing phase is left unchanged but after that we don't mention types anymore. The reasons why it is a good thing are that

- this speeds up execution (execution times x3 higher because we don't have to maintain types - which is quite costly, for instance each time we use a variable we have to instantiate its type which requires going through the whole type and copying it, each time we apply a function we have to perform unification, etc.)
- the kernel is simpler: for instance generalization had to consider all types occurring in all terms, whereas we can simply consider the type of the current term now, as usual
- the kernel of the language is smaller and thus safer and more modular
- as a particular cas of the above point, I needed this in for record (#1197) which would be hell to implement otherwise.
The only place where types were needed are in order to compute the number of (audio/video/midi) channels to produce for operators. This is now inferred by unification when creating the operators (I use the same mechanism than for clocks). The PR also simplifies much the typing of channels: they roughly all have the same type whereas we had something mildly different to type frame kinds and source kinds, etc. We could go even further, but I didn't want to ruin the readability of this PR.

The downside. We essentially do the work twice: we check that the typing of channels is correct at typing time, and once again at runtime. In my opinion, this could be entirely removed from typing, since unification is performed right at the beginning of the execution of the program which is roughly the same as typing phase. The only difference is for dynamically created sources, but those aren't used much (for now). And there is no reason to incorporate the number of channels in typing, but not say size of images, samplerate, etc. Let's keep that at runtime. I did not remove it for now because our users are "used" to the current types source('a,'b,'c) (to be honest, I am not even sure of that: many of them would simply prefer source...)

---
## [hikuii/android_kernel_samsung_smdk4412](https://github.com/hikuii/android_kernel_samsung_smdk4412)@[44feb83c42...](https://github.com/hikuii/android_kernel_samsung_smdk4412/commit/44feb83c422ad156b4f4942b40d8f64187a43f9c)
#### Monday 2020-05-25 18:28:36 by leewp14

mali400: reconfigure GPU (3)

Raise step 1 (L0) frequency again, up to 533MHz.

Some personal notes here:
The problem now is, the animation load on Android 10 is very high (probably due to n7000's 720p resolution), it consumes nearly 100% both CPU cores at maximum frequency. The GPU misses frames like drinking glasses of water.
At this stage, anything that could be done to further improve the graphic performance is very unlikely to be 'release quality'. It is most likely that the final build is only for my personal use.
Guess n7000 has reached its limits on Android 10. It is day and night difference compared to Android 9. Really. Bet that current kernel configuration runs smooth as hell on Android 9.

---
## [Evilgrill/rpg](https://github.com/Evilgrill/rpg)@[7be7b5037d...](https://github.com/Evilgrill/rpg/commit/7be7b5037dd7085a8e90b07338f49fbd77a730dd)
#### Monday 2020-05-25 19:16:32 by grill

add zone 1 act opening trigger in map_rpg.vmap

add spawn, act opening pic, sound and text in spawn.lua but it is still not in CSS box

remove low ground in zone 1 in map_rpg.vmap

unleash hell in brood toxin max stacks from 20 > 12/8/4.

make venge bubble unit to have no attack and no movement capabilities(old code it can attack and move but restricted new code it can't from the start).

change boss spellhaste debuff from flat to percent.

buff venge quake more slow from 10/13/16 to 10/15/20, 0.3s ministun per pulse and will now shake the screen a little bit.

another attempt to remove vine thinker in treant hook.

make luna curse, wax wane now use different icons from the skills themselves.

add 3 girls boss to require.lua.

add brief description of new spellhaste system in item_example.lua

add boss reset position and aggro tied to modifier creep scaling in if boss

---
## [Paxilmaniac/tgstation](https://github.com/Paxilmaniac/tgstation)@[a65408e2cf...](https://github.com/Paxilmaniac/tgstation/commit/a65408e2cfba098cb8a79f64cfcb7a41ab9088e4)
#### Monday 2020-05-25 20:34:24 by Paxilmaniac

holy shit how did i not see how underpowered this is

good god why didnt i actually test this against people

---
## [EOBGames/tgstation](https://github.com/EOBGames/tgstation)@[2990643910...](https://github.com/EOBGames/tgstation/commit/2990643910ee788540ee875b034a418e6bc7432c)
#### Monday 2020-05-25 22:09:50 by LemonInTheDark

ADDS SPEED (#12)

* FUCK FUCK FUCK SHIT I BROKE IT AGAIN

* Kills my dreams in the NAME OF SPEED

* and some cleanup

---
## [BhavanaLalwani/Text-Sentiment-Analysis](https://github.com/BhavanaLalwani/Text-Sentiment-Analysis)@[8b6a518154...](https://github.com/BhavanaLalwani/Text-Sentiment-Analysis/commit/8b6a518154a7ae62a50ccab6010f7c23455df97e)
#### Monday 2020-05-25 23:24:12 by Bhavana Vijay Lalwani

Text-Sentiment-Analysis (Python)

The emotion in the text is recognized using Natural Language Processing and Deep Neural Networks. The emotion labels identified are joy, anger, sadness, guilt, fear, shame and disgust.

---

# [<](2020-05-24.md) 2020-05-25 [>](2020-05-26.md)

