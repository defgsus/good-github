# [<](2020-04-16.md) 2020-04-17 [>](2020-04-18.md)

162,993 events, 88,853 push events, 142,100 commit messages, 12,116,485 characters


## [diesel-rs/diesel](https://github.com/diesel-rs/diesel)@[8e1a934d5f...](https://github.com/diesel-rs/diesel/commit/8e1a934d5f049a6c5fb5fa251fa5157e804ea25f)
#### Friday 2020-04-17 22:10:45 by Sean Griffin

Replace `NonAggregate` with something less broken

This commit implements the proposal laid out at
https://discourse.diesel.rs/t/proposed-change-replace-nonaggregate-with-something-less-broken-that-can-support-group-by/18.

The changes made in this commit now correctly enforce semantics around
the mixing of aggregate/non-aggregate expressions, and lays the
foundations required for full `GROUP BY` support in the future. This
commit does not implement `GROUP BY` as a feature in public API, though
I have added some minimal support to prove the soundness of the change.

Since this will likely be the largest breaking change in 2.0, I am going
to include as much detail as I can about the problem, the reasoning
behind the solution, and the likely impact of the change.

Recap of the problem
----

`NonAggregate` was originally introduced in
c66d96fa9cefaba0a418834e8cb0e78a0a87269a. The goal was to prevent the
following error at compile time:

   [local] sean@sean=# select count(*), name from users;
   ERROR:  42803: column "users.name" must appear in the GROUP BY clause or be used in an aggregate function

I didn't think about this nearly as much as I should have at the time,
which resulted in a hilariously broken implementation that has prevented
the addition of `group_by` support, and left bugs in the codebase for
more than 4 years.

At the time I was focused on "mixing aggregate and non-aggregate
expressions in a select statement". Since select uses tuples to
represent multiple values, I added a trait to represent non-aggregate
values, added it as a bound for `impl Expression for AnyTuple`, and
called it a day. This had a number of problems.

The most obvious was that it prevented valid queries involving multiple
aggregate expressions. At the time I figured we'd have a separate
trait for aggregate expressions, and then `impl Expression for AnyTuple
where AllFields: NonAggregate | AllFields: Aggregate`. This eventually
led to [RFC #1268](https://github.com/rust-lang/rfcs/pull/1268), which
doesn't seem likely to be stabilized soon, and even if it were we still
have the other issues with this solution.

The next issue is that you cannot say whether a given expression is
aggregate by looking at it on its own. The answer to "Is `users`.`name`
aggregate?" depends on whether or not that column appears in the group
by clause. So any trait which correctly handles this must be generic
over the group by clause, or it cannot be correctly implemented for
columns.

However, the most egregious issue with that commit is that it does not
handle *any* composite expressions besides tuples. Even today,
`.select((count_star(), id))` fails, but `.select(count_star() + id)`
will compile (and either error at runtime or give non-deterministic
results depending on your backend).

User Impact
----

This change will unfortunately have more breakage than I had
anticipated. That said, the breakage only affects *extremely* generic
code, and I do not believe that the majority of our users will notice or
care about this change.

There are three main ways in which the breakage will affect users:

- The additional bound on `SelectStatement<...>: SelectDsl` and
  `SelectStatement<...>: Query`.
  - This one broke our test suite in a few places, mainly where we have
    *really* generic code to say "I can select T.eq(sql_string)". I do
    not believe this is representative of real code.
  - I did a GitHub-wide search of all occurances of
    `SelectableExpression` (which is *not* the bound on the public API,
    but is the bound on `SelectStatement`'s impl, and would point to
    broken code). I found one repo which is relying on internals that
    will break, and a lot of results from Wundergraph. I didnt' look at
    those. This probably breaks Wundergraph. Sorry, Georg. It should be
    easy to fix I promise.
- `NonAggregate` can no longer be directly implemented
  - I did a GitHub-wide search for `NonAggregate`. With one exception,
    every repo implementing this trait directly was on pre-1.0. The only
    affected repo is manually implementing `Expression` instead of using
    `#[derive(AsExpression)]`. With that change they will be
    future-proofed.
- `T: NonAggregate` no longer implies `(OtherType, T): NonAggregate`
  - This broke `infer_schema`, since it was relying on `AssocType:
    NonAggregate` to know `(known_column, AssocType, known_column):
    Expression`. Ironically, that's no longer important, it did still
    break due to the first item on this list. I could not find any code
    in the wild that fell into this category.

Originally I thought that the only code which would be affected by this
is code that wrote `impl NonAggregate`, since that code would need to
change to `impl ValidGrouping`. However, I missed a few things when I
made that assessment.

The first is that... Well the feature exists. The whole point of this
was to prevent `aggregate + non_aggregate` from compiling when passed to
select, which implies a new trait bound *somewhere*. While
`SelectStatement` and its impls are private API, it's really easy to
couple yourself ot the bounds on those impls. It doesn't help that
`rustc` literally recommends that folks do that when errors occur. Any
code that is written as `Foo: SelectDsl<Selection>` will be fine, but
any code that's gone down the rabbit hole and has copied the bounds from
`impl SelectDsl for SelectStatement<...>` will break. I didn't find many
cases in the wild, but I do think it's relatively common.

The second thing I missed is that "is this aggregate" is not a binary
question. Originally I expected we would have two answers to the
question, and compound expressions would enforce that their
sub-expressions all had the same answer. The issue is that `1` doesn't
care. You can have `count(*) + 1`, and you can also have `non_aggregate
+ 1`. `1` is always valid, regardless of aggregation. So we need three
answers. The problem is that this means we can't have `T: NonAggregate`
mean everything it used to.

On stable `T: NonAggregate` will mean `T: ValidGrouping<()>`, and that
`T` can be passed to everything with a `NonAggregate` bound (`filter`,
`order`, etc). On nightly, it also implies `T::IsAggregate:
MixedAggregates<is_aggregate::No, Output = is_aggregate::No>`. In
English, it implies that this is valid with no group by clause, and its
output can appear with an expression which is not aggregate (but might
be with a different group by clause). The outcome of this is that `T:
NonAggregate` implies `(T, Other): NonAggregate`. However the missing
link from both stable and unstable is `is_aggregate::No:
MixedAggregates<T::IsAggregate>` being implied, which would mean
`(Other, T): NonAggregate` would be implied.

Ultimately this is a really long-winded way of saying that `T:
NonAggregate` used to imply interactions with other types. That is no
longer consistently true. It's unlikely there are many affected users,
but any that are affected will need to directly have a `ValidGrouping`
bound.

Implementation Notes
---

Because this broke diesel_infer_schema, I had to do a version bump to
get that crate to rely on the released 1.4.

There's a note on the unsoundness of the `NonAggregate` impl of
`Subselect`. I haven't changed the bounds on that impl, but we almost
certainly should address it before 2.0 is released.

I opted to validate the new bound in `SelectDsl`, so folks get errors on
`.select` instead of `.load`. We can't validate this on calls to both
`.select` *and* `.group_by`, since a select statement valid with a group
by is often invalid without one, and a group by clause usually makes the
default select clause invalid.

While this commit does not add proper group by support, I fleshed it out
a bit to test the type constraints. Right now a column only considers
itself valid if there is no group by clause, or if the group by clause
is exactly that column.

I had more to say but I went on a call and lost my train of thought. I
need to come back and finish writing this later.

Notable Limitations
---

`SELECT lower(name) FROM users GROUP BY lower(name)` probably can't be
represented.

Unanswered Questions
---

`BoxableExpression` has been limited to only work when there's no
group by clause, and only work with types which are `is_aggregate::No`.
This is probably not what we want to do, but was the smallest change to
start.

---
## [mpv-player/mpv](https://github.com/mpv-player/mpv)@[ab201ce042...](https://github.com/mpv-player/mpv/commit/ab201ce04235e61534b1070cc49ea455a8296e26)
#### Friday 2020-04-17 22:19:41 by wm4

sd_lavc: mitigate evil rounding issue that could lead to off-by-1 frames

A mkv sample file was provided to me, which contained a moving PGS
subtitle track, with the same track rendered into the video as
reference. The subtitle track appeared to stutter (while the video one
was smooth). It turns out this was a timestamp rounding issue in mpv.

The subtitle timestamps in the file match the video ones exactly.
They're the same within the mpv demuxer too. Unfortunately, the
conversion from and to libavcodec timestamps is lossy, because mpv uses
a non-integer timebase, while libavcodec supports integers only. See
mp_pts_to_av() and mp_pts_from_av(). The recovered timestamp is almost
the same, but is off by a very minor part. As a result, the timestamps
won't compare equal, and if that happens, display of the subtitle frame
is skipped. Subtitle timestamps don't go through this conversion
because... libavcodec is special? The libavcodec subtitle API is
special.

Fix this by giving it a microsecond of slack. This is basically as if we
used an internal microseconds integer timebase, but only for the purpose
of image subtitle display.

The same could happen to sd_ass, except in practice it doesn't. ASS
subtitles (well, .ass files) inherently use a timebase incompatible to
video, so to ensure frame exactness, ASS timestamps are usually set to
slightly before the video frame's.

Discussion of better solutions:

One could rewrite mpv not to use float timestamps. You'd probably pick
some integer timebase instead (like microseconds), which would avoid the
libavcodec interop issue. At the very least this would be a lot of work.

It would be interesting to know whether the rounding in ther mpv<->lavc
timestamp conversion could be fixed to round-trip in this case. The
conversion tries to avoid problems by using the source timebase (e.g.
milliseconds with mkv). But in general some rounding is unavoidable,
because something between decoder and lowest demuxer layer could
transform the timestamps.

One could extend libavcodec to attach arbitrary information to avpacket
and return it in the resulting avframe. To some degree, such a mechanism
already exists (side data). But there are certain problems that make
this unfeasible and broken.

One could pass through exact mpv float timestamps by reinterpret-casting
them to int64_t, the FFmpeg timestamp type. Actually mpv used to do
this. But there were problems, such as FFmpeg (or things used by FFmpeg)
wanting to interpret the timestamps. Awful shit that make mpv change to
the current approach.

There's probably more but I'm getting bored. With some luck I wasted
precious seconds of your life with my nonsense.

---
## [mpv-player/mpv](https://github.com/mpv-player/mpv)@[a09c7691d7...](https://github.com/mpv-player/mpv/commit/a09c7691d7ecaf49666d16f5276b9e7a14197c37)
#### Friday 2020-04-17 22:19:41 by wm4

draw_bmp: silence another ridiculous ubsan warning

UB sanitizer complains that aval<<24 (if >=128) cannot be represented as
int. Indeed, we would shift a bit into the sign of an int, which is
probably UB or implementation defined (I can't even remember, but the
stupidity of it burns). So technically, ubsan might be right.

Change aval to uint32_t, which I don't think has a chance of getting
promoted to int. Change the other *val to uint32_t too for cosmetic
symmetry.

So we have to obscure the intention of the code (*val can take only 8
bits) out of language stupidity. How nice. (What a shitty language.)

---
## [Awbz/OneLife](https://github.com/Awbz/OneLife)@[ad723e6257...](https://github.com/Awbz/OneLife/commit/ad723e625702d97b77a99912ed657cf4587734f3)
#### Friday 2020-04-17 22:58:16 by Jason Rohrer

If your last life was a short life (currently under 10 years, a live server setting), then you are not counted toward posse size when you join a posse.  This prevents people from die-cycling to find their friends and then gang up on people to kill them.  You earn the right to join a posse by surviving through childhood in your previous life.  This is similar to the twin restriction on being counted toward a posse.  People who are die-cycling to find each other are essentially non-identical twins.

---
## [Kerbalism/Kerbalism](https://github.com/Kerbalism/Kerbalism)@[d3dbc343ab...](https://github.com/Kerbalism/Kerbalism/commit/d3dbc343ab0adfa0597eeeca567a82b5c26ffa0b)
#### Friday 2020-04-17 23:16:43 by Gotmachine

Radiation handling refactor + other changes

Radiation refactor :
- Parts that have modules implementing IRadiationReceiver get their radiation evaluated.
- All parts that are heavy and "blocky" enough act as radiation occluders against emitters and solar storm radiation, but not against "ambiant" radiation. Occluding "force" is determined based on :
  > The part intrinsic "wall thickness" derived from the part mass and volume.
  > The part resources amount, according to the resource amount and density
  > Resources can have a HVL definition (see settings) to define their occluding capacities (ex : shielding) and if they are "wall" occlusion or "going trough" occlusion
- Modules can implement IRadiationEmitter causing their radiation to be evaluated for all IRadiationReceiver parts
- All emitters are raytraced to all receivers, taking in-between occluder parts into account, using a simplified sphere-based raytracing system
- Receivers that are also occluders protect themself from "ambiant" radiation (bodies, belts...) based on half their wall thickness (non "wall" resource are ignored)
- Solar storm radiation is raytraced to every receiver, using the same sphere based occlusion system but with a different set of HVL values to simulate the higher energy of particule based radiation, and generating a bremsstrahlung effect
- Magnetic coils generate a capsule shaped magnetic field when placed in a radial array. All receivers enclosed in the field have the radiation they receive reduced, regardless of the source.
  > You need at least 2 coils to provide the effect.
  > An array must be "charged" using a massive amount of EC. radiation protection depend on the charge level.
  > An array can be discharged to recover the stored EC. Consequently, it can act as a very high capacity battery.
  > Some charge is continuously lost, in proportion of the charge level
  > Parts that are partially enclosed in the field may get partially protected, we check the part center and every stack attach node and scale the effect based on how many of these points are enclosed.
- This is still very WIP, and there has been very little balancing done (the coils in particular).

Other changes :
- The loader now use ModuleManagerPostLoad() MM-called method instead of the OnGameDatabaseLoaded KSP event.
- Refactored the calendar evaluation, fixed potential issues when dealing with "non-round" days and years.
- We now get the correct hoursInDays and DaysInYear value immediatly on ModuleManagerPostLoad to allow correct values to be displayed in part tooltips.
- Config durations use config defined values (see settings.cfg) to make sure we stay consistent no matter what the actual calendar is.
- Config option to use the KSP main menu settings (Kerbin time / Earth time) instead of the "real" values derived from the home body orbital parameters
- Reinstored a partdata persistence system and editor <> flight persistence, refactored the ParDataCollection handling around a base abstract class
- Introduced a fixed update cycle in Vesseldata that call OnFixedUpdate(double elapsedSec) on all ModuleDatas in the vessel (loaded/unloaded/editor agnostic)
- Introduced a central early "all parts, all modules" iteration in VesselData.
- Introduced a OnStart() virtual method called on all ModuleData when the module is instantiated, or when the vessel becomes simulated.
- Added a PartResourceData list stored in PartData, holding a PartVirtualResource that derive from VesselVirtualResource.
  > Unlike the non-persisted VesselVirtualResource, a PartVirtualResource is persisted on a per part amount/capacity basis.
  > This more or less replicate the behavior of a standard KSP resource (minus the mass and cost).
  > Currently used for the radiation coils charge.
  > Implementation is very WIP and probably has some issues : capacity desynchronization, and lifecycle management is quite clunky and could use a refactor (I really did this quick and dirty).
- Reorganization of the science configs (again, hopefully for good this time), fixed the goo and matbay not having any private drive

TODO / WIP :
- There is still some refactoring that need to be done regarding the VesselData core update cycle.
- VesselDataShip (editor) is a mess and lack the implementation of many of the recent changes
- The radiation system is missing a few features (inter-vessel / EVA evaluation, implementation of a global occluder database, handling of "wall" occluders...)
- The passive radiation shield doesn't really make sense anymore as it is, and need a refactor
- Radiation-based reliability will need a refactor (but reliability as a whole need to be migrated to KsmPartModules anyway)
- The radiation coils don't have any automation feature currently. Also, we might want to implement charge loosing during radiation storms.

---
## [cameled/linux](https://github.com/cameled/linux)@[c0d0381ade...](https://github.com/cameled/linux/commit/c0d0381ade79885c04a04c303284b040616b116e)
#### Friday 2020-04-17 23:54:13 by Mike Kravetz

hugetlbfs: use i_mmap_rwsem for more pmd sharing synchronization

Patch series "hugetlbfs: use i_mmap_rwsem for more synchronization", v2.

While discussing the issue with huge_pte_offset [1], I remembered that
there were more outstanding hugetlb races.  These issues are:

1) For shared pmds, huge PTE pointers returned by huge_pte_alloc can become
   invalid via a call to huge_pmd_unshare by another thread.
2) hugetlbfs page faults can race with truncation causing invalid global
   reserve counts and state.

A previous attempt was made to use i_mmap_rwsem in this manner as
described at [2].  However, those patches were reverted starting with [3]
due to locking issues.

To effectively use i_mmap_rwsem to address the above issues it needs to be
held (in read mode) during page fault processing.  However, during fault
processing we need to lock the page we will be adding.  Lock ordering
requires we take page lock before i_mmap_rwsem.  Waiting until after
taking the page lock is too late in the fault process for the
synchronization we want to do.

To address this lock ordering issue, the following patches change the lock
ordering for hugetlb pages.  This is not too invasive as hugetlbfs
processing is done separate from core mm in many places.  However, I don't
really like this idea.  Much ugliness is contained in the new routine
hugetlb_page_mapping_lock_write() of patch 1.

The only other way I can think of to address these issues is by catching
all the races.  After catching a race, cleanup, backout, retry ...  etc,
as needed.  This can get really ugly, especially for huge page
reservations.  At one time, I started writing some of the reservation
backout code for page faults and it got so ugly and complicated I went
down the path of adding synchronization to avoid the races.  Any other
suggestions would be welcome.

[1] https://lore.kernel.org/linux-mm/1582342427-230392-1-git-send-email-longpeng2@huawei.com/
[2] https://lore.kernel.org/linux-mm/20181222223013.22193-1-mike.kravetz@oracle.com/
[3] https://lore.kernel.org/linux-mm/20190103235452.29335-1-mike.kravetz@oracle.com
[4] https://lore.kernel.org/linux-mm/1584028670.7365.182.camel@lca.pw/
[5] https://lore.kernel.org/lkml/20200312183142.108df9ac@canb.auug.org.au/

This patch (of 2):

While looking at BUGs associated with invalid huge page map counts, it was
discovered and observed that a huge pte pointer could become 'invalid' and
point to another task's page table.  Consider the following:

A task takes a page fault on a shared hugetlbfs file and calls
huge_pte_alloc to get a ptep.  Suppose the returned ptep points to a
shared pmd.

Now, another task truncates the hugetlbfs file.  As part of truncation, it
unmaps everyone who has the file mapped.  If the range being truncated is
covered by a shared pmd, huge_pmd_unshare will be called.  For all but the
last user of the shared pmd, huge_pmd_unshare will clear the pud pointing
to the pmd.  If the task in the middle of the page fault is not the last
user, the ptep returned by huge_pte_alloc now points to another task's
page table or worse.  This leads to bad things such as incorrect page
map/reference counts or invalid memory references.

To fix, expand the use of i_mmap_rwsem as follows:
- i_mmap_rwsem is held in read mode whenever huge_pmd_share is called.
  huge_pmd_share is only called via huge_pte_alloc, so callers of
  huge_pte_alloc take i_mmap_rwsem before calling.  In addition, callers
  of huge_pte_alloc continue to hold the semaphore until finished with
  the ptep.
- i_mmap_rwsem is held in write mode whenever huge_pmd_unshare is called.

One problem with this scheme is that it requires taking i_mmap_rwsem
before taking the page lock during page faults.  This is not the order
specified in the rest of mm code.  Handling of hugetlbfs pages is mostly
isolated today.  Therefore, we use this alternative locking order for
PageHuge() pages.

         mapping->i_mmap_rwsem
           hugetlb_fault_mutex (hugetlbfs specific page fault mutex)
             page->flags PG_locked (lock_page)

To help with lock ordering issues, hugetlb_page_mapping_lock_write() is
introduced to write lock the i_mmap_rwsem associated with a page.

In most cases it is easy to get address_space via vma->vm_file->f_mapping.
However, in the case of migration or memory errors for anon pages we do
not have an associated vma.  A new routine _get_hugetlb_page_mapping()
will use anon_vma to get address_space in these cases.

Signed-off-by: Mike Kravetz <mike.kravetz@oracle.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Cc: Michal Hocko <mhocko@kernel.org>
Cc: Hugh Dickins <hughd@google.com>
Cc: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
Cc: "Aneesh Kumar K . V" <aneesh.kumar@linux.vnet.ibm.com>
Cc: Andrea Arcangeli <aarcange@redhat.com>
Cc: "Kirill A . Shutemov" <kirill.shutemov@linux.intel.com>
Cc: Davidlohr Bueso <dave@stgolabs.net>
Cc: Prakash Sangappa <prakash.sangappa@oracle.com>
Link: http://lkml.kernel.org/r/20200316205756.146666-2-mike.kravetz@oracle.com
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

---

# [<](2020-04-16.md) 2020-04-17 [>](2020-04-18.md)

