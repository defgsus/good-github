# [<](2020-02-02.md) 2020-02-03 [>](2020-02-04.md)

2,085,005 events, 1,047,679 push events, 1,647,172 commit messages, 126,113,988 characters


## [Yokinman/NTTE@010e17ef47...](https://github.com/Yokinman/NTTE/commit/010e17ef47543fd3d6154f8efac30f191c218cea)
##### 2020-02-03 03:42:22 by Yokin

desert supreme
temenu.mod.gml
+ New file, contains NTTE's menu and loadout crown code from ntte.mod.gml and teassets.mod.gml

Scorpion City
+ Spawns a few little scorpion nest rooms
+ Now deletes isolated walls
~ Scorpions replace enemies based on their size, small enemies are replaced by babies and are less likely to be gold
~ Now only spawns on the level right after you get a scorpion pet, 100% chance
~ Big maggot nest scorpion drop chance upped from 50% to 100%
- Enemies on b-floors can't get replaced by scorpions
- Gold baby scorpions now only spawn during this event

Bandit Camp
+ Cowboy synergy with Scorpion City
~ Reduced loop spawn chance on subareas 1-1 and 1-2 from 1/10 to 1/20

Maggot Park
+ Added 1 big maggot nest, so it's back to 3
+ Spawns a few burrowed big maggots that pop up when you come near
+ Floor area generates more tendril-like now
~ Spawn chance is now 1/60
~ Now only uses b-style floors
~ Spawns less maggot nests
~ Normal maggot nests can't get replaced by big ones during the event
- Doesn't scale with loop anymore

Big Maggot Nest
+ Alert for the rare L0 fly
~ Reduced health from 50 to 42
~ Now spawns maggots every 3 lost HP instead of 2
* Now ensures its maggoty ambience sound stops when it dies

Scorpion Rock
+ Becomes friendly after all enemies on the level are dead
- Doesn't spawn friendly based on the player's HP anymore, and now only spawns before subarea 3

Wall Bandit
~ Now uses a TopPot object instead of a TopDecalDesert so it doesn't spawn wall cacti
* Doesn't stare at invisible players (player went through the portal)

Coast
~ Reduced Pelican health from 50 to 45
~ Reduced Diver health from 12 to 10
~ Messed with Seal King's seal spawning alert indicators a bit

Crown of Bonus
* Moved pickup replacement code to a script_bind_step to fix the 1 frame normal pickup flash
* Overheal mimics now use the health mimic tell sound

Backpack
+ The rare ally/bandit drops now get a cool alert indicator

Weapon Mimic
* Fixed only the shotgun variant spawning

Misc
+ floor_fill_set_center() script to further help work with the awful floor & wall system of the nuclear throne game
~ PortalPrevent now uses a "becomenemy" object instead of a "CustomEnemy"
* Fixed enemy_shoot_ext not supporting CustomSlashes

---
## [Chris-plus-alphanumericgibberish/dNAO@81ae7d2bd7...](https://github.com/Chris-plus-alphanumericgibberish/dNAO/commit/81ae7d2bd7f3e0048a2fc259f56f0a941e8de473)
##### 2020-02-03 05:09:07 by ChrisANG

Sanity, Madness, and general Lovecraftian update

Android quest has
-More android variants
-Handling for the fact that, logically, a death ray would kill the parasite but not the non-living host.

Trephination kits in Caveman and Healer quests

Boxes full of crazy (daughters of Bedlam) in the Convict quest.

The Dark Pharaoh (Hmnyw-Pharaoh) and the Good Neighbor added as Nyar-spawners on the temple level.
-Good Neighbor buffs witches and curses the player.
-Nitocris/Dark Pharaoh interaction
--Nitocris's wrappings give nullmagic instead of antimagic
--If the Pharaoh is present, she can still cast
--If she loses her protection, the Paraoh will kill her
--When she dies, she instead turns into a Ghoul.
--Wrapped, living, and ghoul Nitocris have different spell lists
-Destroying one of Nyarlathotep's mask releases a more-terrible mask, as advertised.

Dolls
-Handling for Dolls dying instead of vanishing at low insight.
-Handling for Dolls comming back to life.

Bugfix: Demogorgon's paranoia shouldn't affect already-placed 'I's

Bugfix: Revise boots handling to work better.

---
## [newstools/2020-daily-nation@f62d4ca032...](https://github.com/newstools/2020-daily-nation/commit/f62d4ca032fe028fb822e77cc02a3cf0b64db3f6)
##### 2020-02-03 07:10:09 by NewsTools

Created Text For URL [www.nation.co.ke/lifestyle/dn2/Will-my-boyfriend-ever-marry-me-/957860-5441608-7a8083z/index.html]

---
## [mrakgr/The-Spiral-Language@f2661b4004...](https://github.com/mrakgr/The-Spiral-Language/commit/f2661b4004235744e150bb5c75031e8b01faad84)
##### 2020-02-03 13:20:50 by Marko GrdiniÄ‡

"10:50am. Uf, I got up late. I might as well have breakfast now then.

11:50am. Done with that. I do not feel like chores straight away. I am still groggy, so let me slack just a bit.

11:55am. Just one ep of Railgun and then I will do the chores. After that comes the codegen.

12:25pm. Chores.

1pm. Now finally it is time to do some programming. I have 5 good hours ahead of me. Let me put them to good use.

Focus me, focus.

Just think...once I finish the codegen, and then get the language running, I will essentially have what I had back in 2018 except without any flaws. No more compilation performance issues.

That is something.

At that point should I want it, I could retrace my old steps and resume where I left off in 2018.

Except I want to go a lot further this time and I will.

It is time for mainstreaming of Spiral's features. I will give it a honest shot at showing the world its full potential. I won't stop at having it be a power tool for experts.

1:05pm. Everything. This time there will be no more compromises in the ability to reason. This time I will have everything.

The perfect language. The proper substrate. The needed algorithms.

The 20s are going to have my everything.

1:15pm. Yeah, my energy is low as I am dealing with the redesign bullshit instead of the kind of programming that I want. When I start working on typechecking, and later do the plugin, it will go up.

I was wrong in 2018. It is not my job to do ML at this stage. Rather I need to do basic research. That means finding the use for spiking nets and such. I won't get anywhere until I figure out the improved data structures that could be used in place of matrices of floats.

I will make it my principle to look for that. I won't move to doing real world ML until this has been done.

That will be one way to atone for my past misdeeds.

1:20pm. If I could just get a little bit more understanding, I could finish the deal myself without relying on the rest of the field so much.

The hints are already all there, just the program specifics are the ones which are being elusive.

1:25pm. I need to bear the burden of not knowing until it happens.

First of all, let me get the things out of the way. I do not want to spend any more time thinking about the partial evaluator or the codegen or whatever.

So let me get that finally out of the way so that I can start doing more important work.

1:30pm.

```
exception CodegenError of string
let raise_codegen_error x = raise (CodegenError x)
```

I do not require codegen errors anymore as I no longer have the danger of type spilling on the value level.

But I will leave it in just in case.

No need to get rid of this.

Now...

Yesterday I removed the printing of the join point cases. To start things off today I will put `RJPToStack` and `RJPToHeap` back in.

1:55pm.

```
        | TyLet(a,trace,x) ->
            try
                let vars = data_free_vars a |> tytags_comma d
                let print_let b = d.Statement(sprintf "let %s = %s" vars b)
                match x with
                | TyOp(RJPToStack,[|b|]) ->
                    match data_free_vars b with
                    | [||] -> "() // unit stack layout type"
                    | free_vars ->
                        let tag = d.types.Tag (data_to_ty a)
                        let b = tytags_comma' d free_vars
                        sprintf "SpiralType%i %s" tag b
                    |> print_let
                | TyOp(RJPToHeap,[|b|]) ->
                    match data_free_vars b with
                    | [||] -> "() // unit heap layout type"
                    | free_vars ->
                        free_vars
                        |> Array.mapi (fun i x -> sprintf "subvar_%i = %s" i (tytag' d x))
                        |> String.concat "; "
                        |> sprintf "{%s}"
                    |> print_let
                | TyOp(RJPToNone,[|b|]) ->
                    match b with
                    | TyV(T(tag,RJPT(_,b))) ->
                        rdata_free_vars b
                        |> Array.map (fun (tag',_) -> sprintf "var_%i.subvar_%i" tag tag')
                        |> String.concat ", "
                        |> print_let
                    | _ -> failwith "impossible"
                | TyJoinPoint _ | TyOp _ -> print_let (op d x)
                | _ -> d.Statement(sprintf "let %s =" vars); op d.Indent x |> ignore
            with :? CodegenError as x -> raise (CodegenErrorWithPos(trace,x.Data0))
        | TyLocalReturnOp(trace,x) ->
            try match op d x with null -> () | x -> d.Statement(x)
            with :? CodegenError as x -> raise (CodegenErrorWithPos(trace,x.Data0))
        | TyLocalReturnData(x,trace) ->
            try d.Statement(typed_data d x)
            with :? CodegenError as x -> raise (CodegenErrorWithPos(trace,x.Data0))
```

I am starting to get the feel back. I've realized that the stack does in fact need the return type in the option after all.

Because otherwise if it is not a part of the let statement it will fail. Whops.

I definitely botched that one.

...Ok, let me go back to the partial evaluator...

2:05pm.

```
let rjp_to_some layout dict (d: LangEnv) = function
    | TyV(T(_,RJPT(t,l))) as x when t = layout -> x
    | x ->
        let x = rjp_to_none d x
        let op = match layout with RJPStack -> RJPToStack | RJPHeap -> RJPToHeap
        let key = op,[|x|]
        match cse_tryfind d key with
        | Some x -> x
        | None ->
            let ret = ty_to_data d.i (RJPT(layout,data_to_rdata dict x))
            d.seq.Add(TyLet(ret,d.trace,TyOp(op,[|x;ret|])))
            cse_add d key ret
            ret
```

Let me do this shit.

Now...

```
        | RJPToStack, [|b;a|] ->
            match data_free_vars b with
            | [||] -> "() // unit stack layout type"
            | free_vars ->
                let tag = d.types.Tag (data_to_ty a)
                let b = tytags_comma' d free_vars
                sprintf "SpiralType%i %s" tag b
        | RJPToHeap,[|b;a|] ->
            match data_free_vars b with
            | [||] -> "() // unit heap layout type"
            | free_vars ->
                free_vars
                |> Array.mapi (fun i x -> sprintf "subvar_%i = %s" i (tytag' d x))
                |> String.concat "; "
                |> sprintf "{%s}"
        | RJPToNone,[|b|] ->
            match b with
            | TyV(T(tag,RJPT(_,b))) ->
                rdata_free_vars b
                |> Array.map (fun (tag',_) -> sprintf "var_%i.subvar_%i" tag tag')
                |> String.concat ", "
            | _ -> failwith "impossible"
```

Plugged it in. Great.

2:10pm. Since I haven't done it yet, let me commit here.

What comes next is the last bit of the codegen.

But besides that, what is really troubling me is that in the previous version of Spiral I had that thing where I convert unit types to `TyT`s.

Now I do not have that anymore, so things are more complicated. I need to that bit of reasoning from the ground up.

But first let me get rid of the red.

2:20pm. Focus me, focus."

---
## [mrakgr/The-Spiral-Language@3d05c963f4...](https://github.com/mrakgr/The-Spiral-Language/commit/3d05c963f41cfa909a3121513431ddbb4715f1b3)
##### 2020-02-03 17:35:26 by Marko GrdiniÄ‡

"5:25pm. Let me give it a shot. At least, let me sketch it out today.

```
let compile_module (m: SpiralModule) =
    match parse m with
    | Ok x -> failwith ""
    | Error er -> failwith ""
```

```
let prepass (var_positions : Dictionary<string,ParserCombinators.PosKey>) (keywords : KeywordEnv) (t_glob : Map<string,TExpr>) (v_glob : Map<string,Expr>) x =
```

Running parse is easy enough, but for starters, I am going to have to pass var_positions as an argument.

```
type CompilationEnv = {
    var_positions : Dictionary<string,ParserCombinators.PosKey>
    keywords : KeywordEnv
    types : Map<string,TExpr>
    values : Map<string,Expr>
    }

let compile_module (d : CompilationEnv) (x : SpiralModule) =
    match parse x with
    | Ok x -> failwith ""
    | Error er -> failwith ""
```

Let me go with this for the time being.

Let me modify the parse so that I am passing keywords as an argument.

5:35pm.

```
let compile_module (d : CompilationEnv) (x : SpiralModule) =
    match parse d.var_positions x with
    | Ok x ->
        let x = prepass d.var_positions d.keywords d.types d.values x
```

Agghhhhh....

I've been thinking about this for a while, but the way keywords work right now is simply problematic. They are going to get in the way later on...

But forget that. When the time comes to do caching, I will do what is needed.

For now being in this half baked state is fine.

5:45pm.

```
let compile_module (d : CompilationEnv) (x : SpiralModule) =
    match parse d.var_positions x with
    | Ok x ->
        match prepass d.var_positions d.keywords d.types d.values x with
        | Ok(t,v) -> t,v
        | Error er -> failwith er
    | Error er -> failwith er
```

As little as this is, it is in fact enough as a starter. I am not really sure how I want to handle errors at this moment.

Let me make the plural of this.

```
match parse d.var_positions x with
```

Oh yes, rather than doing var positions like this, I can just throw away the dictionary when I am done.

6pm.

```
type CompilationEnv = {
    keywords : KeywordEnv
    types : Map<string,TExpr>
    values : Map<string,Expr>
    }

let module' (d : CompilationEnv) (x : SpiralModule) =
    match parse x with
    | Ok(var_positions,x) ->
        match prepass var_positions d.keywords d.types d.values x with
        | Ok(t,v) -> {d with types=t; values=v}
        | Error er -> failwith er
    | Error er -> failwith er

let modules (d : CompilationEnv) (x : SpiralModule) =
    let m = Dictionary(HashIdentity.Reference)
    let rec f (d : CompilationEnv) (x : SpiralModule) =
        memoize m (fun _ -> module' (List.fold f d x.prerequisites) x) x

    f d x

let compile d x =
    let d = modules d x
    match d.values.[x.name].["main"] with
    | Raw
```

Ah, whoops. I know why I am confused.

Er, I need to think how to exactly extend them.

6pm. Right now I am just extending the globals straightforwardly. But there is a difference between globals and modules specifically.

6:10pm. I'll need to modify the prepass, but I definitely do not feel like doing it now.

It is past the 6pm mark and the day is done as per my stress relieving rules. I am definitely going to get the language to compile for the first time tomorrow.

It has been a long journey hasn't it? I suffered quite a bit to get this out of me.

And yet, things are just starting for the new Spiral.

I will never forget the lesson of needing to be patient.

I said that I lost to nature, but that is not exactly true.

Even nature did it by starting with an embryonic nervous system and working from there.

GPUs are a red herring, the hardware that I really need is yet to arrive. In fact for doing RL, GPUs might even be a negative.

I am arrogant and naive.

How could I forget that it would have been impossible for me to learn programming without computers? It would have been impossible for me to learn functional programming without F#. Type theory without Coq.

The path towards the Singularity follows a long trail of evolution.

6:20pm. I was arrogant while writing Simulacrum. The self insert is not going to start the Singularity right away after getting that chip from Intel. Rather, that is when the research will really start.

Before anything else, the absolute main thing to replicate would be that embryonic nervous system.

It is the very first step that is the most important. It is something deep learning hasn't succeeded in doing yet.

This is something that is very primordial to the cause. Even before insect brains, a victory here will mark the true start of the race. Actually having insect tier intelligence pretty much means that the Singularity is imminent. It is not really a low bar compared to the human brain like that one neurochip professor implied.

6:25pm. I have to work hard, so that when things get hot, I am ready.

6:30pm. Tensorflow, PyTorch...is wringing out some NN model using frameworks such as those the way AI research should be conducted. Should it not be something more? Shouldn't be making models be more like working on a language?

So far programming skill really has not played into this whole thing.

I'd really preferred it if programming lifelike agents was really about composing primitives. I would like it if it was more like actual engineering.

If the base step of creating the Embryonic Nervous System can be done, then it might be possible to achieve that."

---
## [komish/postgres-operator@8e97e41464...](https://github.com/komish/postgres-operator/commit/8e97e414645d8b7517437dd24b50b36e8242376d)
##### 2020-02-03 19:35:15 by Jonathan S. Katz

Add support for PostgreSQL tablespaces

Tablespaces can be used to spread out PostgreSQL workloads across
multiple volumes, which can be used for a variety of use cases:

- Partitioning larger data sets
- Putting data onto archival systems
- Utilizing hardware (or a storage class) for a particular database
object, e.g. an index

and more.

Tablespaces can be created via the `pgo create cluster` command using
the `--tablespaces` flag. The arguments to `--tablespaces` can be passed
in via a command-separated list; each argument consister of two values:

- The name of the tablespace
- The type of storage to use for the tablespace

For example:

  pgo create cluster hacluster --tablespaces=ts=nfsstorage

All tablespaces are mounted in the `/tablespaces` directory. The
PostgreSQL Operator manages the mount points and persistent volume
claims (PVCs) for the tablespaces, and ensures they are available
throughout all of the PostgreSQL lifecycle operations, including:

- Provisioning
- Backup & Restore
- High-Availability, Failover, Healing
- Clone

etc.

Two additional values were added to the pgcluster CRD:

- TablespaceMounts: a map of the name of the tablespace and its
associated storage.

Tablespaces are automatically created in the PostgreSQL cluster. You can
access them as soon as the cluster is initialized. For example, using
the tablespace created above, you could create a table on the tablespace
`ts` with the following SQL:

  CREATE TABLE (id int) TABLESPACE ts;

Presently, tablespaces can only be added to a PostgreSQL cluster when
it is initialized. Based on usage, future work will look to making this
more flexible. Dropping tablespaces can be tricky as no objects must
exist on a tablespace in order for PostgreSQL to drop it (i.e. there is
no DROP TABLESPACE .. CASCADE command).

Co-authored-by: Brian Faherty <anothergenericuser@gmail.com>
Issue: [ch6495]

---

# [<](2020-02-02.md) 2020-02-03 [>](2020-02-04.md)

