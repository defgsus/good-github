# [<](2020-09-12.md) 2020-09-13 [>](2020-09-14.md)

1,899,933 events, 1,015,668 push events, 1,393,688 commit messages, 85,750,210 characters


## [ibeckermayer/Nand2TetrisFPGA](https://github.com/ibeckermayer/Nand2TetrisFPGA)@[acf66fef95...](https://github.com/ibeckermayer/Nand2TetrisFPGA/commit/acf66fef95a55285cbd452d4ceb4d259c1a08741)
#### Sunday 2020-09-13 00:57:19 by Isaiah Becker-Mayer

BOOM BABY! ITS FUCKING WORKING AS FUCK! Realized that I mistakenly have 116C in there rather than 1234. But otherwise it's fucking correct. Holy shit

---
## [TheMalachite/DemonSlayer-begonia](https://github.com/TheMalachite/DemonSlayer-begonia)@[8e3956fc97...](https://github.com/TheMalachite/DemonSlayer-begonia/commit/8e3956fc974c616851b2e14c02ec029074e192a5)
#### Sunday 2020-09-13 01:57:05 by Linus Torvalds

Revert "x86/apic: Include the LDR when clearing out APIC registers"

[ Upstream commit 950b07c14e8c59444e2359f15fd70ed5112e11a0 ]

This reverts commit 558682b5291937a70748d36fd9ba757fb25b99ae.

Chris Wilson reports that it breaks his CPU hotplug test scripts.  In
particular, it breaks offlining and then re-onlining the boot CPU, which
we treat specially (and the BIOS does too).

The symptoms are that we can offline the CPU, but it then does not come
back online again:

    smpboot: CPU 0 is now offline
    smpboot: Booting Node 0 Processor 0 APIC 0x0
    smpboot: do_boot_cpu failed(-1) to wakeup CPU#0

Thomas says he knows why it's broken (my personal suspicion: our magic
handling of the "cpu0_logical_apicid" thing), but for 5.3 the right fix
is to just revert it, since we've never touched the LDR bits before, and
it's not worth the risk to do anything else at this stage.

[ Hotpluging of the boot CPU is special anyway, and should be off by
  default. See the "BOOTPARAM_HOTPLUG_CPU0" config option and the
  cpu0_hotplug kernel parameter.

  In general you should not do it, and it has various known limitations
  (hibernate and suspend require the boot CPU, for example).

  But it should work, even if the boot CPU is special and needs careful
  treatment       - Linus ]

Link: https://lore.kernel.org/lkml/156785100521.13300.14461504732265570003@skylake-alporthouse-com/
Reported-by: Chris Wilson <chris@chris-wilson.co.uk>
Acked-by: Thomas Gleixner <tglx@linutronix.de>
Cc: Bandan Das <bsd@redhat.com>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Sasha Levin <sashal@kernel.org>

---
## [systemd/systemd-stable](https://github.com/systemd/systemd-stable)@[8ea6ec18e7...](https://github.com/systemd/systemd-stable/commit/8ea6ec18e785599e357eecebc44a726cccc126e3)
#### Sunday 2020-09-13 08:49:04 by Lennart Poettering

btrfs: if BTRFS_IOC_DEV_INFO returns /dev/root generate a friendly error message

On systems that boot without initrd on a btrfs root file systems the
BTRFS_IOC_DEV_INFO ioctl returns /dev/root as backing device. That
sucks, since that is not a real device visible to userspace.

Since this has been that way since forever, and it doesn't look like the
kernel will get fixed soon for this, let's at least generate a useful
error message in this case.

This is not a bug fix, just a tweak to make this more recognizable.

Once the kernel gets fixed to report the correct device nodes in this
case, in a way userspace can make sense of them things will magically
work for systemd, too.

(Note that this doesn't add a log message about this to really all cases
we call get_device() in, but just the main ones that are called in early
boot context, after all all there's no benefit in seeing this message
too many times.)

https://github.com/systemd/systemd/issues/16953
https://bugs.freedesktop.org/show_bug.cgi?id=84689
https://bugzilla.kernel.org/show_bug.cgi?id=89721
(cherry picked from commit 67f0ac8c79bb08451a70ee314daf06ee081ef24d)

---
## [gmoshkin/dotvim](https://github.com/gmoshkin/dotvim)@[040dd7bc1b...](https://github.com/gmoshkin/dotvim/commit/040dd7bc1b4969d5ca5592fb5499c9e91e1af1af)
#### Sunday 2020-09-13 11:38:33 by Georgy Moshkin

YouCompleteMe out. coc.nvim in

YCM is shit: you have to write the ugly fucking .ycm_blabla_conf files
in fucking python. It wouldn't be such a big deal if it was documented
adequately, but there's absolutely no documentation of this shit.

Also the basic features don't fucking work. GoToDefinition just stops
working for no fucking reason. And the interface is fucking ugly as shit

And there's no fucking support for anything other than c++ and maybe
fucking python

coc.nvim is awesome. There's rust language server support! And a bunch
of diagnostics ala VS Code.

Let's see if I get frustrated with it anytime soon...

---
## [Predeactor/Predeactor-Cogs](https://github.com/Predeactor/Predeactor-Cogs)@[dbb0543259...](https://github.com/Predeactor/Predeactor-Cogs/commit/dbb05432590a4127c24e0ec299eceadf91cf72cc)
#### Sunday 2020-09-13 13:38:31 by Predeactor

The infinite, Captcher, Beta v0.5

Welcome to the new era of Captcher!
This time, Captcher evolved seriously and has been seriously worked on.
Over 10 hours of work, approximately

Let's go over the patch notes:

# Commands
- Removed logging.
- Added differents aliases for commands
- Added settings command (Bot won't ping the role, don't worry).
- giverole is now called autorole, same in config.
- I reworked a little bit on command's processing.
- verificationchannel is now verifchannel.
- verifchannel will check for permission in verification channel, same for logschannel.
- Autoconfig is back, and is handling well better channels and categories (AKA. Won't fuck up your server)
- challengeuser now enforce to only use one method.
- More checks on all commands to avoid problems.

# Functions
- Removed (now) unused packages.
- Changed some var name in config.
- self._cache is now self.in_challenge.
- Instead of directly using the challenge method, challenger will perform checks before anything.
- Added _permissions_checker, a powerful checker for permissions.
- Rewrite of whole challenging function.
- _give_role has been rewriten.
- _report_log got some fix and use Union (Which is maybe a bad idea since I don't know much about typing lol).
- _get_log_channel has been rewriten and USE THE CACHE OH WOW INCREDIBLE, CACHE IS USEFUL!
- _kicker kick ass better.
- Old _permissions_checker has been deleted for using the new one.
- _role_keeper renamed to _roles_keeper.
- roles_remover now need a list.
- _add_roles is less dumb.
- _overwrite_server won't nuke your server by overwriting all channels.
- _mute_or_unmute_user will handle mute instead of returning new permissions.
- on_member_remove for nuking bot's message in case the user leave.

---
## [ReinhardLenz/paper-roll-storage](https://github.com/ReinhardLenz/paper-roll-storage)@[4b2748d209...](https://github.com/ReinhardLenz/paper-roll-storage/commit/4b2748d209d15c4bebe618de62d309a3851dffc6)
#### Sunday 2020-09-13 14:04:26 by ReinhardLenz

Add files via upload

I put a detailed description of what the program does, into my web page http://raikkule.mbnet.fi/kruunu-klaava.php?lang=en

The pure text ofthe web page is below, but the very important diagrams are missing, unfortunately.
at a factory, the production is running around the clock. The products are put directly into a storage. The input and output orders are entering randomly. Input is always constant, but output only at daytimes. Because the overall storage content must remain constant, this means, that during the times, when output is done (daytime), on top of the input cycles, relatively more output movements must be performed. Daytime is then the "rush hour" of the storage, because most movements must be done during daytime. In the daytime, the probability of output is double of the input probability. So you could compare this with a game of dice. A third of the dice numbers is painted red, and red would then mean that an input happens. Two thirds of the dice numbers are painted blue, and blue would then mean that an output happens.

In the picture the top zig-zag line indicates the filling of the storage. When the line rises, the storage fills up and when it goes down, the storage is emptied. Because the filling of the storage is slower , the upward inclination is double of the downward inclination. In the lower diagram, the rate of filling as pcs/h is marked on the time axis. The input (blue) to the storage is continuous along the time axis (x), because the factory works around the clock. The y- axis marks the pieces per hour going into the storage. The light red area is the output from the storage during the daytime. So if the storage content is constant over several days, the Area_output (= Output pcs/h times 12 hours) must be equal to the Area_input (Input - pcs/hour times 24 hours). and that means that during day the probability of output (2/3) is double of the probability of input (1/3). 

The worker can do 3 different type of movements: 1.) input cycle 2.) output cycle 3.) combined cycle combined means: input an item, and directly after output an item from storage with one movement. The combined cycle is faster than simply adding an input plus an output cycle, because there are less trips involved. (It is basically what a wife tells her husband: "When you go shopping, could you please take out the trash at the same time"). Therefore it is essential to consider the positive effect of the combined cycle to the throughput capacity of the storage. For calculating the possible throughput capacity of a storage, the cycle times of all input, output and combined cycles together are relevant. In the game of throwing a dice above, it would mean, "when do we have a case, that a red number follows after a blue number" and in this case, it would be a "lucky" (or better: a time saving) combination. The question is then, how many of the input and output cycles can be combined, to make use the benefit of the combined cycle as much as possible.

What is the probability, that a worker can do the combined movement? starting from the most simple case, that there are only two consecutive movements. So the first movement can be either input (1/3 probability) or output (2/3 probability). After the first movement, the probability for the next movement is exactly the same (1/3 against 2/3) as before. So there we are with 4 different combinations of movements, and each of this consecutive event chain has a different probability. In the sum, however, the probability sums up to totally 1/9 + 2/9+2/9 + 4/9=1. But this number does not give the combined cycle seperately, and also, in is not accounted for, that the combined cycle has reduced the number of total steps.

The diagram shows the tree diagram but made in scale, but the x- axis is the portion of the probability of each course of events is made in scale. The lowest blue curve represents the scale of the output movements. So what is shown on the "tree" diagram as the right branch is the course of events with first event as Output (p=2/3) and next an Input(p=1/3) with a total probability of 2/9 = 22%, which is now the first step (Step height is 1, because we talk about one output event) on a stairway curve with totally two steps with an width of the step is 22%. And the outer right-right branch of the upper "tree" curve is the next step of the blue curve, and it has a width of 44% (=2/3*2/3=4/9). And the height of the step is 2, because we have 2 output events. Similarly the red curve shows the probability of the input cycle, but in scale. The steepest part is on the left side, and it represents the outer left branch of the tree scheme above, with a probability of 1/3 * 1/3 = 1/9 (11%), which is then the width of the first step of the downward going light red stairway curve. The height of this step is 2 because it is two input movements together. In the middle is another brick, with a width of 1/3* 2/3= 33% and the height of 1. The top grey curve shows the part of the combined cycle, which is marked in grey colour in the tree diagram. The width (synonymous with probability) is 1/3*2/3 =2/9 =22% and the height is 1, as we are having only one event. If we wouldn't have the "synergy" effect of the combined cycle, the height of this block would have to be 2, but as we have only one movement to do, the height of this block is only 1. The area below each of these 3 different curves represents the probability of the respective event. So the area under output cycle curve is 0.22*1 +0.44*2= 0.22+0.88=1. The area under the input curve is 0.11*2+0.22*1=0.44 and the area under the combined cycle curve is 0.22*1=0.22. The area under all the three curves together must be 1 (100%) as it cannot be more. And the probability of the output cycle is the quotient of area under the output curve with the total area under all three curves. So the area under the output curve was 1 and the area under all curves together is 0.22+0.44+1=1.6, so the relative probability of the output cycle is therefore 1/1.6=0.6 (60% probability of the output cycle) Respectively, the relation of the area under input curve to the total area is 0.44/1.6=0.265 (meaning a probability of 26.5% for the input cycle) And the probability of the combined cycle is 0.2271.6= 0.13 (13%) Totally all probabilities must sum up to 100% = 13.5%+26.5% + 60%= 100%.
 The probability of the different events (combined, input, output) is the area of the respective event divided by the area of all the events together.


The next step in the consideration is to add one step more, so we would have 3 consecutive events. The combined cycle now appears three times in a total amount of eight different possibilities of events. So dependent on the amount of consecutive events, the possibilities are always 2 to the square of event amount. Respectively, the chain of 3 consecutive input events is 1/3*1/3*1/3=1/27 0.037 = 3.7% which is not high number.

So with 3 consecutive events, the probability of combined cycle is 18%, the probability of input cycle is 22% and probability of output cycle is 60% and the sum of all probabilities is of course 100%. We can also see, that our "stairway curve" has got one step more, total three steps, but the combined cycle curve has only one step.

As we have now got routine with this procedure and we get more and more curious, we can continue to make the tree diagram to even four consecutive steps.

Unfortunately there is a problem with space in the paper width direction, it seems to be impossible to fit even more branches into this tree diagram. But the probability scheme can be continued, although the step widths are getting narrower and narrower. It gives quantitative overview of how many combined cycles can be achieved in comparision to the input and output cycle, as areas under the three different curves are compared.

When continuing to increase the events, the combined cycle probability is approaching 26%, the input cycle probability is 16% and ouptput cycle probability runs to about 58%.

Until now, all thoughts were based on the assumption, that the factory was running 24h / 24h and the output was at daytime 12 hours per day. Another question is, how the situation would look like when the daytime would be 16 hours, which would correspond to a day with three shifts, where two shifts can be used for loading activities. Could it be possible, that, if loading is done even 24 hours per day, that all cycles could maybe done in a combined mode?

This curve, where the output time during the daytime is variates is a little it theoretical, because it also shows unrealistic situation, that -for instance- when there is only very few output hours per day (let's say 1h only) in means, that during the rush hour almost all of the movements have to be output movements, so no combinations are possible and also input is not possible. But this is a rather unrealistic scenario. On the other extreme end of the curve the proportions the different movements (input, output and combined) are quite even, almost like 1/3 - 1/3 - 1/3. But, unlike expected, the combined cycle can never be completely exploited, obviously because of the stochastic nature of the process, where it cannot be predicted or controlled which one of the different movement will come next.

---
## [Lumos-SS13/Lumos](https://github.com/Lumos-SS13/Lumos)@[2580d66fe1...](https://github.com/Lumos-SS13/Lumos/commit/2580d66fe167764658796c80839a65a4dc7e1530)
#### Sunday 2020-09-13 14:13:00 by FargothUr

New EVA suits (#71)

* rip original EVA

* Delete _material.dm

fucking forgot to remove this lmao

* there we go holy shit im dumb

* comments code

---
## [MaxAlber/BarnesHut](https://github.com/MaxAlber/BarnesHut)@[a3fde9143a...](https://github.com/MaxAlber/BarnesHut/commit/a3fde9143a58c6e44fcbf707800e8e7a14a9010f)
#### Sunday 2020-09-13 16:22:32 by max

fixed some shit, dont remember what, sorry future me

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[fba7a3a52f...](https://github.com/mrakgr/The-Spiral-Language/commit/fba7a3a52facf2125c77a711ce6e441f5cf5337b)
#### Sunday 2020-09-13 17:03:27 by Marko Grdinić

"9:50am. I am up. Let me do my morning reading and then I am going to try to get something done.

Let me make a goal. I've made all sorts of plans yesterday, but it still feels so heavy. What I am going to aim for today is to just do `BundleType`. Just focus on doing a single case. A single step.

If you can't move, then all your effort needs to be in shaking free of restraints. Once the first step is made, the second and the third will come.

I won't aim for anything more today. Just that single case as an exercise.

The Inspired could do 1,000 times as much as me in only a fraction of my time. They would have a lot more fun as well. It is unfair, but I've decided to accept this unfairness and despair and just go foward.

10:25am. Ok, enough wasting time.

For the rest of the day, I will just focus on gathering my motivation and programming. I'll get rid of distractions completely.

10:40am. When I get my bearings, I'll get back to the usual kind of life.

```fs
type TopEnv = {
    tern : Map<string,Expr>
    ty : Map<string,TExpr>
    }
```

I am just so uninspired. Even what the `TopEnv` should be here is not obvious.

For now, I guess it is fine if I just do this.

10:50am. Focus me, focus. Stop reading threads on the side.

Let me write down what I think the prototype should be.

10:55am.

```fs
prototypes : Map<int,{|arity : int; body : Expr|}> PersistentVector
```

Oh, yeah. Rather than just arity, I've decided yesterday that I should be checking the kinds in the partial evaluator. Things will be less confusing that way even if it will slow down compilation.

11am.

```fs
type Kind = Type | Fun of Kind * Kind
```

The kinds will be easier this time around.

```fs
| Forall of Range * FreeVars * Id * Kind * Expr
```

I'll have the foralls have kinds.

```fs
| Fun of Range * FreeVars * Id * Expr
```

The functions on the other hand should have type annotations.

```fs
| Fun of Range * FreeVars * Id * Expr * TExpr
```

11:10am. Focus me, focus. As I said, stop going to threads. You know what. I am just going to physically remove the damn cable. There. No more Internet.

11:25am. It is hard, it is hard.

```fs
module Spiral.Prepass

type Id = int32
//type FreeVars = {|ty : int; term : int|}
type FreeVars = unit
type Range = { uri : string; range : Config.VSCRange }

type Kind = Type | Fun of Kind * Kind
type TypeVar = Id * Kind

type Macro =
    | MacroText of Range * string
    | MacroTypeVar of Range * Id
    | MacroTermVar of Range * Id
type RecordWith =
    | RecordWithSymbol of (Range * string) * Expr
    | RecordWithSymbolModify of (Range * string) * Expr
    | RecordWithInjectVar of (Range * Id) * Expr
    | RecordWithInjectVarModify of (Range * Id) * Expr
and RecordWithout =
    | RecordWithoutSymbol of Range * string
    | RecordWithoutInjectVar of Range * Id
and PatRecordMember =
    | PatRecordMembersSymbol of (Range * string) * Id
    | PatRecordMembersInjectVar of (Range * Id) * Id
and Expr =
    | B of Range
    | V of Range * Id
    | Lit of Range * Tokenize.Literal
    | DefaultLit of Range * string * TExpr
    | SymbolCreate of Range * string
    | Type of Range * TExpr
    | Fun of Range * FreeVars * Id * Expr * TExpr
    | Recursive of Expr ref
    | Forall of Range * FreeVars * TypeVar * Expr
    | RecBlock of Range * ((Range * Id) * Expr) list * on_succ: Expr
    | RecordWith of Range * Expr list * RecordWith list * RecordWithout list
    | Op of Range * BlockParsing.Op * Expr list
    | JoinPoint of Range * FreeVars * Expr
    | Annot of Range * Expr * TExpr
    | Typecase of Range * TExpr * (TExpr * Expr) list
    | ModuleOpen of Range * (Range * Id) * (Range * string) list * on_succ: Expr
    | Macro of Range * Macro list
    | Inline of Range * FreeVars * Expr
    // Regular pattern matching
    | Let of Range * Id * Expr * Expr
    | PairTest of Range * bind: Id * pat1: Id * pat2: Id * on_succ: Expr * on_fail: Expr
    | KeywordTest of Range * string * bind: Id * on_succ: Expr * on_fail: Expr
    | RecordTest of Range * PatRecordMember list * bind: Id * on_succ: Expr * on_fail: Expr
    | AnnotTest of Range * TExpr * bind: Id * on_succ: Expr * on_fail: Expr
    | LitTest of Range * Tokenize.Literal * bind: Id * on_succ: Expr * on_fail: Expr
    | UnitTest of Range * bind: Id * on_succ: Expr * on_fail: Expr
    | HigherOrderTest of Range * ho: Id * bind: Id * on_succ: Expr * on_fail: Expr
    // Typecase
    | TypeLet of Range * Id * Expr * Expr
    | TypePairTest of Range * bind: Id * pat1: Id * pat2: Id * on_succ: Expr * on_fail: Expr
    | TypeFunTest of Range * bind: Id * pat1: Id * pat2: Id * on_succ: Expr * on_fail: Expr
    | TypeKeywordTest of Range * string * bind: Id * on_succ: Expr * on_fail: Expr
    | TypeRecordTest of Range * Map<string,Id> * bind: Id * on_succ: Expr * on_fail: Expr
    | TypeUnitTest of Range * bind: Id * on_succ: Expr * on_fail: Expr
    | TypeHigherOrderTest of Range * ho: Id * bind: Id * on_succ: Expr * on_fail: Expr
    | TypeHigherOrderDestruct of Range * pat: Id list * bind: Id * on_succ: Expr * on_fail: Expr
and TExpr =
    | Unit of Range
    | Var of Range * Id
    | Pair of Range * TExpr * TExpr
    | Arrow of Range * TExpr * TExpr
    | Record of Range * Map<string,TExpr>
    | Symbol of Range * string
    | Apply of Range * TExpr * TExpr
    | Prim of Range * Config.PrimitiveType
    | Term of Range * Expr
    | Macro of Range * Macro list
    | Fun of Range * FreeVars * TypeVar * TExpr
    | HigherOrder of Range * TypeVar

open FSharpx.Collections

type HigherOrderCases =
    | Union of name: string * TypeVar list * Map<string,TExpr>
    | Nominal of name: string * TypeVar list * TExpr

type TopEnv = {
    prototypes : Map<int,{|prefix : Kind list; body : Expr|}> PersistentVector
    hoc : HigherOrderCases PersistentVector
    tern : Map<string,Expr>
    ty : Map<string,TExpr>
    }

open BlockParsing
open TypecheckingUtils
let prepass (top_env : TopEnv) expr =
    match expr with
    | BundleType(r,a,b,c) -> ()
```

I've barely started the skeleton, and already I want to hide in a hole somewhere. But I have to keep moving. I did not think that the prepass of all things would be giving me this much trouble.

```fs
    | TUnit of Range
    | TVar of Range * Id
```

Let me add a prefix to `Expr` and `TExpr`'s cases. I should make it a rule to at least prefix the ones from the same module. I do not feel like making union types submodules in Spiral and I'll adopt the convetion to program as if that were true in F#.

It is not a big deal.

11:35am.

```fs
module Spiral.Prepass

type Id = int32
//type FreeVars = {|ty : int; term : int|}
type FreeVars = unit
type Range = { uri : string; range : Config.VSCRange }

type TT = Type | Fun of TT * TT
type TypeVar = Id * TT

type Macro =
    | MText of Range * string
    | MTypeVar of Range * Id
    | MTermVar of Range * Id
type RecordWith =
    | RSymbol of (Range * string) * E
    | RSymbolModify of (Range * string) * E
    | RVar of (Range * Id) * E
    | RVarModify of (Range * Id) * E
and RecordWithout =
    | WSymbol of Range * string
    | WVar of Range * Id
and PatRecordMember =
    | Symbol of (Range * string) * Id
    | Var of (Range * Id) * Id
and E =
    | EB of Range
    | EV of Range * Id
    | ELit of Range * Tokenize.Literal
    | EDefaultLit of Range * string * T
    | ESymbolCreate of Range * string
    | EType of Range * T
    | EFun of Range * FreeVars * Id * E * T
    | ERecursive of E ref
    | EForall of Range * FreeVars * TypeVar * E
    | ERecBlock of Range * ((Range * Id) * E) list * on_succ: E
    | ERecordWith of Range * E list * RecordWith list * RecordWithout list
    | EOp of Range * BlockParsing.Op * E list
    | EJoinPoint of Range * FreeVars * E
    | EAnnot of Range * E * T
    | ETypecase of Range * T * (T * E) list
    | EModuleOpen of Range * (Range * Id) * (Range * string) list * on_succ: E
    | EMacro of Range * Macro list
    | EInline of Range * FreeVars * E
    // Regular pattern matching
    | ELet of Range * Id * E * E
    | EPairTest of Range * bind: Id * pat1: Id * pat2: Id * on_succ: E * on_fail: E
    | EKeywordTest of Range * string * bind: Id * on_succ: E * on_fail: E
    | ERecordTest of Range * PatRecordMember list * bind: Id * on_succ: E * on_fail: E
    | EAnnotTest of Range * T * bind: Id * on_succ: E * on_fail: E
    | ELitTest of Range * Tokenize.Literal * bind: Id * on_succ: E * on_fail: E
    | EUnitTest of Range * bind: Id * on_succ: E * on_fail: E
    | EHigherOrderTest of Range * ho: Id * bind: Id * on_succ: E * on_fail: E
    // Typecase
    | ETypeLet of Range * Id * E * E
    | ETypePairTest of Range * bind: Id * pat1: Id * pat2: Id * on_succ: E * on_fail: E
    | ETypeFunTest of Range * bind: Id * pat1: Id * pat2: Id * on_succ: E * on_fail: E
    | ETypeKeywordTest of Range * string * bind: Id * on_succ: E * on_fail: E
    | ETypeRecordTest of Range * Map<string,Id> * bind: Id * on_succ: E * on_fail: E
    | ETypeUnitTest of Range * bind: Id * on_succ: E * on_fail: E
    | ETypeHigherOrderTest of Range * ho: Id * bind: Id * on_succ: E * on_fail: E
    | ETypeHigherOrderDestruct of Range * pat: Id list * bind: Id * on_succ: E * on_fail: E
and T =
    | TUnit of Range
    | TVar of Range * Id
    | TPair of Range * T * T
    | TArrow of Range * T * T
    | TRecord of Range * Map<string,T>
    | TSymbol of Range * string
    | TApply of Range * T * T
    | TPrim of Range * Config.PrimitiveType
    | TTerm of Range * E
    | TMacro of Range * Macro list
    | TFun of Range * FreeVars * TypeVar * T
    | THigherOrder of Range * TypeVar

open FSharpx.Collections

type HigherOrderCases =
    | Union of name: string * TypeVar list * Map<string,T>
    | Nominal of name: string * TypeVar list * T

type TopEnv = {
    prototypes : Map<int,{|prefix : TT list; body : E|}> PersistentVector
    hoc : HigherOrderCases PersistentVector
    tern : Map<string,E>
    ty : Map<string,T>
    }

open BlockParsing
open TypecheckingUtils
let prepass (top_env : TopEnv) expr =
    match expr with
    | BundleType(r,a,b,c) -> ()
```

Concision. Let me clean this a bit like this.

11:40am. My brain is a slime. What exactly should I do next here?

```fs
| EJoinPoint of Range * E
```

I'll wrap join points in Inline after all. It will make things easier.

11:50am. There is no helping it. Let me have breakfast, and then I'll step away from the screen for a while. The prepass is just wrecking me.

I get a lot of the individual pieces. And now I've managed to put in all the types that I need. But the fact that I have a top level now makes things more complicated. Previously everything was uniform and now that I have this I am not sure how I should structure the prepass.

11:55am. Let me just stop here, before I get even more lost in daydreams.

I will iron this all out today."

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[d15ffdea1e...](https://github.com/mrakgr/The-Spiral-Language/commit/d15ffdea1e140b20d5d76b8245597963829a218f)
#### Sunday 2020-09-13 17:03:27 by Marko Grdinić

"1:05pm. Done with breakfast. Let me just finish ch 1 of Otherside Picnic and I will spend the rest of the day in bed.

Today I need to think about how to connect the core of the prepass (those 3 passes) to what I will do at the top level. Right now, it feels like there is static in my head whenever I think about it. I am completely perplexed.

6:50pm. After cooking myself in bed for this long I have it. I have the feeling now. I feel stronger as well. I know how I am going to organize things.

Before I start, I am going to have to go back and put constraints in their own separate environment after all. It was a mistake to put them in the type dictionary after all. Since I will erase the constraints during partial evaluation, and won't have them in the type env during the prepass that might lead to missing variable exceptions.

I should have segregated them from the beginning. I am also going to make their instances recursive.

On the bright side, this will simplify the `typevars` function since I won't have to be concerned about forall vars shadowing the constraints. On the dark side, I am going to have to pass the new env explicitly, but that is not a huge deal.

7pm. I feel like I am still in need of more cooking, but I'll try to at least do the constraints refactor in the typechecker tomorrow.

That I am starting to get comfortable with thinking about the prepass is a good sign. I think it won't be long before I actually feel like working on it"

---
## [efipaka/Heart_Diseases](https://github.com/efipaka/Heart_Diseases)@[4a30928e94...](https://github.com/efipaka/Heart_Diseases/commit/4a30928e9412895e4dfd027b5eff882cf59d7750)
#### Sunday 2020-09-13 20:05:09 by Efi Pecani

Add files via upload

This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to
this date. The "goal" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4.


Attribute Information:

age
sex
chest pain type (4 values)
resting blood pressure
serum cholestoral in mg/dl
fasting blood sugar > 120 mg/dl
resting electrocardiographic results (values 0,1,2)
maximum heart rate achieved
exercise induced angina
oldpeak = ST depression induced by exercise relative to rest
the slope of the peak exercise ST segment
number of major vessels (0-3) colored by flourosopy
thal: 3 = normal; 6 = fixed defect; 7 = reversable defect


The names and social security numbers of the patients were recently removed from the database, replaced with dummy values. 
One file has been "processed", that one containing the Cleveland database.
All four unprocessed files also exist in this directory.

To see Test Costs (donated by Peter Turney), please see the folder "Costs"

Acknowledgements
Creators:

Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.
Donor:
David W. Aha (aha '@' ics.uci.edu) (714) 856-8779

Inspiration
Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).

See if you can find any other trends in heart data to predict certain cardiovascular events or find any clear indications of heart health.

---
## [jroinc/TerraGov-Marine-Corps](https://github.com/jroinc/TerraGov-Marine-Corps)@[16aab972af...](https://github.com/jroinc/TerraGov-Marine-Corps/commit/16aab972af6d239ef015a30b44779a65a7865137)
#### Sunday 2020-09-13 20:25:35 by jroinc

Chemical additions

Initial add of 2 chemicals, QC+ and Larvaway.

QC+ is highly toxic and stuns, but heals IB very, very rapidly. 

Metabolism rate 0.5u/tick, intended dose 5u, OD 6u, crit OD 10u. Healrate will be 2.5/tick, for a total of 25 pts of IB healed/dose, additional if OD'd (next commit). That's the good stuff.

The bad stuff is that it gives you 5u of toxins/tick, AND takes 15 stamina/tick, AND maxes out your pain. Give with antitox and it's 100% safe, but you'll still go down for about 20 seconds.

OD deals 3 toxin/tick and some minor bloodloss.
Crit OD deals hilariously high bloodloss. Maybe don't clot all your blood at once?

Larvaway is moderately toxic, and can cause stamina issues, but delays larva growth by 50% or so (next commit). Over time, it will become lethal.

Metabolism of 0.1u/tick, design dose 10u (200 seconds). OD's at 15u, crit OD at 25u.
The first 10u cause 0.5 toxin damage/tick with a 25% chance of 0.5 staminaloss/tick.
The second 10u cause 1 toxin damage/tick with a 25% chance of 20 staminaloss/tick.
Anything after 20u is processed causes 3 toxin/tick (but no staminaloss, yay?)

OD and crit OD just increase the toxin damage by 1 and 2, respectively.

Oh, and antitox purges it while healing the damage. Yay!

Antitox no longer fixes eating larval jelly. That's on you.

---

# [<](2020-09-12.md) 2020-09-13 [>](2020-09-14.md)

