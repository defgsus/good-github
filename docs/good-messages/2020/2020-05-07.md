# [<](2020-05-06.md) 2020-05-07 [>](2020-05-08.md)

2,697,069 events, 1,402,138 push events, 2,234,355 commit messages, 151,343,006 characters


## [RavenJFelix/Herobrine-Soul](https://github.com/RavenJFelix/Herobrine-Soul)@[0fcac5cd92...](https://github.com/RavenJFelix/Herobrine-Soul/commit/0fcac5cd9219128c11f5a531f334145bbd33816f)
#### Thursday 2020-05-07 00:27:22 by RavenJFelix

Add ability to turn off if player curses fuck for shit and gigs

---
## [pytorch/pytorch](https://github.com/pytorch/pytorch)@[35693e9b4b...](https://github.com/pytorch/pytorch/commit/35693e9b4b09de02a18f0840ec491726f2e61fe2)
#### Thursday 2020-05-07 01:21:16 by Michael Carilli

Give at::cuda::blas::gemv<at::Half> parity with <float> and <double>. Nature is healing. (#37569)

Summary:
Fixes https://github.com/pytorch/pytorch/issues/37157 on my machine.

This was annoying to track down.  The essence is that cublas expects column major inputs and Pytorch tensors are usually row major.  Cublas lets you request that it act on transposed data, and the erroring `gemv` calls in https://github.com/pytorch/pytorch/issues/37157 make that request.  The problem is, [cublasSgemv and cublasDgemv](https://docs.nvidia.com/cuda/cublas/index.html#cublas-lt-t-gt-gemv) (called by [`gemv<float>`](https://github.com/pytorch/pytorch/blob/091a1192d7c1013915b100dd1a4d00eecf6abe5e/aten/src/ATen/cuda/CUDABlas.cpp#L318) and `gemv<double>`) regard their `m, n` arguments values as _pre_-transpose sizes, while [cublasGemmEx](https://docs.nvidia.com/cuda/cublas/index.html#cublas-GemmEx) (called by `gemv<at::Half>`, see [here](https://github.com/pytorch/pytorch/blob/091a1192d7c1013915b100dd1a4d00eecf6abe5e/aten/src/ATen/cuda/CUDABlas.cpp#L342) and [here](https://github.com/pytorch/pytorch/blob/091a1192d7c1013915b100dd1a4d00eecf6abe5e/aten/src/ATen/cuda/CUDABlas.cpp#L229)) regards its `m, k` argument values as _post_-transpose sizes.  This is inconsistent.  It turns out the `gemv<float>/<double>` calls are configured correctly and the `gemv<at::Half>` calls aren't.

Strikethrough text below is no longer accurate, ngimel suggested a better way to handle gemv->gemm forwarding.  [Comments in code](https://github.com/pytorch/pytorch/pull/37569/files#diff-686aa86335f96b4ecb9b37f562feed12R323-R348) provide an up-to-date explanation.

Keeping out-of-date strikethrough text because I don't have the heart to delete it all and because it captures an intermediate state of my brain that will help orient me if i ever have to fix this again.

~~To convince myself this PR keeps `at::cuda::blas::gemv`'s external API consistent across dtypes, I need to think through what happens when a pytorch tensor input of size `(a,b)` multiples a vector of size `(b,)` for 4 cases:~~

### ~~1. input is row-major (needs cublas internal transpose)~~
#### ~~1a. input is float or double~~
~~`gemv<float>/<double>` call `cublasS/Dgemv`, forwarding `trans`,** `m`, and `n` directly.~~

~~`cublasS/Ggemv` expects "a m × n matrix stored in column-major format" (so m is the input's fast dim).  Input has size `(a, b)` in row-major format.  We can reinterpret it as a column-major matrix with size `(b, a)` without any memory movement.  So the gemv call should supply `m=b`, `n=a`.  However, we're not trying to multiply a matrix `(b, a)` x a vector `(b,)`, we're trying to sum across `b` for matrix and vector.  So we also request that cublas transpose the matrix internally by supplying `trans='t'` to `blas::gemv`, which becomes `trans=CUBLAS_OP_T` to the `cublasS/Ggemv`.~~

~~As long as the code calling `blas::gemv` thinks carefully and passes `trans='t'`, `m=b`, `n=a`, cublas carries out `(a, b) x (b,)` and all is well.~~

#### ~~1b. input is half or bfloat16~~
~~`blas::gemv<at::Half>` takes a different code path, calling `gemm<at::Half>` which calls `cublasGemmEx`.  The job of this PR is to make sure the exterior `blas::gemv` caller's carefully thought-out argument choices (`trans='t'`, `m=b`, `n=a`) remain correct.~~

~~`cublasGemmEx` takes args `transa, transb, m, n, k, ....others we don't care about` and carries out~~
```
 C = α op ( A ) op ( B ) + β C
where α and β are scalars, and A , B and C are matrices stored in column-major format with
dimensions op ( A ) m × k , op ( B ) k × n and C m × n Also, for matrix A
           A if  transa == CUBLAS_OP_N
op ( A ) = A^T if  transa == CUBLAS_OP_T ...
```
~~`gemv<at::Half>` hacks a gemv by calling gemm such that the raw gemm's `m` is the output dim, `k` is the summed dim, and `n=1`, .  Reasonable, as long as we get the values right, given that we also need to transpose the input.~~

~~To conform with cublas docs we interpret input as column-major with size `(b, a)`.  As for the `<float>/<double>` gemv we want cublas to carry out input (interpreted as column major), internally transposed, times vector of size `(b,)`.  In other words we want cublas to apply `op(A) x B`, where op is transpose and `A` is input interpreted as column major.  Docs define `m` and `k` by saying `op(A)` has dims `m x k` **(`m` and `k` are _post_-`op` sizes)**.  `A` was `(b, a)`, `op(A)` is `(a, b)`, so the correct thing is to supply `m=a`, `k=b` to the underlying gemm.  **For the `<float>/<double>` gemv, we passed `m=b`, not `m=a`, to the raw `cublasS/Dgemv`.**~~

~~The exterior `blas::gemv` must have been called with `trans='t'`, `m=b`, `n=a` (as required by the `<float>/<double>` versions).  So when gemv is about to call gemm, **we [swap](https://github.com/pytorch/pytorch/pull/37569/files#diff-686aa86335f96b4ecb9b37f562feed12R330) the local values of `m` and `n` so that `m=a`, `n=b`,** then put `m (=a)` in the gemm's `m` spot, 1 in the gemm's `n` spot, and `n (=b)` in the gemm's `k` spot.  All is well (we made the right gemm call after ingesting the same arg values as `blas::gemv<float>/<double>`).~~

### ~~2. input is column-major (doesn't need cublas transpose)~~
#### ~~2a. input is float or double~~
~~input is `(a,b)`, already column-major with strides `(1,a)`.  Code calling `blas::gemv` supplies `trans='n'` (which becomes `CUBLAS_OP_N`, no internal transpose), `m=a`, `n=b`.~~

#### ~~2b. input is half or bfloat16~~
~~`blas::gemv` should pass `transa='n'`, `m=a`, `n=1`, `k=b` to the underlying gemm. The exterior `blas::gemv` must have been called with `trans='t'`, `m=a`, `n=b` (as required by the `<float>/<double>` versions). So **in this case we _don't_ swap `blas::gemv`'s local values of `m` and `n`.** We directly put `m (=a)` in the gemm's `m` spot, 1 in the gemm's `n` spot, and `n (=b)` in the gemm's `k` spot. All is well (we made the right gemm call after ingesting the same arg values as `blas::gemv<float>/<double>`).~~

~~** `trans` is a string `t` or `n` in the `at::cuda::blas::gemv` API, which gets [converted](https://github.com/pytorch/pytorch/blob/091a1192d7c1013915b100dd1a4d00eecf6abe5e/aten/src/ATen/cuda/CUDABlas.cpp#L314) to a corresponding cublas enum value `CUBLAS_OP_T` (do transpose internally) or `CUBLAS_OP_N` (don't transpose internally) just before the raw cublas call.~~
Pull Request resolved: https://github.com/pytorch/pytorch/pull/37569

Differential Revision: D21405955

Pulled By: ngimel

fbshipit-source-id: e831414bbf54860fb7a4dd8d5666ef8081acd3ee

---
## [newstools/2020-naija-news-agency](https://github.com/newstools/2020-naija-news-agency)@[6249e9f95f...](https://github.com/newstools/2020-naija-news-agency/commit/6249e9f95fbee351dbd28b77ae7d623d2a0283b2)
#### Thursday 2020-05-07 02:51:20 by NewsTools

Created Text For URL [naijanewsagency.com/american-rapper-meek-mill-girlfriend-milan-harris-welcome-baby-boy-on-his-33rd-birthday/]

---
## [michaelmonson/TextAdventuresMichael](https://github.com/michaelmonson/TextAdventuresMichael)@[40ebdaf3c3...](https://github.com/michaelmonson/TextAdventuresMichael/commit/40ebdaf3c3914b8dcaea93c68979262103afd7fc)
#### Thursday 2020-05-07 05:08:57 by michaelmonson

A whole slew of changes!  Most exciting is that initial Room navigation is working!  I can go North!  Here are all of the changes:
   *  Added a cool little "Miser's House" as ASCII art
   *  More modificatoins to my "game loop" to include a call to a separate method to process player input.  It will become huge eventually... thousands of lines long
   * Added a "I don't understand..." method for randomly generating an ignorant/confused response when the game oracle doesn't understand a command
   *  Added an "AnalyzePlayerInput" method to process a user's input.  This will become huge, as I stated previously.  It can now split a player's input into separate words, check against its list of known verbs for a match, and then handle basic compass directions, although only North (N) is supported at this time.
   *  Also alters the 'changeRooms' boolean so that the main game loop will refresh the screen and display the new room data.  It keeps the screen from scrolling too much! :-)
   *  Discoverd the use of 'static' for objects that should be instantiated just once!  That allows me to use my RoomLocation data as a global, for instance, from any class, since I never want more than one ste of that data.  And I think it can change (aka not final)
   * Fixed a bug where I created the locationMap (for directions) as an array of size 5 instead of 4.  At this time, there are only four compass directions.  I might add four more for NE, NW, SE, and SW, though I think that makes the came too complex and confusing for the purposes I need.

Take a look at some of the creative ideas I was fishing around in my mind.  It would be an awful lot of fun.  Really the complexity of the game is primarily in the language parser (how well does the game oracle understand the player's commands?), the interaction of the player with their environment, and the business logic that processes everything.  Once that is all in place, adding new rooms is relatively easy, and new objects won't be much harder.  As long as the directions are sound, everything else is pretty straightforward, and the joy of the game comes from the richness of the writing.  I'm a decent writer, so it should be fun.
    Hmmm... should any elements from Harry Potter occur?  Or perhaps the player will run into Mickey Mouse as the Sorcerer's Apprentace, or maybe a Disney Princess or two is wandering about?
     The sky is the limit!  But some self-control is important, because the game needs to have a purpose to work towards!
     Certainly I need to look into saving games.  As long as I keep my focus on this game to non-work hours, it's just a matter of time.

---
## [ShieldBattery/ShieldBattery](https://github.com/ShieldBattery/ShieldBattery)@[3876f6d6a6...](https://github.com/ShieldBattery/ShieldBattery/commit/3876f6d6a6823c3d7944717ce40c0fa3eba82fc2)
#### Thursday 2020-05-07 06:52:48 by Marko Žarković

Streamline the deployment process using docker. [Version 6.1.3]

- Add a deployment script and guide.
- Adjust the production server to allow for prebuilt client scripts
  to reduce the deploy size/startup time.

- Version 6.1.3. Not a "real" version, I just don't want to make containers
  for a version we already pushed before. No changelog associated with this
  even though there's a lot of changes, we should write a changelog that
  encompasses everything for the next version (6.1.4? 7.0.0? Who knows).

- Add the concept of "update" scripts that will run every time a new
version of the server container setup is deployed, and lets us do things
like enable DB extensions, run DB/redis migrations, etc.

- Make redis migrations run automatically through the update script.
This is mostly dependent on these migrations being idempotent so uh...
don't fuck that up I guess :)

- Add nginx reverse proxy and letsencrypt cert generation.

- Use the node server to serve installer files. I had reasons for not doing
  this before, but they're mostly not well-founded I think, and this is
  easier to accomplish with this docker setup. If this ends up being a
  problem, we could always start hosting the installers on some other service
  (e.g. DO Spaces, GCP storage, etc.).

- Move to using environment variables for configuration, rather than
  config.js/database.json. This *will* require you to update your dev
  setups, sorry in advance :( Hopefully it's fairly easy though, and
  it's cleaner in the long run.

- Add some network isolation to the deployment setup.

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[fbfa16338f...](https://github.com/mrakgr/The-Spiral-Language/commit/fbfa16338f0b449681945d2c5caa64cf0ff2acc7)
#### Thursday 2020-05-07 10:25:37 by Marko Grdinić

"9:35am. As expected, deep sleep during the night is really great for my mental state. I am up.

9:40am. I am still groggy though. Surprisingly no peep in that F# thread I opened. I guess I am on my own here. I'll have to go with Suave and do some research into how IPC communication actually works.

Yeah, I have regrets. If I am going to regret something, I should regret that I wasn't at my current level in 2017 when I was starting work on Spiral. That would have made things go really quickly.

Once Spiral v0.2 is done, I'll be at yet another level once again.

I...must not regret this. Different skills means that I can pursue fundamentally different tactics. Maybe this time doing ML and PL side by side will actually work. Assuming my aim is right this time. Of course the best results would be attained with Spiral actually finished, but I'll have to grind away to get to that point.

9:50am. There will be some ups along the way.

I need to make a resolution that it is finally the time to start.

What I've been doing for the past 3 months was one thing, but now the real deal comes.

10am. Am I hyped enough yet to start reading the Suave docs top to bottom and play with it?

Let me do just a little. I have the mental energy to think properly today so I should be able to do something. Though it will take me a while to get the engine going all the way. It will take some effort to fully convince myself to drop my regrets and fully commit to this course.

Reason is one thing, but giving my subconsciousness the needed emotional momentum to get going takes effort. It is going to take a few days like yesterday where I just sharpen my desire.

10:05am. Let me do it for just a bit.

I should set up a test server in Suave and play with it. It is just too strange that local sockets do not use ports. Just what is that path pointing to? Could I communicate with that local socket server using Postman?

Well, first let me refresh my memory of Suave. There was that local socket option in there somewhere. I'll find it if I go from top to bottom.

10:30am. Had to take a little break. Let me do it.

10:45am. https://suave.io/restful.html

This might be worth getting familiar with.

10:55am. https://suave.io/api.html

I really can't find anything here for what I want. This confused me yesterday as well, but yesterday I was too tired to cope with it properly. Let me continue the search. The documentation is not too large.

https://en.wikipedia.org/wiki/Uniform_Resource_Identifier

This wiki article is really good at explaining Uris. I get it now. Let me get back on track.

11:10am. https://suave.io/websockets.html

Is this what I need? I am not sure. I do not like the 'web' in 'websockets'.

11:20am. This is really getting me nowhere. I am not sure what the right path to take here is, but what do I do feel like is investigating `node-ipc` more. Why does it does not use ports? Just what is the Uri it is using to set up the server?

Let me try plugging in what it shows into Postman. Maybe I should just go through it with a debugger.

11:30am. > is the path of the Unix Domain Socket File, if the System is Windows, this will automatically be converted to an appropriate pipe with the same information as the Unix Domain Socket File. If not set this will default to

By pipe, does this mean Windows named pipe? I read about that once. Let me Google 'Unix Domain Socket File'.

https://en.wikipedia.org/wiki/Unix_domain_socket

There is a bunch of stuff on the wiki. I should get familiar with this.

11:40am. https://docs.microsoft.com/en-us/dotnet/standard/io/how-to-use-named-pipes-for-network-interprocess-communication

11:45am. https://github.com/postmanlabs/postman-request/blob/master/README.md#unix-domain-sockets
```
/* Pattern */ 'http://unix:SOCKET:PATH'
/* Example */ request.get('http://unix:/absolute/path/to/unix.socket:/request/path')
```

I really should just use a regular http server rather than messing with this. Definitely.

https://stackoverflow.com/questions/14973942/tcp-loopback-connection-vs-unix-domain-socket-performance

```
Here you have the results on a single CPU 3.3GHz Linux machine :

TCP average latency: 6 us

UDS average latency: 2 us

PIPE average latency: 2 us

TCP average throughput: 0.253702 million msg/s

UDS average throughput: 1.733874 million msg/s

PIPE average throughput: 1.682796 million msg/s
```

11:50am. https://stackoverflow.com/questions/40195290/how-to-connect-to-a-unix-domain-socket-in-net-core-in-c-sharp

11:55am. Let me go with this. It does not seem like Postman supports UDS.

...Actually, now that I know the protocol is UDS, let me check out Giraffe again.

12pm. https://github.com/giraffe-fsharp/Giraffe/blob/master/DOCUMENTATION.md

I am confused. Didn't I see the protocol list in here yesterday?

12:10pm. I can't find it. Here is what I am going to do - I am going to ignore the LSP protocol and having an TCP server. Trying to fit Spiral into the LSP framework will just add a bunch of complexity I do not need at the moment. The very first thing I will have to do is implement display of traces and I do not want deal with a protocol that does not support it right off the bat.

Similarly, through there are portability benefits to using network sockets, having to use stuff designed for the web will bring its own complications.

I definitely do not need Suave or Giraffe considering all that I want to do is IPC communication of text.

What I will do is give using the sockets directly a try.

Things like adhering to the LSP protocol and doing a network server can wait for when Spiral gets popular. I definitely do not need to do things like support multiple editors right off the bat - VS Code will do just nicely on its own.

12:15pm. There really are many benefits from starting things out from a low level.

I really could have done this back in February. I did not need to study all the web technologies and whatever, but my knowledge was just too insufficient to even know which direction to go in. I should have anticipated all of this, but I instead choose to play it safe.

...Hmmmm...

I wonder if there is a NPM package that specifically supports pipes?

...Also I said that LSP does not support traces, but I am only 80-90% sure of that. I'll have to go from the top to make fully sure.

https://stackoverflow.com/questions/11750041/how-to-create-a-named-pipe-in-node-js

12:25pm. Let me take a break here."

---
## [sgn/git](https://github.com/sgn/git)@[7c34686350...](https://github.com/sgn/git/commit/7c34686350daa7464a33e5628bc957c06a5fe617)
#### Thursday 2020-05-07 12:00:22 by Jeff King

ci: allow per-branch config for GitHub Actions

Depending on the workflows of individual developers, it can either be
convenient or annoying that our GitHub Actions CI jobs are run on every
branch. As an example of annoying: if you carry many half-finished
work-in-progress branches and rebase them frequently against master,
you'd get tons of failure reports that aren't interesting (not to
mention the wasted CPU).

This commit adds a new job which checks a special ref within the
repository for CI config, and (optionally) causes all of the other jobs
to be skipped.

There have been a few alternatives discussed:

One option is to carry information in the commit itself about whether it
should be tested, either in the tree itself (changing the workflow YAML
file) or in the commit message (a "[skip ci]" flag or similar). But
these are frustrating and error-prone to use:

  - you have to manually apply them to each branch that you want to mark

  - it's easy for them to leak into other workflows, like emailing patches

We could likewise try to get some information from the branch name. But
that leads to debates about whether the default should be "off" or "on",
and overriding still ends up somewhat awkward. If we default to "on",
you have to remember to name your branches appropriately to skip CI. And
if "off", you end up having to contort your branch names or duplicate
your pushes with an extra refspec.

By comparison, this commit's solution lets you specify your config once
and forget about it, and all of the data is off in its own ref, where it
can be changed by individual forks without touching the main tree.

I used refs/ci/config as the config ref, which should be a commit whose
tree contains various config files (right now the only one is
"ref-whitelist"). It was intentional to avoid refs/heads/ here so we
don't conflict with any branch workflows. But it does make it a little
awkward to edit, since you can't check it out directly.

Right now the logic is to run CI for all branches by default, unless a
whitelist exists, in which case the branch must be mentioned there
(using its fully qualified ref name). We could easily add in a
blacklist, as well. Or since we're running a shell in a VM, we really
could just run "./allow-ref $refname" and let individual forks specify
whatever shell code they like.

Signed-off-by: Jeff King <peff@peff.net>

---
## [pascua28/s5-kernel](https://github.com/pascua28/s5-kernel)@[553150be03...](https://github.com/pascua28/s5-kernel/commit/553150be0343744739f7fb23397a0158f1571e9b)
#### Thursday 2020-05-07 12:47:26 by Shrenuj Bansal

msm: kgsl: Add struct kgsl_device to kgsl_allocate_contiguous API

We need to pass a non NULL struct device * for the call to
dma_alloc_coherent(). Change certain APIs to allow us to pass
down struct kgsl_device ptr so we can pass in a valid struct
device * to dma_alloc_coherent()

Change-Id: I24eaa2b7834b573b0520f6aa1f00447eb1f35dc6
Signed-off-by: Shrenuj Bansal <shrenujb@codeaurora.org>

msm: kgsl: Remove unused sharedmem functions

No sense in keeping these sharedmem functions around and have to
try and maintain them.

Change-Id: I14b8584c575ed1f935251c54610c572cb51279d4
Signed-off-by: Carter Cooper <ccooper@codeaurora.org>

msm: kgsl: Make the dma_set_coherent_mask call universal

Now that we are required to send a non-NULL device ptr to
dma_alloc_coherent(), we need to interrogate the kernel to see if
the DMA controller can properly support the device's addressing
limitation. Therefore, moving the dma_set_coherent_mask to
adreno_probe before we allocate the ringbuffer.

Change-Id: I29e9c77e7551bc3447877aa5570e4d89fbb94a2e
Signed-off-by: Shrenuj Bansal <shrenujb@codeaurora.org>

msm: kgsl: Consolidate the contiguous memory allocation functions

We have competing contiguous memory allocation functions that
serve the same purpose. Use CMA for all our contiguous needs
and factor out the legacy code.

Change-Id: Ic0dedbad9965a456b24bc78e1f360242568f15bb
Signed-off-by: Jordan Crouse <jcrouse@codeaurora.org>

msm: kgsl: Remove Z180 driver

Support for any target that had the Z180 2D core has been removed
from the kernel.

Change-Id: Ic0dedbad1aaa8bbb9062b31f4140c1a17269ff51
Signed-off-by: Jordan Crouse <jcrouse@codeaurora.org>

msm: kgsl: Remove adreno postmortem

All the cool kids use snapshot now so remove adreno postmortem and
associated functionality.  Sorry postmortem - I think we should see
other people.  Its not you, its me. I've grown up.

Change-Id: Ic0dedbadf461ebab439c91068a0c43e1de74b74b
Signed-off-by: Jordan Crouse <jcrouse@codeaurora.org>

msm: kgsl: Remove A2XX support

All targets supporting A2XX GPUs were removed from the kernel in
b3270aa98aa7f4d7ccf1eef10e0624409dfe415f. If we left A2XX code
in KGSL it would bitrot that much faster. Farewell old friend.

Change-Id: Ic0dedbad7d31ab1c30e1fabf4f10f867a73299dc
Signed-off-by: Jordan Crouse <jcrouse@codeaurora.org>

msm: kgsl: Remove A3XX legacy context save/restore

The A3XX context save/restore code in the kernel is no longer needed by the
UMD.  Remove it and all other vestiges of context save/restore.
And there was much rejoicing.

Change-Id: Ic0dedbad84e862216ee9ad02d3bfe7558a209cca
Signed-off-by: Jordan Crouse <jcrouse@codeaurora.org>

---
## [p3ol/buddy](https://github.com/p3ol/buddy)@[fb526f2265...](https://github.com/p3ol/buddy/commit/fb526f226575cc05148d249a77185ad0480dd854)
#### Thursday 2020-05-07 13:50:39 by Ugo Stephant

docs: fix readme

that's what happens when you copy/paste shit like the lazy ass fuck you are

---
## [wincent/wincent](https://github.com/wincent/wincent)@[98b5a4af6f...](https://github.com/wincent/wincent/commit/98b5a4af6f690ffa0a98e4e5a79b991d1db790a7)
#### Thursday 2020-05-07 14:18:49 by Greg Hurrell

fix(git): avoid annoying breakage of starting "/" in Git pager output

Originally this commit was going to be a different hack to remedy an
annoying problem with `less --pattern=anything +r`, which breaks an
initial "/" on entering the pager (causes it to print "Pattern not found
(press RETURN)").

So, I had code in here to look at our buffer and:

- If there is a match, we know we don't need the "+r", so strip it:
  problem solved!
- If there is no match, we just delete both "--pattern" and "+r".

But I realized that if I just remove all of that (no "--pattern", no
"+r" in our Git "pager.<cmd>" config, and no special handling inside
"menos"), we can rely on our other hack, the one that manipulates the
LESSHISTFILE, to do the trick for us.

Bonus: this stops `less` from highlighting the search pattern as soon as
you hit "j", "k".

The ugly bit: "menos" looks like a generic wrapper, but it isn't really.
It (still) assumes a particular "pattern" is being passed (hence our check for
"commit|diff") and needs to be kept in sync with whatever is in
".gitconfig". A "proper" fix here would make a regexp from the pattern,
but that is made trickier due to the possibility of special characters
like C-k... I still might do that as a follow-up.

---
## [peff/git-ci](https://github.com/peff/git-ci)@[7fe3f9927f...](https://github.com/peff/git-ci/commit/7fe3f9927fddd78b4e23aaf8cfa448aa0ea8a120)
#### Thursday 2020-05-07 16:06:46 by Jeff King

ci: allow per-branch config for GitHub Actions

Depending on the workflows of individual developers, it can either be
convenient or annoying that our GitHub Actions CI jobs are run on every
branch. As an example of annoying: if you carry many half-finished
work-in-progress branches and rebase them frequently against master,
you'd get tons of failure reports that aren't interesting (not to
mention the wasted CPU).

This commit adds a new job which checks a special branch within the
repository for CI config, and then runs a shell script it finds there to
decide whether to skip the rest of the tests. The default will continue
to run tests for all refs if that branch or script is missing.

There have been a few alternatives discussed:

One option is to carry information in the commit itself about whether it
should be tested, either in the tree itself (changing the workflow YAML
file) or in the commit message (a "[skip ci]" flag or similar). But
these are frustrating and error-prone to use:

  - you have to manually apply them to each branch that you want to mark

  - it's easy for them to leak into other workflows, like emailing patches

We could likewise try to get some information from the branch name. But
that leads to debates about whether the default should be "off" or "on",
and overriding still ends up somewhat awkward. If we default to "on",
you have to remember to name your branches appropriately to skip CI. And
if "off", you end up having to contort your branch names or duplicate
your pushes with an extra refspec.

By comparison, this commit's solution lets you specify your config once
and forget about it, and all of the data is off in its own ref, where it
can be changed by individual forks without touching the main tree.

There were a few design decisions that came out of on-list discussion.
I'll summarize here:

 - we could use GitHub's API to retrieve the config ref, rather than a
   real checkout (and then just operate on it via some javascript). We
   still have to spin up a VM and contact GitHub over the network from
   it either way, so it ends up not being much faster. I opted to go
   with shell to keep things similar to our other tools (and really
   could implement allow-refs in any language you want). This also makes
   it easy to test your script locally, and to modify it within the
   context of a normal git.git tree.

 - we could keep the well-known refname out of refs/heads/ to avoid
   cluttering the branch namespace. But that makes it awkward to
   manipulate. By contrast, you can just "git checkout ci-config" to
   make changes.

 - we could assume the ci-config ref has nothing in it except config
   (i.e., a branch unrelated to the rest of git.git). But dealing with
   orphan branches is awkward. Instead, we'll do our best to efficiently
   check out only the ci/config directory using a shallow partial clone,
   which allows your ci-config branch to be just a normal branch, with
   your config changes on top.

 - we could provide a simpler interface, like a static list of ref
   patterns. But we can't get out of spinning up a whole VM anyway, so
   we might as well use that feature to make the config as flexible as
   possible. If we add more config, we should be able to reuse our
   partial-clone to set more outputs.

---
## [NetDenizen/hairsnip-archive-viewer](https://github.com/NetDenizen/hairsnip-archive-viewer)@[fb17cf81b1...](https://github.com/NetDenizen/hairsnip-archive-viewer/commit/fb17cf81b1836197838058c5349135e534c3f38d)
#### Thursday 2020-05-07 16:27:31 by NetDenizen

The custom set implementation was a fucking terrible idea.

Revert two commits:
Try our own, faster set implementation. It's broken, but why? (4cd53e76632ca9612aef6889c6cfefd808c60b37)
Way too complicated optimization that's still too slow.  (2fe48f852cfc30fb592ec0c797aac9f6507fa455)

Holy fucking shit, I can't believe I wasted 16 hours of my life on this.

---
## [golang/go](https://github.com/golang/go)@[6f52790a20...](https://github.com/golang/go/commit/6f52790a20a2432ae61e0ec9852a3df823a16d40)
#### Thursday 2020-05-07 19:23:03 by Filippo Valsorda

crypto/x509: use Security.framework without cgo for roots on macOS

+----------------------------------------------------------------------+
| Hello, if you are reading this and run macOS, please test this code: |
|                                                                      |
| $ GO111MODULE=on go get golang.org/dl/gotip@latest                   |
| $ gotip download                                              |
| $ GODEBUG=x509roots=1 gotip test crypto/x509 -v -run TestSystemRoots |
+----------------------------------------------------------------------+

We currently have two code paths to extract system roots on macOS: one
uses cgo to invoke a maze of Security.framework APIs; the other is a
horrible fallback that runs "/usr/bin/security verify-cert" on every
root that has custom policies to check if it's trusted for SSL.

The fallback is not only terrifying because it shells out to a binary,
but also because it lets in certificates that are not trusted roots but
are signed by trusted roots, and because it applies some filters (EKUs
and expiration) only to roots with custom policies, as the others are
not passed to verify-cert. The other code path, of course, requires cgo,
so can't be used when cross-compiling and involves a large ball of C.

It's all a mess, and it broke oh-so-many times (#14514, #16532, #19436,
 #20990, #21416, #24437, #24652, #25649, #26073, #27958, #28025, #28092,
 #29497, #30471, #30672, #30763, #30889, #32891, #38215, #38365, ...).

Since macOS does not have a stable syscall ABI, we already dynamically
link and invoke libSystem.dylib regardless of cgo availability (#17490).

How that works is that functions in package syscall (like syscall.Open)
take the address of assembly trampolines (like libc_open_trampoline)
that jump to symbols imported with cgo_import_dynamic (like libc_open),
and pass them along with arguments to syscall.syscall (which is
implemented as runtime.syscall_syscall). syscall_syscall informs the
scheduler and profiler, and then uses asmcgocall to switch to a system
stack and invoke runtime.syscall. The latter is an assembly trampoline
that unpacks the Go ABI arguments passed to syscall.syscall, finally
calls the remote function, and puts the return value on the Go stack.
(This last bit is the part that cgo compiles from a C wrapper.)

We can do something similar to link and invoke Security.framework!

The one difference is that runtime.syscall and friends check errors
based on the errno convention, which Security doesn't follow, so I added
runtime.syscallNoErr which just skips interpreting the return value.
We only need a variant with six arguments because the calling convention
is register-based, and extra arguments simply zero out some registers.

That's plumbed through as crypto/x509/internal/macOS.syscall. The rest
of that package is a set of wrappers for Security.framework and Core
Foundation functions, like syscall is for libSystem. In theory, as long
as macOS respects ABI backwards compatibility (a.k.a. as long as
binaries built for a previous OS version keep running) this should be
stable, as the final result is not different from what a C compiler
would make. (One exception might be dictionary key strings, which we
make our own copy of instead of using the dynamic symbol. If they change
the value of those strings things might break. But why would they.)

Finally, I rewrote the crypto/x509 cgo logic in Go using those wrappers.
It works! I tried to make it match 1:1 the old logic, so that
root_darwin_amd64.go can be reviewed by comparing it to
root_cgo_darwin_amd64.go. The only difference is that we do proper error
handling now, and assume that if there is no error the return values are
there, while before we'd just check for nil pointers and move on.

I kept the cgo logic to help with review and testing, but we should
delete it once we are confident the new code works.

The nocgo logic is gone and we shall never speak of it again.

Fixes #32604
Fixes #19561
Fixes #38365
Awakens Cthulhu

Change-Id: Id850962bad667f71e3af594bdfebbbb1edfbcbb4
Reviewed-on: https://go-review.googlesource.com/c/go/+/227037
Reviewed-by: Katie Hockman <katie@golang.org>

---
## [Shinoow/AbyssalCraft](https://github.com/Shinoow/AbyssalCraft)@[248eceb82e...](https://github.com/Shinoow/AbyssalCraft/commit/248eceb82e0c3cd11345c951f764f79f0948f007)
#### Thursday 2020-05-07 19:40:33 by Shinoow

AbyssalCraft 1.9.19

*Changed the default values for a couple of config options (check the description of GitHub commit 69817fc for more info)
*Changed the internals of fuel handling for the Crystallizer and Transmutator (event runs before the defaults are applied, so you can override them)
*Added some ambient void particle rendering in Omothol and the Dark Realm
*Added a config option that toggles whether or not Evil Animals spawn Demon Animals on death
*Added a config option that toggles whether or not Evil Animals only spawn at night during a new moon
*Fixed the sky color in the Darklands biome (closes #425)
*Omothol Ghouls are actually immune to fire now (apparently they weren't, despite the book claiming they were)
*The PE Stream particle (the thing you see when PE is being transferred) now respects the particle settings (lower setting = fewer particles)
*Changed a plethora of Crystallizer recipes (added ore doubling, among others) and Transmutator recipes (reverting crystals is cost inefficient) along with removing crystals as fuels
*Added a config option (under modules) to revert back to the old recipes and behavior
*Crystal Clusters are now in the Ore Dictionary (as "crystalClusterX", where X is the element)
*Added Calcium, Beryllium and Beryl crystals to the Ore Dictionary
*Reworked the PE transfer logic in the statues to increase performance (closes #424)
*Added an upper limit to how many PE particles can spawn at a time (should boost performance for larger PE generation and/or transportation setups)
*Optimized the worshiping AI for Lesser Shoggoths and Remnants slightly
*Added a config option that toggles whether or not Lesser Shoggoth eyes will glow (will save you some performance if you drop FPS while looking at them) (closes #353)
*Added API support for adding your own Rendings to the Staff of Rending (currently the Rending Pedestal doesn't support custom Rendings)

---
## [alexbarraboldu/OneMonthJam](https://github.com/alexbarraboldu/OneMonthJam)@[9b523bd8e3...](https://github.com/alexbarraboldu/OneMonthJam/commit/9b523bd8e381099178a343969c64d75cfba76c57)
#### Thursday 2020-05-07 19:40:44 by AlexBarra

FIXED ALL YOUR BULLSHIT CODE

u stupid ass bitch n*gga

---
## [PartyLich/kyren.github.io](https://github.com/PartyLich/kyren.github.io)@[76646ab7e9...](https://github.com/PartyLich/kyren.github.io/commit/76646ab7e944bae2c3600aae65e97446c88288c6)
#### Thursday 2020-05-07 20:32:13 by Arthur

small typos and hyperlinks for sections and crates

The typo (leftover word) in the opening paragraphs bothered me, so I fixed it....and then I got carried away and kept fixing little trivial things as I read. Sorry about that.

I enjoyed that conf talk and the longer written version, and as I start to read through the code in some of your repos I think/hope I'm learning more. At the very least, learning more about the gigantic magnitude of the things I do not know. If you're still publicly posting thoughts/research/essays/etc somewhere, I'd love to have a link.

---
## [saqib-ali/hivemined](https://github.com/saqib-ali/hivemined)@[eb2d6d28a7...](https://github.com/saqib-ali/hivemined/commit/eb2d6d28a7b6822866febdf4f306fe9166266cae)
#### Thursday 2020-05-07 23:45:24 by Saqib Ali

Udemy - Senior Machine Learning Engineer. Udemy - Senior Machine Learning Engineer. Machine Learning Expert for Autonomy, Lead - MITRE Careers. Laplace’s Demon: A Seminar Series about Bayesian Machine Learning at Scale «  Statistical Modeling, Causal Inference, and Social Science. Lecture 11: Introduction to Machine Learning | Lecture Videos | Introduction to Computational Thinking and Data Science | Electrical Engineering and Computer Science | MIT OpenCourseWare. Catalogue of new Herbig Ae/Be and classical Be stars. A machine learning approach to Gaia DR2 - NASA/ADS. Machine Learning Researcher/Engineer | ResearchJobs.cz. AI, Automation and Machine Learning - the Future of Work is Now | DCU. Principal Software Automation Engineer (Machine Learning Toolchain) - FocusKPI Inc. - Career Page. Engineering Manager, Ads Machine Learning  - Seattle, Washington, United States.

---

# [<](2020-05-06.md) 2020-05-07 [>](2020-05-08.md)

