# [<](2020-07-27.md) 2020-07-28 [>](2020-07-29.md)

2,568,634 events, 1,283,521 push events, 2,053,478 commit messages, 164,874,759 characters


## [kamilyman/Sugar-Honey-Ice-Tea](https://github.com/kamilyman/Sugar-Honey-Ice-Tea)@[7a1f0cc2b6...](https://github.com/kamilyman/Sugar-Honey-Ice-Tea/commit/7a1f0cc2b60b43f6acd2a256dadf6c710edf6ec3)
#### Tuesday 2020-07-28 01:39:00 by kamilyman

Create README.md

Look at the pool behind the dumpster in the morning but I'm still waiting for my mom to take a shower then go wash her hands and get what you want to do with my boyfriend and my mom and dad who are true to the store for cigarettes and some shirts for you now where I live in a tent at the pool behind the dumpster at the pool behind the dumpster at the pool behind the dumpster in a black and green whatever you can get a new one on my phone is about you all kinds when you have a good look to go back and plus I can get you some stamps and get what you want to do with my kids at my house tonight so they'll have to be with me on lockdown at the same day I left the room right now I live on a date to get some food and stuff for the first corner its black in my room right here and be the last one I believe to be with me on the way you know your sexy ass can be with me on the way to the store for a few hours I just need to get some money for my family because my mom is supposed to pick me up at my house tonight.

---
## [jsburger/defpack](https://github.com/jsburger/defpack)@[22ba00759b...](https://github.com/jsburger/defpack/commit/22ba00759b226526a5f18242f5054b4b2e8aa4f0)
#### Tuesday 2020-07-28 02:32:29 by BioOnPC

BIG FUCKING TIP UPDATE

Changed tips for the following weapons:

- Ultra Gunhammer: UNBELIEVABLE POWER → UNBELIEVABLE HAMMERING
- Smarter Gun: MASSIVE BRAIN → THINK FASTER
- Rifle: CHROME LINED, 4150 STEEL BARREL → HIT REGISTRATION
- Flak Shotgun: 540/600 → TOP RATED
- Phlogenitator: OH @rYEAH → BURNING COMETS
- Wide Slugger: BRICK BLASTER → GOODBYE BODY
- Good Shotgun: replace me pls → A STRAIGHT UPGRADE
- Blood Crossbow: BONE LAUNCHER, THE BONE ZONE → NOTHING GOES TO WASTE
- Splinter Cannon: CONSIDER IT HYPER → THAT HAS TO HURT
- Millimata: FANCY ME A VOODOO DOLL → WHO NEEDS VOODOO
- Bouncer Disc Gun: SORRY → OOPS
- Sticky Disc Gun: DAMAGE OVER TIME → THIS IS YOUR OWN FAULT
- Record Dealer: A FUNKY MIX → WRITE A LOVE SONG
- Disc Spam Gun: Our sincere apologies → SORRIES WON'T COVER THIS
- Dart Rifle: STICKY @wDARTS → GET IT OFF
- Dart Shotgun: ANTI-PERSONELL WATER GUN → THEY WON'T COME OFF
- Dart Bazooka: 1179 POINTS, BIG @wDART → 100.86 AVERAGE
- Knife Thrower: LITTLE TERROR → REN FAIRE
- Heavy Toxic Crossbow: FILL THE AIR WITH GREEN GOODNESS → STALE AIR
- Hyper Crossbow: BOLT STREAMER → 1 FAST BOLT PER SHOT
- Abris Rifle: FASTER, FASTER → IN YOUR SIGHTS
- Blood Abris Launcher: THE SPLASH ZONE → GRUESOME
- Sonic Launcher: NOISY NADES → NOISY
- Supersonic Launcher: A TRUE BOOMBURST, SHIFT SOME SMOKE, CLOSE COMBAT INFUSION → DEAFENING
- Sonic Hammer: HERE WE GO → BASS IN YOUR EAR
- Grenade Minigun: BLESSED BY#THE @wGRENADE @sGOD HIMSELF → LOAD IT UP, HARD TO BE CAREFUL
- Auto Grenade Launcher: GOES WELL WITH STRESS → CONSTANT EXPLOSIONS
- Herald: THIS IS THE END OF IT → THE END OF IT ALL
- Vector Rifle: POINTY → MOVING PARTICLES
- Vector Shotgun: POINTY → PARTICLE ACCELERATION
- Plasmite Pistol: THE FUTURE OF PAINTBALL → EHE
- Turbo-Murderizer 3000: RIDICULOUS → COMEDY GREEN
- Bone: DEVILISH → GHOULISH
- Rapier: MAKE SOME NEW FRIENDS → FANCY FOOTWORK
- Rebounce Axe: "BE BRAVE", "STRIKE AGAIN" → "BE BRAVE, STRIKE AGAIN", "DON'T STOP HITTING THEM"
- Impact Fist: YOU WILL BE MISSED → OBLITERATE
- Hex Needle: WORKIN' THE MOJO → ANGRY SPIRITS
- Soda Popper: THE FIZZY REVOLVER → CAN'T GET ENOUGH
- Smarter Bouncer Gun: MASSIVE BRAIN → RELOCATING FILES
- Smarter Fire Gun: MASSIVE BRAIN → HOTTER HEAD
- Mega Pest Revolver: TOO BIG FOR THE HOLSTER → THROW THE HOLSTER IN THE WASH
- Pest SMG: replace me pls → UNENDING TOXICITY
- Smarter Pest Gun: MASSIVE BRAIN → INTRUSIVE THOUGHTS
- Heavy Assault Psy Rifle: NO ESCAPE → HUNT THEM DOWN
- Smarter Psy Gun: MASSIVE BRAIN → NEURAL NETWORK
- Heavy Smart Thunder Gun: LIGHTNING → JUDGEMENT OF ZEUS
- Smarter Thunder Gun: MASSIVE BRAIN → RACING MIND

---
## [payday-restoration/restoration-mod](https://github.com/payday-restoration/restoration-mod)@[6f76837c6d...](https://github.com/payday-restoration/restoration-mod/commit/6f76837c6d6ee7dd7c33ce307fe25c90f59cb70a)
#### Tuesday 2020-07-28 02:55:17 by Neslon-Poggers

FUCK FUCK FUCK FUCK!!!!!! FIX FOR THE ANDREAS' O' DEATH

HOLY SHIT HOLY SHIT I'M SORRY

---
## [CliMA/ClimateMachine.jl](https://github.com/CliMA/ClimateMachine.jl)@[e4a9641dea...](https://github.com/CliMA/ClimateMachine.jl/commit/e4a9641dea86079f2b0ca2235224d313d849f562)
#### Tuesday 2020-07-28 03:48:21 by bors[bot]

Merge #1162 #1383

1162: DifferentialEquations.jl-Based ODE Solvers r=charleskawczynski a=ChrisRackauckas

This sets up "two" ODE solvers: DiffEqJLSolver and DiffEqJLIMEXSolver. These solvers allow taking in a `DEAlgorithm` which can be any DiffEq common interface ODE solver that satisfies the common integrator interface, which includes OrdinaryDiffEq, Sundials, and a few others. 

The only kernel calls are done through fused broadcasts, so in theory there shouldn't be any overhead on large problems as long as we are only using the right number of kernels. In practice, since this is our first super larger scale application since we plan to track, there may be an extra kernel call somewhere, and so I assume that after we get attempt 1 done here we may need to make an upstream change. The standard RK methods (including the SSP methods, which includes some methods with enhanced stability specifically for DG discretizations) should all be optimized already. I think we may need to do something special for the low-storage RK methods.

As for implicit and IMEX methods, I setup the interface for how to hook into them, though we may need to setup a linear solver for DiffEq. That can be done via https://docs.sciml.ai/latest/features/linear_nonlinear/#Linear-Solvers:-linsolve-Specification-1 , so we can just make the solvers call your linear solvers.

## Why?

There are a few things we're looking at for how this will benefit both our own research and Clima. To list a few:

- Our methods for [numerical uncertainty quantification](https://docs.sciml.ai/latest/analysis/uncertainty_quantification/) will allow for understanding the error induced by the time stepping methods. There's other (undocumented) UQ methods being published soon which could be useful too.
- [Checkpointed adjoint sensitivity analysis](https://docs.sciml.ai/latest/analysis/sensitivity/) for parameter fitting and UQ is probably a big feature Clima would gain from this. More work might be required to complete the integration of this, but I think there could be a lot of uses.
- Stochastic differential equation models would be pretty accessible from this form, so if there are reasonable extensions to SPDEs they can be considered and high order adaptive methods can be applied.
- [Generalized Physics-Informed Learning](https://youtu.be/SEhMWkgcTOI): you can see from this talk that I want to start taking this to climate models for developing surrogates.
- Tons of new methods. Specifically:
  - [A bunch of SSP methods](https://docs.sciml.ai/latest/solvers/ode_solve/#Explicit-Strong-Stability-Preserving-Runge-Kutta-Methods-for-Hyperbolic-PDEs-(Conservation-Laws)-1)
  - [A bunch of low-storage RK methods](https://docs.sciml.ai/latest/solvers/ode_solve/#Low-Storage-Methods-1)
  - [A bunch of IMEX methods](https://docs.sciml.ai/latest/solvers/split_ode_solve/#OrdinaryDiffEq.jl-1)
  - Whatever we build in the future.

The benefits to SciML are:

- We see that there's been some recent work in MRI methods. It would be nice to capture that momentum as something that can be added directly to OrdinaryDiffEq (or even just in SimpleDiffEq.jl or another common interface algorithm package) so that they can be used on an SplitODEProblem. This would enhance the Julia ecosystem beyond Clima and be something that can then be demonstrated as a benefit of the Clima project to other projects down the line. By creating this common interface ODE solver algorithm for Clima, I hope we can accelerate this effort because now, if the MRI methods are moved to a DiffEq interface compatible package, they should be usable in Clima without overhead which should be a good incentive to do so!
- We can start to use Clima as one of our canonical benchmarks, and hopefully overtime improve algorithm performance on Clima's type of problems and use it as a source of real-world problems in publications and grants (possibly we could look for a joint grant in this area).
- This serves as a good testing ground for MPI and GPU based array usage. It won't be perfect until we have a real test, so let's get a test!

So in short, this should help Clima get a few new features while improving SciML for large models to help out other PDE-based modeling projects beyond Clima.

## Current Issues

There are a few small issues noticed in this PR:

- What test case should I be using? I just grabbed what was in the ODESolver tests, but what's a good demo climate simulation I can start using to test out CPU usage, GPU usage, and MPI+GPU usage? I'd like to have these three cases for development and to add to [DiffEqBenchmarks.jl](https://github.com/SciML/DiffEqBenchmarks.jl).
- When is `p` defined? In the DiffEq solvers, we want `p` at the time of the construction of the `ODEProblem` so we can concretely type the integrator. We at least need to know and have something of its type. The test just has `nothing` parameters, so that works, but I wonder if this will be an issue. I added `p` as a keyword argument to the solver's constructor.
- The methods from Sundials and other C++/Fortran libraries are "technically" supported, but in reality they need the array type to be an `Array`, which I assume will almost never be the case with Clima. Sundials does have some good MRI methods that would be interesting to try out here, but making them work would require making NVector wrappers which, it might just be easier to make Julia versions of all of that (and that is a summer project for students).
- Is there any more structure in the ODEs that can be exploited? Semilinearity for exponential integrators or anything of that sort? Symplecticness or partitioning of the states? 
- Dependencies: are you open to a DiffEqBase dependency? That's a whole lot smaller than OrdinaryDiffEq or DifferentialEquations.jl. A user would need to `using DifferentialEquations` (or just `using OrdinaryDiffEq`) to actually get solver methods.

## What's Next?

If this is setup, then I would like to have some of our GSoC and MLH students optimize this interfacing and demonstrate results using it. That would then set the stage for less technical more mathematical students to just do pure algorithm development in OrdinaryDiffEq knowing that this would be efficient. I hope we can demonstrate that this connection ends up calling the optimal number of kernels by the end of the summer.

In 18.337 Scientific Machine Learning and Parallel Computing in the next fall, each student has final projects to do and, if this is all setup, I would like to point a few students towards implementing some new methods and demonstrating the results on Clima, so this is where new IMEX, MRI, etc. methods can get developed, improved, and tested.



1383: Add `flattened_tup_chain ` and chained getproperty/getindex methods r=charleskawczynski a=charleskawczynski

# Description

Debugging highly nested models (e.g., EDMF) is difficult because, at the moment, checking fields in all sub-models requires manually writing out all fields/subfields, or writing recursive `getproperty`/`getindex` methods, which is painful/overkill just for debugging. This PR adds a method `flattened_tup_chain`, along with a recursive and interleaved `getindex`/`getproperty`, to `VariableTemplates` so that users can iterate through every field in compute kernels in a convenient way, as demonstrated in a new test in the test suite:

```julia
    ftc = flattened_tup_chain(st)
    @test ftc[1] === (:ntuple_model, 1, :scalar_model, :x)
    @test ftc[2] === (:ntuple_model, 2, :scalar_model, :x)
    @test ftc[3] === (:ntuple_model, 3, :scalar_model, :x)
    @test ftc[4] === (:vector_model, :x)
    @test ftc[5] === (:scalar_model, :x)

    # getproperty with tup-chain
    for i in 1:N
        @test v.scalar_model.x == getproperty(v, (:scalar_model, :x))
        @test v.vector_model.x == getproperty(v, (:vector_model, :x))
        @test v.ntuple_model[i] == getproperty(v, (:ntuple_model, i))
        @test v.ntuple_model[i].scalar_model == getproperty(v, (:ntuple_model, i, :scalar_model))
        @test v.ntuple_model[i].scalar_model.x == getproperty(v, (:ntuple_model, i, :scalar_model, :x))
    end
```

If we change our initialization, as suggested by @trontrytel and discussed with @kpamnany, to initializing fields to `NaN`s, a very practical use-case of this might look like:

```julia
function init_heldsuarez!(balance_law, state::Vars{st}, aux::Vars{au}, coords, t) where {st,au}

    # Initialize fields...

    for tc in flattened_tup_chain(st)
        @assert getproperty(state, tc) ≠ NaN
    end
    for tc in flattened_tup_chain(au)
        @assert getproperty(aux, tc) ≠ NaN
    end
    # All fields in all balance_law submodels are now gauranteed to be initialized
end
```



Co-authored-by: Chris Rackauckas <accounts@chrisrackauckas.com>
Co-authored-by: Charles Kawczynski <kawczynski.charles@gmail.com>

---
## [JuliaData/CSV.jl](https://github.com/JuliaData/CSV.jl)@[ac3761d1bf...](https://github.com/JuliaData/CSV.jl/commit/ac3761d1bffe64a5d83644366df2e38edac11424)
#### Tuesday 2020-07-28 04:16:50 by Jacob Quinn

Change deprecation warning for CSV.read

Fixes https://github.com/JuliaData/DataFrames.jl/issues/2309. After much
discussion, people really like the `CSV.read` function call naming, so
it was decided to keep it around, while still allowing a break from
DataFrames.jl as a dependency.

I also realized that `CSV.read` does indeed provide one bit of
value/functionality: we can wrap `CSV.File` in `Tables.CopiedColumns`.
What this means is that columnar sinks can safely use the columns passed
without needing to make copies; i.e. they can assume ownership of the
columns. In `CSV.read`, the user is essentially saying, "I want to make
a `CSV.File` and pass it directly to `sink`" which also implies that
`CSV.File` doesn't need to "own" its own columns.

The only question left in my mind is, with the 1.0 release, what to do
with `CSV.read(file)` when no `sink` argument is passed. Suggestions
have included just returning a `CSV.File`, since it's a valid table
anyway. Or allowing DataFrames.jl to define the no-sink-arg version and
return a `DataFrame`; that one's a bit awkward as a form of "blessed"
type piracy, but could also be useful for users as convenience (they
just have to remember to do `using DataFrames` before trying to use it).
The other awkward part is that we're currently warning users of the
deprecation and that they should explicitly spell out `DataFrame`
whereas we might not actually require that.

---
## [xyzyzl/hard-cp](https://github.com/xyzyzl/hard-cp)@[2eb9659321...](https://github.com/xyzyzl/hard-cp/commit/2eb9659321641f874450f62f919865b68c75fccd)
#### Tuesday 2020-07-28 04:52:33 by Albert Ye

cowmbat redone, original was probably a copy of the editorial as usual
fuck yeah i am not that stupid anymore YUH

---
## [payday-restoration/restoration-mod](https://github.com/payday-restoration/restoration-mod)@[59ae37dbb8...](https://github.com/payday-restoration/restoration-mod/commit/59ae37dbb86d952ef536669cdfe75f210ad1b79a)
#### Tuesday 2020-07-28 06:02:05 by Neslon-Poggers

buncha shit

OMNIA Dozer Bullshit:
- removed removable uv seams
- added proper lods
- made materials easier to sort through
- added in proper decal mesh for headshots so blood sprays out
- Dr. Bob

other stuff
- added in proper m60 sounds (holy shit how did sounds_prefix not crash)

- please let me know if there's anything wrong with the ominac dosers, i didn't come across much during testing

---
## [deguix/DnD](https://github.com/deguix/DnD)@[1b262238a5...](https://github.com/deguix/DnD/commit/1b262238a55ea1865e08fa6d8dc474774f0e3f62)
#### Tuesday 2020-07-28 08:22:49 by Doruk Aksoy

Experimental Build, Don't Host

 - Rewrote monster code structure to allow easy modification of all monsters through a single source.
  - As such, all monster arche-types have the same innate weakness or resists, no exceptions.
  - Monsters that didn't benefit fully from Elite Extra Fast modifier now properly benefit from it.
  - Spider Mastermind minigun spin sound fixed.
  - Monster classes have been regularized. All monsters of a certain archetype have proper weakness or resists.
  - Stone monsters have "Stone Creature" label. This gives: Physical resist, explosive resist, lightning and poison immunity, fire resist and ice weakness.
  - Earth monsters have "Earth Creature" label. This gives: Poison Immunity, Lightning Weakness.
  - Fire monsters have "Fire Creature" label. This gives: Fire Immunity, Ice Weakness.
  - Fixed floor clip flag of flying monsters after they resurrect.
  - Terminator now has "Energy Resist".
  - Azazel now has "Magic Immune".
  - Azazel heal regulated to be a flat 150 health instead of random (100, 160).
  - Avatar of Chaos now has "Magic Resist".
  - Gladiator no longer has fire resistance.
  - Godslayer now has "Energy Resist".
  - Corpulents now have "Elemental Weakness".
  - Daedabus and Mafibus are now "Fire Creatures".
  - Gamon no longer has a weird lightning weakness, and has "Energy Resist".
  - Gold Golem now has "Magic Resist".
  - Blood Lich resists converted to fit "Fire Creature" model.
  - Blood Lich frame durations for attacking and getting hurt increased a bit.
  - Hell Arbiter now has "Fire Creature".
  - Hades Elemental now properly tosses the Hades Spheres, and will prefer that attack more often.
  - Hades Elemental has a new attack variation.
  - Angel of Death now has "Magic Resist".
  - Removed crappy melee attack from Gold Lich.
  - Spider Overlord now has "Energy Immune".
  - Hell Warrior melee now works as intended.
  - Earth Lich, Earth Golem and Kjaroch now have "Earth Creature".
  - Ice Golem and Yeti are no longer weak against explosives.
  - Soul ammo now only drops from Baron, Mancubus, Arachnotron or Boss tier monsters. And they have to be Demon type monsters as well.
  - Soul ammo drop rate lowered to a general 10%, but this can increase with Luck or other stats that improve drop rates.
  - Mo_Revived is no longer used. Direct flag checks are done on MonsterProperties instead.
  - Boss monsters now have their names in orange as intended.
  - Any monster that leaves a corpse behind except Cyberdemon or Spider Mastermind tier monsters can be resurrected.
  - The only exception to the above rule are ArchVile type monsters that can resurrect monsters.
  - Lava Giant melee issue fixed and made more lethal.
  - Cerberus has a new attack pattern and chance to use pattern attack increased.
  - Monster modifier codex updated.
  - Hells Fury has new combos.
  - Bullet tracers from zombies no longer count as special fx. (So clients don't get hit by unknown things)
  - Regulated the gib format, they all properly use blood colors of their respective monsters. Depending on monster type more or less gibs are created.
  - Monsters should now gib more properly and frequently.
  - Dreaming God can now corpse explode as intended.
  - Dreaming God will do a spread attack on his long range attack.

---
## [l1k/linux](https://github.com/l1k/linux)@[909c4651ab...](https://github.com/l1k/linux/commit/909c4651ab77d30ab7bfbfc2350a5a1d436f05cf)
#### Tuesday 2020-07-28 10:45:44 by Lukas Wunner

PCI: pciehp: Reduce noisiness on hot removal

When a PCIe card is hot-removed, the Presence Detect State and Data Link
Layer Link Active bits often do not clear simultaneously.  I've seen
delays of up to 244 msec between the two events with Thunderbolt.

After pciehp has brought down the slot in response to the first event,
the other bit may still be set.  It's not discernible whether it's set
because a new card is already in the slot or if it will soon clear.
So pciehp tries to bring up the slot and in the latter case fails with
a bunch of messages, some of them at KERN_ERR severity.  The messages
are false positives if the slot is no longer occupied and annoy users.

Stuart Hayes reports the following splat on hot removal:

KERN_INFO pcieport 0000:3c:06.0: pciehp: Slot(180): Link Up
KERN_INFO pcieport 0000:3c:06.0: pciehp: Timeout waiting for Presence Detect
KERN_ERR  pcieport 0000:3c:06.0: pciehp: link training error: status 0x0001
KERN_ERR  pcieport 0000:3c:06.0: pciehp: Failed to check link status

Dongdong Liu complains about a similar splat:

KERN_INFO pciehp 0000:80:10.0:pcie004: Slot(36): Link Down
KERN_INFO iommu: Removing device 0000:87:00.0 from group 12
KERN_INFO pciehp 0000:80:10.0:pcie004: Slot(36): Card present
KERN_INFO pcieport 0000:80:10.0: Data Link Layer Link Active not set in 1000 msec
KERN_ERR  pciehp 0000:80:10.0:pcie004: Failed to check link status

Users are particularly irritated to see a bringup attempt even though
the slot was explicitly brought down via sysfs.  In a perfect world, we
could avoid this by setting Link Disable on slot bringdown and
re-enabling it upon a Presence Detect State change.  In reality however,
there are broken hotplug ports which hardwire Presence Detect to zero,
see 80696f991424 ("PCI: pciehp: Tolerate Presence Detect hardwired to
zero").  Conversely, PCIe r1.0 hotplug ports hardwire Link Active to
zero because Link Active Reporting wasn't specified before PCIe r1.1.
On unplug, some ports first clear Presence then Link (see Stuart Hayes'
splat) whereas others use the inverse order (see Dongdong Liu's splat).
To top it off, there are hotplug ports which flap the Presence and Link
bits on slot bringup, see 6c35a1ac3da6 ("PCI: pciehp: Tolerate initially
unstable link").

pciehp is designed to work with all of these variants.  Surplus attempts
at slot bringup are a lesser evil than not being able to bring up slots
at all.  Although we could try to perfect the behavior for specific
hotplug controllers, we'd risk breaking others or increasing code
complexity.

But we can certainly minimize annoyance by emitting only a single
message with KERN_INFO severity if bringup is unsuccessful:

* Drop the "Timeout waiting for Presence Detect" message in
  pcie_wait_for_presence().  The sole caller of that function,
  pciehp_check_link_status(), ignores the timeout and carries on.
  It emits error messages of its own and I don't think this particular
  message adds much value.

* There's a single error condition in pciehp_check_link_status() which
  does not emit a message.  Adding one allows dropping the "Failed to
  check link status" message emitted by board_added() if
  pciehp_check_link_status() returns a non-zero integer.

* Tone down all messages in pciehp_check_link_status() to KERN_INFO
  severity and rephrase them to look as innocuous as possible.  To this
  end, move the message emitted by pcie_wait_for_link_delay() to its
  callers.

As a result, Stuart Hayes' splat becomes:

KERN_INFO pcieport 0000:3c:06.0: pciehp: Slot(180): Link Up
KERN_INFO pcieport 0000:3c:06.0: pciehp: Slot(180): Cannot train link: status 0x0001

Dongdong Liu's splat becomes:

KERN_INFO pciehp 0000:80:10.0:pcie004: Slot(36): Card present
KERN_INFO pciehp 0000:80:10.0:pcie004: Slot(36): No link

The messages now merely serve as information that presence or link bits
were set a little longer than expected.  Bringup failures which are not
false positives are still reported, albeit no longer at KERN_ERR
severity.

Link: https://lore.kernel.org/linux-pci/20200310182100.102987-1-stuart.w.hayes@gmail.com/
Link: https://lore.kernel.org/linux-pci/1547649064-19019-1-git-send-email-liudongdong3@huawei.com/
Reported-by: Stuart Hayes <stuart.w.hayes@gmail.com>
Reported-by: Dongdong Liu <liudongdong3@huawei.com>
Signed-off-by: Lukas Wunner <lukas@wunner.de>

---
## [patricksnape/flask-on-docker](https://github.com/patricksnape/flask-on-docker)@[5a5bb60d79...](https://github.com/patricksnape/flask-on-docker/commit/5a5bb60d79f440bdfc1939cb2c11da801585787a)
#### Tuesday 2020-07-28 11:10:57 by Patrick Snape

Add poor mans class for tracking RSVP state changes

I'm not totally happy with this implementation but it does seem
pragmatically like the simplest thing to do. I explicitly store
the set of changes in a new table. The really ugly thing is I had
to create an extra frozen RSVP class to store the RSVP state because
sqlalchemy is annoying and changes the ORM state silently when I
update the state. So I can;t just hold a reference to the "before"
state because sqlalchemy will expire the state and refetch it when
I go to commit. I tried various tricks around expire_on_commit
and new transactions etc to stop this (including explicitly
expunging the ORM objects) but none of it worked. So now I have
a frozen object class that feels awfully like it should be a database
table. BUT I don't like the lack of referential integrity around
storing a list of attending guest IDs...

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[33a930202e...](https://github.com/mrakgr/The-Spiral-Language/commit/33a930202e381b826f1b6cd7d0e0b03521628751)
#### Tuesday 2020-07-28 11:55:46 by Marko Grdinić

"11:30am. Yeah, I think in review you will always regret not being rational in the end. I think this is one lesson I can take from my decades of life.

12:30pm. Done with breakfast.

What I'll do today is do the monthly review. What did I even do this month?

Blockization and parsing after that. It seems I've been working on the parser for 2.5 weeks now. I has been longer than I thought it has. Yeah, progress is being made slowly. Let me start the review with this.

///

In July, I made the tokenizer incremental, finished the blockizer and then made the block parser. Rather than redoing the whole file on every change, in v0.2 the file is split into blocks based on where statements begin and end. Meaning, every top-level statement is treated as its own block independent of the rest.

In the previous version of Spiral (and the January v0.2 prototype) I did not spend too much effort on making parser errors good, in fact it really bothered me how arbitrary they appeared to be during testing, but what I have now is worlds apart. Start the server, and start the VS Code plugin and you can see the errors exactly on point in the editor now. I do not think the error messages are great, but they are not poor by any means. If you know the language syntax they are quite satisfactory. The language syntax requires almost no backtracking, so I've been able to take advantage of that to good effect.

If I were competing with F# for which language has better tooling I'd have quite a hard time. The same goes with Haskell when it comes to type system features. I've made up my mind to ignore those temptations and just focus on getting the product to ship. The main goal with v0.2 is to make something broadly useful, and then if I can get those ensemble agents to work, only then will I focus on polishing up the language. I must not forget that the killer use of type systems is that they enable top-down reasoning. Once you have a working type system and incremental compilation, you get 85% of the benefit of a language. Things like auto complete, unused variable highlighting, renaming, reference finding...plus esoteric type system features that have substitutes, all the things that while being beneficial would also take a lot of work can be left for the future.

The next thing on my list is the top-down type system. At the time of writing this, I just finished annotating every part of the parsed AST with its range and thanks to that I can finally start considering the type checking phase seriously. I thought I might do the prepass and the partial evaluation pass with which I am much more familiar before this, but I've decided in the end that I do not want redo those after I go back and do type checking. So I'll do it all in order.

Mastering type inference is one of the main challenges for me in v0.2. Everything else, while a lot of work, I already know how to do. Once I push through this part, the core feature of v0.2 will be done and I will be able to put everything into place.

My estimated time until I am done is 2-3 months. I'll need at least a month to get type checking done, and then at least a week each for the prepass and the partial evaluator which is fast, but I am quite familiar with those parts. Add codegen and testing to that and it will fill out another two. More likely, this will be an underestimate. The type checker might take longer, or work that I haven't anticipated might need doing. Back in 2017 I wanted to be done with Spiral in a few months, but it took much longer than that.

Still, by the end of the year I will have Spiral in a very usable state. I am eagerly anticipating that moment. At that time, I will be able to breathe a welcome sigh of relief. This sweltering summer is much like the work I am doing right now. I want to exchange it for the coolness of fall. To me Spiral was always a means to an end, and once it is done I am looking forward to testing my vision whether Spiral is really a necessity for catching the wave of new AI hardware that will soon arrive.

///

1:50pm. This is good. Today was the ideal time to do this review.

1:55pm. For the rest of the day I will slack. I think I will take some time off away from the screen simply to charge up the motivation to do the next step."

---
## [tannerhelland/PhotoDemon](https://github.com/tannerhelland/PhotoDemon)@[e636dbac4b...](https://github.com/tannerhelland/PhotoDemon/commit/e636dbac4b0be3a060fc99c3b24f07bceea7d177)
#### Tuesday 2020-07-28 13:30:15 by Tanner

pdDisplay: modernize the way we retrieve display properties

The usual jokers over at vbforums are writing questionable code for detecting display parameters, and somehow my work has been dragged into it.  (Funny how the VB6 community loves to steal people's work and misrepresent it as their own, but when they encounter bugs, suddenly they have nothing to do with the code.
 Sigh.)

PhotoDemon pulls display EDID data for color-management purposes (something I doubt is relevant to most devs), but since I wrote PD's display detection code years ago, I thought it worth dragging into the modern era before others appropriate it for unintended purposes.

The setupapi class of functions can be used to map between GDI display handles (HMONITORS) and physical display devices/drivers, which in our case we want to resolve against specific registry keys with extended display information.  I've done this with help from this link, specifically the comments below the article:

https://ofekshilon.com/2014/06/19/reading-specific-monitor-dimensions/

Many thanks to those authors for sharing their work.  The "magic" APIs in question are SetupDiEnumDeviceInterfaces and SetupDiGetDeviceInterfaceDetail; these are a little cumbersome to wrap in VB6 due to their use of variable-size structs, but the end result is a Microsoft-approved technique for matching detailed display parameters against a given GDI display handle.

(Before now, I had reverse-engineered the likely registry location of this same data, and while I'd never encountered problems with it, that was never meant to be a "permanent" solution.  This new solution should be good for the life of Win 10, at least.)

---
## [cossacklabs/themis](https://github.com/cossacklabs/themis)@[1ca96de89b...](https://github.com/cossacklabs/themis/commit/1ca96de89b66391114f615658fbc4819aa248b9b)
#### Tuesday 2020-07-28 13:34:45 by Alexei Lozovsky

Add missing OpenSSL includes (#684)

* Add missing OpenSSL includes

Add those files use BIGNUM API of OpenSSL but do not include relevant
headers. Due to miraculous coincidence, this seems to somehow work for
the OpenSSL versions we use, but only because either existing headers
include this "bn.h" transitively, or because the compiler generates
code that kinda works without function prototype being available.

However, curiously enough, this breaks when building Themis for macOS
with recent OpenSSL 1.1.1g but not with OpenSSL 1.0.2, or OpenSSL 1.1.1g
on Linux. The issue manifests itself as missing "_BN_num_bytes" symbol.
Indeed, there is no such symbol because this function is implemented as
a macro via BN_num_bits(). However, because of the missing header, the
compiler -- being C compiler -- decides that this must be a function
"int BN_num_bytes()" and compiles it like a function call.

Add the missing includes to define the necessary macros and prototype,
resolving the issue with OpenSSL 1.1.1g. It must have stopped including
<openssl/bn.h> transitively, revealing this issue.

This is why you should always include and import stuff you use directly,
not rely on transitive imports.

P.S. A mystery for dessert: BoringSSL backend *includes* <openssl/bn.h>.

* Treat warnings as errors in Xcode

In order to prevent more silly issues in the future, tell Xcode to tell
the compiler to treat all warnings as errors. That way the build should
fail earlier, and the developers will be less likely to ignore warnings.

* Fix implicit cast warnings

Now that we treat warnings as errors, let's fix them.

themis_auth_sym_kdf_context() accepts message length as "uint32_t" while
it's callers use "size_t" to avoid early casts and temporary values.
However, the message length has been checked earlier and will fit into
"uint32_t", we can safely perform explicit casts here.

* Suppress documentation warnings (temporarily)

Some OpenSSL headers packaged with Marcin's OpenSSL that we use have
borked documentation comments. This has been pointed out several
times [1][2], but Marcin concluded this needs to be fixed upstream.

[1]: https://github.com/krzyzanowskim/OpenSSL/pull/79
[2]: https://github.com/krzyzanowskim/OpenSSL/pull/41

Meanwhile, having those broken headers breaks the build if the warnings
are treated as errors. Since we can't upgrade Marcin's OpenSSL due to
other reasons (bitcode support), we have no hope to resolve this issue.

For the time being, suppress the warnings about documentation comments.

* Fix more implicit cast warnings

There are more warnings actual only for 32-bit platforms. Some iOS
targets are 32-bit, we should avoid warnings there as well.

The themis_scell_auth_token_key_size() and
themis_scell_auth_token_passphrase_size() functions compute the size of
the autentication token from the header. They return uint64_t values to
avoid overflows when working with corrupted input data on the decryption
code path. However, they are also used on the encryption path where
corruption is not possible. Normally, authentication tokens are small,
they most definitely fit into uint32_t, and this is the type used in
Secure Cell data format internally.

It is not safe to assign arbitrary uint64_t to size_t on 32-bit
platforms. However, in this case we are sure that auth tokenn length
fits into uint32_t, which can be safely assigned to size_t.

Note that we cast into uint32_t, not size_t. This is to still cause
a warning on platforms with 16-bit size_t (not likely, but cleaner).

---
## [ololobus/postgres](https://github.com/ololobus/postgres)@[401202b798...](https://github.com/ololobus/postgres/commit/401202b7988ca75549c6cb6609ac958675f0aeb7)
#### Tuesday 2020-07-28 14:06:26 by Tom Lane

Yet further rethinking of build changes for macOS Mojave.

The solution arrived at in commit e74dd00f5 presumes that the compiler
has a suitable default -isysroot setting ... but further experience
shows that in many combinations of macOS version, XCode version, Xcode
command line tools version, and phase of the moon, Apple's compiler
will *not* supply a default -isysroot value.

We could potentially go back to the approach used in commit 68fc227dd,
but I don't have a lot of faith in the reliability or life expectancy of
that either.  Let's just revert to the approach already shipped in 11.0,
namely specifying an -isysroot switch globally.  As a partial response to
the concerns raised by Jakob Egger, adjust the contents of Makefile.global
to look like

CPPFLAGS = -isysroot $(PG_SYSROOT) ...
PG_SYSROOT = /path/to/sysroot

This allows overriding the sysroot path at build time in a relatively
painless way.

Add documentation to installation.sgml about how to use the PG_SYSROOT
option.  I also took the opportunity to document how to work around
macOS's "System Integrity Protection" feature.

As before, back-patch to all supported versions.

Discussion: https://postgr.es/m/20840.1537850987@sss.pgh.pa.us

---
## [Enalean/tuleap](https://github.com/Enalean/tuleap)@[62881960f8...](https://github.com/Enalean/tuleap/commit/62881960f8523591c1ab7751324b95ce3592dc60)
#### Tuesday 2020-07-28 14:25:59 by Nicolas Terray

Use tlp-relative-date in angular-artifact-modal

Change your user preference "relative_dates_display" to
"absolute_first-relative_shown". (You have to do it manually in the db)

Go to planning v2. Open an artifact in the modal with comments. The
comments should have their dates displayed with the following format: YYYY-MM-DD X seconds ago

The same for kanban
The same for ttm

You need to rebuild ttm, planning-v2 and kanban app.

Note: due to AngularJS magic lifecycle, the component is rendered too
earlier and the computed attributes does not match the expected ones.
Therefore the generated errors have been swept under the carpet in
production mode. They are still raised in development mode though. I agree, it
is ugly as hell and should be fixed. Do you have any suggestion?

Part of story #14828: display dates with both absolute and relative dates

Change-Id: Iafd64ae1438fdd23e631e848ceaa8236438f97e6

---
## [dylanlangston/EngageRC](https://github.com/dylanlangston/EngageRC)@[3c0a48afa0...](https://github.com/dylanlangston/EngageRC/commit/3c0a48afa096c48f4d3759c2d7faf90042526ef9)
#### Tuesday 2020-07-28 14:32:33 by Dylan Langston

1.0.2.5

Made serveral changes in an attempt to resolve an issue with the screen going blank on some machines.

First:
In previous versions of the application (1.0.0.5-1.0.2.3) I had used the following to disabled GPU use. This was done to resolve the issue with black bars on the top and left portions of the screen Mason was seeing.
settings.CefCommandLineArgs.Add("disable-gpu");
In the latest build (1.0.2.4) this has been replaced with the line below.
settings.CefCommandLineArgs.Add("disable-gpu-compositing");
I'm hoping to see if this resolve the original issue with black bars without disabling the gpu rendering.

Second:
I've removed a line which disabled on disk GPU cache and forced CEF to used system memory instead. This we added early on in the development to resolve issues with cache paths. Those issues haven't been a concern for a while now but this line lingered in the code.
settings.CefCommandLineArgs.Add("disable-gpu-shader-disk-cache", "1");
Now that it's removed CEF should cache shaders to "Resources\CEFSharp\cache\GPUCache".

Third:
I've also added two new command line flags "-DisableGPU" and "-DisableWebGL". These can be used to troubleshoot display issues that pop up in the future.
In addition to the command line flags there are two additional tags being looked for in the config.xml file. "DisableGPU" and "DisableWebGL" which accept boolean values. These can be used to permanently enable one of these options.
DisableGPU reverts to the behavior from version 1.0.2.3. This disables GPU rendering and compositing, can result in better performance (higher fps).
DisableWebGL disables all GPU acceleration. WebGL will use Swiftshader (https://swiftshader.googlesource.com/SwiftShader#introduction) This can have a performance impact but may resolve display issues.

Forth:
Progress Update. Yesterday I worked with the main developer of CEFSharp to troubleshoot the blank screen issue that people have been seeing. He was extremely helpful and gave me a few things to verify in the application code. Based on what he said, I think what was causing the issue was the use of Thread.Sleep in the main thread of my application when displaying a notification. I updated the code last night to move any Thread.sleep calls into their own thread which I’m hopeful will resolve the issue.

---
## [menixator/easyride](https://github.com/menixator/easyride)@[0329ed72ee...](https://github.com/menixator/easyride/commit/0329ed72ee2c5ee6624ee67a100511dfcaeb3ee6)
#### Tuesday 2020-07-28 14:40:35 by Ahmed Miljau

Remove Ant and use Maven

Steps involved:
	* Creating a new project because netbeans is so brittle that it
	cant handle a conversion from one built tool to another
	* Edit the configuration for netbeans because maven requires
	embedding paths in arguments which netbeans doesnt handle by
	default
	* Manually adding mirrorlists to maven configurations for the
	embedded maven binary because that isnt maintained and the maven
	binary is ancient.
Netbeans is a shitty IDE, and java is a horrible language. Definitely a
match made in heaven.

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[726f7f242f...](https://github.com/mrakgr/The-Spiral-Language/commit/726f7f242ff205015a456955aff81b8ac362a9a4)
#### Tuesday 2020-07-28 16:50:40 by Marko Grdinić

"6:30pm. Damn, I was in bed for long. I guess the hunger I feel is not because I had a light breakfast.

Let me put in a few words and I will close for the day.

I had a lot of time to think about it. I've been raising the tension as I brainstormed.

So...before I can start I need to do the block merger. Right now I have the parser, but the top level statements can be mutually recursive. I need to deal with that first.

Then there are `real inl` and `real let`.

Then comes doing type checking and inference.

I've come to a few decisions. Higher ranked types are out. I thought I would need them, but now that I am going through it much more in detail, I see that they would not be necessary after all.

Higher ranked types are very borderline in Spiral.

The only place they could possibly appear would be in...

```
inl f (g : forall x. x) = ...
```

...in function arguments. Nowhere else. Because it would lead to invalid code. So I'll simplify my work and the language and kick them out.

That means the only place where they will be able to appear is in prototype declarations.

```
prototype bind m a : forall b. m a -> (a -> m b) -> m b
```

I am going to remove that `forall` from the `root_type` parser. Since that will mean I have one flag less, that will simplify the function significantly. With HRT out of the way, I do not need explicit application of the type variables, nor I have to do find ways to defer applying them.

Things will be much easier for me then.

I've thought how to do unification quite a bit in detail. The only thing I do not know is how to apply the type vars in recursive functions. The way to handle mutually recursive blocks is still a mistery. But I will get through that.

Seriously, it is always the recursive functions that give me trouble. It took me ages to understand how to compile them in the prepass too. I should be able to find something if I put my mind to it.

6:40pm. At any rate, now that I've come this far, if I restrict myself to just prenex polymorphism + constraints it feels rather than a month of work, it would be more like a week or two instead. I can kick out higher ranked types and use those extra two weeks to implement autocomplete and other editor support stuff instead.

As I said, HRT are very borderline as a feature in Spiral. Even if I put them in, I'd have to put in checks to restrict the types to the base universe.

6:45pm. I've also decided to restrict the constraints to very simple ones. I won't even bother with the mapping ones and will just throw an error in the peval stage.

This will leave the type system very simple, with only GADTs as a possible extension at some point.

This will be really simple and doable. I feel really good about this.

6:50pm. The design I have in my head feels like something I could do without much trouble.

Tomorrow I might want to do more brainstorming, but today I am done. Let me get some grub."

---
## [Noobmaster23/Website-Andi](https://github.com/Noobmaster23/Website-Andi)@[e24f01e7f8...](https://github.com/Noobmaster23/Website-Andi/commit/e24f01e7f88fffec6dee6a43d2ed696c8c24ae0d)
#### Tuesday 2020-07-28 19:12:06 by Noobmaster23

form: fuck it

ok so i just make the information about the mail process on the new page, i had enough, fuck you javascript and forms, thanks for nothing and really fun 5 hours of brainless stupid work and googling. tihi

---
## [daniel5151/clicky](https://github.com/daniel5151/clicky)@[3862454bd0...](https://github.com/daniel5151/clicky/commit/3862454bd0ec623dddf9bff474f57a5690c19c02)
#### Tuesday 2020-07-28 19:41:07 by Daniel Prilik

fix hang on Rockbox splash screen

Ughhhhh this was an annoying bug to track down. I'm starting to reach
the point in the project where I'm not "failing loudly" anymore (e.g: by
not having a device implemented / hitting unmapped memory), but instead,
the code is ostensibly running correctly, but my _implementation_ has a
bug that's causing it to hang...

This particular hang exposed a couple of different issues in my IRQ
implementation:
1. I needed to implement Mailbox IRQs, which ended up requiring some
changes to the interrupt controller, as unlike every other IRQ in the
system, mailbox IRQs are core-specific!
2. My premature efficiency trick with `irq_pending` bit me in the ass,
since it didn't account for the possiblity of CPU cores _internally_
disabling interrupts... I ended up half-assing a fix, but I really aught
to take a closer look.
3. So, uh, turns out cloning signal::Master had a bug in it lol. The
addition of an Arc fixed it right up.

I really aught to revisit my approach to IRQs... It's kinda hard to
follow tbh.

---
## [Locorock/automata](https://github.com/Locorock/automata)@[955b69eb2b...](https://github.com/Locorock/automata/commit/955b69eb2b023ac57c32eeb25c9a1f1789d78b6d)
#### Tuesday 2020-07-28 20:23:35 by locorock

tweak world wrapping code to suck a bit less. it still sucks and the borders are a graveyard
add straight pathing to cross the border
fix stupid enviro painting infinite loop when too many things were generated
add keyboard listener, i ran out of combinations for the mouse. I should really add a menu
add single frame skip trough keyboard input (f)
tweak redscale and pop overlay to mesh with the background, also the background is gray/dark gray depending if there's ocean or not behind
add critter inspection tool through a keyboard input after selecting the inhabited cell (c), it tracks some of the things it should track in real time
add critter tracking, critters that are currently being inspected show as bright yellow on the map

---
## [TheViperShow/MinecraftBot](https://github.com/TheViperShow/MinecraftBot)@[901d873b80...](https://github.com/TheViperShow/MinecraftBot/commit/901d873b80a6d0234e9ec4fbb0685ecc71a4b212)
#### Tuesday 2020-07-28 22:11:14 by TheViperShow

Trying to fix the fucking protocol. Fuck you mojang

---
## [chobocoda/testing](https://github.com/chobocoda/testing)@[49529b36c9...](https://github.com/chobocoda/testing/commit/49529b36c9bde8fd9051e37b0517b682164990c5)
#### Tuesday 2020-07-28 23:02:52 by Chobo

just wanted to remind you that loosers haha fuck you all!

just wanted to remind you that loosers haha fuck you all!

---
## [mscalindt/android-kernel-rosy](https://github.com/mscalindt/android-kernel-rosy)@[51f53cc7bf...](https://github.com/mscalindt/android-kernel-rosy/commit/51f53cc7bfa22c390d57428b111c877bf2cda8e8)
#### Tuesday 2020-07-28 23:49:56 by Dimitar Yurukov

rosy: dts: Overlay changes

With overlay:
- All stock .dts files are compilable.
- Rosy's code is isolated from other .dtsi files.

Note that, to successfully overlay rosy's changes specifically, we have to use
an ugly hack. It involves predefining essential nodes for msm8953 dtsi
(to evade "node not found" errors), and also involves deleting a node
that conflicts with msm-pmi8940. The true fix would be CAF fixing their own
shit to not conflict when some specific headers are included.

Improves: 78f9bfa0b4e14b2f050b4675f0ff8aff22aad585 ("rosy: Import DTS changes")
Signed-off-by: Dimitar Yurukov <mscalindt@protonmail.com>

---

# [<](2020-07-27.md) 2020-07-28 [>](2020-07-29.md)

