# [<](2020-01-16.md) 2020-01-17 [>](2020-01-18.md)

1,919,457 events, 968,022 push events, 1,546,942 commit messages, 113,184,841 characters


## [Bawhoppen/-tg-station@65485b9c54...](https://github.com/Bawhoppen/-tg-station/commit/65485b9c54e9d2fc269e40502ab929888cdb2db3)
##### 2020-01-17 06:10:55 by ArcaneMusic

Adds a new Tech to the B.E.P.I.S., Specialized Engineering, and a new Minor Reward. (#48507)

About The Pull Request

Round 2.
image
Adds a new tech to be unlocked within the B.E.P.I.S.'s major techs, called "Specialized Engineering". Within that tech are 2 new items, Heat Resistant Rods, and the Tinker's Gloves, as well as a new minor tech, the Survival Pen.
Heat Resistant Rods:
Have you ever wanted to expand Lavaland Base? Build a lava fortress worthy of your magnificence? Well, now you can! Using Heat Resistant Rods, you can make a catwalk to cross lava tiles, as well as build atop lava, without messy methods like using the RCD!
Tinker's Gloves:
This just in engineers, insulated gloves have new competition in town! The Tinker's gloves are complicated, overdesigned gloves that, while not very shockproof, allow for faster wall girder construction. No longer will you need to die of old age walling off an area when you're out of RCD ammo! Warning: This product contains no likeness to clockwork gauntlets used by the extinct cult of Rat'Var, and any such similarity is by no means intentional.

Survival Pen:
Have you ever been stuck on lavaland, trapped by your survival pod with just a few chairs, some titanium walls, and walls of ash closing in on you? Well THANK GOD you have your Rockbreaker brand Survival Pen! Allows for basic mining operations, and is portable like a standard pen!
BUT WAIT!
A watcher blocks your path. Thankfully, your expensive, diamond encrusted pen isn't just good for being the world's slowest pickaxe, it's ALSO coated in the one thing watchers crave: DIAMONDS. Toss the pen to draw the watcher's attention elsewhere.
Why It's Good For The Game

Starts to fill our B.E.P.I.S. Major Reward Techs, as intended, and fills a niche that doesn't get much play nowadays: Building on Lavaland. This was something I've had in the back of my mind since we did the first tests of the Disaster gamemode a few months ago, so each item here was made with the intention of improving the mining base should the station become un-livable. Lava-Proof Rods are beneficial in that you'll be able to cross and build over lava by the mid-end of the shift. RCDs still work as usual, but this way you won't have to worry about getting specialized engineering equipment as a member of cargo or science. The tinker's gloves are basically a variant of the nitrile gloves, but they grant a speed bonus to adding plating to metal girders, so that some kind of functional alternative to giving every engineer insulated gloves.
Survival Pens are quite honestly very niche, but getting dumb pens with extra functionality is a tradition of trade shows all over the world, so it feels right at home as a minor reward.

Also, does a tiny change to the doe sprites, just to look a little bit less old.
Changelog

cl
add: A new Technology has been implemented as a major reward in the B.E.P.I.S., Specialized Engineering, to appeal to engineering utility and new construction horizons.
tweak: Watchers will now actively consume diamond ore left lying around, alongside the new survival pens.
/cl

---
## [facebook/pyre-check@7a703fcfd6...](https://github.com/facebook/pyre-check/commit/7a703fcfd659bfd2be7447050944603751b2a49d)
##### 2020-01-17 06:54:22 by Jia Chen

Introduce APIs for parallel scheduling policy

Summary:
We'll need to go through a fair amount of background before one can make sense out of my proposal here.

Context
======

The problem we are trying to address here is to figure out a reasonable way to schedule the list of workloads passed into `Scheduler.map_reduce` (or `Scheduler.iter`). Past experience has shown that the scheduling algorithm has critical impact on the performance profile of both `pyre` and `pysa` (examples where a simple decision change lead to hundreds of seconds of perf win: D19385381, D13330658).

Here's a little bit of background on how the underlying `MultiWorker` module in `hack_parallel` is coded up. Supposed that we have `M `tasks and `N` workers. Conceptually, the way it works is that we take the list of tasks, break it apart into smaller chunks (aka. `bucket` in the code), and put all the chunks into a queue. Then we repeatedly poll from a pool of workers -- if all workers are busy, we block and wait for one that becomes non-busy; otherwise, we pull a task out of the queue, assign it to a non-busy worker, and poll for the next non-busy worker.

As you can see from the description above, there's really not a lot we can fine-tune given this framework -- picking a scheduling algorithm, under this context, essentially boils down to deciding how the list of `M` input tasks can be chunked.

Although the underlying `MultiWorker` API makes it possible to implement more advanced chunking algorithm, I think to avoid over-engineering we'll just stick with the simplest and dumbest chunking method possible for now: splitting the `M` jobs into chunks of equal length. Given that the input size `M` can vary across different invocations of `Scheduler.map_reduce`, naturally there are two ways we can do the split:
- The Fixed-Bucket-Size policy keeps the size of each chunk (henceforth denoted as `B`) constant, and let the number of chunks vary as `M / B`.
- The Fixed-Bucket-Count policy keeps the number of chunks (henceforth denoted as `C`) constant, and let the size of each chunk vary as `M / C`. Note that if this kind of policy is used, it usually makes more sense to let `C` scale with the number of workers -- hence in the code you won't find  `C` directly because it is always derived by multiplying the worker count and a multiplier.

Choosing Policies
=============

I've thought a lot about how we should choose between the Fixed-Bucket-Size policy and the Fixed-Bucket-Count policy. My current understanding is that there's no clear winner and it's always about tradeoffs:
- The Fixed-Bucket-Size policy tends to have more predictable **latency**
  + It's easier to estimate how long it takes for a worker to complete a given chunk of work if the chunk size is known.
- The Fixed-Bucket-Count policy tends to have more predictable **throughput**
  + It's easier to estimate the amount of IPC communication overhead if we know how many chunks need to be processed in total.

Following this line of thoughts, the first principle we should follow seems to be that we should do Fixed-Bucket-Size whenever progress needs to be shown to the user (because humans are more latency sensitive), and do Fixed-Bucket-Count otherwise for better overhead control. Note that I'm simplifying the issues a lot -- there are more perf/memory concerns regarding the worker GC if we are willing to dig into more details. But I want to get the big picture right first, before we can dive into micro-optimizations.

Fallback Behaviors
==============

Unfortunately, I can't conclude the discussion of scheduling policy at this point, as we do have some devils that hide in the edge cases.

The simple Fixed-Bucket-Size and Fixed-Bucket-Count policies described above work great when the number of task `M` is sufficiently large. But when the number becomes small, we run into troubles fairly quickly:
- The Fixed-Bucket-Size policy is prone to the problem of *starvation*: when the number of work `M` is not sufficient enough to fill `N` buckets (with `N` being the number of workers) of size `B`, some worker is going to be left with little to none work to do, while other workers will keep getting `B` chunks of works.
- The Fixed-Bucket-Count policy is prone to the problem of *excessive overhead*: when the number of work `M` is not sufficient to the extent that each bucket only contains very few work to do, the IPC/synchronization overhead between master-worker starts to dominate the wall clock. I've seen in practice cases where for a small amount of work, doing everything in master takes milliseconds while sending the same workloads to workers would take tens of seconds.

To mitigate these two issues, I propose two simple adaptations to the two policies mentioned before:
- First, we introduce the notion of *fallback behavior*, which kicks in when we find that following the original Fixed-Bucket-Size or Fixed-Bucket-Count policy may lead to issues due to insufficient input size.
  + For Fixed-Bucket-Size policy, if we detect that the number of buckets would be smaller than a threshold `C`, we fall back to a Fixed-Bucket-Count policy of count `C` instead to avoid starvation. The other way of looking at this is that we always cap the number of buckets to be at least `C`.
  + For Fixed-Bucket-Count policy, if we detect that the bucket size would be smaller than a threshold `B`, we fall back to a Fixed-Bucket-Size policy of size `B` to avoid excessive overhead. The other way of looking at this is that we always cap the bucket size to be at least `B`.
- Second, we introduce the notion of `sequential_cutoff`. This is going to be a parameter of our policy, and it means that if the input size `M` is smaller than `sequential_cutoff`, we unconditionally run everything sequentially in the master process. The exact value of `sequential_cutoff` may vary: if each task takes long time to compute (e.g. Pysa fixpoint iteration), we should use a small number; if each task only takes miliseconds (e.g. most of the environment table update), we should use a larger number. Note that this number should always be larger than 1: if `M` is 1, it is unconditionally better to do it in master than in worker.
  + In the code, `sequential_cutoff` is implicitly computed by multiplying the minimum bucket size `C` and the minimum bucket count `B`.

Overview of This Diff
===============

This diff tries to provide implementations for both Fixed-Bucket-Size-WIth-Fallback policy and the Fixed-Bucket-Count-With-Fallback policy. It also preserves the two policies currently used in production (denoted as "legacy" policies in the code) -- the goal is to keep this particular diff semantic-preserving, and gradually phase out the legacy policies in followup diffs.

See `schduler.mli` first to get an idea of how the `Scheduler` API evolves. My change should be fairly straightforward: the `bucket_size` parameter (which used to switch between our legacy version of Fixed-Bucket-Size and Fixed-Bucket-Count policy) is replaced with a full-blown policy type `Policy.t`.

The type `Policy.t` is kept private to ensure that one can only create them via the provided APIs. Under the hood it is nothing but a function that computes the bucket count.

Rest of the changes are there to cope with the `Scheduler` API updates.

Reviewed By: sinancepel

Differential Revision: D19402492

fbshipit-source-id: a9b627cdf9af083b021fe51e825168dc3abfaa45

---
## [ynot01/Yogstation-TG@41b11557be...](https://github.com/ynot01/Yogstation-TG/commit/41b11557be7e0f9016bb0be52ac94df621e0685e)
##### 2020-01-17 08:02:18 by Codeatmos

OH GOD OH FUCK THEY KNOW IM A GRAYTIDE SHITLER NO PLEASE I JUST WANTED THEM TO BE PRINTABLE AT CARGO OHG OD OH FU

---
## [boomerstation/boomerstation@09282e1ad9...](https://github.com/boomerstation/boomerstation/commit/09282e1ad977c2de9f510eb004bb498aae2fdeed)
##### 2020-01-17 10:43:50 by Rob Bailey

SEVERAL mask sprite fixes (#48744)

* society moment

god im so funny

* do you apes not know what consistency means?

seriously who the fuck made these sprites

---
## [mmihaeladraghici/talks@48c0f89b97...](https://github.com/mmihaeladraghici/talks/commit/48c0f89b97b492bb5032d2daa4df3c7909202a73)
##### 2020-01-17 16:23:14 by mmihaeladraghici

Product Managers, to pair or not to pair?

Product Managers, to pair or not to pair?
Speaker : Mihaela Draghici
Available : first day, second day, third day
Length : 30 minutes
Language : English
Description
What does pairing mean for PMs? Why is it great? Why does it suck? When is it good to pair? And more than that, how to make the most of it when you do pair?

There are little resources available regarding pairing for Product Managers. That's because it's not too common.   I aim to share my lessons learned and tips & tricks about pairing for PMs (from own experience), to give you more insights on this topic.

Speaker Bio
A Romanian, with a British passport, living in Lisbon. Marketing girl, turned tech girl, building products that deliver happiness. Strong advocate for gender equality and inclusive work environments in tech industries.

Links
Company: https://www.linkedin.com/company/volkswagen-digital-solutions/
GitHub: https://github.com/mmihaeladraghici/
Photo: https://pbs.twimg.com/profile_images/1271157175/mihaela-draghici1_400x400.jpg
Extra Information
The purpose of this talk is to offer more information regarding pairing practices for Product Managers to to help:

those who have not heard of pairing for PMs, learn more about it;
those who have heard about it but have not considered pairing in their product teams: start considering it and weigh options around benefits for their products/business;
those who have tried it: open a conversation about advantages/disadvantages and exchange knowledge.
I have over 10 years of international work experience in digital marketing and product management. I have contributed to both small and large scale product initiatives to bring business value and worked closely with engineering teams, UX designers, localisation specialists as well as business stakeholders across regions.    I am passionate about what I do, the products I've built and the people I work with.  Since I have learned a lot throughout my career and benefited from great colleagues and mentors, I am looking to share my knowledge and give back to the community through talks, events & mentoring.

Some references to myself and my work:  

https://www.facebook.com/GirlsinTechLondon/
https://www.youtube.com/watch?v=VSHNdMvXlUY  
https://www.eventbrite.co.uk/e/getting-into-tech-tech-spectrum-panel-for-graduates-tickets-50451371410#
https://issuu.com/businesswomanclub/docs/april_digital_business_women_emagaz/60
https://www.eventbrite.co.uk/e/in-common-women-at-work-tickets-65778833261#
https://www.linkedin.com/pulse/10-things-i-love-being-product-manager-mihaela-draghici 
https://performancein.com/news/2019/06/18/awin-thinktankuk-2019-and-future-proofing-affiliate-industry/

---
## [mrakgr/The-Spiral-Language@a89cdbdc37...](https://github.com/mrakgr/The-Spiral-Language/commit/a89cdbdc37c0d2cc100ced92d1d472a068a2eb0d)
##### 2020-01-17 17:22:17 by Marko GrdiniÄ‡

"9:30am. I am up.

10:50am. Done with vol 7. Let me have that breakfast.

12:40pm. I am nearly a third of the way into vol 8, but let me stop here. It is time for me to mentally start preparing for the programming day. It is also time I deal with the chores.

2:10pm. Today's chores took a bit more than I thought they would. Let me catch my breath for 10m and then I will start.

2:20pm. Let me start.

What I need to do now is really start the prepass.

I just need to do this thing. I feel lethargic just thinking about it.

It is not that any of the pieces are hard, but as is usual at times like these the main problem is gathering momentum.

Still if there is something that I've learned during my long years of programming that would be - if the pieces are there, then it is possible to complete the entire thing.

2:25pm. So focus me, focus. The pieces are all there.

Right now when I think of ML, the pathways that I use to create Spiral are the ones that respond.

This is not a ability that the average guy off the cubicle has. The ML guys certainly do not have it. So I have my own edge. I just need to draw it out.

Just one more time.

I've been saying this like a broken record for the past 5 years, but it is not like 5 years is that long of a time.

In order to win a game, you just need to start making the right moves.

Now that damn prepass.

Let me just focus on annotating the all the functions with their free variables and stack sizes. This is something that I've done before - this time what I need to do is also take note of the type variables.

This kind of simple task should serve me well for what will come after that.

2:30pm. Still...damn.

Yeah, free vars and stack sizes are not difficult by themselves. Neither is the prepass.

But what do I do about inlining?

Inlining is supposed to be done during the prepass (so I do not have to keep around the extra info during caching)

2:40pm. I have no idea.

Hrrrmmmm...Just like yesterday I am going to have to dedicate some time to thinking about this.

There are 3 pieces to the prepass:

1) The free vars and stack size calculations.
2) The renaming and conversion from raw expressions to the array friendly ones that the peval needs.
3) And now inlining of globals.

3:10pm. I am still thinking about it.

3:50pm. I am still thinking about it.

The whole inlining thing being in the last place in the order really throws a wrench in my plans.

4:45pm. I've actually been thinking about it all this time. I nearly have it.

I am going to switch to an alternative naming scheme that will make it unecessary to do things in two passes. This will simplify things.

But the typecase bindings and global inlining makes things complicated and I haven't been able to figure out how to push that through completely yet.

Of course I know ways of doing it, but I haven't settled on the right one exactly.

4:50pm. I just need to go a little bit further in my reasoning - just how do I pass globals around during the prepass?

5:25pm. Ok, I think I've pretty much 95% settled on the new architecture for the prepass.

In fact, I had this idea last time, but decided to go with the more complicated scheme that v0.1 has for some reason.

Now that it has come to this, I need to go all out.

5:30pm. Ok, I figured out one more detail. That is 98% where I am at.

The last 2% is just me wrapping up essentially.

5:35pm. Let me wax the idea for a while longer and then I am going to call it a day.

5:40pm. Ok, I am done.

Here is what I am going to do the basic idea is simple...

```
inl x -> let y = 2 in b + c + x + y
```

Given a function like this, I am going to tag free variables in the negative direction `b -> -1`, `c -> -2` while the bound variables will go in the positive direction `x -> 0`, `y -> 1`. This will make a second of renaming unecessary.

As for the general architecture....

```
let prepass (global_type : Map<string, ExprT>) (global_value : Map<string, Expr>) =
    let rec loop (free_vars_type : Dictionary<string, ExprT>) (free_vars_value : Dictionary<string, Expr>) (vars_type : Set<string>) (vars_value : Set<string>) (local_type : Map<string, ExprT>) (local_value : Map<string, Expr>) = ...
```

5:55pm. Writing this out like this is making me realize that it made more sense in my head.

But...an idea is occurring to me.

Maybe it would not be bad to get rid of maps completely.

Remember that one test in v0.09 which gave me compilation issues I could not get rid of?

```
//let speed3 = // Minus the startup, this takes 0.05s to peval versus 1.5s for the previous version of the compiler.
//    let code =
//        let var i = sprintf "var_%i" i
//        let bnd (a, b) = sprintf "inl %s = %s" a b
//        let vars = [|0..900|] |> Array.map var // Any more than this and it will stack overflow.
//        let bnds =
//            vars |> Array.pairwise |> Array.map (fun (a,b) -> b,a)
//            |> Array.map bnd |> String.concat "\n"
//        let adds = String.concat " + " vars
//        String.concat "\n" [|bnd (var 0, "dyn 0");bnds;adds|]

//    "speed3",([] : Module list),"Does the linear sequence of bindings get compiled in linear time?",code
```

It is difficult to understand what it does just by looking at it now, but as far as I remember, this is a simple program with like 900 different let statements in a row.

Propagating all the free variables takes a crazy amount of time and the main problem is that the immutable data structures are just slow to deal with this. I think the union operation was the main culprit.

```
let prepass (global_type : Map<string, ExprT>) (global_value : Map<string, Expr>) =
    let rec loop (free_vars_type : Dictionary<string, ExprT>) (free_vars_value : Dictionary<string, Expr>) (vars_type : Set<string>) (vars_value : Set<string>) (local_type : Map<string, ExprT>) (local_value : Map<string, Expr>) = ...
```

It seems complicated at first glance, but what if I used a dictionary and cps'd the program so that the adds get removed as soon as the let statements go out of scope.

That would resolve the issues with if statements.

```
(vars_type : Set<string>) (vars_value : Set<string>)
```

As for these two, well, I really need `vars_type` in order to insert the bindings into typecase.

Very well, I guess I'll just keep `vars_type` around for that then.

The missing variables error I can just calculate from the free variables in the global statements.

`(global_type : Map<string, ExprT>) (global_value : Map<string, Expr>)`

These two I will turn into dictionaries as well. No need for immutable maps here.

6:10pm. Let me stop here.

I think the dual naming scheme and the CPS'd dictionaries idea are what I was really looking for. I am going to absolutely crush the prepass this time and forge it to perfection. I admit, before now it never even occurred to me to consider removing things from a dictionary, but it is a great idea.

6:20pm. Oh, yes. I am going to need `vars_value` if nothing else, but just to avoid inlining the globals incorrectly.

Well, I'll figure it out tomorrow as I go along."

---
## [newstools/2020-the-guardian-uk@64552b259b...](https://github.com/newstools/2020-the-guardian-uk/commit/64552b259b67eb219dd73ced060abd4ea6d4acee)
##### 2020-01-17 19:07:00 by NewsTools

Created Text For URL [www.theguardian.com/lifeandstyle/2020/jan/17/experience-my-brother-framed-me-for-murder]

---
## [icarus496/MAT157@70e06cbe10...](https://github.com/icarus496/MAT157/commit/70e06cbe10e8e119f2519c455f66f9836f58b9e8)
##### 2020-01-17 22:21:34 by icarus496

Oh my god I think this is the answer but it's fucking gross

---
## [Finbarr-1/Expedition@12ac9c029f...](https://github.com/Finbarr-1/Expedition/commit/12ac9c029f7ac0d0e03214b481157e6ae8cfab2f)
##### 2020-01-17 22:56:36 by PepperLola

As of 2:12 on January 17th, I have decided to rename the "isfacebooktrackingme" app icon to "thezucc". This reflects society as it stands today, as an homage to the fact Mark "The Zucc" Zuckerberg is controlling our everyday lives, as well as the lives of our friends and family. I believe that "isfacebooktrackingme" is simply too precise of a name, only addressing the fact that Facebook is tracking literally everyone, whereas "thezucc" is much more broad, addressing all of Facebook, as well as the creator of it. "How does this affect the user, and overall provide an exceptionally fantastic user experience?" you might ask. The simple answer is, it doesn't. Because this icon isn't commonly used among the majority of the population, it provides no real improvement to the experience of most users. However, it does make the life of our more *important* users a slight bit easier. Let's face it. "thezucc" is much easier and faster to type than "isfacebooktrackingme". Expedition is focused primarily on ease of use, so why not make everything as easy to use as possible? What's the point in having an app icon name that both takes longer to type, and isn't as intuitive. Most people have said the phrase "the zucc" at least once in their lives. If not, it still provides for a memorable phrase they won't forget whey they inevitably decide one of their apps needs The Zucc's face on it. Overall, renaming this app icon will provide not only an acceptable user experience, but an absolutely *fantastic* user experience, and have side effects such as excessive happiness, or the need to brag to friends about their fancy new app icon. With side effects like that, who wouldn't want to have an app icon this much easier to access. All we ask is that you change your app icons with caution, lest you have *too* much fun.

---
## [DanaL/AdventOfCode@c6cada20c0...](https://github.com/DanaL/AdventOfCode/commit/c6cada20c015abc6aa43c3b833556ccf12c325f2)
##### 2020-01-17 23:10:15 by Dana Larose

Almost have my goddamn priority queue/dijkstra's working, god I hate Rust

---

# [<](2020-01-16.md) 2020-01-17 [>](2020-01-18.md)

