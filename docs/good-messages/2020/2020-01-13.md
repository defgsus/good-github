# [<](2020-01-12.md) 2020-01-13 [>](2020-01-14.md)

2,109,781 events, 1,034,195 push events, 1,641,753 commit messages, 133,453,082 characters


## [yogstation13/yogbot](https://github.com/yogstation13/yogbot)@[4a43d32d50...](https://github.com/yogstation13/yogbot/commit/4a43d32d50cb79209b121203890ec3d8a72149ec)
#### Monday 2020-01-13 00:17:35 by monster860

I LOVE GETTING MY SHIT CASTED TO NUMBER WHEN ITS A REALLY BIG NUMBER

---
## [javashin/REALTIME-X](https://github.com/javashin/REALTIME-X)@[408a5effc9...](https://github.com/javashin/REALTIME-X/commit/408a5effc92776ae52efbdb57f8a56c3aa5495ab)
#### Monday 2020-01-13 01:40:08 by Carlos Jimenez (JavaShin-X)

Experimental = I Just Added And Injected ZFS https://github.com/zfsonlinux/zfs Last Master Tip :

( commit 6e1c594d6491ed5c9cc052ad5d94098eff684e2a ) To My Kernel REALTIME-X-SOURCES.

Sorry Torvalds...... But We Love ZFS.

Compiling Now.

---
## [wongdark2017/CUGBACM-Library](https://github.com/wongdark2017/CUGBACM-Library)@[598850059d...](https://github.com/wongdark2017/CUGBACM-Library/commit/598850059d7a56af42481d2f6dd8321dba51af46)
#### Monday 2020-01-13 02:37:39 by wongdark2017

题目

题目来自第十场牛客多校:
题目描述 
>His majesty chatted with Han Xin about the capabilities of the generals. Each had their shortcomings. His majesty asked, ``How >many troops could I lead?" Han Xin replied, ``Your highness should not lead more than 100000." His majesty said, ``And what >about you?" ``For your humble servant, the more the merrier!" said Han Xin.

---Records of the Grand Historian
Han Xin was a military general who served Liu Bang during the Chu-Han contention and contributed greatly to the founding of the Han dynasty. Your friend, in a strange coincidence, also named Han Xin, is a military general as well.

One day you asked him how many troops he led. He was reluctant to tell you the exact number, but he told you some clues in certain form, for example:
- if we count the troops by threes, we have two left over;
- if we count by fives, we have three left over;
- if we count by sevens, two are left over;
- ...
You wonder the number of his troops, or he was simply lying. More specifically, you would like to know the minimum possible number of troops he leads, and if the minimum number is too large, then you suspect he was lying.

输入描述:
The first line of input contains two integers n, m $(1 \leq n \leq 100, 1 \leq m \leq 10^{18})$, the number of clues he told you and the threshold that you think he was probably lying.

The remaining part of the input are n lines, specifying the clues, Each line consists of two integers a, b $(0 \leq b < a < 10^5)$, representing a clue that b troops are left over if we count them by a's.
输出描述:
If there does not exist a non-negative number of troops satisfying all clues, print \texttt{he was definitely lying}he was definitely lying; otherwise, if the minimum non-negative possible number of troops is greater than m, print \texttt{he was probably lying}he was probably lying; otherwise, print the minimum non-negative number.

---
## [smullitconsulting/sitcs.net](https://github.com/smullitconsulting/sitcs.net)@[22c3c4fe71...](https://github.com/smullitconsulting/sitcs.net/commit/22c3c4fe71eee268d6bff92ec4bc432e07403659)
#### Monday 2020-01-13 03:14:59 by Shelby M. Smull - Administrator

Fixed dependencies as well as the fucking audit issues with the god damn tree-kill package.

---
## [gyakovlev/linux-pinebook-pro](https://github.com/gyakovlev/linux-pinebook-pro)@[c7084edc3f...](https://github.com/gyakovlev/linux-pinebook-pro/commit/c7084edc3f6d67750f50d4183134c4fb5712a5c8)
#### Monday 2020-01-13 08:11:19 by Greg Kroah-Hartman

tty: mark Siemens R3964 line discipline as BROKEN

The n_r3964 line discipline driver was written in a different time, when
SMP machines were rare, and users were trusted to do the right thing.
Since then, the world has moved on but not this code, it has stayed
rooted in the past with its lovely hand-crafted list structures and
loads of "interesting" race conditions all over the place.

After attempting to clean up most of the issues, I just gave up and am
now marking the driver as BROKEN so that hopefully someone who has this
hardware will show up out of the woodwork (I know you are out there!)
and will help with debugging a raft of changes that I had laying around
for the code, but was too afraid to commit as odds are they would break
things.

Many thanks to Jann and Linus for pointing out the initial problems in
this codebase, as well as many reviews of my attempts to fix the issues.
It was a case of whack-a-mole, and as you can see, the mole won.

Reported-by: Jann Horn <jannh@google.com>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

---
## [bzhaoopenstack/gpdb](https://github.com/bzhaoopenstack/gpdb)@[b9e8636599...](https://github.com/bzhaoopenstack/gpdb/commit/b9e8636599271948f269de7426a93e7e49a785f9)
#### Monday 2020-01-13 08:44:21 by Heikki Linnakangas

Fix attaching Init Plans to Motion nodes.

There were a few places in the late stages of planning and at executor
startup that assumed that a Motion node cannot have Init Plans attached to
it. And there were hacks in createplan.c, to avoid doing that. That seems
like a strange wart; there's no fundamental reason why a Motion node
couldn't or shouldn't have Init Plans. Also, the logic in createplan.c to
avoid doing that was slightly broken, and actually attached Init Plans to
multiple nodes in the plan tree, including Motion nodes. Apparently it
doesn't cause harm to have the Init Plans attached to multiple nodes in the
plan tree, because things still worked, but it sure seems wrong.

createplan.c
------------

Previously, whenever a Motion node was created, any Init Plans accumulated
so far were attached to the node below the Motion node. Revert that
change, getting rid of the create_subplan() function, and reverting
create_plan() mostly the way it is in PostgreSQL. Init Plans are now
always attached to top node of the (sub)query's plan tree.

For some reason, we were also using create_subplan() instead of
create_plan_recurse() when creating Split Update nodes. I don't know why;
perhaps a copy-pasto from the code that creates Motions. It was also
failing to save & restore curOuterRels and curOuterParams. That apparently
didn't cause any problems in practice, but seems wrong. Change it to use
create_plan_recurse() like all other create_*_plan() functions.

cdbmutate.c
-----------

Now that we attach Init Plans to Motion nodes, we have to be more careful
toalso process them in apply_motion_mutator(). Previously, we recursed
into the 'lefttree' of a Motion node directly, but skipped the targetlist,
initPlans, and other fields on a Motion node itself. That was previously
harmless because Motions didn't have Init Plans attached to them, or more
precisely, any Init Plans on Motions were *also* attached to the node
below the Motion. But now it matters. In principle, we should've scanned
the targetlist, hashExprs, quals etc. fields on a Motion node too, even
before this change, but in practice I believe that didn't cause issues
because those fields cannot contain SubPlans that are not also present in
the nodes below the Motion. But even if that doesn't cause trouble today,
let's be tidy and scan those fields, too.

execUtils.c
-----------

Executor startup makes several passes through the nodes in the plan tree,
or in the local slice of the plan tree, to find SubPlans and initplan
Params that are needed in the local slice. The walker routines to do that,
getLocallyExecutableSubplans() and ExtractParamsFromInitPlans(), had a
similar problem as apply_motion(), and didn't process a Motion node that
was a the top of the slice. The walkers don't recurse into Motions,
to restrict the scan to the local slice, but the sending Motion at the top
should be considered as part of the local slice, and now that it can
contain Init Plans, we need to scan those too.

This patch changes the EXPLAIN output of a few regression tests, that
contain Init Plans. Slice numbers have changed, because the init plans are
now encountered in different order in apply_motion().

Reviewed-by: Jesse Zhang <jzhang@pivotal.io>
Reviewed-by: Soumyadeep Chakraborty <sochakraborty@pivotal.io>

---
## [elboulangero/goodvibes](https://github.com/elboulangero/goodvibes)@[24f7e4a0c0...](https://github.com/elboulangero/goodvibes/commit/24f7e4a0c0e629a77f352097ce9495d9946e4867)
#### Monday 2020-01-13 11:01:27 by Arnaud Rebillout

application: Simplify struct declarations, use a pragma to avoid compiler warning

If we omit the empty fields when we declare these struct entries, GCC
will raise a `missing-field-initializers` warning. Up to now I solved
that by explicitly declaring all the fields, but it's a bit ugly. Plus,
if in the future new fields are added to the struct (hence shortening
the padding field), compilation will break. And it will be an ugly fix,
because we'll need ifdef depending on the glib/amtk version to properly
initialize everything. A pain.

So letting these fields alone is a bit more elegant, and will make our
life simpler in the future. Of course, GCC now raises a warning.

A possible solution is to compile the whole code with
`-Wno-missing-field-initializers`, and a better solution is to use GCC
pragmas to ignore `missing-field-initializers` just for these particular
structs that need it.

THese pragmas are also supported by Clang [1], so it looks like a pretty
good solution.

Last word: after digging a bit, I'm not even quite sure that
un-initialized fields will be initialized to zero by the compiler in
this case, as the struct is declared in a function, with the `const`
keyword only, not `static`. I guess it's OK as I've seen that in other
code, but wait for next commit...

[1]: https://clang.llvm.org/docs/UsersManual.html#controlling-diagnostics-via-pragmas

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[40f4385d59...](https://github.com/mrakgr/The-Spiral-Language/commit/40f4385d59d720cc14cf46bf527c8b7be73674ce)
#### Monday 2020-01-13 13:46:57 by Marko Grdinić

"9:50am. I am up and it is Monday. Tog, Dendro (I am really into it), breakfast, chores, then comes programming.

...Oh, it seems a Satanophany raw came out two days ago.

12:25pm. Finally done with vol 2. The novels were each over 300 pages long, I've been reading them like a madman.

Right now let me take a break from that, I really had enough for the time being and need some downtime. It was pretty good while it lasted, but I want to focus on programming for a bit.

12:30pm. Now before I begin, I still have chores to do, and I want to chill a bit before doing them. Let me get to it.

1:20pm. It is time to start this thing.

1:25pm. Now that I've had my fill of entertainment, and am done with the chores, I finally feel like doing some work.

1:30pm. Now the next thing on the list to do is to take care of error printing.

But I before I start that, there is something that bothers me.

```
    | RawTForall of (string * RawTypeTypeExpr) [] * RawTypeExpr
    | RawTInl of (string * RawTypeTypeExpr) [] * RawTypeExpr
```

The type level functions. There is a certain inconsistency in my thinking.

```
nominal real Tensor dim ty = tensor_init dim ty
```

Remember those nominal types whose body is a call to the real segment function?

1:35pm. Last night (like past 12am) it occurred to me that I do not have a smooth way of taking care of this.

I wanted to simplify things for myself by doing explicit substitution (as opposed to using environments) for type level functions, but this would wreck that. Also on the face of it, while `nominal real Tensor dim ty = tensor_init dim ty` seems super straightforward, I find myself confused as to what `Tensor dim ty` is supposed to be.

It is not a type level function. It is not a forall either. So what should it be then?

Back while I was thinking this through, it was super obvious to me once I had the idea what the effect of this should be. Partially evaluate `tensor_init dim ty` and strip its type. Then use that for the body of the nominal type.

1:50pm. But now that I've looked at it again and am thinking what that really entails, I am finding myself unprepared for having to do value level computation at the type level.

2:40pm. Yeah, this is difficult. I am going to have to add the equivalent of `RawType` to the type expressions. And type level functions will be just like regular functions - I am in fact going to have to give them environments and wait till they are fully applied.

```
    | RawTForall of (string * RawTypeTypeExpr) [] * RawTypeExpr
    | RawTInl of (string * RawTypeTypeExpr) [] * RawTypeExpr
```

I am going to get rid of arrays here. I'll split them up into multiple arguments.

Now, it is great that I've decided all this, but I need to think about it some more. Unification will really be a hell to deal with won't it?"

---
## [rubygems/rubygems](https://github.com/rubygems/rubygems)@[6f2468c5d8...](https://github.com/rubygems/rubygems/commit/6f2468c5d86642610cd2d0b7951c5cbe9bcb815c)
#### Monday 2020-01-13 14:30:26 by Bundlerbot

Merge #3073

3073: Remove the bundler version selector r=bronzdoc a=deivid-rodriguez

# Description:

I do like the idea of bundler being able to lock its own version, but this implementation is not the right way to do it in my opinion.

I aim to reimplement this inside bundler in the near future, but it needs to be done in a more user friendly way that properly informs the user about what's going on, and never raises when not necessary.

But for now I think we should remove this code from rubygems because this is causing more problems than benefits and it's being counterproductive.

Closes #2671.
Closes #3044.
Closes rubygems/bundler#6913.
Closes rubygems/bundler#7031.
Closes rubygems/bundler#7489.
Closes rubygems/bundler#7517.
Closes rubygems/bundler#7538.
Closes rubygems/bundler#7564.

# Tasks:

- [x] Describe the problem / feature
- [ ] Write tests
- [x] Write code to solve the problem
- [ ] Get code review from coworkers / friends

I will abide by the [code of conduct](https://github.com/rubygems/rubygems/blob/master/CODE_OF_CONDUCT.md).


Co-authored-by: David Rodríguez <deivid.rodriguez@riseup.net>

---
## [cockroachdb/cockroach](https://github.com/cockroachdb/cockroach)@[d4166813ab...](https://github.com/cockroachdb/cockroach/commit/d4166813ab419334d7c479367ba9d38b7212ed2e)
#### Monday 2020-01-13 15:41:38 by Andrei Matei

storage: don't account for MaxOffset in liveness expiration

Before this patch, a node writing its expiration record would add an
extra MaxOffset to its Liveness.Expiration, and the Liveness.IsLive()
method would subtract MaxOffset from the expiration before comparing it
to the current time. The adding and subtracting cancel each other.

I think this doesn't make any sense. I've thought about it a bunch, and
I can't find any justification for any of this.
Historically, at first came the subtracting, from the very beginning of
liveness records. I think that's the original sin - the code was very
pessimistic about whether records were expired or not.
Then came #12232, which put in the adding to counteract the subtracting :)
It says
// We need to add the maximum clock offset to the expiration because it's
// used when determining liveness for a node.
And in a review comment:
"
We need to add in max offset or else nodes will be considered not live
sooner than expected for very small heartbeat intervals, assuming the
max offset stays at 250ms.
"
Can't argue with that.

This PR gets rid of the pair of adding and subtracting. It seems to me
that that's the sane thing to do. Besides taking offsets out of where
they don't belong, this PR also hopes to open the door to improving the
liveness api: right now there's a Liveness.IsLive(maxOffset) method and
a Liveness.IsDead(threshold) method. If you want to make IsDead() be the
inverse of IsLive(), you'd have to pass a negative threshold
(-maxOffset).

When thinking what could go wrong and how the max offset fares into the
liveness expiration, one has to take into account that the stasis of an
epoch-based lease starts at (liveness.expiration - maxOffset):
https://github.com/cockroachdb/cockroach/blob/6bf028ced62e7c3970afe7aa7de1afd6fedd945e/pkg/storage/replica_range_lease.go#L567
Symmetry with this code may have been what prompted the original
subtracting. However, I think that symmetry was misguided.

I believe the migration story to be fine: liveness records written by
old nodes will be considered by new nodes to be alive marginally longer,
and liveness records written by new nodes will be considered by old
nodes to be alive marginally less. Liveness records are supposed to
expire in 9s, and they're updated after 4.5s.

Release note: None

---
## [cockroachdb/cockroach](https://github.com/cockroachdb/cockroach)@[fd44a00856...](https://github.com/cockroachdb/cockroach/commit/fd44a0085627e8022dae7bce2dbe661bf09646cd)
#### Monday 2020-01-13 15:41:47 by craig[bot]

Merge #43863

43863: storage: don't account for MaxOffset in liveness expiration r=andreimatei a=andreimatei

Before this patch, a node writing its expiration record would add an
extra MaxOffset to its Liveness.Expiration, and the Liveness.IsLive()
method would subtract MaxOffset from the expiration before comparing it
to the current time. The adding and subtracting cancel each other.

I think this doesn't make any sense. I've thought about it a bunch, and
I can't find any justification for any of this.
Historically, at first came the subtracting, from the very beginning of
liveness records. I think that's the original sin - the code was very
pessimistic about whether records were expired or not.
Then came #12232, which put in the adding to counteract the subtracting :)
It says
// We need to add the maximum clock offset to the expiration because it's
// used when determining liveness for a node.
And in a review comment:
"
We need to add in max offset or else nodes will be considered not live
sooner than expected for very small heartbeat intervals, assuming the
max offset stays at 250ms.
"
Can't argue with that.

This PR gets rid of the pair of adding and subtracting. It seems to me
that that's the sane thing to do. Besides taking offsets out of where
they don't belong, this PR also hopes to open the door to improving the
liveness api: right now there's a Liveness.IsLive(maxOffset) method and
a Liveness.IsDead(threshold) method. If you want to make IsDead() be the
inverse of IsLive(), you'd have to pass a negative threshold
(-maxOffset).

When thinking what could go wrong and how the max offset fares into the
liveness expiration, one has to take into account that the stasis of an
epoch-based lease starts at (liveness.expiration - maxOffset):
https://github.com/cockroachdb/cockroach/blob/6bf028ced62e7c3970afe7aa7de1afd6fedd945e/pkg/storage/replica_range_lease.go#L567
Symmetry with this code may have been what prompted the original
subtracting. However, I think that symmetry was misguided.

I believe the migration story to be fine: liveness records written by
old nodes will be considered by new nodes to be alive marginally longer,
and liveness records written by new nodes will be considered by old
nodes to be alive marginally less. Liveness records are supposed to
expire in 9s, and they're updated after 4.5s.

Release note: None

Co-authored-by: Andrei Matei <andrei@cockroachlabs.com>

---
## [Bianxing-Mifeng/nier-project](https://github.com/Bianxing-Mifeng/nier-project)@[adf1f8d1a7...](https://github.com/Bianxing-Mifeng/nier-project/commit/adf1f8d1a722a453c21758be10e4a3911b6608d0)
#### Monday 2020-01-13 17:39:55 by n

Serve me introduce this by language I AM NOT DISCRIMINATORY nor do I forgive antiblack activitities by said discriminatories. I favourite Obama and I have many souls of the sullen salmagundi.  My fiction began as I was enjoying a pleasant-tasting nutrition at my localised Applebee’s upland the chance ; when I go on to request this microscopic canine butt tiddler victimisation the piece of ass element flow.  for discourse interest, she was in reality of Mortal American language Lineage  ultimate schedule I patterned I wasn’t at a goddamned installation, so reason the relation is this priest not mistreatment the flushed H2O outflow?? terrorist organization me narrate you, this neighbourhood trash was effort on my braveries but I stimulate it transparency; as I wasn’t some take of discriminatory that discriminated on Someone American languages.  But I was observation her intensely now. And Reasonable when I’m about to decline evoke, I slang you not the flyspeck little terror force out a course disgraceful Iphone SEVENERS7 summation that she closely-held.  Gush actress...  Pitch-black...  She closely-held a Dark...  This kvetch was a racial! I grabbed my combat stand by from underneath my White mask and whipped this genetically graphic symbol medicate dependant kid plunk for into the Cotten airfields wherever she belonged.  I told her that me and my FTO phalluses would communicatings her cut off body part in a crateful to Continent, and this is wherever I titled her the [normality language unit]  She was existence a backward bigot diddly; which is a real joint attribute in the Somebody English language juveniles. Because of this I conceive I was guaranteed in line of work her the [normality parole].  So Reddit AITA?

gamer

---
## [troglobit/watchdogd](https://github.com/troglobit/watchdogd)@[90f69d2ff1...](https://github.com/troglobit/watchdogd/commit/90f69d2ff1c14758e67813ac49500b5bf809c47d)
#### Monday 2020-01-13 17:55:53 by Joachim Nilsson

Clarify nomenclature; cause is from kernel, reason from watchdogd

Richard Alpe brought to my attention the confusing nomenclature used in
watchdogd today.  Reset *cause* and reset *reason* were sloppily, and
often interchangeably, used.  It was not clear to a user of watchdogd
what was the status from the kernel WDT, and what was the extra info
that watchdogd had added.

After a brief discussion he convinced me it was a good idea to clean
up this mess and we arreived at the following conclusion;

  - Reset cause should always be the `WDIOF_` flags returned from the
    kernel `WDIOC_GETBOOTSTATUS` ioctl.
  - Reset reason is the extra value watchdogd adds.  This, at its core,
    is a `code` that can be set by any of the supervisor or monitor
    plugins supported; e.g. a monitored process fails to meet its
    deadline, a system memory leak, or CPU overload (loadavg plugin)

95% of this patch is a search-and-replace of:

  - cause --> reason
  - cause --> code
  - etc.

The remaining 5% are adaptations, comments, and updated documentation.

The biggest implication of this change is the change in the libwdog API.
The wdog_reason_t::cause rename to ::code.  Hence the ABI version bump.
We could of course add an ugly union to support both ::cause and ::code,
but that seems silly since we might also want to add the kernel reset
cause to that struct later.  So, in the immortal words of a good friend
of mine;

>  "I'd rather be consistent than please everyone."

Also, I'd be very surpised if this really breaks anyone's code, because
that would mean someone other than Westermo actually uses libwdog ...

Signed-off-by: Joachim Nilsson <troglobit@gmail.com>

---
## [notcake/gcompute](https://github.com/notcake/gcompute)@[ce4b4fed29...](https://github.com/notcake/gcompute/commit/ce4b4fed2972585a9342dd2d5677be5ea487034a)
#### Monday 2020-01-13 19:17:26 by notcake

Revert "fuck this stupid shit"

This reverts commit e22eeca1c8c25ae95e1f66ae53295346727ddab4.

---
## [amardvinau/github-public](https://github.com/amardvinau/github-public)@[4463378188...](https://github.com/amardvinau/github-public/commit/4463378188e70b1eb4c9e7e9f7618f8116c99ea1)
#### Monday 2020-01-13 20:05:36 by Anton

Add files via upload

Just added the code which I've written for the task mentioned in Automate the Boring Stuff with Python book by Al Sweigart. Love the book!
The task itself sounds like that:
Fantasy Game Inventory
You are creating a fantasy video game. The data structure to model the player’s inventory will be a dictionary where the keys are string values describing the item in the inventory and the value is an integer value detailing how many of that item the player has. For example, the dictionary value {'rope': 1, 'torch': 6, 'gold coin': 42, 'dagger': 1, 'arrow': 12} means the player has 1 rope, 6 torches, 42 gold coins, and so on.

Write a function named displayInventory() that would take any possible “inventory” and display it like the following:

Inventory:
12 arrow
42 gold coin
1 rope
6 torch
1 dagger
Total number of items: 62

Hint: You can use a for loop to loop through all the keys in a dictionary.

# inventory.py
stuff = {'rope': 1, 'torch': 6, 'gold coin': 42, 'dagger': 1, 'arrow': 12}

def displayInventory(inventory):
    print("Inventory:")
    item_total = 0
    for k, v in inventory.items():
        # FILL THIS PART IN
    print("Total number of items: " + str(item_total))

displayInventory(stuff)

List to Dictionary Function for Fantasy Game Inventory
Imagine that a vanquished dragon’s loot is represented as a list of strings like this:

dragonLoot = ['gold coin', 'dagger', 'gold coin', 'gold coin', 'ruby']

Write a function named addToInventory(inventory, addedItems), where the inventory parameter is a dictionary representing the player’s inventory (like in the previous project) and the addedItems parameter is a list like dragonLoot. The addToInventory() function should return a dictionary that represents the updated inventory. Note that the addedItems list can contain multiples of the same item. Your code could look something like this:

def addToInventory(inventory, addedItems):
    # your code goes here

inv = {'gold coin': 42, 'rope': 1}
dragonLoot = ['gold coin', 'dagger', 'gold coin', 'gold coin', 'ruby']
inv = addToInventory(inv, dragonLoot)
displayInventory(inv)

The previous program (with your displayInventory() function from the previous project) would output the following:

Inventory:
45 gold coin
1 rope
1 ruby
1 dagger

Total number of items: 48

NB: But I've made some changes: firstly I wanted to use the initial inventory dictionary, with the values already quoted. So, I've added the new list (loot) to the current inventory which was created. Secondly I've made this via PyCharm app and saved it as a .py file at first, and only then copied it to my Jupyter Notebook and saved it as .pynb file. Now it is here. 
(I've written two options of the code: with "try" and "except" methods - which is shorter and less time consuming, and without them, making a loop within a loop).
Hope you'll like the program and the code.

---
## [peterdeepsix/deepsixdesign](https://github.com/peterdeepsix/deepsixdesign)@[209234d373...](https://github.com/peterdeepsix/deepsixdesign/commit/209234d3730b9579a56894533e883f1750406a4c)
#### Monday 2020-01-13 20:29:09 by Peter Arnold

with all my love, i thank you. i thank us, for the present, past and future. cheers my friends. onwards and upwards

---
## [psathyrella/partis](https://github.com/psathyrella/partis)@[0164f682a6...](https://github.com/psathyrella/partis/commit/0164f682a6b7b7811a3180d13e3573a7700109eb)
#### Monday 2020-01-13 20:34:52 by duncan ralph

re-implement relative affinity plots

holy fuckballs that sucked

---
## [tgstation/tgstation](https://github.com/tgstation/tgstation)@[65485b9c54...](https://github.com/tgstation/tgstation/commit/65485b9c54e9d2fc269e40502ab929888cdb2db3)
#### Monday 2020-01-13 22:21:43 by ArcaneMusic

Adds a new Tech to the B.E.P.I.S., Specialized Engineering, and a new Minor Reward. (#48507)

About The Pull Request

Round 2.
image
Adds a new tech to be unlocked within the B.E.P.I.S.'s major techs, called "Specialized Engineering". Within that tech are 2 new items, Heat Resistant Rods, and the Tinker's Gloves, as well as a new minor tech, the Survival Pen.
Heat Resistant Rods:
Have you ever wanted to expand Lavaland Base? Build a lava fortress worthy of your magnificence? Well, now you can! Using Heat Resistant Rods, you can make a catwalk to cross lava tiles, as well as build atop lava, without messy methods like using the RCD!
Tinker's Gloves:
This just in engineers, insulated gloves have new competition in town! The Tinker's gloves are complicated, overdesigned gloves that, while not very shockproof, allow for faster wall girder construction. No longer will you need to die of old age walling off an area when you're out of RCD ammo! Warning: This product contains no likeness to clockwork gauntlets used by the extinct cult of Rat'Var, and any such similarity is by no means intentional.

Survival Pen:
Have you ever been stuck on lavaland, trapped by your survival pod with just a few chairs, some titanium walls, and walls of ash closing in on you? Well THANK GOD you have your Rockbreaker brand Survival Pen! Allows for basic mining operations, and is portable like a standard pen!
BUT WAIT!
A watcher blocks your path. Thankfully, your expensive, diamond encrusted pen isn't just good for being the world's slowest pickaxe, it's ALSO coated in the one thing watchers crave: DIAMONDS. Toss the pen to draw the watcher's attention elsewhere.
Why It's Good For The Game

Starts to fill our B.E.P.I.S. Major Reward Techs, as intended, and fills a niche that doesn't get much play nowadays: Building on Lavaland. This was something I've had in the back of my mind since we did the first tests of the Disaster gamemode a few months ago, so each item here was made with the intention of improving the mining base should the station become un-livable. Lava-Proof Rods are beneficial in that you'll be able to cross and build over lava by the mid-end of the shift. RCDs still work as usual, but this way you won't have to worry about getting specialized engineering equipment as a member of cargo or science. The tinker's gloves are basically a variant of the nitrile gloves, but they grant a speed bonus to adding plating to metal girders, so that some kind of functional alternative to giving every engineer insulated gloves.
Survival Pens are quite honestly very niche, but getting dumb pens with extra functionality is a tradition of trade shows all over the world, so it feels right at home as a minor reward.

Also, does a tiny change to the doe sprites, just to look a little bit less old.
Changelog

cl
add: A new Technology has been implemented as a major reward in the B.E.P.I.S., Specialized Engineering, to appeal to engineering utility and new construction horizons.
tweak: Watchers will now actively consume diamond ore left lying around, alongside the new survival pens.
/cl

---
## [dom64/dompack-client](https://github.com/dom64/dompack-client)@[a5e207dff1...](https://github.com/dom64/dompack-client/commit/a5e207dff117e304e33ffdd19096f42c3f9363df)
#### Monday 2020-01-13 22:47:19 by dom64

Added a shit ton of mods

Mystcraft
RFTools Dimensions
Blood Arsenal
Animus
Modular Powersuits
Mekanism
Deez Nuts Creepers
Portal Gun
Better Than Mending
Clarity
SwingThroughGrass
AttributeFix
Open Modular Turrets
OMLib
Numina

---
## [clayne/mpv](https://github.com/clayne/mpv)@[57fbc9cd76...](https://github.com/clayne/mpv/commit/57fbc9cd76f7a78f1034c42dd3c453ff35123264)
#### Monday 2020-01-13 23:50:02 by wm4

player: make repeated hr-seeks past EOF trigger EOF as expected

If you have a normal file with audio and video, and keep "spamming"
forward hr-seeks, the player just kept showing the last video frame
instead of exiting or playing the next file. This started happening
since commit 6bcda94cb. Although not a bug per se, it was odd, and very
user-noticable.

The main problem was that the pending seek command was processed before
the EOF was "noticed". Processing the command reset everything, so the
player did not terminate playback, but repeated the seek.

This commit restores the old behavior.

For one, it makes video return the correct status (video.c). The
parameter is a bit ugly, but better than duplicating the logic or having
another MPContext field. (As a minor detail, setting r=VD_EOF makes sure
have_new_frame() returns true, rather than going through another
iteration or whatever the hell will happen instead, which would clobber
logical_eof.)

Another thing is making the seek logic actually wait until the seek
outcome has been determined if audio is also active. Audio needs to wait
for video in order to get the video seek target position. (Which in turn
is because hr-seek still "snaps" to video frames. You can't seek in
between two frames, so audio can't just use the seek target, but always
has to wait on the timestamp of the video frame. This has other
disadvantages and is a misdesign, but not something I'll fix today.)

In theory, this might make hr-seeks less responsive, because it needs to
fully decode/filter the audio too, but in practice most time is spent on
video, which had to be fully decoded before this change. (In general,
hr-seek could probably just show a random frame when a queued hr-seek
overrides the current hr-seek, which would probably lead to a better
user experience, but that's out of scope.)

Fixes: #7206

---
## [clayne/mpv](https://github.com/clayne/mpv)@[cc746c9508...](https://github.com/clayne/mpv/commit/cc746c9508a2e64a69cb75ea7b9ec8ac437934ff)
#### Monday 2020-01-13 23:50:02 by wm4

vo_gpu: x11egl: cleanup EGL correctly

...probably.

The EGL backend had a strange problem: when recreating the window, EGL
surface creation sometimes mysteriously failed. For example, keeping the
"_" key down (cycles video by default) destroys and recreates the window
in rapid succession, which will often enough show the "Could not create
EGL surface!" message.

This was puzzling because due to mpv's architecture, the X11 Window and
even the X11 Display were fully destroyed, the thread on which they ran
was destroyed, and then everything was recreated. There shouldn't have
been any state that could make subsequent EGL initialization fail.

It turns out mpv forgot to free EGLSurfaces in the x11 code. EGL is a
pretty crazy API (full of thread local and global state with weird
lifetime requirements), and for example it seems EGLDisplay cannot be
explicitly released, but apparently implicitly dies when the native
display is closed (at least EGL 1.5 claims eglTerminate() does _not_
invalidate the display, only certain objects linked to it). It appears
that Mesa still referenced at least EGLSurface in some form, and either
some pointer or some X11 ID was dangling, and when it randomly matched
when eglCreateWindowSurface() was called, it failed.

Fix this by calling eglTerminate(), which supposedly destroys (or rather
unreferences) contexts and surfaces created from the display (but
absurdly not the display itself).

Now why can't you just destroy the display? If it's implicitly
invalidated, why can't it just call eglTerminate() implicitly when this
happens? Did Mesa do something wrong when they somehow didn't
automatically remove the dangling object (so I could claim not to be
responsible for the bug)? Who the fuck knows, and I'm too tired to
figure this out (both because it's late, and because I'm tired of this
EGL crap API).

Still not sure if the code is correct now. I think EGL was designed to
maximize implementation and API-use complications. How else could you
possibly come up with something like the EGLDisplay life cycle? Or am I
just making a fuss? Anyway, fuck EGL, fuck computers, fuck technology.

Fixes: #7129

---

# [<](2020-01-12.md) 2020-01-13 [>](2020-01-14.md)

