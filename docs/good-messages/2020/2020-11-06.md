# [<](2020-11-05.md) 2020-11-06 [>](2020-11-07.md)

2,662,314 events, 1,391,534 push events, 2,143,911 commit messages, 158,056,678 characters


## [aparcar/pyload](https://github.com/aparcar/pyload)@[3668cdcc80...](https://github.com/aparcar/pyload/commit/3668cdcc80c5445ba8fa52cbf80c2a825fbf5200)
#### Friday 2020-11-06 00:04:07 by Paul Spooren

Update AUTHORS

Some 11 years ago I started pyLoad (initially written in shell) and
posted it on the gulli.com board (down). RaNaN, sebnapi, mkaay and a few
more joined early on and basically taught me how to Python & *open
source*, I was 15 by that time.  I think Jonn3y came up with the name
and logo, maybe someone else, sorry.

We started at BitBucket and later went on to GitHub. Using the wayback
machine this is the oldest version I could find is from 27th May 2009.
Even earlier versions are lost, but it's nothing to brag with anyway.

At some point the jDownloader people gave us a DLC decryption key which
we (me) accidently pushed as an unobfuscated `pyc`, so within 24 hours a
website appeared using our keys to decryption DLC to plaintext on
demand.

Also there was this guy *jbauer* who did some developing at the
beginning but then turned evil and screw our entire infrastructure, I
never understood why.

Looking at the log I stopped my pyLoad career with a rather uncool
commit (a4c306cb). Last thing I remember that we were just about to
release pyLoad 0.5...

Back in the day it was really important to stay somewhat anonymous, so
my name appears nowhere in those old sources, I think.

Signed-off-by: Paul Spooren <mail@aparcar.org>

---
## [aparcar/pyload](https://github.com/aparcar/pyload)@[b2d2fc900a...](https://github.com/aparcar/pyload/commit/b2d2fc900aa7bffe0b7d1811b53edaf47e971764)
#### Friday 2020-11-06 00:05:50 by Paul Spooren

Update AUTHORS

Some 11 years ago I started pyLoad (initially written in shell) and
posted it on the gulli.com board (down). RaNaN, sebnapi, mkaay and a few
more joined early on and basically taught me how to Python & *open
source*, I was 15 by that time.  I think Jonn3y came up with the name
and logo, maybe someone else, sorry.

We started at BitBucket and later went on to GitHub. Using the wayback
machine this is the oldest version I could find is from 27th May 2009.
Even earlier versions are lost, but it's nothing to brag with anyway.

At some point the jDownloader people gave us a DLC decryption key which
we (me) accidentally pushed as an unobfuscated `pyc`, so within 24 hours
a website appeared using our keys to decryption DLC to plaintext on
demand.

Also there was this guy *jbauer* who did some developing at the
beginning but then turned evil and screw our entire infrastructure, I
never understood why.

Looking at the log I stopped my pyLoad career with a rather uncool
commit (a4c306cb). Last thing I remember that we were just about to
release pyLoad 0.5...

Back in the day it was really important to stay somewhat anonymous, so
my name appears nowhere in those old sources, I think.

Signed-off-by: Paul Spooren <mail@aparcar.org>

---
## [Buildstarted/linksfordevs](https://github.com/Buildstarted/linksfordevs)@[594b0e135f...](https://github.com/Buildstarted/linksfordevs/commit/594b0e135fbfb332308704c0411dcd37c55db883)
#### Friday 2020-11-06 00:06:37 by Ben Dornis

Updating: 11/6/2020 12:00:00 AM

 1. Added: Goodbye USA
    (https://larrysalibra.com/goodbye-usa/)
 2. Added: The winner of the election is... Big Tech
    (https://creativegood.com/blog/20/winner-of-election-big-tech.html)
 3. Added: Weekly Update 216
    (https://www.troyhunt.com/weekly-update-216/)
 4. Added: A Productive Productivity System
    (https://mrbalihai.github.io/2020/11/05/a-productive-productivity-system.html)
 5. Added: Compose for Desktop UI Framework
    (https://www.jetbrains.com/lp/compose/)
 6. Added: Don't make me think about whether I should pay you
    (https://www.krewast.de/artikel/dont-make-me-think-about-whether-i-should-pay-you/)
 7. Added: Life and Death of a Linux Process
    (https://natanyellin.com/posts/life-and-death-of-a-linux-process/)
 8. Added: Everybody be Coil. You... Be Coil - Tink - Léonie Watson
    (https://tink.uk/everybody-be-coil/)
 9. Added: Stop telling me to exercise: dealing with a mild short-term depression
    (https://rasulkireev.com/dealing-with-mild-depression/)
10. Added: We Don't Need to Boycott Wayland
    (https://refi64.com/posts/dont-boycott-wayland.html)
11. Added: The problem of centralisation
    (https://jae.moe/blog/nov2020-centralization/)
12. Added: Underjord | The BEAM marches forward
    (https://underjord.io/the-beam-marches-forward.html)
13. Added: Learning how to learn (Pt. 1)
    (https://oldmanrahul.com/2020/11/04/re-use-trained-muscles/)
14. Added: Corporate Password Security with Troy Hunt | Authlogics
    (https://authlogics.com/troyhunt/)

Generation took: 00:06:25.6017449

---
## [monori-site/frontend](https://github.com/monori-site/frontend)@[a108e69424...](https://github.com/monori-site/frontend/commit/a108e694244606e297e9897060b2fc160f4b8247)
#### Friday 2020-11-06 04:12:27 by Noel

npm is fucking shit, revert to OUR DAMN SAVIOUR -- Yarn.

---
## [Cassius-P/B3-Workshop](https://github.com/Cassius-P/B3-Workshop)@[6470f2f085...](https://github.com/Cassius-P/B3-Workshop/commit/6470f2f0853349d9b4ee14a98616b3d0272b2ddd)
#### Friday 2020-11-06 06:53:11 by Cassius-P

Dernier commit et push les boys, <3 sur vous en tout cas. On a pas forcément des masses dormi mais c'était cool.

Morale de ce workshop => Fuck Chantal

---
## [juju/juju](https://github.com/juju/juju)@[9e25139d10...](https://github.com/juju/juju/commit/9e25139d104ed52b9ca1f224770541ff10db66c8)
#### Friday 2020-11-06 07:25:38 by Juju bot

Merge pull request #12267 from benhoyt/fix-machine-az-test

https://github.com/juju/juju/pull/12267

This fixes the intermittent test failure we were seeing in the provisioning worker test `TestAvailabilityZoneMachinesStartMachinesAZFailures`. [Example Jenkins output here.](https://jenkins.juju.canonical.com/job/Unit-RunUnitTests-arm64/17/testReport/junit/github/com_juju_juju_worker_provisioner/TestPackage/)

The fix in the end is simply to make this test more forgiving, as this can happen in real life, but is rare and would be complicated to work around, and the "failure mode" is not bad -- one AZ just has one fewer instances on it than the others. Details below.

## Repro steps

To repro, add a `time.Sleep(100 prdesc time.Millisecond)` inside the `if startInstanceParams.AvailabilityZone != "" {` after line 1129 of `worker/provisioner/provisioner_task.go`. Then run

```
go test github.com/juju/juju/worker/provisioner -test.count=10 -test.v -check.f 'TestAvailabilityZoneMachinesStartMachinesAZFailures$' -check.vv
```

and the failure will occur about 50% of the time. The failure looks like:

```
provisioner_test.go:1628:
 assertAvailabilityZoneMachinesDistribution(c, availabilityZoneMachines)
provisioner_test.go:1555:
 c.Assert(max-min, jc.LessThan, 2)
... obtained int = 2
... expected int = 2
```

and the relevant log lines are:

```
[LOG] 0:00.953 INFO test trying machine 1 StartInstance in availability zone zone1
[LOG] 0:00.963 INFO test trying machine 3 StartInstance in availability zone zone3
[LOG] 0:00.971 INFO test trying machine 2 StartInstance in availability zone zone4
[LOG] 0:00.971 WARNING test machine 2 failed to start in availability zone zone4: zing
[LOG] 0:00.971 INFO test trying machine 4 StartInstance in availability zone zone1
[LOG] 0:00.971 DEBUG test failed to start machine 2 in zone "zone4", retrying in 5ms with new availability zone: zing
[LOG] 0:00.983 DEBUG test machine 2 does not match az zone4: excluded in failed machine ids
[LOG] 0:00.983 INFO test trying machine 2 StartInstance in availability zone zone3
```

## Gory details

The test starts 4 machines (machine IDs 1, 2, 3, 4) in 3 availability zones (zone1, zone3, zone4 -- zone2 is marked not available), with machine 2 returning error from StartInstance on the first call and success subsequently. The test asserts that the machines are spread across the AZs as evenly as possible, in this case meaning 1 machine on each of two zones and 2 machines on the other zone. If there are 2 machines on each of two zones and no machines on the other zone the test fails with the error we're seeing.

The failure happens when the machines are started with machine 2 as the second or third to be started (not the first or last), *and* the subsequent machines are started before the `markMachineFailedInAZ()` function is called for the failed machine 2. This results in one of the AZs being unused. For example, here's a failure example:

```
machine 1 started on zone1
machine 3 started on zone3
machine 2 start attempt on zone4 (will fail on first attempt)
machine 4 started on zone1
markMachineFailedInAZ() called for machine 2 (marking zone 4 unusable by machine 2)
machine 2 started on zone3
test fails - zone1 has machines 1 and 4, zone3 has machines 2 and 3, zone4 has none
```

With these parameters, this would actually happen around 50% of the time if StartInstance took a decent amount of time, but it happens much less frequently than that in testing because of the timing issues -- I believe mostly because of how the test's `mockBroker` locks a mutex in its StartInstance, so those calls essentially happen sequentially and not concurrently, and I guess the Go scheduler normally calls the `markMachineFailedInAZ()` before starting machine 4 (allowing machine 4 to be started on zone4 and then the machine 2 retried on zone1).

I don't see a simple way around this. Obviously we want to start these things in parallel in real life, so we can't lock the the zones data structure for that whole time (seconds or minutes). We could retry on the same AZ once before marking that zone unusable by the failed instance? But that complicates the already-complex provisioning logic.

This will happen sometimes in real life (if you're starting N machines in M zones and N > M, and one or more machines fail to start up, and the failed machines aren't the first or last machines started). However, it's going to be fairly rare, and the "failure case" is not bad anyway -- one zone will just have fewer machines assigned to it.

So I'm inclined to just say "this is okay" and change the test assertion to allow 2 machines on each of two zones and none on the other zone.

---
## [CNeuroUSTC/CNeuroUSTC.github.io](https://github.com/CNeuroUSTC/CNeuroUSTC.github.io)@[f117531fcf...](https://github.com/CNeuroUSTC/CNeuroUSTC.github.io/commit/f117531fcf476fc2b83b70b5f7704bc23a446e0e)
#### Friday 2020-11-06 07:50:16 by Li-Pinjie

paper: "Early-Life Social Experience Shapes Social Avoidance Reactions in Larval Zebrafish"   url: "https://www.sciencedirect.com/science/article/pii/S0960982220311477#:~:text=Specifically%2C%20larvae%20raised%20in%20isolation,more%20frequently%20during%20social%20interactions.&text=Taken%20together%2C%20our%20results%20show,avoidance%20reactions%20in%20larval%20zebrafish."   pdf: "None"   authors: "Antonia H. Groneberg, Joa˜o C. Marques, A. Lucas Martins, Ruth Diez del Corral, Gonzalo G. de Polavieja, Michael B. Orger"   location: <a href="https://map.baidu.com/search/%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6(%E8%A5%BF%E6%A0%A1%E5%8C%BA)-%E7%94%9F%E5%91%BD%E7%A7%91%E5%AD%A6%E5%A4%A7%E6%A5%BC/@13054067.545,3720295.44,19z?querytype=s&da_src=shareurl&wd=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6(%E8%A5%BF%E6%A0%A1%E5%8C%BA)-%E7%94%9F%E5%91%BD%E7%A7%91%E5%AD%A6%E5%A4%A7%E6%A5%BC&c=127&src=0&wd2=%E5%90%88%E8%82%A5%E5%B8%82%E8%9C%80%E5%B1%B1%E5%8C%BA&pn=0&sug=1&l=13&b=(13043472.77821802,3712418.4285550946;13063946.357629184,3730135.2423363887)&from=webmap&biz_forward=%7B%22scaler%22:2,%22styles%22:%22pl%22%7D&sug_forward=f2f7c92a9921ecdbb54f5426&device_ratio=2">429</a>

---
## [supermaxiste/ARPEGGIO](https://github.com/supermaxiste/ARPEGGIO)@[d2fecd5c68...](https://github.com/supermaxiste/ARPEGGIO/commit/d2fecd5c68275d59d9d3cbc1c52f20b527933ead)
#### Friday 2020-11-06 10:11:43 by supermaxiste

Fuck your pricing plan Travis

Let's have one last run on Travis just because

---
## [kikotheexile/Endless-Sky-Civil-War](https://github.com/kikotheexile/Endless-Sky-Civil-War)@[150fff012f...](https://github.com/kikotheexile/Endless-Sky-Civil-War/commit/150fff012ff961a7c2b17f9b29803886482c54b3)
#### Friday 2020-11-06 13:23:14 by kikotheexile

OK LOOK SO I KNOW IT SOUNDS CRAZY

But hear me out, by this point in time the Navy/Oathkeepers and the Deep have been independently working with the Free Worlds to clear the Free Worlds of any wrongdoing during the course of the war. In fact, in this mission, the Deep tells the Cap-i-taaaan to to check out the deep sky shit. Well thats navy military equipment. So shouldnt that be locked behind the navy license? (why yes, yes it should be, thank you for catching this.) Since the Free Worlds and the rest of the universe have kinda reconciled, and since first last is besties with a bunch of people who have the authority to give first last a navy loicense, why wouldnt first last get a navy loicense here in rec. 

granted they still wouldnt get it in check

Which means, during the same branch for the RNOathkeepers, wouldnt First Last get access to Free Worlds loicenses, too? Why, yes, yes they would. 

So this is future proofing for the southern republic storyline.

---
## [canalplus/rx-player](https://github.com/canalplus/rx-player)@[66aff23b12...](https://github.com/canalplus/rx-player/commit/66aff23b120df62a329d1aea0cb7345e1140ec56)
#### Friday 2020-11-06 13:35:24 by prosset

second working try, implementing audioTrackSwitchMode feature

adapt comment

remove option from transportOptions

unit test the front loadVideo api

refining the PR by moving logic in period_stream and adding a new event needsSourceBufferFlush

fix typo and doc

remove isFirstAdaptation on adaptationChange since not used anymore

make the switch audio strategy live in getAdaptationSwitchStrategy as other adaptation switching strategy

fix linter

make observable for flush strategy instead of lone boolean

get rid of isFirstAdaptation boolean but rather look at the adaptation buffer to decide and make shared obs

fire event need-source-buffer-flush when we removed buffers

remove useless share operator

remove line break

remove unused share operator

get the right adaptation strategy

add default audiotrackswitchingmode on warn options parser

Clean stuff

Clean stuff part2

log init

set mediaElement currentTime to the overall duration

add log when flushing through seek on medialement

parent 87cf782defe433c82d17131b8b2a73bfced26ab4
author Paul Berberian <pea.berberian@gmail.com> 1601302697 +0200
committer prosset <paulrosset96@gmail.com> 1604668921 +0100

parent 87cf782defe433c82d17131b8b2a73bfced26ab4
author Paul Berberian <pea.berberian@gmail.com> 1601302697 +0200
committer prosset <paulrosset96@gmail.com> 1604668920 +0100

parent 87cf782defe433c82d17131b8b2a73bfced26ab4
author Paul Berberian <pea.berberian@gmail.com> 1601302697 +0200
committer prosset <paulrosset96@gmail.com> 1604668919 +0100

remove husky dependency

This is a proposal to remove the husky dependency which imposes two git
hooks today:

  1. A pre-commit hook which ensures tests are run before all commits

  2. A pre-push which ensures the branch name has the right format
     (namespace + ":" + text)

There are multiple reasons why I think both of those are unnecessary:

  1. It's not really necessary.

     For the first one (pre-commit), tests are usually run by CI once
     the branch is in a Pull-Request. There is still commits that are
     potentially not stable as a standalone but the reviewer can quicly
     guess that on review and asks for multiple commits to be squashed.

     For the second one, we didn't really encounter any case where
     namespacing a branch was really necessary. It looks cleaner for
     sure but there's no real other advantage (well, aside from seeing a
     based bear when a branch is badly named!).

  2. It adds both a relation of distrust and a lot of inconvenience
     (especially for outside developpers) for two minor things.

  3. I'm tired of waiting time after commiting when I usually already
     ran tests (and I hope most us main contributors already do anyway).

Fix typo presentationMediaOffset (#831)

parsers: add white default color to ttml

fix(directfile-eme): Fix a bug where the CDM will never know when the media key will be atached in directfile

features: avoid circular dependency in `src/features`

This is a small fix to avoir a circular dependency in the `src/features`
directory.

Basically, the `features` object, which, was declared in
`src/features/index.ts`, was imported by `src/features/add_features.ts`.
This is problematic because `src/features/index.ts` also imports
`src/features/add_features.ts`.

There was no real reason to declare the `features` object in `index.ts`
other than convenience. In this commit, I move it to its own
`features_object.ts` file.

This issue led to no build error that I know of, but it is still an
ugly avoidable situation.

eme: better log why a session is not considered as "usable"

Previously, when loading a persistent session with keys deemed as not
usable, we just logged that the loaded MediaKeySession was "not usable".

To help debugging, this commit now clearly enounce which of the three
reasons are to blame:

  1. There are no keys
  2. At least one key has the "expired" status*
  3. At least one key has the "internal-error" status*

*On this subject, we might want to change that rule in the future.
Persisted licences might contain multiple keys, and we might only care
about some of them. The more sensible thing to do might be to check that
at least one can be used (even if it can also get more complicated, e.g.
we might want to re-request expired ones anyway).

demo: integrate RxPlayer directly in the demo bundle

This commit tries to simplify the building phase of the demo, especially
now that we'll be more and more dependant on using external RxPlayer
tools in it.

Previously, the demo code was separated into two big files:
  - the RxPlayer "lib" file as `lib.js`
  - the demo file as `bundle.js`

Both of them were then included in the demo's `index.html` and
`bundle.js` relied on the RxPlayer being accessible through
`window.RxPlayer`.

This worked perfectly but there are multiple drawbacks here:

  - Going through `window.RxPlayer` corresponds to the legacy way of
    depending on the RxPlayer. We advise people to rely on usual ES6
    `import` statements everywhere else.

  - In this mode, we cannot rely on features such as tree-shaking.

  - In this mode, we cannot access to the RxPlayer's tools as they are
    not exposed through `window` but only when imported through
    `"rx-player/tools"`. This is becoming even more important now that
    the `VideoThumbnailLoader` and the `StringUtils` tools are coming,
    as both could become useful to the demo.

What I decided here is to update the `webpack-demo.config.js` file which
was previously only used to compile the demo down to a `bundle.js` to
now also be able to build the RxPlayer's code (by adding typescript
rules and by setting compile-time constants there).

I then relied on a webpack features called "alias" which allows to
easily gives alias to modules, so as the RxPlayer defined in
`src/index.ts` can be always imported through "rx-player" and, more
importantly, tools can be imported through "rx-player/tools".

The build time seems to not be impacted by this change which is a good
news. Another good news is that the whole demo size was slightly
reduced.

A downside is that the re-building happening after a file modification
seems to take a little more time, but it stays at an acceptable level (3
seconds on my PC for a modification on the RxPlayer's
`RepresentationStream`).

scripts: fix tools path generated by the generate_builds script

The `/tools` files generated by the generate_builds had a supplementary
`../` which completely broke imports.

This is because they had been copy-pasted from `experimental/tools`
where a new level exists.

source-buffer: remove inventory calculation logic from the QueuedSourceBuffer

-- Basic context about the modules involved

This modification concerns both the `Stream` module (the part of the
code deciding which segments should be loaded then pushed) and the
source-buffers (the part of the code handling browser-side media buffers
known as `SourceBuffers`).

The latter containing among other things both a `QueuedSourceBuffer`, an
abstraction over native and custom-defined SourceBuffers and a
`SegmentInventory` which will store information about which segments (as
in which quality, which track etc.) are actually present right now in
those.

-- What was the previous status

Just after pushing a segment, the `SegmentInventory` receives
information about it, so it can complete its internal representation
of what is contained in the linked SourceBuffer.

To do that, it relies notably on a `start` and `end` today refined two
times:

  1. First by the `transports` module, which will parse those
     information from the segments themselves and apply to it any
     possible offsets (such as the `timestampOffset`).

  2. Then by the `QueuedSourceBuffer`, which applies on it the
     append windows.

This behavior was bad for two reasons:

  1. On the `QueuedSourceBuffer` point of view, it makes no sense that
     it should apply both append windows on those time but not other
     SourceBuffer-related modifications such as the `timestampOffset`

     It was however necessary due to the fact that security paddings
     are added to those append windows to avoid removing too much data
     from segments on too-aggressive browsers.

     Setting those security paddings in the `transports` code make no
     sense in the whole RxPlayer architecture.

  2. In a future version of the RxPlayer where we might want to re-define
     one different type of `QueuedSourceBuffer` class for each type of
     buffers, that same logic have to be applied to all of them.

     This was actually the main reason behind that update, as
     low-latency contents may force us to update our source-buffers code
     for complex reasons.

-- What this commit does

This update moves the task of calculating the start and end of a given
segment from append windows for the `SegmentInventory`, from the
`QueuedSourceBuffer` to the `Stream`.

This also meant that security paddings added to append windows also had
to be moved there (which might still seems out of place, you're the judge
here).

remove unnecessary empty comment line

api: implement initialManifest API

Implement a new `initialManifest` property in the `loadVideo`'s
`transportOptions` which allows to provide an already loaded Manifest.

Applications sometimes pre-load the Manifest to obtain information such
as available tracks, or time offsets. By being able to provide the
initial version (before any refresh) of the Manifest allow to speed-up
the initial time it takes before loading the content.

I had to refactore the manifest fetcher code in
`src/core/fetchers/manifest` to be able to parse a Manifest without
needing to load it first. I didn't really change the old logic, I
created a `ManifestFetcher` class which can either load+parse a Manifest
though its `fetch` method or juste parse one through its `parse`
method.

api: throw more verbose error when no url is set on loadVideo

---
## [love-bytes/qt5-b64-encoder](https://github.com/love-bytes/qt5-b64-encoder)@[70377c3930...](https://github.com/love-bytes/qt5-b64-encoder/commit/70377c39308c5f3ffa30a6a8c28e5a67903dc1ff)
#### Friday 2020-11-06 17:08:39 by love-bytes

Create LICENSE

The Do What The Fuck You Want To Public License

---
## [Phil228-Discord-Bot-Development/WikingStorm-BOT](https://github.com/Phil228-Discord-Bot-Development/WikingStorm-BOT)@[2f9de985c8...](https://github.com/Phil228-Discord-Bot-Development/WikingStorm-BOT/commit/2f9de985c8b0a3ba6f8a8662038c644c1c61cf00)
#### Friday 2020-11-06 18:59:21 by Phil228

DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE

DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE

---
## [payday-restoration/restoration-mod](https://github.com/payday-restoration/restoration-mod)@[7895c8c8ce...](https://github.com/payday-restoration/restoration-mod/commit/7895c8c8ce58682e6683cc79556bf638019c1cba)
#### Friday 2020-11-06 19:41:47 by Neslon-Poggers

yeezy season approaching

- fixed murky helmet invisible shitting itself apparently it needs an annoying ass little bodies thing in its .object
- captain summers
neck
neck
neck

---
## [Looskie/backend](https://github.com/Looskie/backend)@[7b17368fed...](https://github.com/Looskie/backend/commit/7b17368fedb9cce64c90cb043e723465447da93d)
#### Friday 2020-11-06 19:53:53 by looskie

relative probably wont merge this but just in...

relative probably wont merge this but just in case he does at like 12am and decides hmm, maybe a switch case right here would be pretty nice, and then also think to himself, this could have a performance boost too. As he did say, "I am *new line* not *new line* using *new line* tha *new line* t *new line* holy *new line* fuck" my hopes are low, but still there.

---
## [SLASHEM-Extended/SLASHEM-Extended](https://github.com/SLASHEM-Extended/SLASHEM-Extended)@[05122bb0b2...](https://github.com/SLASHEM-Extended/SLASHEM-Extended/commit/05122bb0b27e55b1457a022e51e5b563bd711645)
#### Friday 2020-11-06 20:02:31 by AmyBSOD

Fix draining/cancel bug properly

Thanks amateurhour for finding it. God, how many other SLASH'EM bugs are lurking in the depths of coding hell? And why on earth do I have to be the girl that fixes them???

---
## [fidencio/cri-o](https://github.com/fidencio/cri-o)@[dd3b75c6bf...](https://github.com/fidencio/cri-o/commit/dd3b75c6bf196bc3553685aeede00bfa1517ed75)
#### Friday 2020-11-06 21:27:59 by Fabiano Fidêncio

runtime_vm: Don't nullify closeIOChan channel

This patch tries to fix the situation of `kubectl cp` hanging forever.

Debugging this issue, I've faced a quite interesting scenarion where
after `closeIOChan` is closed, the `CloseStdin` function "resumes" but
`closeIOChan` is **nil**.

Honestly, this bogus my mind quite a bit as I was under the impression
that all the receptients would be notified about the closed channel
before and a situation like this would never ever happen.  Well, Today I
Learned.

The simplest way I see to work this issue around is to avoid nullifying
closeIOChan.  By doing this, we can get rid of the following code[0] as
we don't want to get ourselves in the situation of trying to close the
already closed channel.

As life **is** a bed of roses we'll always find at least one thorn in it,
which is, in our case, having to explicitly close `closeIOChan` in case
of errors happening before the channel is healthly closed.

[0]:
```
defer func() {
        if closeIOChan != nil {
                close(closeIOChan)
        }
}()

```

Fixes: #4353

Thanks to @liubin, @haircommander, and @r4f4 for being available to
discuss the issue.

Signed-off-by: Fabiano Fidêncio <fidencio@redhat.com>

---

# [<](2020-11-05.md) 2020-11-06 [>](2020-11-07.md)

