# [<](2020-07-01.md) 2020-07-02 [>](2020-07-03.md)

2,589,002 events, 1,189,946 push events, 1,932,726 commit messages, 141,619,482 characters


## [Thaumatorium/thaumatorium.github.io](https://github.com/Thaumatorium/thaumatorium.github.io)@[da5e57936d...](https://github.com/Thaumatorium/thaumatorium.github.io/commit/da5e57936d6e5079d96da7404ea5f7019ccf330f)
#### Thursday 2020-07-02 03:09:08 by NostraDavid

update about.html to contain a rant on what I want to see changed on the internet

In short: Fuck the normies that have ruined the internet, fuck the LGBT virtue signalling coompanies (lmao) that have a grip on us and fuck the right winging shitheads that just ruin everything else.

PS: Fuck nazis and commies too. You retards have held us back too.

---
## [fuglore/PD2-Hyper-Heisting](https://github.com/fuglore/PD2-Hyper-Heisting)@[2259435e43...](https://github.com/fuglore/PD2-Hyper-Heisting/commit/2259435e434646b48a6e201df0d17599e447b848)
#### Thursday 2020-07-02 03:53:02 by Fuglore

lol increase melee damage and do cool coplogicidle shit  idk fuck you

---
## [muhdarifrawi/personal-resume](https://github.com/muhdarifrawi/personal-resume)@[74921c20f4...](https://github.com/muhdarifrawi/personal-resume/commit/74921c20f4b679454785ae340e211ef65725c8a4)
#### Thursday 2020-07-02 06:01:38 by MuhdArifRawi

Made changes to social media icons
- honestly i forgot to commit my last changes
- I think it was social media icons that I changed
- If i'm wrong i'm sorry

---
## [AlpacaGang/kernel_xiaomi_platina](https://github.com/AlpacaGang/kernel_xiaomi_platina)@[2959722c7d...](https://github.com/AlpacaGang/kernel_xiaomi_platina/commit/2959722c7da52600da28df362f596e60822bb602)
#### Thursday 2020-07-02 06:45:51 by George Spelvin

lib/sort: make swap functions more generic

Patch series "lib/sort & lib/list_sort: faster and smaller", v2.

Because CONFIG_RETPOLINE has made indirect calls much more expensive, I
thought I'd try to reduce the number made by the library sort functions.

The first three patches apply to lib/sort.c.

Patch #1 is a simple optimization.  The built-in swap has special cases
for aligned 4- and 8-byte objects.  But those are almost never used;
most calls to sort() work on larger structures, which fall back to the
byte-at-a-time loop.  This generalizes them to aligned *multiples* of 4
and 8 bytes.  (If nothing else, it saves an awful lot of energy by not
thrashing the store buffers as much.)

Patch #2 grabs a juicy piece of low-hanging fruit.  I agree that nice
simple solid heapsort is preferable to more complex algorithms (sorry,
Andrey), but it's possible to implement heapsort with far fewer
comparisons (50% asymptotically, 25-40% reduction for realistic sizes)
than the way it's been done up to now.  And with some care, the code
ends up smaller, as well.  This is the "big win" patch.

Patch #3 adds the same sort of indirect call bypass that has been added
to the net code of late.  The great majority of the callers use the
builtin swap functions, so replace the indirect call to sort_func with a
(highly preditable) series of if() statements.  Rather surprisingly,
this decreased code size, as the swap functions were inlined and their
prologue & epilogue code eliminated.

lib/list_sort.c is a bit trickier, as merge sort is already close to
optimal, and we don't want to introduce triumphs of theory over
practicality like the Ford-Johnson merge-insertion sort.

Patch #4, without changing the algorithm, chops 32% off the code size
and removes the part[MAX_LIST_LENGTH+1] pointer array (and the
corresponding upper limit on efficiently sortable input size).

Patch #5 improves the algorithm.  The previous code is already optimal
for power-of-two (or slightly smaller) size inputs, but when the input
size is just over a power of 2, there's a very unbalanced final merge.

There are, in the literature, several algorithms which solve this, but
they all depend on the "breadth-first" merge order which was replaced by
commit 835cc0c8477f with a more cache-friendly "depth-first" order.
Some hard thinking came up with a depth-first algorithm which defers
merges as little as possible while avoiding bad merges.  This saves
0.2*n compares, averaged over all sizes.

The code size increase is minimal (64 bytes on x86-64, reducing the net
savings to 26%), but the comments expanded significantly to document the
clever algorithm.

TESTING NOTES: I have some ugly user-space benchmarking code which I
used for testing before moving this code into the kernel.  Shout if you
want a copy.

I'm running this code right now, with CONFIG_TEST_SORT and
CONFIG_TEST_LIST_SORT, but I confess I haven't rebooted since the last
round of minor edits to quell checkpatch.  I figure there will be at
least one round of comments and final testing.

This patch (of 5):

Rather than having special-case swap functions for 4- and 8-byte
objects, special-case aligned multiples of 4 or 8 bytes.  This speeds up
most users of sort() by avoiding fallback to the byte copy loop.

Despite what ca96ab859ab4 ("lib/sort: Add 64 bit swap function") claims,
very few users of sort() sort pointers (or pointer-sized objects); most
sort structures containing at least two words.  (E.g.
drivers/acpi/fan.c:acpi_fan_get_fps() sorts an array of 40-byte struct
acpi_fan_fps.)

The functions also got renamed to reflect the fact that they support
multiple words.  In the great tradition of bikeshedding, the names were
by far the most contentious issue during review of this patch series.

x86-64 code size 872 -> 886 bytes (+14)

With feedback from Andy Shevchenko, Rasmus Villemoes and Geert
Uytterhoeven.

Change-Id: I338ed749723c7c2d9e9cd04288ba836da751977d
Link: http://lkml.kernel.org/r/f24f932df3a7fa1973c1084154f1cea596bcf341.1552704200.git.lkml@sdf.org
Signed-off-by: George Spelvin <lkml@sdf.org>
Acked-by: Andrey Abramov <st5pub@yandex.ru>
Acked-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Cc: Geert Uytterhoeven <geert@linux-m68k.org>
Cc: Daniel Wagner <daniel.wagner@siemens.com>
Cc: Don Mullis <don.mullis@gmail.com>
Cc: Dave Chinner <dchinner@redhat.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

---
## [AlpacaGang/kernel_xiaomi_platina](https://github.com/AlpacaGang/kernel_xiaomi_platina)@[bcde09e0b0...](https://github.com/AlpacaGang/kernel_xiaomi_platina/commit/bcde09e0b0bf99221511446911ae4e1e10a4e790)
#### Thursday 2020-07-02 06:45:51 by George Spelvin

lib/list_sort: optimize number of calls to comparison function

CONFIG_RETPOLINE has severely degraded indirect function call
performance, so it's worth putting some effort into reducing the number
of times cmp() is called.

This patch avoids badly unbalanced merges on unlucky input sizes.  It
slightly increases the code size, but saves an average of 0.2*n calls to
cmp().

x86-64 code size 739 -> 803 bytes (+64)

Unfortunately, there's not a lot of low-hanging fruit in a merge sort;
it already performs only n*log2(n) - K*n + O(1) compares.  The leading
coefficient is already at the theoretical limit (log2(n!) corresponds to
K=1.4427), so we're fighting over the linear term, and the best
mergesort can do is K=1.2645, achieved when n is a power of 2.

The differences between mergesort variants appear when n is *not* a
power of 2; K is a function of the fractional part of log2(n).  Top-down
mergesort does best of all, achieving a minimum K=1.2408, and an average
(over all sizes) K=1.248.  However, that requires knowing the number of
entries to be sorted ahead of time, and making a full pass over the
input to count it conflicts with a second performance goal, which is
cache blocking.

Obviously, we have to read the entire list into L1 cache at some point,
and performance is best if it fits.  But if it doesn't fit, each full
pass over the input causes a cache miss per element, which is
undesirable.

While textbooks explain bottom-up mergesort as a succession of merging
passes, practical implementations do merging in depth-first order: as
soon as two lists of the same size are available, they are merged.  This
allows as many merge passes as possible to fit into L1; only the final
few merges force cache misses.

This cache-friendly depth-first merge order depends on us merging the
beginning of the input as much as possible before we've even seen the
end of the input (and thus know its size).

The simple eager merge pattern causes bad performance when n is just
over a power of 2.  If n=1028, the final merge is between 1024- and
4-element lists, which is wasteful of comparisons.  (This is actually
worse on average than n=1025, because a 1204:1 merge will, on average,
end after 512 compares, while 1024:4 will walk 4/5 of the list.)

Because of this, bottom-up mergesort achieves K < 0.5 for such sizes,
and has an average (over all sizes) K of around 1.  (My experiments show
K=1.01, while theory predicts K=0.965.)

There are "worst-case optimal" variants of bottom-up mergesort which
avoid this bad performance, but the algorithms given in the literature,
such as queue-mergesort and boustrodephonic mergesort, depend on the
breadth-first multi-pass structure that we are trying to avoid.

This implementation is as eager as possible while ensuring that all
merge passes are at worst 1:2 unbalanced.  This achieves the same
average K=1.207 as queue-mergesort, which is 0.2*n better then
bottom-up, and only 0.04*n behind top-down mergesort.

Specifically, defers merging two lists of size 2^k until it is known
that there are 2^k additional inputs following.  This ensures that the
final uneven merges triggered by reaching the end of the input will be
at worst 2:1.  This will avoid cache misses as long as 3*2^k elements
fit into the cache.

(I confess to being more than a little bit proud of how clean this code
turned out.  It took a lot of thinking, but the resultant inner loop is
very simple and efficient.)

Refs:
  Bottom-up Mergesort: A Detailed Analysis
  Wolfgang Panny, Helmut Prodinger
  Algorithmica 14(4):340--354, October 1995
  https://doi.org/10.1007/BF01294131
  https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.6.5260

  The cost distribution of queue-mergesort, optimal mergesorts, and
  power-of-two rules
  Wei-Mei Chen, Hsien-Kuei Hwang, Gen-Huey Chen
  Journal of Algorithms 30(2); Pages 423--448, February 1999
  https://doi.org/10.1006/jagm.1998.0986
  https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.4.5380

  Queue-Mergesort
  Mordecai J. Golin, Robert Sedgewick
  Information Processing Letters, 48(5):253--259, 10 December 1993
  https://doi.org/10.1016/0020-0190(93)90088-q
  https://sci-hub.tw/10.1016/0020-0190(93)90088-Q

Feedback from Rasmus Villemoes <linux@rasmusvillemoes.dk>.

Change-Id: Ic7e916ce59b2f6116c20c6c34887ee17f269c154
Link: http://lkml.kernel.org/r/fd560853cc4dca0d0f02184ffa888b4c1be89abc.1552704200.git.lkml@sdf.org
Signed-off-by: George Spelvin <lkml@sdf.org>
Acked-by: Andrey Abramov <st5pub@yandex.ru>
Acked-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Cc: Daniel Wagner <daniel.wagner@siemens.com>
Cc: Dave Chinner <dchinner@redhat.com>
Cc: Don Mullis <don.mullis@gmail.com>
Cc: Geert Uytterhoeven <geert@linux-m68k.org>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

---
## [RubberDuckShobe/adVanceBepis](https://github.com/RubberDuckShobe/adVanceBepis)@[a61d2722d0...](https://github.com/RubberDuckShobe/adVanceBepis/commit/a61d2722d0339c004ca4a82f4df878f8cf819389)
#### Thursday 2020-07-02 10:23:44 by RubberDuckShobe

i honestly have no idea what hell i just unleashed but i hope i didn't just fuck the repo

---
## [carry0828-baiquan/data-science-projects](https://github.com/carry0828-baiquan/data-science-projects)@[8554057dc0...](https://github.com/carry0828-baiquan/data-science-projects/commit/8554057dc02d2776ed3070baa30fe32e9e1088a2)
#### Thursday 2020-07-02 11:17:31 by carry0828-baiquan

Add files via upload

Whether or not you like football, the Super Bowl is a spectacle. There's drama in the form of blowouts, comebacks, and controversy in the games themselves. There are the ridiculously expensive ads, some hilarious, others gut-wrenching, thought-provoking, and weird. The half-time shows with the biggest musicians in the world, sometimes riding giant mechanical tigers or leaping from the roof of the stadium. And in this project, you will find out how some of the elements of this show interact with each other. You will answer questions like:

What are the most extreme game outcomes?
How does the game affect television viewership?
How have viewership, TV ratings, and ad cost evolved over time?
Who are the most prolific musicians in terms of halftime show performances?
This project gives you an opportunity to apply the skills from Intermediate Python for Data Science.

The dataset used in this project was scraped and polished from Wikipedia. It is made up of three CSV files, one with game data, one with TV data, and one with halftime musician data for all 52 Super Bowls through 2018.

---
## [fbezdeka/meta-iot2000](https://github.com/fbezdeka/meta-iot2000)@[6e9e85065f...](https://github.com/fbezdeka/meta-iot2000/commit/6e9e85065fa3d923c770f20468d57e7fd89ff793)
#### Thursday 2020-07-02 13:22:01 by Jan Kiszka

bsp: Switch to 4.4-cip kernel

Using the long-life kernel for the Civil Infrastructure Platform project
instead of the Yocto kernel comes with a number of advantages:

- long-term source for stable maintenance (10+ years)
- improved quality due to second review by cip kernel maintainer
- removal of license-wise problematic firmware files

This first version is based on current 4.4.98-cip plus two required
commits that are currently pending for integration. In addition, we just
have 5 local hacks that account for an issue in the BIOS and
dependencies of the current libmraa and the arduino sketches on the
original Intel BSP. Those will be eventually resolved.

We also switch to a defconfig based kernel configuration at this chance
which provides better control over our kernel. This configuration is
still subject to further tuning.

Currently, we keep our usage of meta-intel, now basically only for the
sake of obtaining its Quark processor tunings. This may be reconsidered
later on.

Signed-off-by: Jan Kiszka <jan.kiszka@siemens.com>

---
## [mohsen-farahani/instagram-php-scraper](https://github.com/mohsen-farahani/instagram-php-scraper)@[3621cd8979...](https://github.com/mohsen-farahani/instagram-php-scraper/commit/3621cd8979479e678e87a6f4485fc5d376bdd08d)
#### Thursday 2020-07-02 14:43:23 by Talles Airan

Update Instagram.php

* the curlOpts is very useful if you want to use ipv6 instead of ipv4, and use custom ips, from your own server
* On some requests it changes the csrftoken from x-csrftoken to X-CSRFToken
* I noticed that sometimes the set-cookie field of lowercase becomes big, so I created a check to avoid it running out of cookie
several changes of structure to make work difficult, but we are here 24 hours working to fuck this damn social network

---
## [crawl/crawl](https://github.com/crawl/crawl)@[80609ef61d...](https://github.com/crawl/crawl/commit/80609ef61d395d5fbd9bf8373aab122702a2ca60)
#### Thursday 2020-07-02 15:55:07 by Nicholas Feinberg

Enact the 13th Amendment

The intended Pikel gameplay is pretty cool. You fight a tough guy
with some tough pals, but if you kill the boss, his pals become
your pals. Neat!

Unfortunately, this didn't quite work as intended. Pikel's former
slaves would wander around the level killing enemies without giving
you any XP, meaning that players would often kill the slaves to avoid
their unwanted 'help'. (Yikes!) Or they'd just kill the slaves to eat
their chunks and animate their corpses, which, very flavorful, but
also double yikes.

So, let's send slaver Pikel straight to hell. His pals are mostly
unchanged mechanically but have been renamed, rethemed, and resprited
to minor demons, 'lemures'. (They're back!) Instead of trading in
humans, Pikel is now cutting deals with the forces of Hell. Very
thematic, very lore-friendly, and no more worries about encouraging
annoying and unfun gameplay, since these lemures poof straight out
of this world as soon as Pikel eats it.

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[3e83a4b264...](https://github.com/mrakgr/The-Spiral-Language/commit/3e83a4b26459f8f7e6cc803d662f1a9f38115390)
#### Thursday 2020-07-02 15:55:49 by Marko Grdinić

"1:25pm. Let me rest for a bit longer.

1:30pm. Just 5-10m more and I will start.

https://github.com/microsoft/vscode/issues/

The stuff in issue 92789 is interesting. It seems that range provider can have issues with flickering since the editor needs to wait for the server to provide the changes for the viewport.

But I guess I'll start off with it regardless.

Now that I am replaning the server, I see that keeping track of the changes would get more complicated.

2:10pm. At first I wanted to slack, but now I am in thought again.

4:55pm. Holy shit, was I just thinking in bed this whole time? It seems so.

All this reminds of me of 2017. I see the language stuff as easy now, but the currency stuff is just as hard to me now as the language stuff was back then.

5pm. Concurrency just requires different patterns of thought, and they are not ones I am familiar with. It took me a really long time to become good at Spiral, both at making it and programming in it. Concurrency is one of the great challenges in programming - it won't be an exception in terms of how much effort it will take to master.

5:05pm. I am not sure I feel like doing anything more in the day.

Since I am not going to be doing programming, let me write down some of the ideas that I had.

I guess the main idea that I had in order to simplify things is that I should ditch the router socket.

One thing I've realized is - I am not really working on an asynchronous server. The reason I am using ZeroMQ in the first place is so I can connect the Node.js parts to the ones on the .NET side. If VS Code was running on the later, I would never even bother with it - it would be all Hopac and synchronous communication across the board.

While I was thinking, I also became completely perplexed. I have absolutely no idea how for example the router or the dealer sockets decide to drop messages. I am sort of thinking that the router is unreliable, but once I try to probe into that, I realize that I do not really understand why I think that.

It is true that I run into issues with them, but are router and dealer really more reliable than request and response?

As I probe deeper it feels, well it feels like I am going senile because I have no idea why I believe the later are synchronous and the former are not.

> When you use REQ to talk to REP, you get a strictly synchronous request-reply dialog. The client sends a request. The service reads the request and sends a reply. The client then reads the reply.

Is this really true? I mean, if I send a request to a router socket...well, I am guessing the send will be a success if it ends up in the other side's buffer.

But I think the guide mentioned that request sockets have a send buffer...

> ZeroMQ uses the concept of HWM (high-water mark) to define the capacity of its internal pipes. Each connection out of a socket or into a socket has its own pipe, and HWM for sending, and/or receiving, depending on the socket type. Some sockets (PUB, PUSH) only have send buffers. Some (SUB, PULL, REQ, REP) only have receive buffers. Some (DEALER, ROUTER, PAIR) have both send and receive buffers.

Ah, Req and Rep only have receive buffers. That means their sends must necessarily be synchronous. And for dealer sockets, they will be asynchronous as it will be putting the messages in the send buffer if it cannot send them right away. Of course, receives will be synchronous.

5:20pm. Right, so my hazy memory of dealer/router being async and the req/res being sync is not wrong.

And in this case, I should be using the later.

I am not doing a stateleess service here - now that the issue is doing the least amount of work needed by sending deltas, missed messages will cause the editor and the language server to desynchronize. Once that happens, the user will get mad and the only choice will be to restart the server.

I want to avoid that. And if something bad happens without the chance to recover rather the server crash loudly.

So...

```fs
        let msg = sock.ReceiveMultipartMessage(3)
        let address = msg.Pop()
        msg.Pop() |> ignore
```

Rather than this thing where I receive a multipart message...

```fs
let uri_editor = "tcp://localhost:13806"
let uri_lang_serv = "tcp://*:13805"
```

I am going to have it connect to a different port and send stuff from the later stages there.

Reliability aside, I am trying to figure out how to make use of a dealer socket to do my stuff on the editor side and am coming up empty. It should be possible, but I really am struggling a lot to simply things in my head. Everything feels awkward and complicated, and it is hard to make things flow naturally.

5:35pm. Yeah, I do not need all this complication. Forget about the server, and just think of it as gluing two processes together.

In that case, doing two binds like the above and making things synchronous as much as possible is a good approach to take. In my thoughts I often indulge myself thinking how I can extend my limits, but here I should be taking the exactly opposite approach. Somewhat ironically, the pattern that I will use here was not in the guide, which why I overlooked it until now.

I learned all this advanced stuff that I missed the value of the simpler patterns.

If I can limit the way I do interprocess communication, that will make other things much easier.

That is what I need to focus on.

5:40pm. Yeah, I do not think I can use a dealer socket on the editor side. Async sends are not good here - I do in fact need confirmation that the request has been received otherwise I might get wrong deltas back.

...Oh, I should note that pair sockets are also async since they have send buffers. In the past I've been tempted to skip the acknowledgement part - in some cases I just need the send to be synchronous, but even if they worked for more than inprocess communication, they are no good for what I want as their sends are async.

5:45pm. I admit, I've been affected - I read that router and dealer are more useful, but haven't exactly thought about why that is. If my Hopac experience is any indication, synchronous messaging is in fact more useful and fundamental.

It is easy to turn synchronous to asynchronous messaging just by putting a buffer between the send and a receive, but going the other way is much harder.

5:50pm. Let me stop here for the day. I really did not think things would go like this today. That I would not realize that only sending individual line changes is a poor idea shows how bad I am still at this. I am still overwhelmed by complexity.

It is going to take some hard though to overcome this. Tomorrow, I will start work on redesigning the servers. Literally none of the pices that I have in mind are hard, but I am struggling to fit them together."

---
## [ghc/ghc](https://github.com/ghc/ghc)@[c846618ae0...](https://github.com/ghc/ghc/commit/c846618ae0f8601515683a4c7677c20c3272a50f)
#### Thursday 2020-07-02 16:00:09 by Ömer Sinan Ağacan

Do CafInfo/SRT analysis in Cmm

This patch removes all CafInfo predictions and various hacks to preserve
predicted CafInfos from the compiler and assigns final CafInfos to
interface Ids after code generation. SRT analysis is extended to support
static data, and Cmm generator is modified to allow generating
static_link fields after SRT analysis.

This also fixes `-fcatch-bottoms`, which introduces error calls in case
expressions in CorePrep, which runs *after* CoreTidy (which is where we
decide on CafInfos) and turns previously non-CAFFY things into CAFFY.

Fixes #17648
Fixes #9718

Evaluation
==========

NoFib
-----

Boot with: `make boot mode=fast`
Run: `make mode=fast EXTRA_RUNTEST_OPTS="-cachegrind" NoFibRuns=1`

--------------------------------------------------------------------------------
        Program           Size    Allocs    Instrs     Reads    Writes
--------------------------------------------------------------------------------
             CS          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
            CSD          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
             FS          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
              S          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
             VS          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
            VSD          -0.0%      0.0%     -0.0%     -0.0%     -0.5%
            VSM          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           anna          -0.1%      0.0%     -0.0%     -0.0%     -0.0%
           ansi          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           atom          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         awards          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         banner          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
     bernouilli          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
   binary-trees          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
          boyer          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         boyer2          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           bspt          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
      cacheprof          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       calendar          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       cichelli          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
        circsim          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       clausify          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
  comp_lab_zift          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       compress          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
      compress2          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
    constraints          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
   cryptarithm1          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
   cryptarithm2          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
            cse          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
   digits-of-e1          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
   digits-of-e2          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         dom-lt          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
          eliza          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
          event          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
    exact-reals          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         exp3_8          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         expert          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
 fannkuch-redux          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
          fasta          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
            fem          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
            fft          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           fft2          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       fibheaps          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           fish          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
          fluid          -0.1%      0.0%     -0.0%     -0.0%     -0.0%
         fulsom          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         gamteb          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
            gcd          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
    gen_regexps          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         genfft          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
             gg          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           grep          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         hidden          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
            hpg          -0.1%      0.0%     -0.0%     -0.0%     -0.0%
            ida          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
          infer          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
        integer          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
      integrate          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
   k-nucleotide          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
          kahan          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
        knights          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         lambda          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
     last-piece          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           lcss          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           life          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           lift          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         linear          -0.1%      0.0%     -0.0%     -0.0%     -0.0%
      listcompr          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       listcopy          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       maillist          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         mandel          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
        mandel2          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           mate          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
        minimax          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
        mkhprog          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
     multiplier          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         n-body          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       nucleic2          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           para          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
      paraffins          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         parser          -0.1%      0.0%     -0.0%     -0.0%     -0.0%
        parstof          -0.1%      0.0%     -0.0%     -0.0%     -0.0%
            pic          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       pidigits          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
          power          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         pretty          -0.0%      0.0%     -0.3%     -0.4%     -0.4%
         primes          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
      primetest          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         prolog          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         puzzle          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         queens          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
        reptile          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
reverse-complem          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
        rewrite          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           rfib          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
            rsa          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
            scc          -0.0%      0.0%     -0.3%     -0.5%     -0.4%
          sched          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
            scs          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         simple          -0.1%      0.0%     -0.0%     -0.0%     -0.0%
          solid          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
        sorting          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
  spectral-norm          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         sphere          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
         symalg          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
            tak          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
      transform          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       treejoin          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
      typecheck          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
        veritas          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           wang          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
      wave4main          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
   wheel-sieve1          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
   wheel-sieve2          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           x2n1          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
--------------------------------------------------------------------------------
            Min          -0.1%      0.0%     -0.3%     -0.5%     -0.5%
            Max          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
 Geometric Mean          -0.0%     -0.0%     -0.0%     -0.0%     -0.0%

--------------------------------------------------------------------------------
        Program           Size    Allocs    Instrs     Reads    Writes
--------------------------------------------------------------------------------
        circsim          -0.1%      0.0%     -0.0%     -0.0%     -0.0%
    constraints          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       fibheaps          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
       gc_bench          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           hash          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
           lcss          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
          power          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
     spellcheck          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
--------------------------------------------------------------------------------
            Min          -0.1%      0.0%     -0.0%     -0.0%     -0.0%
            Max          -0.0%      0.0%     -0.0%     -0.0%     -0.0%
 Geometric Mean          -0.0%     +0.0%     -0.0%     -0.0%     -0.0%

Manual inspection of programs in testsuite/tests/programs
---------------------------------------------------------

I built these programs with a bunch of dump flags and `-O` and compared
STG, Cmm, and Asm dumps and file sizes.

(Below the numbers in parenthesis show number of modules in the program)

These programs have identical compiler (same .hi and .o sizes, STG, and
Cmm and Asm dumps):

- Queens (1), andre_monad (1), cholewo-eval (2), cvh_unboxing (3),
  andy_cherry (7), fun_insts (1), hs-boot (4), fast2haskell (2),
  jl_defaults (1), jq_readsPrec (1), jules_xref (1), jtod_circint (4),
  jules_xref2 (1), lennart_range (1), lex (1), life_space_leak (1),
  bargon-mangler-bug (7), record_upd (1), rittri (1), sanders_array (1),
  strict_anns (1), thurston-module-arith (2), okeefe_neural (1),
  joao-circular (6), 10queens (1)

Programs with different compiler outputs:

- jl_defaults (1): For some reason GHC HEAD marks a lot of top-level
  `[Int]` closures as CAFFY for no reason. With this patch we no longer
  make them CAFFY and generate less SRT entries. For some reason Main.o
  is slightly larger with this patch (1.3%) and the executable sizes are
  the same. (I'd expect both to be smaller)

- launchbury (1): Same as jl_defaults: top-level `[Int]` closures marked
  as CAFFY for no reason. Similarly `Main.o` is 1.4% larger but the
  executable sizes are the same.

- galois_raytrace (13): Differences are in the Parse module. There are a
  lot, but some of the changes are caused by the fact that for some
  reason (I think a bug) GHC HEAD marks the dictionary for `Functor
  Identity` as CAFFY. Parse.o is 0.4% larger, the executable size is the
  same.

- north_array: We now generate less SRT entries because some of array
  primops used in this program like `NewArrayOp` get eliminated during
  Stg-to-Cmm and turn some CAFFY things into non-CAFFY. Main.o gets 24%
  larger (9224 bytes from 9000 bytes), executable sizes are the same.

- seward-space-leak: Difference in this program is better shown by this
  smaller example:

      module Lib where

      data CDS
        = Case [CDS] [(Int, CDS)]
        | Call CDS CDS

      instance Eq CDS where
        Case sels1 rets1 == Case sels2 rets2 =
            sels1 == sels2 && rets1 == rets2
        Call a1 b1 == Call a2 b2 =
            a1 == a2 && b1 == b2
        _ == _ =
            False

   In this program GHC HEAD builds a new SRT for the recursive group of
   `(==)`, `(/=)` and the dictionary closure. Then `/=` points to `==`
   in its SRT field, and `==` uses the SRT object as its SRT. With this
   patch we use the closure for `/=` as the SRT and add `==` there. Then
   `/=` gets an empty SRT field and `==` points to `/=` in its SRT
   field.

   This change looks fine to me.

   Main.o gets 0.07% larger, executable sizes are identical.

head.hackage
------------

head.hackage's CI script builds 428 packages from Hackage using this
patch with no failures.

Compiler performance
--------------------

The compiler perf tests report that the compiler allocates slightly more
(worst case observed so far is 4%). However most programs in the test
suite are small, single file programs. To benchmark compiler performance
on something more realistic I build Cabal (the library, 236 modules)
with different optimisation levels. For the "max residency" row I run
GHC with `+RTS -s -A100k -i0 -h` for more accurate numbers. Other rows
are generated with just `-s`. (This is because `-i0` causes running GC
much more frequently and as a result "bytes copied" gets inflated by
more than 25x in some cases)

* -O0

|                 | GHC HEAD       | This MR        | Diff   |
| --------------- | -------------- | -------------- | ------ |
| Bytes allocated | 54,413,350,872 | 54,701,099,464 | +0.52% |
| Bytes copied    |  4,926,037,184 |  4,990,638,760 | +1.31% |
| Max residency   |    421,225,624 |    424,324,264 | +0.73% |

* -O1

|                 | GHC HEAD        | This MR         | Diff   |
| --------------- | --------------- | --------------- | ------ |
| Bytes allocated | 245,849,209,992 | 246,562,088,672 | +0.28% |
| Bytes copied    |  26,943,452,560 |  27,089,972,296 | +0.54% |
| Max residency   |     982,643,440 |     991,663,432 | +0.91% |

* -O2

|                 | GHC HEAD        | This MR         | Diff   |
| --------------- | --------------- | --------------- | ------ |
| Bytes allocated | 291,044,511,408 | 291,863,910,912 | +0.28% |
| Bytes copied    |  37,044,237,616 |  36,121,690,472 | -2.49% |
| Max residency   |   1,071,600,328 |   1,086,396,256 | +1.38% |

Extra compiler allocations
--------------------------

Runtime allocations of programs are as reported above (NoFib section).

The compiler now allocates more than before. Main source of allocation
in this patch compared to base commit is the new SRT algorithm
(GHC.Cmm.Info.Build). Below is some of the extra work we do with this
patch, numbers generated by profiled stage 2 compiler when building a
pathological case (the test 'ManyConstructors') with '-O2':

- We now sort the final STG for a module, which means traversing the
  entire program, generating free variable set for each top-level
  binding, doing SCC analysis, and re-ordering the program. In
  ManyConstructors this step allocates 97,889,952 bytes.

- We now do SRT analysis on static data, which in a program like
  ManyConstructors causes analysing 10,000 bindings that we would
  previously just skip. This step allocates 70,898,352 bytes.

- We now maintain an SRT map for the entire module as we compile Cmm
  groups:

      data ModuleSRTInfo = ModuleSRTInfo
        { ...
        , moduleSRTMap :: SRTMap
        }

   (SRTMap is just a strict Map from the 'containers' library)

   This map gets an entry for most bindings in a module (exceptions are
   THUNKs and CAFFY static functions). For ManyConstructors this map
   gets 50015 entries.

- Once we're done with code generation we generate a NameSet from SRTMap
  for the non-CAFFY names in the current module. This set gets the same
  number of entries as the SRTMap.

- Finally we update CafInfos in ModDetails for the non-CAFFY Ids, using
  the NameSet generated in the previous step. This usually does the
  least amount of allocation among the work listed here.

Only place with this patch where we do less work in the CAF analysis in
the tidying pass (CoreTidy). However that doesn't save us much, as the
pass still needs to traverse the whole program and update IdInfos for
other reasons. Only thing we don't here do is the `hasCafRefs` pass over
the RHS of bindings, which is a stateless pass that returns a boolean
value, so it doesn't allocate much.

(Metric changes blow are all increased allocations)

Metric changes
--------------

Metric Increase:
    ManyAlternatives
    ManyConstructors
    T13035
    T14683
    T1969
    T9961

---
## [LightningFastRom/android_packages_apps_Trebuchet](https://github.com/LightningFastRom/android_packages_apps_Trebuchet)@[411266277b...](https://github.com/LightningFastRom/android_packages_apps_Trebuchet/commit/411266277b818c1ada0ad42487325bdc5016bbb1)
#### Thursday 2020-07-02 17:26:53 by DJABhipHop

Restart with change only on exit

This change allow the user to change everything they have to inside the
homescreen activity and only restart on exit. Previously this was a pain
in the fucking ass because you had to go in and set each option one by one
with a restart inbetween. At least now is not that big of a pain.

- Restart on destroy (hitting the back button, actionbar arrow)
- Restart when a chance is made and the home button is pressed

** Thanks "Jack" for code to detect home button
https://stackoverflow.com/a/27956263

- Cleaned up restart code

@eyosen adapted to 10

Change-Id: I4962916ae0bd59d08247b59de585a97a2b9da3a1
Signed-off-by: DennySPB <dennyspb@gmail.com>

---
## [Aurorastation/Aurora.3](https://github.com/Aurorastation/Aurora.3)@[3160508c1a...](https://github.com/Aurorastation/Aurora.3/commit/3160508c1a9f367be0ab054cceaf2e36c0b66250)
#### Thursday 2020-07-02 17:40:20 by Wowzewow (Wezzy)

Makes tool colors work, despaghettifies code (#9231)

I finally figured out how to make tool inhands and inhand coloring work properly, so custom colors can apply to inhands! (yes, even the stuff from loadout.)

Code-wise, this guts the superfluous our_color variable.
This cuts it out from screwdrivers, wirecutters, cable, and everything else which uses this shit.
I'm pretty sure testing this has taken out a day out of my life.

Also I fixed up the cable examine to be less crappy. (so you can finally see cable descriptions.)

Don't mind the commits, I just built this on top the handcuff noose PR.

---
## [ASYelsub/Carpal-PI](https://github.com/ASYelsub/Carpal-PI)@[b7545a5abc...](https://github.com/ASYelsub/Carpal-PI/commit/b7545a5abc197180e90400eae826be88a60bf76c)
#### Thursday 2020-07-02 18:43:35 by Abigail

trying to have one sequence finish and go to the next... struggling bc of the different kinds or whatever. lots of logic and thoughts in my brain but the scripts are so badly organized its cursed

---

# [<](2020-07-01.md) 2020-07-02 [>](2020-07-03.md)

