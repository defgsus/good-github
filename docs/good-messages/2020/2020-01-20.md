# [<](2020-01-19.md) 2020-01-20 [>](2020-01-21.md)

1,921,089 events, 976,650 push events, 1,512,863 commit messages, 105,150,163 characters


## [newstools/2020-naija-news-agency@8aeb73cef3...](https://github.com/newstools/2020-naija-news-agency/commit/8aeb73cef36e5ce3f14076730275b9c54d0480a8)
##### 2020-01-20 07:17:20 by NewsTools

Created Text For URL [naijanewsagency.com/i-killed-my-three-months-pregnant-girlfriend-to-avoid-the-shame-of-having-a-child-outside-wedlock-suspect/]

---
## [JoaoTMDias/talks@7a94980bc6...](https://github.com/JoaoTMDias/talks/commit/7a94980bc6423c5e96310a6112118b13ce25939a)
##### 2020-01-20 10:44:23 by João Dias

Hooking up with React Hooks
=================================================

* Speaker   : **João Dias** and **Mickael Costa**
* Available : **All days**
* Length    : **90 minutes**
* Language  : **English**

Description
-----------

In the last months, React Hooks changed how we write and think about reusable and straightforward code. This training workshop will cover the fundamentals of React Hooks, how to convert your codebase and also how to take advantage and create your own custom ones. All of this in simple, straightforward and understandable examples.

By the end of this workshop we will be able to do the following:

-   Use built-in React Hooks to create more reusable and straightforward code
-   Re-factor Class components into functional components using hooks
-   Create custom hooks and reuse them throughout a project
-   Know where React Hooks fall short and we should choose class components instead.

Speaker Bio
-----------

### João

João is a Frontend Engineer at Feedzai with over 4 years of developer experience and over 9 as an interface designer. Mostly, he just loves to design and build stuff for the Web. His designer/developer cross-breed skills are his main strength and help him to bring the best of both worlds to every project he gets involved into.

### Mickael

Mickael is Senior Frontend Engineer at Feedzai. He had the chance to work and experiment with a variety of languages and frameworks namely React. He was a teacher so he enjoys teaching and learning with a good conversation about technology. He has other tastes like sports (futebol and Krav Maga) and travel.

Links
-----

### João

-   Company: https://feedzai.com
-   GitHub: https://github.com/joaotmdias
-   Personal: https://joaodias.me
-   LinkedIn: https://www.linkedin.com/in/joaotmdias/

### Mickael

-   Company: https://feedzai.com
-   GitHub: https://github.com/Mickael24
-   LinkedIn: https://www.linkedin.com/in/dinomickael/

Extra Information
-----------------

### João

-   [Speaker at ENEMM 2019 with the keynote "State of the Web in 2019"](https://www.enemm.pt/speakers/joao-dias)
-   _Workshop: The User's Perception of Speed_ (2016)
-   _Keynote: State of Javascript 2018: Angular or Vue or React?_ (2018)
-   _Keynote: Let's talk about Accessibility_ (2019)

### Mickael

-   ["First React Application" workshop teacher at FEUP Code Week 2019"](https://www.linkedin.com/posts/dinomickael_feup-codeweek-feedzai-activity-6592090630468448256-k9Jk/)
-   Assistant Professor at the Polytechnic Institute of Cávado and Ave

---
## [mrakgr/The-Spiral-Language@6839d2f1c0...](https://github.com/mrakgr/The-Spiral-Language/commit/6839d2f1c0d256e7e1fd085d5c209997663e823a)
##### 2020-01-20 11:36:33 by Marko Grdinić

"10:40am. Making things continuous is really one of the greatest inventions of modern optimization. Even in discrete optimization, you can make things semi-continuous by postulating move probabilities and adjusting those.

It is not going to go away.

Though SL in terms of training on a static dataset as is done now will not be important, supervised learning itself will be used for administrative tasks such as knowledge transfer and distillation. So it will be quite important.

10:45am. Yeah, it is one thing to imagine how to be courageous and kill oneself in order to gain power, but if the issue was merely to play with the continuum of being, I would have long become the king of universe.

The issue in gaining power post-Singularity might be quite similar to the issues facing me today.

Right now I am here in this chair, and there a bunch of programs on the computer (outside my mind). How do I eat them?

10:50am. What I am writing here should be common sense, but programming is as much a matter of feeling as it is a matter of reason. It is difficult to get the feeling unless you really put yourself in that position of living in the future.

Post-Singularity - functional programming is not going to go away. All the algorithms that work well today, will work well in the future as well. Quicksort is not going to go away for example.

And I think the principles of deep learning as were discovered in the past decade will not necessarily be swept away just like that.

So it is not like I learned nothing. I can make inferences based on the current knowledge.

Of course, there will definitely be new things in the future, but knowledge I can use as a part of the foundation is definitely here today, and a lot of that knowledge was not there before the 10s (or was rediscovered there).

10:55am. Self optimization will play a role, but I blew up the importance of it.

The most important thing is to learn from perfected imagination.

11:15am. This is the right subjective perspective. And those are important. Programs are one thing, but the you do need to put yourself into the thick of things mentally to gain understanding.

11:35am. Right now I am just chilling, but I'll get breakfast pronto and then do the chores. After that I will do more programming.

I just really needed Spiral v0.09 to do the ML library, but now that it has come to this, I am not sure what I should aim for.

But if programs are understanding then I really should not be satisfied with semi-dynamic languages like F#. I need Spiral to do my thing properly.

Maybe I have failed at really understanding ML, but it might be possible to understand everything around it.

I really have learned a lot from Spiral haven't I?

Imagine if I had the brain cores - would I really want to program in F#? Or would I rather do it in Spiral?

Spiral really allows quite a lot of freedom that even DTLs do not, let alone F#.

Without a doubt, Spiral is the closest to the true language of computation.

11:40am. If programs are the meal of tomorrow, I certainly would not want to eat lesser ones.

11:45am. I really have been quite confused. I said I would like to create a poker agent and make money, but if this were the post-Singularity era, you'd really want to create an agent so you can do knowledge transfer.

The Inspired did their hacks in the stories, but...the way optimization works is that you impose continuity and then ride that. And this would hold even if you use evoalgos in combination with local updates like backprop or something to that effect.

The total expansion in capacity corresponds to architectural changes.

11:50am. Yeah, I am different from 6 years ago. I really did learn a bunch, and as a result I cannot really look at things the same way I have before.

Rather that the caricature of self improvement that Simulacrum described, I really should be able to see much more what it actually is. I can definitely see details that I haven't been able to before.

11:55am. I should make Spiral...if I believe it is the language I will be using 10 years from now.

In the post-Singularity era, I would expect that the programmers would have complete mastery of both the hardware and the software they are running themselves on. That in fact does mean making your own OS and language, in addition to having the ability to synthesize cores from residual material.

Fundamentally, other people giving you the hardware, the software and the language is no way to go about this.

Even short term - remember the Deep CFR episode?

If I was on the brain core, and had only access to some Python and C++ code, would I have tried translating that to my own language, or would I just tried hacking Python as the average code monkey would?

12pm. In 2018 I was really tired by the time the new year came around, but it does feel like growing your own thing is the way gains are accumulated in this area.

I do not really gain anything by having access to a large number of libraries done by other people.

That is because I am not trying to solve a problem. I am merely trying to make the power of these algorithms my own.

And isn't that really learning?

I am pissed at ML. I am pissed at classical math. I am pissed at not going everywhere in 5 years. I am pissed that despite all this effort I still do not really understand ML.

But what did I really expect? What should understanding even be in this situation? Because it is not like I did not know that I wouldn't be able to trace these float using algorithms with just the power of my mind.

It should been obvious to me - if understanding is really interaction, then the real way to understand these programs is to put them directly inside one's head and do knowledge transfer directly. This sort of fusion is the pinnacle of interaction.

12:10pm. If I am going to make v0.2, I need a real reason. The problem I am really trying to solve is one of interaction.

I might not be able to put stuff in my head directly, but just like before I should anticipate the future and act on it.

It is true that other languages exist that might get the job done, but if this sort of thing is really that important, then I should not allow more than one chef in the kitchen.

12:15pm. Languages are important. They really are.

12:20pm. What should I do here?

Adults look down on kids, but as strange as things might seem, the best thing for kids is to act as they are. Kids should act like kids rather than adults.

If I one day want to be a real post-Singularity tier programmer, I should just accept the cuts and the curses, and larp as one. It is not given that one day I am not going to grow up.

For the sake of one day attaining the power of the machines, I should strive for it. For I desire that power from the bottom of my heart.

12:25pm. Let me take that break here.

I want to take the time to internalize the full implications of the basic idea that the way to really understand complicated things is to put them inside the head. In fact, for simple algorithms that I can understand that is literally true. So really, why did it take me so long to understand this?

Well, one thing.

There are still some principles missing. That standard ML algorithms as they work now are not really generative. The way optimization work is quite primitive right now, so I could not connect the dots.

Without a doubt, the way living agents work is definitely more lifelike than current ML. So in the torrent of conflicting view and perspective I am not sure what I should believe.

But I should definitely believe this.

Math talent might be necessary to derive new algorithms, but I can be certain after my 2019 experiences - the reason why I can't understand these algorithms is definitely not because I am too dumb. Real understanding that I seek should be impossible for everybody right now.

12:30pm. If I really want that power, what I need to is to reduce the interactive distance.

Partial evaluation is the true foundation of computation.

But now I need to elaborate upon this.

12:35pm. It might turn out to be that to make ML really work, I do not need wholly new algorithms anymore that I need to replace Spiral's partial evaluation with something else. Instead what I really need is the equivalent of additional structure as would be afforded by top-down typing and unification.

12:35pm. Once again, let me take that break here."

---
## [ProtoChuz/everest_lavender@51f41809e7...](https://github.com/ProtoChuz/everest_lavender/commit/51f41809e782af031790fb75662bd13df921df83)
##### 2020-01-20 11:51:19 by George Spelvin

lib/sort: make swap functions more generic

Patch series "lib/sort & lib/list_sort: faster and smaller", v2.

Because CONFIG_RETPOLINE has made indirect calls much more expensive, I
thought I'd try to reduce the number made by the library sort functions.

The first three patches apply to lib/sort.c.

Patch #1 is a simple optimization.  The built-in swap has special cases
for aligned 4- and 8-byte objects.  But those are almost never used;
most calls to sort() work on larger structures, which fall back to the
byte-at-a-time loop.  This generalizes them to aligned *multiples* of 4
and 8 bytes.  (If nothing else, it saves an awful lot of energy by not
thrashing the store buffers as much.)

Patch #2 grabs a juicy piece of low-hanging fruit.  I agree that nice
simple solid heapsort is preferable to more complex algorithms (sorry,
Andrey), but it's possible to implement heapsort with far fewer
comparisons (50% asymptotically, 25-40% reduction for realistic sizes)
than the way it's been done up to now.  And with some care, the code
ends up smaller, as well.  This is the "big win" patch.

Patch #3 adds the same sort of indirect call bypass that has been added
to the net code of late.  The great majority of the callers use the
builtin swap functions, so replace the indirect call to sort_func with a
(highly preditable) series of if() statements.  Rather surprisingly,
this decreased code size, as the swap functions were inlined and their
prologue & epilogue code eliminated.

lib/list_sort.c is a bit trickier, as merge sort is already close to
optimal, and we don't want to introduce triumphs of theory over
practicality like the Ford-Johnson merge-insertion sort.

Patch #4, without changing the algorithm, chops 32% off the code size
and removes the part[MAX_LIST_LENGTH+1] pointer array (and the
corresponding upper limit on efficiently sortable input size).

Patch #5 improves the algorithm.  The previous code is already optimal
for power-of-two (or slightly smaller) size inputs, but when the input
size is just over a power of 2, there's a very unbalanced final merge.

There are, in the literature, several algorithms which solve this, but
they all depend on the "breadth-first" merge order which was replaced by
commit 835cc0c8477f with a more cache-friendly "depth-first" order.
Some hard thinking came up with a depth-first algorithm which defers
merges as little as possible while avoiding bad merges.  This saves
0.2*n compares, averaged over all sizes.

The code size increase is minimal (64 bytes on x86-64, reducing the net
savings to 26%), but the comments expanded significantly to document the
clever algorithm.

TESTING NOTES: I have some ugly user-space benchmarking code which I
used for testing before moving this code into the kernel.  Shout if you
want a copy.

I'm running this code right now, with CONFIG_TEST_SORT and
CONFIG_TEST_LIST_SORT, but I confess I haven't rebooted since the last
round of minor edits to quell checkpatch.  I figure there will be at
least one round of comments and final testing.

This patch (of 5):

Rather than having special-case swap functions for 4- and 8-byte
objects, special-case aligned multiples of 4 or 8 bytes.  This speeds up
most users of sort() by avoiding fallback to the byte copy loop.

Despite what ca96ab859ab4 ("lib/sort: Add 64 bit swap function") claims,
very few users of sort() sort pointers (or pointer-sized objects); most
sort structures containing at least two words.  (E.g.
drivers/acpi/fan.c:acpi_fan_get_fps() sorts an array of 40-byte struct
acpi_fan_fps.)

The functions also got renamed to reflect the fact that they support
multiple words.  In the great tradition of bikeshedding, the names were
by far the most contentious issue during review of this patch series.

x86-64 code size 872 -> 886 bytes (+14)

With feedback from Andy Shevchenko, Rasmus Villemoes and Geert
Uytterhoeven.

Link: http://lkml.kernel.org/r/f24f932df3a7fa1973c1084154f1cea596bcf341.1552704200.git.lkml@sdf.org
Signed-off-by: George Spelvin <lkml@sdf.org>
Acked-by: Andrey Abramov <st5pub@yandex.ru>
Acked-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Cc: Geert Uytterhoeven <geert@linux-m68k.org>
Cc: Daniel Wagner <daniel.wagner@siemens.com>
Cc: Don Mullis <don.mullis@gmail.com>
Cc: Dave Chinner <dchinner@redhat.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Dede Dindin Qudsy <xtrymind@gmail.com>

---
## [spellcastersa/Powerful-Love-spells-caster-Marriage-spells-for-you-@5afff7e6ac...](https://github.com/spellcastersa/Powerful-Love-spells-caster-Marriage-spells-for-you-/commit/5afff7e6acfb6e6fdcc8763285842f48076016ab)
##### 2020-01-20 13:56:08 by Powerful online spell caster  All time best spells online‎

Powerful online spell caster, All time best spells online‎

Make a LOVE SPELL Prayer Request to MAMA NANA a very powerful Spiritual & The Best Spell Caster For Both Love And Business Success, with intercessory power. Love Spells Really Help for the people who are struggling with Love Issues.

EXCELLENT SPELL CASTING SERVICE

Mama Nana gives 100% in every spell cast and as a professional, I make sure that all goes right. I give 100% to make you satisfied with my service. If you have a complex situation, I urge you to contact me first. The situation regarding love then uses my popular "Ancient love Spell Combo" to have rapid and long-lasting results!

Binding Love Spells
Marriage Spells
Bring back ex-lover Spells
Business & Success Spells 
Stop a cheating partner
Candle Love Spells
Win Court Spells & Jail Spells
Faithfulness Spells 
Job Spells.
Revenge Spells (For The Good Intentions/Revenge For Success)
Sangoma love spells

FOR ANY INQUIRES
Emergency: Mama Nana +27672073600

---
## [tpan496/terrier@290f07f746...](https://github.com/tpan496/terrier/commit/290f07f7466c897d4d0235fec13f0e78acb20336)
##### 2020-01-20 17:10:28 by Wan Shen Lim

Parser/Plan Nodes/Catalog ManagedPointer and JSON refactor (#547)

Wan's magical rewrite of the parser to use the ManagedPointer.

This releasing Wan from his personal hell. This PR has been a serious detriment to his health and well being (and his love life!).

---
## [punkduckable/SPH@ac4677b5f9...](https://github.com/punkduckable/SPH/commit/ac4677b5f923214e3fede4f32ea72f864485e287)
##### 2020-01-20 20:22:23 by Robert Stephany

Implemented Particle BC approach + got load/save working!

Body.h, Body.cc: I wrote a new method, Apply_BCs, which simply applies BCs to each patticle in a body. This is done using a parallel for loop to optimize performance.

Body_IO.cc: Removed an intentional bug that I introduced yesterday (to test the whole exception thing) but forgot to remove... oops.

Update.cc: While getting the code to work, I ran into a bunch of problems with nan accelerations. I was able to quickly debug the problem by having the particle print its info if it gets nan.

Save_Simulation.cc: There was a bug in here. I wrote a line to print the "plus_x_BC" (an approach that I am NOT using any more), but forgot to remove it.. that line caused a bunch of problems. Also, I added some extra spaces to the "Has_BC" part of "Save_Particle" to improve readability.

Load_Simulation.cc: Oh boy, there were some bugs in here. The part that read in "Time_Steps_Between_Updates" only worked if a body was not a box... This line should be read in for ALL bodies, not just non-box ones. I have no idea why that if statement was there. I fixed it. There was also a strange typo in the sscanf lines (318 and 326)... I double typed something. For some reason, the compiler didn't comaplin about this one, idek.

Particle.cc: I updated the particle printing method to improve debugging.

Partice.h: Updated friend function prototypes.

Boundary_Conditions.cc: Made the BC functions work with the "Paritcles have BCs" approach. This involved renaming some functions and changing a few lines. Surprpsingly painless.

Simulation_Setup.cc: Renamed Free_Box_BC as FREE. Renamed Startup_Simulation as Setup_Simulation. Added BC setting to Setup_Box method.

Simulation.cc: Updated function names. Updated the way that BCs are applied (108-109) and fixed a REALLY ANNOYING bug. Before, time_update was an unsigned. this was a TYPO, it's suposed to be a double. This bug caused a ton of problems. Finding it took forever :-1:. Anyway, after fixing that (and encountering another bug with time_update when loading in files... Time_Steps_Between_Updat was not being set for box bodies, see my discussion on Load_Simulation.cc for more), I realized that this line should have some printouts for debugging. I added some (141-144), and defined a new variable, "SIMULATION_DEBUG" to toggle printing.

Simulation.h: Added SIMULATION_DEBUG definition (and commeted it out), updated some names, and played around with some settings.

With these changes, the code ran, saved, loaded, and ran again! Save/Load is finally working again, and BCs are fully implemented!

In the future, I want to implement the setup file.

---

# [<](2020-01-19.md) 2020-01-20 [>](2020-01-21.md)

