# [<](2020-01-02.md) 2020-01-03 [>](2020-01-04.md)

1,699,764 events, 879,764 push events, 1,357,764 commit messages, 97,183,835 characters


## [codekane/Notebooker](https://github.com/codekane/Notebooker)@[a2cc3181b2...](https://github.com/codekane/Notebooker/commit/a2cc3181b2da5489b244004b4acda5fb42d8a365)
#### Friday 2020-01-03 00:10:35 by Ryan Horricks

Incorporate some of the Jekyll works. Ongoing. Holy fuck, I forgot how to Ruby. The shame.

---
## [GNOME/glib-networking](https://github.com/GNOME/glib-networking)@[1c86e4721f...](https://github.com/GNOME/glib-networking/commit/1c86e4721fcdd97494cbe3876bdd12f2465a256b)
#### Friday 2020-01-03 02:06:37 by Michael Catanzaro

Remove TLS rehandshaking support

Rehandshaking was removed from the TLS protocol in TLS 1.3. It's
possible that we still need to support it for TLS 1.2 connections, but
I'm pretty sure we don't. There are three ways a rehandshake could be
triggered: (1) by application API request, when calling
g_tls_connection_handshake() for a connection that has already
handshaked; (2) for a client connection, when the server peer requests a
rehandshake; (3) for a server connection, when the client requests a
rehandshake. Let's consider each case.

For (1), I previously deprecated this functionality in GLib 2.60.
Calling handshake multiple times is now undefined behavior, except it's
guaranteed to not break the connection in any way, for backwards
compatibility. See also glib!1305 for recent documentation
clarifications. I'm relatively confident that no real-world applications
are relying on this behavior; if they are, they're probably broken now
anyway, because we default to TLS 1.3 nowadays and have no documented
way to change that. (There's an undocumented environment variable.) If
your application is intentionally doing (1) and this causes problems for
you, please let us know (but I'll be surprised :)

In case (2), the client can simply ignore the rehandshake request. This
could in theory also break some applications... but again, I'm not
expecting much in the way of bug reports. I don't think this should
affect web browsers, at least. Maybe if a website decides it wants to
authenticate an existing connection without starting a new page load,
then it could be a problem? My suspicion is zero users will complain.

Finally, case (3). In this case, we have no choice but to terminate the
connection. However, this also should basically never happen. Almost all
users of GTlsConnection are using GTlsClientConnection, for starters.
The main user of GTlsServerConnection is probably cockpit. Since we
support TLS 1.3, and virtually all clients nowadays do too, almost all
negotiated connections should wind up using TLS 1.3. We need to
continue supporting TLS 1.2 indefinitely for *client* connections, until
web servers migrate to TLS 1.3 over the course of the next decade.
But clients have mostly already migrated. So for a server, rehandshaking
is pretty much out of the question already: a GTlsServerConnection
relying on this behavior is already broken.

Conclusion: I think we can get away with this. Now, we could keep the
rehandshaking code around forever if it doesn't cause problems, but I'm
trying to finish up a major refactor -- during which I removed
rehandshaking support to simplify things -- and bringing it back for
that would entail some additional complexity that I'd rather not have.
Also, now that support for TLS 1.2 session resumption has been removed,
rehandshakes are the only remaining legacy TLS feature that we support,
and it's kind of nice to clean house with an entirely modern
implementation as long as doing so doesn't break real-world
applications. Lack of bug reports will be interpreted as lack of
breakage.

Lastly, note that we still need to support TLS 1.3 post-handshake
authentication, #39. That's still a TODO item regardless of this change.

---
## [KeinR/Quiz_Kards](https://github.com/KeinR/Quiz_Kards)@[e668a03cee...](https://github.com/KeinR/Quiz_Kards/commit/e668a03ceedfaf694ea50c3338052961e8aa7f92)
#### Friday 2020-01-03 02:55:59 by Kein

Fuck me

I wasted 2 hours trying to work with Space Engineers scripts. Not only was it a waste of time as it turned out I needed to know some complex vector math, but since I opened a game (in working on them) I broke my discipline and now my head hurts, hurting my concentration.
Fuck man, what an idiot. Oh well, guess I'ma just have to be a little more intense next few days...

---
## [Nicklas373/kernel_xiaomi_lavender](https://github.com/Nicklas373/kernel_xiaomi_lavender)@[8ce9202a5c...](https://github.com/Nicklas373/kernel_xiaomi_lavender/commit/8ce9202a5ccf47ad460f86757a96cf0ba44d033f)
#### Friday 2020-01-03 02:58:47 by George Spelvin

lib/sort: make swap functions more generic

Patch series "lib/sort & lib/list_sort: faster and smaller", v2.

Because CONFIG_RETPOLINE has made indirect calls much more expensive, I
thought I'd try to reduce the number made by the library sort functions.

The first three patches apply to lib/sort.c.

Patch #1 is a simple optimization.  The built-in swap has special cases
for aligned 4- and 8-byte objects.  But those are almost never used;
most calls to sort() work on larger structures, which fall back to the
byte-at-a-time loop.  This generalizes them to aligned *multiples* of 4
and 8 bytes.  (If nothing else, it saves an awful lot of energy by not
thrashing the store buffers as much.)

Patch #2 grabs a juicy piece of low-hanging fruit.  I agree that nice
simple solid heapsort is preferable to more complex algorithms (sorry,
Andrey), but it's possible to implement heapsort with far fewer
comparisons (50% asymptotically, 25-40% reduction for realistic sizes)
than the way it's been done up to now.  And with some care, the code
ends up smaller, as well.  This is the "big win" patch.

Patch #3 adds the same sort of indirect call bypass that has been added
to the net code of late.  The great majority of the callers use the
builtin swap functions, so replace the indirect call to sort_func with a
(highly preditable) series of if() statements.  Rather surprisingly,
this decreased code size, as the swap functions were inlined and their
prologue & epilogue code eliminated.

lib/list_sort.c is a bit trickier, as merge sort is already close to
optimal, and we don't want to introduce triumphs of theory over
practicality like the Ford-Johnson merge-insertion sort.

Patch #4, without changing the algorithm, chops 32% off the code size
and removes the part[MAX_LIST_LENGTH+1] pointer array (and the
corresponding upper limit on efficiently sortable input size).

Patch #5 improves the algorithm.  The previous code is already optimal
for power-of-two (or slightly smaller) size inputs, but when the input
size is just over a power of 2, there's a very unbalanced final merge.

There are, in the literature, several algorithms which solve this, but
they all depend on the "breadth-first" merge order which was replaced by
commit 835cc0c8477f with a more cache-friendly "depth-first" order.
Some hard thinking came up with a depth-first algorithm which defers
merges as little as possible while avoiding bad merges.  This saves
0.2*n compares, averaged over all sizes.

The code size increase is minimal (64 bytes on x86-64, reducing the net
savings to 26%), but the comments expanded significantly to document the
clever algorithm.

TESTING NOTES: I have some ugly user-space benchmarking code which I
used for testing before moving this code into the kernel.  Shout if you
want a copy.

I'm running this code right now, with CONFIG_TEST_SORT and
CONFIG_TEST_LIST_SORT, but I confess I haven't rebooted since the last
round of minor edits to quell checkpatch.  I figure there will be at
least one round of comments and final testing.

This patch (of 5):

Rather than having special-case swap functions for 4- and 8-byte
objects, special-case aligned multiples of 4 or 8 bytes.  This speeds up
most users of sort() by avoiding fallback to the byte copy loop.

Despite what ca96ab859ab4 ("lib/sort: Add 64 bit swap function") claims,
very few users of sort() sort pointers (or pointer-sized objects); most
sort structures containing at least two words.  (E.g.
drivers/acpi/fan.c:acpi_fan_get_fps() sorts an array of 40-byte struct
acpi_fan_fps.)

The functions also got renamed to reflect the fact that they support
multiple words.  In the great tradition of bikeshedding, the names were
by far the most contentious issue during review of this patch series.

x86-64 code size 872 -> 886 bytes (+14)

With feedback from Andy Shevchenko, Rasmus Villemoes and Geert
Uytterhoeven.

Link: http://lkml.kernel.org/r/f24f932df3a7fa1973c1084154f1cea596bcf341.1552704200.git.lkml@sdf.org
Signed-off-by: George Spelvin <lkml@sdf.org>
Acked-by: Andrey Abramov <st5pub@yandex.ru>
Acked-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Cc: Geert Uytterhoeven <geert@linux-m68k.org>
Cc: Daniel Wagner <daniel.wagner@siemens.com>
Cc: Don Mullis <don.mullis@gmail.com>
Cc: Dave Chinner <dchinner@redhat.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Dede Dindin Qudsy <xtrymind@gmail.com>

---
## [ShayanJavadi/tonal](https://github.com/ShayanJavadi/tonal)@[aff7db5dee...](https://github.com/ShayanJavadi/tonal/commit/aff7db5deeccf9e10b72ea6f05ce7c56a7b7a04d)
#### Friday 2020-01-03 05:13:05 by Shayan Javadi

Added showcase section in readme

Hi!

First thank you so much for creating Tonal. It's been an absolute lifesaver for my app.

I'm making this PR to create a showcase section under the project's README. 

I'd be absolutely honored to have my app Solfej showcased on there.

Solfej would quite frankly not be possible without Tonal. There's some very complex music theory stuff going on behind the scenes throughout the ~80 lessons/exercises, and Tonal plays a key part in all of them.

A bit about the app:

Solfej is a music theory and ear training app (iOS, Android, Web).

As a self taught musician and guitarist I've always struggled with music theory. This has been due to the lack of true user friendly resources (the amount of nights I've spent down youtube/wikipedia rabbit holes...)

In the last couple of months I've set out to fix this gap for myself and everyone by creating Solfej.

The iOS version of the app is in beta with ~1000 users, and the android and web versions are being released soon.

Website for Solfej: https://www.solfej.io/
Source code for Solfej: https://github.com/ShayanJavadi/solfej

---
## [scott-fryxell/realness](https://github.com/scott-fryxell/realness)@[1c66157678...](https://github.com/scott-fryxell/realness/commit/1c66157678cb6f8b1077e6118d6f73896830c003)
#### Friday 2020-01-03 05:30:44 by Scott Fryxell

Make user writen text selecable.

dates and shit still remain unselectble. 

I love being able to select text but I also love a clean ui that isn't 
loosing it's mind with affordances.

---
## [peff/git](https://github.com/peff/git)@[efb3d89be5...](https://github.com/peff/git/commit/efb3d89be52937b0b71f72c330ff8a9d864b821c)
#### Friday 2020-01-03 06:07:28 by Jeff King

ahead-behind: do not die when we see no INTERESTING pending object

We currently die if we are fed an ahead/behind with zero
objects (`foo..foo` in the most basic case, but in practice
something like `foo@{upstream}..foo`, when `foo` has just
been merged).  The problem is that we let
`handle_revision_arg` parse it, and then pick the pieces out
of the pending object list. So "^foo" looks no different to
us there than "foo".

This patch hacks around it by picking up the UNINTERESTING
object in that case. However, this isn't great because:

  1. Now we won't notice some types of bogus input.

  2. We end up reporting the name of the UNINTERESTING object.

We probably should pick apart the ".." ourselves, or even
just change it to ":" or whitespace.

---
## [peff/git](https://github.com/peff/git)@[3c27727320...](https://github.com/peff/git/commit/3c27727320e02db1bf3c873e933ee804d2583b7a)
#### Friday 2020-01-03 06:07:52 by Jeff King

commit: give a hint when a commit message has been abandoned

If we launch an editor for the user to create a commit
message, they may put significant work into doing so.
Typically we try to check common mistakes that could cause
the commit to fail early, so that we die before the user
goes to the trouble.

We may still experience some errors afterwards, though; in
this case, the user is given no hint that their commit
message has been saved. Let's tell them where it is.

Signed-off-by: Jeff King <peff@peff.net>

---
## [qmk/qmk_firmware](https://github.com/qmk/qmk_firmware)@[983026ad8b...](https://github.com/qmk/qmk_firmware/commit/983026ad8bb1226e6929f6a59ecafea1e43f31aa)
#### Friday 2020-01-03 07:22:27 by Rossman360

[Keymap] adding tf68 keymap, my first pull request. expecting there's lots of bad practice, sorry (#7763)

* adding tf68 keymap

* had tf keymap in wrong folder

* added tragicforce readme

* cleaned up code

* more cleanup

* indent love and layer name change

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[805bfe7fa9...](https://github.com/mrakgr/The-Spiral-Language/commit/805bfe7fa9793eba1c7a01e5a315d1bab04e9615)
#### Friday 2020-01-03 08:48:44 by Marko Grdinić

"9:25am. I am up. Let me chill a bit and then I will start. I'll leave Pandora vol 12 and those replies for later. If I go to Reddit right now, no doubt I will spend 2 hours making another useless rant and wasting my morning.

9:40am. Let me start. I need to get going. Last night I've been mostly simulating these math arguments in my head rather than thinking about the parser. But at the very least, I know that nothing good will come from these. There is no way to win this, but at the very least, I am decently sure that I cannot expect anything in terms of insight from a group that cannot even do numbers properly.

Programming is what I need to stick to. Dependently typed languages should be saved for the agents. For actual AIs, programming errors will take an entirely different meaning - they will literally kill them or cause them to go insane. Even with backups, those risks are not something you can just sweep away.

So they will have their own role to play.

And my role is what is always was - to fish for the opportunity.

Let me just sit down and write that parser code like I had begun yesterday.

Yesterday once I started, I began to get into it. That is the main thing I need to aim for today - just to get the fire going.

">>11271358
Only repeatedly testing "random" things can lead to new knowledge. Science is obsessed with people and theories who could predict things correctly, but that is just glorified survivorship bias. Only experiments that cannot be reasonably predicted can provide new insights, only repeatedly forming new theories and discarding those that do not fit can lead to legitimate new knowledge."

The /sci/ anon has a point to an extent. I need to increase my rate of experimentation. I need a better language than the old Spiral where I can move quickly.

Of course, I will still be below the rate of what I could achieve in Python, but on the other hand I am also aiming to be a high tech criminal. I definitely do not want to compete with the ML community in their field. I just want to fulfill my potential as a programmer. Let me go to the very limits of what humans are capable of.

Insight really is important. Just trying out random things will get you lost pretty quickly. The essence of search is focused randomness. The optimization needs that."

---
## [Project-Xtended/vendor_xtended](https://github.com/Project-Xtended/vendor_xtended)@[92e2f0f6ff...](https://github.com/Project-Xtended/vendor_xtended/commit/92e2f0f6ff041ce52bdcb7e0e57ef3aff7cc8ff2)
#### Friday 2020-01-03 12:10:38 by Kshitij Gupta

vendor: notch-city: Add 3 mode display cutout handler [2/3]

[@AgentFabulous - POSP]
- Introduces the HideCutout and StatusBarStock overlay used in the
  3 mode display cutout handler. The HideCutout overlay is necessary
  since we can't register a content observer in the display manager code.
  We only have access to resources during boot. Thus, leave this as an
  overlay and let the config and overlay change methods handle this.
  Though we can probably do statusbar stock height toggling in the
  SystemUI code without overlays, I kinda got lazy by the end, just
  live with it god damn it xD

Signed-off-by: Kshitij Gupta <kshitijgm@gmail.com>
Change-Id: I62f63f39bcb410cfbc68e0028b9cef3d748d7eb6

---
## [davo964/MathsVisualisationTool](https://github.com/davo964/MathsVisualisationTool)@[5f3f9db1f3...](https://github.com/davo964/MathsVisualisationTool/commit/5f3f9db1f36cf78d1ddd05388c7f44f6bd95f81c)
#### Friday 2020-01-03 12:58:08 by Andy

Merge pull request #24 from davo964/GUI

For the love of god do not give me any shit today Github!!!! - Merge

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[fdcc4607de...](https://github.com/mrakgr/The-Spiral-Language/commit/fdcc4607def5e00d8138ec077121b721cd5eebb2)
#### Friday 2020-01-03 13:10:52 by Marko Grdinić

"9:50am. Ah, I did not notice the random being in quotes. So that is exactly what he meant then.

```
let arr_cons next = sepBy1 next arr_fun |>> function [x] -> x | x -> pair_from_end RawTConstraint x
```

Ok, so I am going to make the constraints exactly this.

Let me also do dependent constraints.

10am.

```
let arr_depcon next = next .>>. (opt (arr_depcon >>. next)) |>> function (a,Some b) -> RawTDepConstraint(a,b) | (a,None) -> a
```

Let me do the forall next.

```
let arr_depcon next = pipe2 next (opt (arr_depcon >>. next)) (function a (Some b) -> RawTDepConstraint(a,b) | a None -> a)
```

Hmmm, actually this might be the first time ever that I've used this `function` pattern in F#. Interesting that it works.

...I think it should work in Spiral.

But if I go with the current union type syntax, it will stop working.

Well, I can make it work on the outer level, no problem.

```
let arr_depcon next = pipe2 next (opt (arr_depcon >>. next)) (function a (Some b) -> RawTDepConstraint(a,b) | a None -> a)
```

Ah, actually this does not work in F#. Nevermind.

10:15am.

```
let forall next = pipe2 (forall >>. many1 next .>> dot) next (fun l x -> RawTForall(List.toArray l,x))
```

What I need next are records and keywords. Then I will tie all of this together.

10:30am.

```
    let forall next (d : ParserEnv) =
        if d.typeforall_allowed then pipe2 (forall >>. many1 next .>> dot) next (fun l x -> RawTForall(List.toArray l,x)) d
        else d.FailWith ForallNotAllowed
    let record next = curlies (many ((var' .>> colon) >>. next)) |>> (Map.ofList >> RawTRecord)
    let keyword next =
        (keyword_unary |>> fun x -> RawTKeyword(fst x,[||]))
        <|> (many (keyword .>>. next) |>> fun l -> let a,b = List.unzip l in RawTKeyword(keyword_concat a, List.toArray b))
```

I need to bring in keyword_concat. As expected, it is really annoying to have to handle positional information explicitly, but I am going to have to deal with it.

```
    let arr_funs next = sepBy1 next arr_fun |>> function [x] -> x | x -> pair_from_end RawTFun x
    let arr_cons next = sepBy1 next arr_cons |>> function [x] -> x | x -> pair_from_end RawTConstraint x
```

Also since these two have the same rightwards precedence, and I am not parsing them using the precedence parser, I am going to have to turn them into one.

10:45am.

```
    let arr_funs_cons next =
        pipe2 next (many (((arr_fun >>% Funs) <|> (arr_cons >>% Cons)) .>>. next))
            (fun a l ->
                let rec loop a = function
                    | [] -> a
                    | (Funs, b) :: l -> RawTFun(a,loop b l)
                    | (Cons, b) :: l -> RawTConstraint(a,loop b l)
                loop a l)
```

10:55am. Ok, I took a little break. Let me get back on track.

`keyword_concat`. That is what I need.

11:15am.

```
    let keyword next =
        (keyword_unary |>> fun x -> RawTKeyword(fst x,[||]))
        <|> (many (keyword .>>. next) |>> (concat_keyword'' (fun _ t -> t) >> fun (a, b) -> RawTKeyword(a, List.toArray b)))
```

Ok, enough. Let me stop here for a while. I am already wasting time on social media as it is.

```
type FunsOrCons = Funs | Cons

let type_ (d : ParserEnv) =
    let unit_ = bracket_round_open >>. bracket_round_close >>% RawTUnit
    let pairs next = sepBy1 next product |>> function [x] -> x | x -> pair_from_end RawTPair x
    let arr_funs_cons next =
        pipe2 next (many (((arr_fun >>% Funs) <|> (arr_cons >>% Cons)) .>>. next))
            (fun a l ->
                let rec loop a = function
                    | [] -> a
                    | (Funs, b) :: l -> RawTFun(a,loop b l)
                    | (Cons, b) :: l -> RawTConstraint(a,loop b l)
                loop a l)
    let arr_depcon next = pipe2 next (opt (arr_depcon >>. next)) (fun a -> function Some b -> RawTDepConstraint(a,b) | None -> a)
    let forall next (d : ParserEnv) =
        if d.typeforall_allowed then pipe2 (forall >>. many1 next .>> dot) next (fun l x -> RawTForall(List.toArray l,x)) d
        else d.FailWith ForallNotAllowed
    let record next = curlies (many ((var' .>> colon) >>. next)) |>> (Map.ofList >> RawTRecord)
    let keyword next =
        (keyword_unary |>> fun x -> RawTKeyword(fst x,[||]))
        <|> (many (keyword .>>. next) |>> (concat_keyword'' (fun _ t -> t) >> fun (a, b) -> RawTKeyword(a, List.toArray b)))

    ()
```

Here is the whole thing as it is.

11:55am. Did, I forget to commit. At any rate, let me deal with those replies, preferably swiftly, then I'll do the chores and slack a little.

Despite it being my mission, I have little motivation to actually do the parser itself, which is a problem. I am going to have to coax and cajole myself until I get through it.

It is easy to decide to do something big, the hard part is following through with it.

1:15pm. "My frustration is that mainstream mathematics is really not giving me what I want. In neural nets for example, there have been efforts to go from 32-bit floats, to 16 and even binarize them. A year or two ago when I last looked into this, this has not been successful.

When you learn programming you very quickly learn about 32-bit, 16-bit, 8-bit and so on integers. They have a range, they have a capacity. The same goes for floats. You can only once a fixed amount of information in a data structure.

Neural nets themselves have a certain capacity, yet today what that capacity is and how to characterize it is a complete mystery. In my eyes it would be a huge accomplishment if somebody could unravel that, along with what exactly their optimization is doing.

With that idea, I step in, learn formal theorem proving and what do I find now that I actually know what proofs are? These novels kinds of 'proofs by divergence' apparently.

I mean how could anybody trust mathematicians from my vantage point? How could people who cannot give a proper treatment of basic numbers be expected to come up with the next great breakthroughs in AI? Why did I even respect them for one moment? I read many papers in ML where I had to skip the proof parts because they were too complex for me at the time, and now that I actually have some skill in theorem proving, I come to these conclusions.

I am beyond pissed off - certainly not all of the fields of mathematics suffer from this affliction (Wildberger gives a list in one of the videos), but certainly all the fields of ML that I am actually interested in are.

What is even the point of studying the theoretical work that went into them?

These questions are mostly rhetorical. I do not think I'll be able to resolve this inner conflict, so I do really want to go back to the things I can actually reason about and trust in my own way. I want to clean up the remains of my earlier work and wrap up the low-style before I do anything else.

Let me just say one more thing - so far I think your arguments have been quite level headed (unlike my own.) You didn't say anything wrong, but as a matter of attitude, I do not think these kinds of arguments will do anything to alleviate any of my concerns. Set theory, reals, current strands of thought are a Gordian knot problem that I have no idea where to begin cutting.

The measured, level headed attitude you are displaying in this debate is not going to be a catalyst for doing the work that needs to be done. And unfortunately, you are definitely channeling the zeitgeist of the community at large.

Am I wrong to feel that this work should be done by pro mathematicians rather than semi-anonymous randos such as myself?"

That one guy gave up and essentially just called me a loony, and I probably am being one right now. I certainly feel like that. This other guy still wants to keep going. I am not sure if /u/be42rin deserves this treatment, but he made an attempt and so I will tell him what is on my mind.

I wanted to be swift, but I am mad. Mad at math.

1:20pm. It is not really a stable state. I look around me and I see only the things I cannot accept.

But deep down I want a break that never comes.

I want a break, but what I need is effort.

I need to spark the flame and keep going with Spiral. I need to get into it.

The way to relax while one is awake is not to lie still. Boredom is hardly restful.

The way to relax is to play a fun game.

I need to start having fun programming. I need to remind myself of the spark that I had.

1:25pm. So I've had to endure many failures.

Spiral v0.1 was not enough, and theorem proving is not enough.

1:30pm. It does not mean that my efforts were a waste.

I just haven't been patient enough.

1:35pm. I mean, isn't that the root of all my ills?

For Spiral v0.09, it has never been enough to just make a language, I had to do something great with it.

It was never enough for me to make some great code. I have a need to control everything.

It is a blessing and a curse.

It is a blessing as staying true to that need is what is making me grow.

It is a curse as it is making me unhappy with the present state of affairs.

1:40pm. The way I am going with Spiral v0.2 is a mistake.

The way I did the previous versions was with my entire mind and body on the line. I hesitated not even a little.

Compared to the past me, right now I am weak.

Still this math thing will blow over. At the very least in the future when I resume reading ML papers, I will not have pangs of insecurity from skipping the proofs. I will just look at whether they use reals or infinite sets and if they do, chuck them where they belong - in the trash pile.

This will strengthen me.

I will find confidence from my 2019 efforts.

If there is something I do not regret, that would be doing that first proof from the CFR paper using randomized testing. Now that was a truly wonderful experience. I guess my current disappointment is partly because I haven't been able to follow through with that for the other proofs. That is definitely the catalyst for my current loss of stability.

Deep down, I am in grief that this world is not giving the technique the proper respect it deserves.

1:50pm. Still...I've been having the idea that machine learning is an evolutionary step forward from randomized testing.

So if I really want to pay my respects to randomized testing, it might make sense to do more ML.

...Hmmm...looking back at 2018, back when I was doing ML my testing protocols were trully atrocious. They really were horrid.

But as I said, I did botch the allocator by not using weak arrays.

And Spiral was still in development for much of that time.

1:55pm. Right now, one of the big things troubling me is that I am not exactly sure what should I do once I have Spiral v0.2.

I mean, I did the ML library back in the previous version. So what do I want to do differently this time.

Deep CFR? Remember that proof that I just mentioned I did using randomized testing?

It gave me an understanding of the perfect recall property. Though the stuff in the paper works, NNs would introduce state aliasing which would break it.

So I am not really enthused at trying random techniques like I was before.

Not in the same manner.

2pm. I understand what is going on.

21st century is going to be part two of the battle between finitists and infinitists. The old finitists were soundly defeated and cast to the fringes of history. They weren't prepared and they were too lightly armed to win.

I should not be a finitist.

I already have a perfectly good label to describe myself - a programmer.

2:05pm. Let me do the chores here.

Before I resume the parser, I am going to just stop and think for a while. What should be the first thing I am going to do in the new language?

Since I do not want agents nor ML libraries anymore, what will the language be for.

Could I take that proof that I did as a guiding light?

I cannot lose hope, it is always like I said it was - given any point in time, there is always a step to the next level.

Could I take all my experiences of the past 5 years and somehow mix them together?

A fast language - for randomized testing?

Would it be possible to envision a goal of going beyond simply making ML libraries and agents in them and doing those things at a meta-level?

2:10pm. Let stop here so I can do the chores.

I should really take the time to think about this.

If I can establish my motivation, then the language will go smoothly. Right now I am just fiddling around with the parser."

---
## [odoo-dev/odoo](https://github.com/odoo-dev/odoo)@[4d3fc431dc...](https://github.com/odoo-dev/odoo/commit/4d3fc431dcf986cc0f44a3717279c596f627e996)
#### Friday 2020-01-03 13:54:37 by Thibault Delavallée

[REM] partner_autocomplete_address_extended: remove broken module

Commits a6e1eb9f0ad285fac7d0ca0b9f89f046d78ec9c7 and 8a1815b31eacc148d6e98795899ee24a9ca8cab1 added among a lot of other things
a bridge module between ``partner_autocomplete`` and ``base_address_extended``.
It is used only to redefine the ``_split_street_with_params`` method from
``base_address_extended``. This method is used to find street name, number and
number2 from an address, given a format coming from the country.

However the override completely fucks up the original method purpose and uses
an hardcoded regex coming out of the blue. Parameters like country format is
not taken into account which is annoying when trying to parse country dependent
data.

Tests from ``base_address_extended`` crash completely when used with the
``partner_autocomplete_address_extended`` implementation.

Considering the original complete specifications from commits
"""
For Name field or M2O, gives a list of companies
Data comes from Odoo IAP Service
"""

Or specs found in the original task ID 1867818 pad
"""
If Extended Address module is installed, the street number should be correctly
splitted Or the complete address is put in street2 if impossible to parse
"""

we think that this implementation is broken by design. Indeed there is no
mention of street2 anywhere in the code, and this implementation ensure street
will never be correctly split. We therefore remove it completely.

Task ID 2158302
PR odoo/odoo#42678

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[db1ec4cff8...](https://github.com/mrakgr/The-Spiral-Language/commit/db1ec4cff87b5027d1a014fa0eb36c8c8480215c)
#### Friday 2020-01-03 14:17:01 by Marko Grdinić

"2:50pm. I think I will just step away from the screen for a while like I said I would yesterday. It is thinking time. Last month I spent quite a value thinking about the design for the language.

But now, I really do need to think about what would eventually use it for.

Clearly I am starting to develop feelings for mathematics.

I just do not know how to express them in a positive manner.

After the experiences of the last year, I am not really going to be able to just abandon mathematics. But I am not going to be able to just go through the ML papers like I wanted to either.

Really, as you go from infinitism to programming, the proofs do get harder, but it is not like you get nothing in return for exiling yourself from paradise.

[Randomized testing.](https://fscheck.github.io/FsCheck/)

When I did that first CFR proof, I could really feel the power of this.

At all really rests on these lightweight methods. I really do think that regular theorem proving should be kept for special things. I wish it were otherwise, but DTLs really are quite hard deal with.

Randomized testing is rarely talked about, but it really might be the killer application that finitists needed, but did not quite have in the early 20th century, along with computers.

3pm. Also, I just realized that I never even pushed the reply to the guy. I must be even madder than I thought to miss this. Still, I think I will just leave it at that since the flow is going against me anyway.

I am not really the kind of person to fish for negative votes.

Even if I made the post it is not like it would have added anything new to the conversation. That guy is just acting like a damage controller for the consensus. Calling constructive mathematics a flavor (therefore normalizing the deviance), and saying rejecting classical logic is unreasonable, I can only spit on this.

3:10pm. I was really fucking tooled like nothing else by classical mathematicians. I really need to think of a suitable reply to that, but whatever that reply is it cannot take the shape of arguing on the Internet.

There should be something better I can do to pay respects to my new principles.

3:15pm. Rejecting faulty assumptions is not unreasonable at all. It will really pare down the search space."

---
## [aviflax/fc4-framework](https://github.com/aviflax/fc4-framework)@[17c2a90434...](https://github.com/aviflax/fc4-framework/commit/17c2a90434bd344624c782e4371cb176599f967d)
#### Friday 2020-01-03 15:27:33 by Avi Flax

Make shell script shebangs consistent

Use `/usr/bin/env` consistently, everywhere.

As per a discussion with @mattsoutherden on commit 9ec9f05f3d6454b565:

He saw that I changed the shebang of a few scripts from
`#!/usr/bin/env bash` to ``#!/bin/bash` and asked:

> Why this change?
>
> I see you're also doing this in `.circleci/bin/require-java `, but not
> elsewhere. Are you specifically targeting the original OS Bash, or
> trying to avoid a different version?

I replied:

> Thanks for asking about this — I kinda had a feeling in my gut that
> this change was ill-considered and half-assed.
>
> As to why, well, I was frustrated by #245 wherein I accidentally broke
> support for Bash 3, which is the default shell on MacOS 10.13 and
> 10.14 (10.15 switched to zsh as the default shell, but it still ships
> with Bash, still 3.2 due to [licensing concerns][verge-catalina-shells]).
>
> I’m still running MacOS 10.14, but I installed Bash 4.x via Homebrew
> and made that my default shell years ago.
>
> So, on my system, `/usr/bin/env bash` resolves to the 4.x version of
> Bash that I’ve installed via Homebrew, while `/usr/bin/bash` resolves
> to the “system” Bash, which is still 3.x.
>
> My thought process was something like “If the fc4 script used the
> system bash then I would have caught this problem sooner, on my local
> system.”
>
> That’s why I started haphazardly switching a few of the shebangs in
> the shell scripts I was looking at to use the “system” Bash rather
> than using `/usr/bin/env` to use the user’s preferred Bash.
>
> Now that you’ve forced me to think this through, this is clearly a bad
> idea. In general, if I’m going to distribute a shell script, I really
> have no control over what version of Bash a user has installed and set
> up. Any shell script I distribute should probably _always_ use
> `/usr/bin/env` to find the user’s preferred _whatever_ — Bash, Python,
> etc.
>
> OTOH, there are two classes of shell scripts included in this project:
> those that are distributed to end-users and therefore must be highly
> portable — there’s only one of these, the `fc4` script — and those
> that run in our CI environment, which we (more or less) control and
> which is drastically more deterministic than the other class.
>
> Wow, this is quite a missive at this point… I’ll just cut it off here.
> Sorry. I think I’ll just change all the scripts to be consistent
> (within the two classes). Let me know if you agree/disagree. Thanks!

[verge-catalina-shells]: https://www.theverge.com/2019/6/4/18651872/apple-macos-catalina-zsh-bash-shell-replacement-features

Matt:

> Even with the `/bin/bash` entries, people can still force update their
> system bash, or it might be a new version in a new OS release. So it's
> not just `env` that may link to a newer version that you might expect.
>
> Given that, I don't think there's any reason not to use `env`, as that
> will still do what you expect in the controlled CI environments, and
> as you say, we should use the user's choice in the distribution
> scripts anyway.

Me:

> Agreed. I’ll fix this soon. Thanks!

Thanks again Matt!

---
## [alanndz/kernel_xiaomi_lavender](https://github.com/alanndz/kernel_xiaomi_lavender)@[fa6a3d4bc4...](https://github.com/alanndz/kernel_xiaomi_lavender/commit/fa6a3d4bc482d3e157c216f4482815dfa8e4a15c)
#### Friday 2020-01-03 15:45:29 by Linus Torvalds

mm: remove unused variable in memory hotplug

When I removed the per-zone bitlock hashed waitqueues in commit
9dcb8b685fc3 ("mm: remove per-zone hashtable of bitlock waitqueues"), I
removed all the magic hotplug memory initialization of said waitqueues
too.

But when I actually _tested_ the resulting build, I stupidly assumed
that "allmodconfig" would enable memory hotplug.  And it doesn't,
because it enables KASAN instead, which then disables hotplug memory
support.

As a result, my build test of the per-zone waitqueues was totally
broken, and I didn't notice that the compiler warns about the now unused
iterator variable 'i'.

I guess I should be happy that that seems to be the worst breakage from
my clearly horribly failed test coverage.

Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: celtare21 <celtare21@gmail.com>

---
## [NHDaly/JuliaBoxTutorials](https://github.com/NHDaly/JuliaBoxTutorials)@[d6cc1a3ce7...](https://github.com/NHDaly/JuliaBoxTutorials/commit/d6cc1a3ce70653deace3f5b6326f979e510f1f01)
#### Friday 2020-01-03 15:47:02 by Nathan Daly

Create README.md with Installation instructions

For brand new would-be julia users who want to get started with Julia, I would love to send them to this github repo to get started, but there's no information on this page explaining _what to do once you're here!_

I know that these tutorials were originally written with JuliaBox in mind, so i've tried to maintain that spirit in these instructions. But hopefully we can also include instructions here about how to get started with julia in _any capacity_, because JuliaBox may not be the preferred option for everyone, and these are great tutorials that it would be a shame to not share! :)

---
## [milafrerichs/browser-repl-js](https://github.com/milafrerichs/browser-repl-js)@[8b66e5281c...](https://github.com/milafrerichs/browser-repl-js/commit/8b66e5281ca9c0fb35bdfbb862ccd3c6094d7c1e)
#### Friday 2020-01-03 16:31:20 by milafrerichs

feat: update console to be internal version

instead of using another eval and replacing console use the way
SvelteRepl is using it by posting the console back to the parent window
and saving it to the store
now we can just use svelte-json-tree directly instead of trying to
fiddle with it inside an iframe

rework the eintire message sending and receiving adding more failsaves
this is mostly directly copied from
https://github.com/sveltejs/svelte-repl with a few small adjustments
the repl has grown very nicely and it was the original inspiration and I
copied a lot of code from there anyway, would love if it would be moved
out of the svelte compiling and made available to a wider audience it's
great work!

---
## [Sathyaish/Practice](https://github.com/Sathyaish/Practice)@[81ad545877...](https://github.com/Sathyaish/Practice/commit/81ad5458774e7830821e16936813e4e0f2aad2c8)
#### Friday 2020-01-03 16:51:25 by Sathyaish Chakravarthy

I wanted to find out if an expired cookie is sent to the server or not.

So, for e.g. there was a cookie named AUTH and it has now expired. Will the cookie remain in the Storage section in the Developer Tools window? Will it be sent by the client to the server with the expiration date set to the past date or will it just not be included in the HTTP payload? If I were writing the server side code, should I check for the absence of the cookie like this:

Request.Cookies["AUTH"] == null

or

Request.Cookies["AUTH"].Expires <= DateTime.Now

Also, if a cookie that has been deleted is sent to the server or not. If you're thinking, "Wait! A deleted cookie? Sent to the server? How can something that's been deleted be sent to the server? Won't it have to be re-created in order to be used if it was already deleted?"

No, no! You see, we know that when either the client or the server needs to delete a cookie

Already used cookies a thousand times. There are some things you remember and some things you'll forget. And I need to use them once again, so I want to test out a few things before I write the actual code. I am presently writing the Login functionality for my website https://sathyaish.net.

---
## [cockroachdb/cockroach](https://github.com/cockroachdb/cockroach)@[30fc4a836c...](https://github.com/cockroachdb/cockroach/commit/30fc4a836c8b6cf0648f89975373ea5b9d03f0dd)
#### Friday 2020-01-03 17:00:31 by craig[bot]

Merge #43712

43712: pkg/security: fix misleading comment r=knz a=aybabtme

Forgive me if I'm wrong, but the current comment appears to be wrong. To be honest, I don't know a ton about TLS and my change might be mislead, but I figured I'd at least raise this via a PR or something.

It seems that when this was changed 5y ago (https://github.com/cockroachdb/cockroach/pull/4957) by @mberhault, the comment wasn't updated.

> One notable difference is that we now have a single certificate for
nodes with double role as server and client authentication.

Sorry for this perhaps pedantic PR.


Co-authored-by: Antoine Grondin <antoinegrondin@gmail.com>

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[ef6d6c2ca7...](https://github.com/mrakgr/The-Spiral-Language/commit/ef6d6c2ca74a51a8409f0b20a8851d22d78c66be)
#### Friday 2020-01-03 17:13:32 by Marko Grdinić

"5:10pm. While us idiots are having this argument on Reddit, maybe the truth is that the world has already moved on.

Maybe it is time that I come to an acceptance that the CFR algorithm is a proof in itself and that I cannot really reduce the strategy averaging aspect to anything more than it already is.

I mean, shouldn't at some point the emergent properties of algorithms be irreducible?

That /sci/ anon is right.

"Only repeatedly testing "random" things can lead to new knowledge. Science is obsessed with people and theories who could predict things correctly, but that is just glorified survivorship bias. Only experiments that cannot be reasonably predicted can provide new insights, only repeatedly forming new theories and discarding those that do not fit can lead to legitimate new knowledge."

Let me paste his post again.

Maybe rather than AI being alchemy or chemistry, its true nature is closer to cooking?

The issue are the damn floats!

Moving from operations on integers to floats makes things 100 times more difficult.

Classical mathematicians smartly skirted the issue with 'reals', but...

Sure, actual formal constructive proofs in Agda/Coq are the pinnacle of rigor. It is not just a flavor. It annoys me that somebody would compare it to picking between vanilla and chocolate ice cream.

But...

> Now the reason that mathematicians are not working with theorem provers is quite simple. Too much of mathematics is not formalized yet for us to build new research on it and it will take millions of hours of work until that has happened. There are people who work on that. However most of us deem our time better spent researching new mathematics. In addition one needs to be a true expert in theorem proving in order to archieve any sort of acceptable productivity (even then I'm not sure that is possible).

Fuck, if I can deny this part. I cannot deny the (im)practicalities of theorem proving.

I've never ever proven anything in Coq or Agda that I was not sure of beforehand! I've never once despite all my effort used it to generate novel insight about the programs I was making!

That randomized testing proof of CFR is actually the exception to this. In that the process of making it really did give me insight that I did not have before.

Fuck!

5:20pm. I did those converge proofs for sqrt over the rationals in Agda, but once I start dealing with imprecise floats, and actual algorithms, just how well will my plans go?

I can't see myself winning arguing for this at all.

Sure, in terms of rigor: Agda/Coq proofs > randomized testing >>> set theory.

Type theory might be the king of the hill, and randomized testing might be its good friend. They are high enough that they deserve their position being able to piss on classical mathematics from above. But type theory is really fat and slow, and if I was randomized testing, I would really be tempted - after the piss was done to give TT a nudge over the ledge in order to move into the huge mansion it was living in.

5:25pm. Back in 2016 I dumped Idris in favor of working on my own language. My impression was that the thing won't scale.

Now I know it and several other DTLs besides. My impression of this has not changed at all.

Now CFR is simple. No doubt future algorithms will just continue to get harder and harder.

I am betting that if you cut classical mathematics and constructive mathematics, and replace them with randomized testing, you'd really not lose anything. That guy mentioned that classical mathematics had successes, but for any success to qualify, it really needs to be applied and randomized testing can cover all of that.

It was not really an option to consider this seriously before now though.

Randomized testing came in without fanfare, and now it just exists. It silently conquered the world of machine learning.

5:30pm. Maybe the right thing to do is to simply start taking it seriously.

I had these thoughts last year, before I got sidetracked with the papers by Blackwell and Hart.

I might have disparaged those ML benchmarks due to the low value of their information, but maybe my problem is simply a matter of scale.

Maybe the right answer is that I need to repeat 2018 except at a far bigger scale.

5:35pm. What I need right now is a lot of energy. I need a firm belief.

And what about Spiral?

Spiral is the low hanging fruit.

The kind of reasoning that I do while making Spiral is definitely rigorous. I could only dream of achieving the degree of accuracy while doing ML that I do while doing PL.

5:40pm. Scale and speed. I can get both development speed and runtime performance with v0.2.

But what about scale? If my aim with v0.2 will not just be to do ML library and an agent, but generalize the concept of randomize testing as a part of doing ML, then what about scale?

I've heard disparaging remarks about languages that do whole program optimization, but in truth Spiral's scaling is no worse than C++.

...Which I am not sure is that good especially compared to langs like C# and F#.

6pm. Still, scale really depends on what you want to do.

Done with lunch.

Basically, there is no way I will ever need to handle more than 100k lines of code in total in one blast. Whatever Spiral v0.2's speed turns out to be, it should be enough to carry me through. I do not need to consider lesser languages like Julia.

Functional programming will rule the world.

6:05pm. Can I stomach doing this work in a weak language? Then pick something else. Otherwise do Spiral.

It really is not a weakness. Would I really be rather working on a PL or do ML experiments? I really can leave the later those research gamblers.

If I am going to program, it is important that I do it with pride.

I think that more than anything else is what makes me special compared to other people. Looking back at my school days, my schoolmates never had it.

6:10pm. I am really quite tired right now, so let me call it a day here.

Hopefully by tomorrow, I will manage to gather some real motivation.

I need to dream bigger. How do I abstract things like ML experiments - rather than just doing them. That is what I need to think about.

Once I have that the parser, the partial evaluator and the typechecker will take care of themselves. They will literally just come to me and out through my fingers."

---
## [Anas-coder/My-Projects](https://github.com/Anas-coder/My-Projects)@[fd203fdd4a...](https://github.com/Anas-coder/My-Projects/commit/fd203fdd4ad88695eb13064324dc1247f6508fc9)
#### Friday 2020-01-03 18:15:17 by Md. Anas Ansari

Baby Names

Analysing Naming Trends
--Splitting the Top 1,000 names into the boy and girl portions is easy to do first
--number of birth per year
Measuring the increase in naming diversity
--Sum of table1000.prop by year and sex
--Number of popular names in top 50%
Boy names that became girl names (and vice versa)
--lesley_like name as male and female transition

---
## [Ian-Macharia/datasciencecoursera](https://github.com/Ian-Macharia/datasciencecoursera)@[3df19dcf44...](https://github.com/Ian-Macharia/datasciencecoursera/commit/3df19dcf448e3e01b1b5790a3999366dea2cbf96)
#### Friday 2020-01-03 18:15:30 by Ian Macharia

Created HelloWorld.md

This is the birth of a new markdown file: HelloWorld.md. As it begins its life, we wish it peace, love and good formatting.

---
## [rawatmanoj/Rainbow-Poem](https://github.com/rawatmanoj/Rainbow-Poem)@[8bae8491e9...](https://github.com/rawatmanoj/Rainbow-Poem/commit/8bae8491e9c66ab351fb018d49f9006ad1bf33ce)
#### Friday 2020-01-03 21:33:51 by rawatmanoj

Poet: Kamala Das

This is an autobiographical poem which throws light on the life and work of Kamala Das. Das begins the poem by saying that she doesn’t understand politics but she knows the name of politicians probably referring to the fact that power is in the hands of a few elites and that it is usually males who run the country. She then gives a brief introduction of herself before she focuses on English being the medium she uses to expresses herself; how people criticize her for that; and why it is no one’s business other than herself. The poem then moves to her early and unsuccessful marriage and how the society she lives in is male dominated. The primary focus of the poem is the situation of women in a patriarchal society and the unjust burdens women have to go through in this male dominated world. Kamala Das or Kamala Surayya is one of the best known Indian female poets and this is her most famous work.

---
## [Radesh-kumar/learngit](https://github.com/Radesh-kumar/learngit)@[0ab4b4af81...](https://github.com/Radesh-kumar/learngit/commit/0ab4b4af81a98808ce9cddd1bb043d49e9997ae8)
#### Friday 2020-01-03 21:39:45 by Radesh-kumar

Merge pull request #1 from Radesh-kumar/newuser

Well fuck you

---
## [Jarpos/jarncc](https://github.com/Jarpos/jarncc)@[7a194a17d1...](https://github.com/Jarpos/jarncc/commit/7a194a17d1a97c472dd78f14e21349af6f00d9b6)
#### Friday 2020-01-03 21:41:31 by Mendl

ref: Change some class properties properties from = to : because fuck you

---
## [rawatmanoj/Rainbow-Poem](https://github.com/rawatmanoj/Rainbow-Poem)@[705fb96f90...](https://github.com/rawatmanoj/Rainbow-Poem/commit/705fb96f904c6764cecd824d4335a2006a0b53ff)
#### Friday 2020-01-03 21:42:46 by rawatmanoj

RASHMIRATHI

In the great Indian epic Mahabharata, Karna was the first-born son of Kunti. However, she abandoned him at birth as he was conceived before her marriage. Karna then grows up in a lowly family but becomes one of the best warriors of his time. He becomes friends with Duryodhana and ultimately fights on his side against his own brothers, the Pandavas. Rashmirathi brilliantly captures the tale of Karna capturing all hues of human emotions he is trapped in due to the various dilemmas he faces. Ramdhari Singh Dinkar is considered as one of the most important modern Hindi poets and Rashmirathi is his most famous as well as his most critically acclaimed work.

---
## [cockroachdb/cockroach](https://github.com/cockroachdb/cockroach)@[7906cbe3d9...](https://github.com/cockroachdb/cockroach/commit/7906cbe3d9c615430f6e892a42e6bccdad2aff00)
#### Friday 2020-01-03 22:52:27 by craig[bot]

Merge #43701 #43709 #43710 #43711 #43713

43701: sqlsmith: add support for interleaved tables r=mjibson a=mjibson

This commit adds interleaved table support to sqlsmith. When running
with the rand-tables configuration, there's a 50% chance of all tables
but the first one to get interleaved into a random other table.

Release note: None

43709: pgwire: use datadriven-based testing for HBA configs r=knz a=knz

(I'm currently working on #31113 and updating this test makes my life easier.)

This patch introduces a datadriven test runner for HBA config tests.
It also replaces the previous `TestHBA` by more exhaustive datadriven
input files, with comments that better explain the narrative of the
test.

Release note: None

43710: pgwire: improve some HBA error messages r=knz a=knz

First commit from #43709.

Before:

```
> set cluster setting server.host_based_authentication.configuration = 'host db all 0.0.0.0/32 cert';
ERROR: database must be specified as all
```

```
> set cluster setting server.host_based_authentication.configuration = 'host all all myhost cert';
ERROR: host addresses not supported
```

```
> set cluster setting server.host_based_authentication.configuration = 'host all all 0.0.0.0/32 sdfsf';
ERROR: unknown auth method "sdfsdf"
```

After:
```
> set cluster setting server.host_based_authentication.configuration = 'host db all 0.0.0.0/32 cert';
ERROR: unimplemented: per-database HBA rules are not supported
SQLSTATE: 0A000
HINT: You have attempted to use a feature that is not yet implemented.
--
Use the special value 'all' (without quotes) to match all databases.
```

```
> set cluster setting server.host_based_authentication.configuration = 'host all all myhost cert';
ERROR: unimplemented: hostname-based HBA rules are not supported
SQLSTATE: 0A000
HINT: You have attempted to use a feature that is not yet implemented.
--
List the numeric CIDR notation instead, for example: 127.0.0.1/8.
```

```
> set cluster setting server.host_based_authentication.configuration = 'host all all 0.0.0.0/32 sdfsdf'
ERROR: unimplemented: unknown auth method "sdfsdf"
SQLSTATE: 0A000
HINT: You have attempted to use a feature that is not yet implemented.
--
Supported methods: cert, cert-password, password
```

Release note (sql change): CockroachDB will now provide more
descriptive error messages and a error hint when an unsupported rule
is provided via `server.host_based_authentication.configuration`.

43711: pgwire: split the authentication code in its own files r=knz a=knz

First two commits from #43709 and #43710.

This patch splits the pgwire authentication in its own files
and adds missing explanatory comments.

No functional changes.

43713: pgwire/hba: fix a bug in the parsing logic r=knz a=knz

Release note (bug fix): There was a bug in the parsing logic for
server.host_based_authentication.configuration, where both
single-character strings, and quoted strings containing spaces and
separated by commas were not properly parsed. This would cause
e.g. rules for usernames consisting of a single characters, or
usernames containing spaces, to apply improperly.

Co-authored-by: Jordan Lewis <jordanthelewis@gmail.com>
Co-authored-by: Raphael 'kena' Poss <knz@thaumogen.net>

---
## [vawser/Cinders-DS3](https://github.com/vawser/Cinders-DS3)@[2d377391d3...](https://github.com/vawser/Cinders-DS3/commit/2d377391d344d0aeb0552e1a86fcad97afeecfac)
#### Friday 2020-01-03 23:20:29 by Vawser

Update

- Champion's Pact: Boosts soul gain by 100%, no longer boosts Item Discovery.
- Lucidity: reduces FP reductiont to 15% (from 20%)
- Holy Moonlight Greatsword is now just part of the base Moonlight Greatsword when infused to Holy (it switches to that model). Removed the separate weapon.
- Reduced the spell FP consumption effects to 20% (from 30%).
- Shira's Set now reduces miracle FP consumption.
- Soul Arrow: damage to 200
- Great Soul Arrow: damage to 300
- Soul Spear: damage to 400
- Crystal Soul Spear: damage to 500
- Soul Greatsword: damage to 400
- Old Moonlight: damage to 400 (500)
- Soul Wave: damage to 300
- Soul Stream: damage to 200, FP to 100
- Unleash Magic: now boosts magic/dark damage by 20% for 30 seconds, but reduces absorption by 100% whilst active.
- Pestilent Mist: now inflicts Curse rather than dealing damage. Will inflict 240 Curse over its whole duration.
- Fire Surge: damage to 150
- Great Chaos Fire Orb: damage to 400
- Chaos Storm: damage to 400 (350)
- Profaned Flame: damage to 350
- Chaos Bed Vestiges: damage to 500
- Cataclysm: FP to 100
- Bursting Fireball: FP to 35, damage to 75
- Boulder Heave: FP to 60, damage to 500, 300
- Sacred Flame: reduced damage multipliers.
- Earthfall: FP to 100
- Acid Surge: deals damage and reduces durability rather than reducing absorption.
- Warmth: deals 30 HP per tick
- Power Within: boosts damage by 35%
- Force: no longer deals damage.
- Emit Force: damage to 250 (100)
- Wrath of the Gods: FP to 50, damage to 500
- Great Lightning Spear: damage to 350
- Sunlight Spear: FP to 75, damage to 500
- Heavenly Thunder: FP to 100
- Atonement: boosts absorption by 25% and grants 1% HP and FP recovery, but slows the caster. FP to 50.
- Sacred Oath: boosts damage and absorption by 20%.
- Seek Guidance renamed to Heavenly Relief
- Heavenly Relief: boosts equipment load by 25% and reveals signs without ember
- Perseverance: boosts Poise by 30 for 60 seconds.
All Dark spells no longer cost HP.
- Deep Barb: FP to 10, damage to 100
- Dark Edge: FP to 20, damage to 250
- Deep Soul: FP to 25, damage to 200
- Great Deep Soul: FP to 30, damage to 300
- Great Soul Dregs: FP to 50, damage to 500
- Climax: FP to 50, damage to 500, removes 1000 souls upon use. Doesn't affect damage.
- Abyssal Edge: FP to 30, damage to 400
- Affinity: FP to 75, damage to 100
- Whisper of Despair: FP to 60, now inflicts 100 Curse.
- Yearning Dregs: FP to 6, damage to 250
- Writhing Deep: FP to 40, damage to 250 [500]
- Dark Bead: FP to 50, damage to 75
- Cascading Deep: FP to 75, damage to 75
- Surging Deep: FP to 5, damage to 100
- Dreg Torrent: FP to 75, damage to 100
- Repel: FP to 25
- Numbness: FP to 100
- Black Fire Orb: FP to 40, damage to 400 (300)
- Black Flame: FP to 30, damage to 350 (200)
- Black Serpent: FP to 40, damage to 300
- Dark Dance: FP to 6, damage to 250
- Recollection: FP to 75, damage to 100
- Mournful Flames: FP to 40, damage to 300
- Nibble: FP to 10
- Gnaw: FP to 25
- Dorhys' Gnawing: FP to 30
- Lifehunt Scythe: FP to 30, damage to 400
- Devouring Swarm: FP to 75
- Dead Again: FP to 30
- Deep Protection: FP to 60
- Dark Blade: FP to 100
- Vow of Silence: FP to 30
- Added the covenant phantom rings to the Primordial shop
- Renamed Ring of the Fingers to Ring of Rosaria
- Renamed Ring of Champions to Ring of the Exalted
- Renamed Beastial Band to Bestial Band
- Dusk Crown Ring: reduces sorcery FP reduction to 25% (from 30%)
- Charred Bone: reduces pyromancy FP reduction to 25% (from 30%)
- Tome of Sunlight: reduces miracle FP reduction to 25% (from 30%)
- Increased the damage of the Soul of Cinder.
- Bosses are slightly tougher to inflict Curse on than before.
- Fixed various localization issues.
- Fixed Darkdrift instantly cursing you.
- Fixed Lightning Moonlight Greatsword not having the correct scaling.
- Fixed various irregularities with the animation cancel changes.

---
## [chris-morgan/zola](https://github.com/chris-morgan/zola)@[4875fbebc6...](https://github.com/chris-morgan/zola/commit/4875fbebc6aab5757b9197ced60ff6d92833e27b)
#### Friday 2020-01-03 23:36:54 by Chris Morgan

Support and default to generating Atom feeds

This includes several breaking changes, but they’re easy to adjust for.

Atom 1.0 is superior to RSS 2.0 in a number of ways, both technical and
legal, though information from the last decade is hard to find.
http://www.intertwingly.net/wiki/pie/Rss20AndAtom10Compared
has some info which is probably still mostly correct.

How do RSS and Atom compare in terms of implementation support? The
impression I get is that proper Atom support in normal content websites
has been universal for over twelve years, but that support in podcasts
was not quite so good, but getting there, over twelve years ago. I have
no more recent facts or figures; no one talks about this stuff these
days. I remember investigating this stuff back in 2011–2013 and coming
to the same conclusion. At that time, I went with Atom on websites and
RSS in podcasts. Now I’d just go full Atom and hang any podcast tools
that don’t support Atom, because Atom’s semantics truly are much better.

In light of all this, I make the bold recommendation to default to Atom.

Nonetheless, for compatibility for existing users, and for those that
have Opinions, I’ve retained the RSS template, so that you can escape
the breaking change easily.

I personally prefer to give feeds a basename that doesn’t mention “Atom”
or “RSS”, e.g. “feed.xml”. I’ll be doing that myself, as I’ll be using
my own template with more Atom features anyway, like author information,
taxonomies and making the title field HTML.

Some notes about the Atom feed template:

- I went with atom.xml rather than something like feed.atom (the .atom
  file format being registered for this purpose by RFC4287) due to lack
  of confidence that it’ll be served with the right MIME type. .xml is a
  safer default.

- It might be nice to get Zola’s version number into the <generator>
  tag. Not for any particularly good reason, y’know. Just picture it:

    <generator uri="https://www.getzola.org/" version="0.10.0">
	Zola
    </generator>

- I’d like to get taxonomies into the feed, but this requires exposing a
  little more info than is currently exposed. I think it’d require
  `TaxonomyConfig` to preferably have a new member `permalink` added
  (which should be equivalent to something like `config.base_url ~ "/" ~
  taxonomy.slug ~ "/"`), and for the feed to get all the taxonomies
  passed into it (`taxonomies: HashMap<String, TaxonomyTerm>`).
  Then, the template could be like this, inside the entry:

    {% for taxonomy, terms in page.taxonomies %}
        {% for term in terms %}
            <category scheme="{{ taxonomies[taxonomy].permalink }}"
		term="{{ term.slug }}" label="{{ term.name }}" />
	{% endfor %}
    {% endfor %}

Other remarks:

- I have added a date field `extra.updated` to my posts and include that
  in the feed; I’ve observed others with a similar field. I believe this
  should be included as an official field. I’m inclined to add author to
  at least config.toml, too, for feeds.
- We need to have a link from the docs to the source of the built-in
  templates, to help people that wish to alter it.

---

# [<](2020-01-02.md) 2020-01-03 [>](2020-01-04.md)

