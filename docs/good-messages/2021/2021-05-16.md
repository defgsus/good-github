# [<](2021-05-15.md) 2021-05-16 [>](2021-05-17.md)

2,102,345 events, 1,164,747 push events, 1,648,700 commit messages, 88,416,282 characters


## [LemonInTheDark/tgstation@c1e2ba748a...](https://github.com/LemonInTheDark/tgstation/commit/c1e2ba748a642f096ce892f8b665905619f4dee9)
##### 2021-05-16 01:47:43 by LemonInTheDark

Prevents players from pressing the haha funny HELL BUTTONS WHAT THE FUCK OLD ME WHY DIDN'T YOU CATCH THIS

---
## [Danny7007/Trivia-Murder-Party@5f6d35f43c...](https://github.com/Danny7007/Trivia-Murder-Party/commit/5f6d35f43c7f1d95f33a02ab1432b75b7076a803)
##### 2021-05-16 05:45:25 by Danny7007

Added Scratch-Off

Akihabara, the electric town--hub for state-of-the-art technology, fashion, otaku goods, and the cutest boys in skirts you will ever see. Pop into the Girls! Girls! Girls!? Cafe and fall in love with one of four charming "ladies..." or maybe even all of them? Jump into a story full of fluff, romance, friendship, and crossdressing that will keep you coming back for more!

---
## [Jummit/cc-restitched@191f9ea5e3...](https://github.com/Jummit/cc-restitched/commit/191f9ea5e3bb6280f6807b32c734bf4502cd697e)
##### 2021-05-16 07:40:24 by Jonathan Coates

Fix mounts being usable after a disk is ejected

This probably fails "responsible disclosure", but it's not an RCE and
frankly the whole bug is utterly hilarious so here we are...

It's possible to open a file on a disk drive and continue to read/write
to them after the disk has been removed:

    local disk = peripheral.find("drive")
    local input = fs.open(fs.combine(disk.getMountPath(), "stream"), "rb")
    local output = fs.open(fs.combine(disk.getMountPath(), "stream"), "wb")
    disk.ejectDisk()

    -- input/output can still be interacted with.

This is pretty amusing, as now it allows us to move the disk somewhere
else and repeat - we've now got a private tunnel which two computers can
use to communicate.

Fixing this is intuitively quite simple - just close any open files
belonging to this mount. However, this is where things get messy thanks
to the wonderful joy of how CC's streams are handled.

As things stand, the filesystem effectively does the following flow::
 - There is a function `open : String -> Channel' (file modes are
   irrelevant here).

 - Once a file is opened, we transform it into some <T extends
   Closeable>. This is, for instance, a BufferedReader.

 - We generate a "token" (i.e. FileSystemWrapper<T>), which we generate
   a week reference to and map it to a tuple of our Channel and T. If
   this token is ever garbage collected (someone forgot to call close()
   on a file), then we close our T and Channel.

 - This token and T are returned to the calling function, which then
   constructs a Lua object.

The problem here is that if we close the underlying Channel+T before the
Lua object calls .close(), then it won't know the underlying channel is
closed, and you get some pretty ugly errors (e.g. "Stream Closed"). So
we've moved the "is open" state into the FileSystemWrapper<T>.

The whole system is incredibly complex at this point, and I'd really
like to clean it up. Ideally we could treat the HandleGeneric as the
token instead - this way we could potentially also clean up
FileSystemWrapperMount.

BBut something to play with in the future, and not when it's 10:30pm.

---

All this wall of text, and this isn't the only bug I've found with disks
today :/.

---
## [AbenezerMamo/100@6d7d4acf66...](https://github.com/AbenezerMamo/100/commit/6d7d4acf66234c28c201e4a83f9fd66acf65a943)
##### 2021-05-16 08:32:03 by Abenezer Mamo

Hoping you too commit to lifelong, continuous, & self-paced learning (“Free Beer Co.” est.: before Bar exams, roll bars, or gold bars)

See? I told you I’m not kidding when I said I said he says “MPH”. Bruh. Hilarious. Yeah I can’t finish anything either. Welcome to fun. Population: +/-

---
## [AbenezerMamo/100@3aa392e2d5...](https://github.com/AbenezerMamo/100/commit/3aa392e2d57420a206c25754fa3cf2b1ecfdc1c7)
##### 2021-05-16 09:01:11 by Abenezer Mamo

Richie Rich not....Whatever, we made it here in California but flew from the mother land

I swear to God if you dare do to anyone what happens to my mans....you are going to feel silly when I say that we’re watching and will not let anyone be ashamed of being a father. Lotta people being really good parents has inspired me so much man. Now imagine being these people’s kids hahaha. They don’t know what it’s like to not have a roof. “I did it without one” is def a ghost line

---
## [mrakgr/The-Spiral-Language@969039e6e6...](https://github.com/mrakgr/The-Spiral-Language/commit/969039e6e6ca8e3daedc29264789027865ea1b79)
##### 2021-05-16 11:02:30 by Marko Grdinić

"10:20am. I ended up going to bed at 2am, so it is no wonder I am waking up this late today.

Rather than programming I want to do some more research on Hebbian learning. I doubt I'll resolve anything, but that is what I want to do.

The way Miconi does it or that fast weights paper by Hinton is not the answer. It does not feel like it.

Now that I've solved some of the other things, Hebbian learning is probably the most mysterious part of the brain. One thing I can understand is that having Hebbian learning would allow easy reversal learning. For regular NNs, I do not think that reversing the output would get inputs that resemble the ones from the input distribution, but Hebbian learning would allow it.

10:25am. Hmmm...how would using Hebbian learning for doing the majority of the learning, and using something like backprop for just learning the scale of the weights work? And I do not need to update the Hebbian weights at every timestep like in Miconi's work, it can be done in a separate phase...

No, actually it is fine if I mutate it. If the goal is to do exact backprop it would be wrong. But if the method is about reconstructing inputs then taking the weights as they are to determine the score is the correct answer.

https://www.sciencedirect.com/science/article/pii/S2352154621000280
Hebbian learning revisited and its inference underlying cognitive function

> Despite the recent success of deep learning in artificial intelligence, the lack of biological plausibility and labeled data in natural learning poses a challenge in understanding biological learning. At the other extreme lies Hebbian learning, the simplest local and unsupervised one, yet considered to be computationally less efficient. The recent development of Hebbian learning re-evaluates its contribution to natural learning and memory association. It highlights the efficiency of Hebbian learning combined with supervised learning in forming a low-dimensional and coarse representation, and its role in many cognitive tasks by providing a basis activity patterns and dynamics. Deriving the form of Hebbian learning from in-vivo data bridges the neural and behavioral data and requires utilizing both spatial and temporal activity changes.

Let me find the pdf for this.

...I can't find it.

https://www.nature.com/articles/nn.4158?proof=t
Inferring learning rules from distributions of firing rates in cortical neurons

https://www.nature.com/articles/srep28073
A Local Learning Rule for Independent Component Analysis

10:45am. I am going to have to try Libgen for Sukbin Lim's papers.

10:50am. No luck. Forget it. There are plenty of other papers on this subject though.

https://scholar.google.com/scholar?as_ylo=2021&q=hebbian+learning&hl=hr&as_sdt=0,5

10:55am. I guess I'll do reading today again. Let me just finish the article by Moldbug so I can clear that tab.

11:10am. https://graymirror.substack.com/p/there-is-no-ai-risk

I think that Moldbug's IQ really did fall at some point in his journey. Seriously dude, even in the worse case, a super AI could make millions a month by doing a thousand lowly paid programming jobs at once which it could use to buy more hardware to do even more work. It boogles my mind how he thinks Rennaisance is the top limit on what superintelligence could do. Endless capacity for work and endless inspiration would allow it to corner any market it decides to enter fairly quickly.

And yes, he is right that there is an IQ gap limit between a leader and a follower, but it does not remotely apply in the context of AI since it would have powerful self control. I might be a weirdo myself, but I have the awareness to know that my internal systems are fucking me over in social situations by making me bored. And AI could deal with that sort of internal issue easily. And moreover, an AI would not need to lead or control humans, just other AI agents. Alternatively, an IQ 200 AI could create an IQ 120 AI which could lead the 100 IQ humans if it does not feel like doing the work on its own.

Just who is he writing these articles for? 90 IQ proles?

11:25am. Let me go back to deep learning.

https://arxiv.org/abs/2102.00428
PyTorch-Hebbian: facilitating local learning in a deep learning framework

https://journals.physiology.org/doi/abs/10.1152/jn.00712.2020
Classic Hebbian learning endows feed-forward networks with sufficient adaptability in challenging reinforcement learning tasks

https://ieeexplore.ieee.org/abstract/document/9321229
Bidirectional Associative Memories: Unsupervised Hebbian Learning to Bidirectional Backpropagation

https://arxiv.org/abs/2103.09002
Hebbian Semi-Supervised Learning in a Sample Efficiency Setting

https://arxiv.org/abs/2104.07959
Evolving and Merging Hebbian Learning Rules: Increasing Generalization by Decreasing the Number of Rules

A lot of paper on Hebbian learning came out. Strange that there is nothing in 2018 and 2019. Did Scholar drop the data from those years?

11:40am. That networks trained with Hebbian learning would be easy to reverse is important insight. I am not sure if anybody is aware of it, but I'd bet the brain takes great advantage of it. It is more realistic than training GANs in the way I've suggested.

https://arxiv.org/abs/2104.07959
Evolving and Merging Hebbian Learning Rules: Increasing Generalization by Decreasing the Number of Rules

This paper was not much.

https://arxiv.org/abs/2103.09002
Hebbian Semi-Supervised Learning in a Sample Efficiency Setting

Let me go for this one next. I want to see some papers with combine HL with backprop for things like learning the scale and the like.

12pm. It is nothing much.

https://ieeexplore.ieee.org/abstract/document/9321229
Bidirectional Associative Memories: Unsupervised Hebbian Learning to Bidirectional Backpropagation

http://sipi.usc.edu/~kosko/BAM-SMC-January-2021.pdf
> Bidirectional backpropagation lets users run deep classifiers and regressors in reverse as well as forward. Bidirectional training exploits pattern and synaptic information that forward-only running ignores.

Bidirectional? This might be something. Let me take a break here.

12:10pm.

> Every real matrix is bidirectionally stable.

What does this mean.

http://sipi.usc.edu/~kosko/B-BP-SMC-Revised-13January2018.pdf
Bidirectional Backpropagation

Oh what is this?

12:20pm. The BAM paper is complicated and I am just skimming it right now.

> Backpropagation is a special case of the generalized EM algorithm for maximum-likelihood estimation of parameters [5], [21].

There is a lot in the BAM paper.

What is backpropagation invariance?

12:25pm. I'll leave the bidi paper for later.

Classic Hebbian learning endows feed-forward networks with sufficient adaptability in challenging reinforcement learning tasks

Let me go for this next.

No, I can't find the pdf for it. Forget it.

https://arxiv.org/abs/2103.10252
Augmenting Supervised Learning by Meta-learning Unsupervised Local Rules

> The brain performs unsupervised learning and (perhaps) simultaneous supervised learning. This raises the question as to whether a hybrid of supervised and unsupervised methods will produce better learning. Inspired by the rich space of Hebbian learning rules, we set out to directly learn the unsupervised learning rule on local information that best augments a supervised signal. We present the Hebbian-augmented training algorithm (HAT) for combining gradient-based learning with an unsupervised rule on pre-synpatic activity, post-synaptic activities, and current weights. We test HAT's effect on a simple problem (Fashion-MNIST) and find consistently higher performance than supervised learning alone. This finding provides empirical evidence that unsupervised learning on synaptic activities provides a strong signal that can be used to augment gradient-based methods.

> We further find that the meta-learned update rule is a time-varying function; thus, it is difficult to pinpoint an interpretable Hebbian update rule that aids in training. We do find that the meta-learner eventually degenerates into a non-Hebbian rule that preserves important weights so as not to disturb the learner's convergence.

This is pretty promising.

...No, it is nothing much.

12:45pm. https://direct.mit.edu/neco/article/33/5/1300/97484/Contrastive-Similarity-Matching-for-Supervised

Huh, actually I hadn't made the connection between contrastive learning and Hebbian learning. Maybe I should think of them as being the same.

> This is because our weight updates solve a minimax problem.

This is promising. I'd expect any unsupervised scheme to do this. What I cannot connect is how the brain does it so quickly.

1pm. https://arxiv.org/abs/2103.09985
A deep learning theory for neural networks grounded in physics

https://arxiv.org/abs/2104.01677
A contrastive rule for meta-learning

https://arxiv.org/abs/2104.04657
Meta-Learning Bidirectional Update Rules

1pm. Let me have breakfast here."

---
## [xdy/twodsix-foundryvtt@9a20e66ade...](https://github.com/xdy/twodsix-foundryvtt/commit/9a20e66ade2970958219850d8e3ac79d16a3f09b)
##### 2021-05-16 13:46:02 by Jonas Karlsson

fix: A bit more support for Cepheus Atom (and friends), there is now a system setting to enable showing only END, Lifeblood and (optionally) Contamination instead of the regular characteristics. (Actually uses STR for Lifeblood and PSI for Contamination).

This is a Dreadful Hack that will undoubtedly Break Things Horribly if looked at too closely. If anyone asks, mutant marauders from the wastelands forced me to do it. :)

I.e. I hacked this together without much (or, well, any) concern for how I had originally intended to do this. If/when this gets redesigned it's probably best to just rip out this commit.

---
## [bajajfiinance/Amazon-customer-care.-09064017013@65e5898703...](https://github.com/bajajfiinance/Amazon-customer-care.-09064017013/commit/65e589870319934e321cd514fa1559adbb99ebf1)
##### 2021-05-16 16:06:35 by bajajfiinance

Amazon customer care. 9064017013

Amazon.com
E-commerce company

OverviewPeople also search for
amazon.in
Amazon.com, Inc. is an American multinational technology company based in Seattle, Washington, which focuses on e-commerce, cloud computing, digital streaming, and artificial intelligence. Wikipedia
CEO: Jeff Bezos (May 1996–) Trending
Customer service: 1800 3000 9009
Contact.09064017013
Stock price: AMZN (NASDAQ) $3,222.90 +61.43 (+1.94%)
14 May, 4:00 pm GMT-4 - Disclaimer
Founder: Jeff Bezos
Founded: 5 July 1994, Bellevue, Washington, United States
Headquarters: Seattle, Washington, United States
Subsidiaries: Audible, Zappos, Whole Foods Market, AbeBooks, Amazon Fresh, Amazon.ae, Ring
Learning Center>Startup Stories>Amazon Startup Story
Amazon Startup Story
Introduction
This startup story features Jeffrey P. Bezos, the innovative founder of Amazon. The company, which now generates over $61 Billion in Revenue and holds the title as the world’s largest  online retailer, was started out of Bezos’s garage at 30 years old.

Amazon Stats:
Industry: Online Retailing
Annual Revenue: $61.09 Billion
# of Employees: 97,000
Famous For: Being the world’s largest online retailer
How Amazon Got Started
The year was 94′ and Bezos was working diligently on Wall Street. At 30 years old, he began to see the internet revolution take place, and made the decision to quit his job and start an internet company.

“The wake up call was finding this startling statistic that web usage in the spring of 1994 was growing at 2,300 percent a year. You know, things just don’t grow that fast. It’s highly unusual, and that started me about thinking, “What kind of business plan might make sense in the context of that growth?” 

After making a list of the ‘top 20’ products that he could potentially sell on the internet, he decided on books because of their low cost and universal demand. It turns out, it was just the beginning…..

The Founder’s Start
As a child, he spent summers at his grandfather’s ranch in southern Texas, “laying pipe, vaccinating cattle and fixing windmills”. The 18-year-old Bezos “said he wanted to build space hotels, amusement parks and colonies for 2 million or 3 million people who would be in orbit. ‘The whole idea is to preserve the earth’ he told the newspaper …. The goal was to be able to evacuate humans. The planet would become a park”. 

Amazon’s Funding
The initial startup capital came from his parent’s personal savings.

From an interview with Jeff Bezos, for the Academy of Achievement:

“The first initial start-up capital for Amazon.com came primarily from my parents, and they invested a large fraction of their life savings in what became Amazon.com. And you know, that was a very bold and trusting thing for them to do because they didn’t know. My dad’s first question was, “What’s the Internet?” Okay. So he wasn’t making a bet on this company or this concept. He was making a bet on his son, as was my mother. So, I told them that I thought there was a 70 percent chance that they would lose their whole investment, which was a few hundred thousand dollars, and they did it anyway.”

Follow on Funding
Amazon raised a series A of $8M from Kleiner Perkins Caufield & Byers in 1995. In 1997, Amazon went public to raise additional capital. By 1999, the value of the Kleiner Perkins Caufield & Byers investment in Amazon created returns of over 55,000%.

Years to profitability
Within two months, Amazon’s sales were up to $20,000/week. However, the company has continued to plow their revenue back into growth. The chart below depicts Amazon’s continued focus on long-term growth, with profit remaining near $0 or below, and revenue rising.

Amazon Profitability

Important Amazon Milestones:
1994: Jeff Bezos quits his job and launches Amazon out of his garage.
             Within 30 Days, it is doing $20,000 per week in sales.

1995: Bezos raises an $8 Million round of funding from Kleiner Perkins.

1997: Amazon goes public at $18 per share.

1999: Bezos is named Time Magazine’s “Person of the Year” for popularizing online shopping.

2009: Bezos acquires Tony Tsieh’s Zappos through a stock swap.

2013: Bezos acquires the Washington Post.

Companies Amazon Has Acquired:
Amazon has made over 44 notable company acquisitions over the years. It’s first Acquisition was in 1998.

1998: PlanetAll, Junglee, Bookpages.co.uk (later became Amazon UK).
1999: Internet Movie Database (IMDb), Alexa, Accept.com, and Exchange.com
2003: CDNow (Defunct)
2004: Joyo.com, an e-commerce site in China.
2005: BookSurge, Mobipocket.com, and CreateSpace.com.
2006: Shopbop, a women’s luxury retailer.
2007: DPReview.com and Brilliance Audio.
2008: Audible.com, Fabric.com, Box Office Mojo, AbeBooks, Shelfari, and Reflexive Entertainment.
2009: Zappos,  Lexcycle, SnapTell,  Stanza (Kindle Rival).
2010: Touchco., Woot, Quidsi, BuyVIP, and Amie Street.
2010: Toby Press
2011: LoveFilm, The Book Depository, Pushbutton, and Yap
2012: Kiva Systems, Teachstreet, and Evi
2013: IVONA Software, GoodReads, and Liquavista
Jeff Bezos Startup Advice
“We are stubborn on vision. We are flexible on details…. We don’t give up on things easily. Our third-party seller business is an example of that. It took us three tries to get the third-party seller business to work. We didn’t give up.”

“If you’re not stubborn, you’ll give up on experiments too soon. And if you’re not flexible, you’ll pound your head against the wall and you won’t see a different solution to a problem you’re trying to solve.”

COMMENTS
No comments yet.
GET OUR WEEKLY NEWSLETTER
Join over 40,000 of your peers who receive regular updates on Fundable, crowdfunding, and starting a business.

you@email.com
SUBSCRIBE
RECENT STARTUP STORIES
March 27, 2014
Patron Tequila Founder - John Paul DeJoria
January 20, 2014
DC Shoes Startup Story
January 20, 2014
Pom Wonderful Startup Story
January 20, 2014
Samuel Adams Startup Story
January 20, 2014
Spanx Startup Story
Ready to Start Raising Capital?

GET STARTED 9
GET STARTED
Start a Fundraise
Investor Signup
Account Login
BROWSE
Trending
Recently Funded
New & Noteworthy
Communities
RESOURCES
FAQ
Guidelines
Contact Us
LEGAL
Privacy Policy
Terms of Service
FOLLOW
the startups.com platform
Startups Education
Startup Planning
Access Mentors
Secure Funding
Reach Customers
Virtual Assistants
Copyright © 2021 Startups.com. All rights reserved.
Fundable is a software as a service crowdfunding platform. Fundable is not a registered broker-dealer and does not offer investment advice or advise on the raising of capital through securities offerings. Fundable does not recommend or otherwise suggest that any investor make an investment in a particular company, or that any company offer securities to a particular investor. Fundable takes no part in the negotiation or execution of transactions for the purchase or sale of securities, and at no time has possession of funds or securities. No securities transactions are executed or negotiated on or through the Fundable platform. Fundable receives no compensation in connection with the purchase or sale of securities.

---
## [mrakgr/The-Spiral-Language@76104e7286...](https://github.com/mrakgr/The-Spiral-Language/commit/76104e7286511157bfe5879f66c3b88a045c0ef4)
##### 2021-05-16 16:32:15 by Marko Grdinić

"1:25pm. Done with breakfast. Let me read the Hellrage MTL for a bit and then I will resume.

1:40pm. Let me resume my reading. I'll do the chores later.

1:50pm. Using HL with backprop learning the scale is too obvious. It is impossible that nobody else tried it before. This is unlike the GAN idea.

So it has to be something else. Right now my understanding of HL is too simple. Being able to reverse inputs is an important principle, but it is not enough.

1:55pm. Actually, let me take a break for a while longer. These papers are complex and right now I feel distracted. I should do the chores.

2:35pm. Done with chores and the bidi backprop paper. I am not sure what to think of it.

I understand that there is zero chance of me figuring out how to fit Hebbian learning into the current framework of deep learning. That talk by Simon Thorpe did shake me up a bit. I started to get confident after figuring out the GAN trick, but the talk reminded me just how far I need to go.

There is no point in playing around with Hebbian learning on the GPUs. If people still haven't figured it out by then, I'll gave it a shot myself once I get those neurochips.

https://arxiv.org/abs/2104.04657
Meta-Learning Bidirectional Update Rules

Let me go for this paper next.

2:40pm. This paper is interesting. It links to many of the references which were of interest to me. I wonder what the proposals will be.

2:55pm. It was a timewaster.

https://arxiv.org/abs/2104.01677
A contrastive rule for meta-learning

Just having some complicated rules and doing benchmarks is not doing me any favors. Let me just go through these.

> When posed with a sequence of tasks that bear some relation to one another, a learning system that is capable of meta-learning will be able to improve its performance as the number of tasks increases. A successful meta-learner discovers shared structure across tasks and modifies its own inductive bias accordingly [1, 2]. Eventually, the system is able to generalize to new problem instances given little additional data. Such ability is believed to be a hallmark of human intelligence [3], and it has been observed in non-human primates as well as in other animal species [4]. Determining which mechanisms support this form of learning in the brain is a fundamental question in neuroscience [5].

I wish neuroscience contributed some actual algorithms rather than being a prophet.

> When applied to learn the weights of a Hopfield network, equilibrium propagation gives rise to a variant of the well-known contrastive Hebbian learning rule [17–21]. Here, we exploit an equivalence between the training of energy-based neural networks and implicit metalearning and show that, when applied to meta-learning problems, equilibrium propagation gives rise to a new meta-parameter learning rule. We term this rule contrastive meta-learning.

I actually do not know much about EP. I should look it up.

3:20pm. https://www.youtube.com/results?search_query=equilibrium+propagation

Done with the paper. It is not something I need. There is a simple rule, plus a lot of math. I do not really understand how it works, but that does not matter. Let me move to the next paper, and then I'll take a look at the EP talk.

https://arxiv.org/abs/2103.09985
A deep learning theory for neural networks grounded in physics

This one is next.

https://arxiv.org/abs/2102.00428
PyTorch-Hebbian: facilitating local learning in a deep learning framework

After that it is this one. After that I'll take a look at the 20' papers. Then I'll take a look at the EP talks.

Oh, that paper is a 110 page PhD.

...No I do not have time for it. Though it is all about equilibrium propagation so maybe the method will be developed to fruition in the context of neurochips in the future. It seems that right now the training is hard and does not match up to backprop.

3:30pm. Not much in the second paper.

https://www.biorxiv.org/content/10.1101/2020.12.30.424888v1.full.pdf
Orchestrated Excitatory and Inhibitory Learning Rules Lead to the Unsupervised Emergence of Up-states and Balanced Network Dynamics

Let me take a look at this next.

It is some biology thing. Forget it.

3:35pm. https://arxiv.org/abs/2104.04132
Replay in Deep Learning - Current Approaches and Missing Biological Elements

> Replay is the reactivation of one or more neural patterns, which are similar to the activation patterns experienced during past waking experiences. Replay was first observed in biological neural networks during sleep, and it is now thought to play a critical role in memory formation, retrieval, and consolidation. Replay-like mechanisms have been incorporated into deep artificial neural networks that learn over time to avoid catastrophic forgetting of previous knowledge. Replay algorithms have been successfully used in a wide range of deep learning methods within supervised, unsupervised, and reinforcement learning paradigms. In this paper, we provide the first comprehensive comparison between replay in the mammalian brain and replay in artificial neural networks. We identify multiple aspects of biological replay that are missing in deep learning systems and hypothesize how they could be utilized to improve artificial neural networks.

This seems really promising.

3:45pm. I'll actually save this paper for later. Most of my own innovation too are related to the use of the replay buffer whether that be GANs or RL methods. So far they are independent of the architectures and training algorithms used.

4:10pm. https://arxiv.org/abs/2101.05848
Unveiling the role of plasticity rules in reservoir computing

Let me go for this paper next.

> While most reservoir computing approaches consider a reservoir with fixed internal connection weights, plasticity was rediscovered as an unsupervised, biologically inspired adaptation to implement an adaptive reservoir. It appeared first as a type of Hebbian synaptic plasticity to modify the reservoir weights [11], but soon the ideas of nonsynaptic plasticity that inspired the first Intrinsic Plasticity (IP) rule [12] were also implemented in an Echo State Network [13]. After that, many different models of plasticity rules have been implemented in RC networks with promising results [14, 15, 16]. Today, the fact that biologically meaningful learning algorithms have a place in these models, together with recent discoveries suggesting that biological neural networks display RCs’ properties [17, 18], make reservoir computing a field of machine learning in continuous growth.

This is interesting. I had no idea that HL played a role in these kinds of nets.

4:20pm. Hmmm, I had an idea. Remember that data dependent initialization method I came up with which pushes the L1 norm of the activations to 1?

Isn't that similar to Hebbian learning?

I never worked out the rules exactly, but it would come to a variant of that wouldn't it?

4:30pm. https://arxiv.org/abs/2007.02686
Meta-Learning through Hebbian Plasticity in Random Networks

Forget the reservior computing paper. Hebbian learning is data dependent intialization isn't it? It is really foolish of me to not have made this connection before.

https://arxiv.org/abs/1511.06856
Data-dependent Initializations of Convolutional Neural Networks

Let me take a look at this old paper before I move on to the rest of them...It is nothing much.

Let me move to the one I linked.

4:45pm. https://arxiv.org/abs/2006.16558
Enabling Continual Learning with Differentiable Hebbian Plasticity

Let me make this the last paper. I am going down the wrong path with Hebbian learning. It is possible to conceptually split the mechnisms into local and more global objectives.

Locally, you can only constraint the layer to have activations that are on average of norm 1. You can give objectives to the individual actionations or it can be the whole layer. Working backwards from that, you arrive at the variants of the Hebbian learning rule depending on the norm used.

There is nothing magical about this. But now that I understand what HL is doing from this perspective, I can see that the neuroscience community is just geeking out about the only thing that they can see. They don't know the more important mechanisms so they are glued to this.

Let me read this more recent paper by Miconi and then I will move to the eq prop papers. After that I'll watch my hands of the HL business. Wasting one day on it is enough.

5:05pm. In constrast to his perivous papers this one is a head layer hack to improve contrinual learning. It does not seem to be that big of a deal on its own, but it performs best when combined with some other methods.

5:10pm. https://arxiv.org/abs/1711.09601
Memory Aware Synapses - Learning what (not) to forget

> Humans can learn in a continuous manner. Old rarely utilized knowledge can be overwritten by new incoming information while important, frequently used knowledge is prevented from being erased. In artificial learning systems, lifelong learning so far has focused mainly on accumulating knowledge over tasks and overcoming catastrophic forgetting. In this paper, we argue that, given the limited model capacity and the unlimited new information to be learned, knowledge has to be preserved or erased selectively. Inspired by neuroplasticity, we propose a novel approach for lifelong learning, coined Memory Aware Synapses (MAS). It computes the importance of the parameters of a neural network in an unsupervised and online manner. Given a new sample which is fed to the network, MAS accumulates an importance measure for each parameter of the network, based on how sensitive the predicted output function is to a change in this parameter. When learning a new task, changes to important parameters can then be penalized, effectively preventing important knowledge related to previous tasks from being overwritten. Further, we show an interesting connection between a local version of our method and Hebb's rule,which is a model for the learning process in the brain. We test our method on a sequence of object recognition tasks and on the challenging problem of learning an embedding for predicting <subject, predicate, object> triplets. We show state-of-the-art performance and, for the first time, the ability to adapt the importance of the parameters based on unlabeled data towards what the network needs (not) to forget, which may vary depending on test conditions.

Is this just learning the variance of the inputs and the gradients?

Before this I saw a paper that suggests what is essentially KFAC to improve continual learning.

5:20pm. > In the Elastic Weight Consolidation work [12], this is done based on an approximation of the diagonal of the Fisher information matrix. In the Synaptic Intelligence work [39], importance weights are computed during training in an online manner. To this end, they record how much the loss would change due to a change in a specific parameter and accumulate this information over the training trajectory. However, also this method has some drawbacks: 1) Relying on the weight changes in a batch gradient descent might overestimate the importance of the weights, as noted by the authors. 2) When starting from a pretrained network, as in most practical computer vision applications, some weights might be used without big changes. As a result, their importance will be underestimated. 3) The computation of the importance is done during training and fixed later. In contrast, we believe the importance of the weights should be able to adapt to the test data where the system is applied to. In contrast to the above two methods, we propose to look at the sensitivity of the learned function, rather than the loss. This simplifies the setup considerably since, unlike the loss, the learned function is not in a local minimum, so complications with gradients being close to zero are avoided

Sensivity of the learned function? So something like a layer compared to a norm loss. It seems reasonable. This is not bad insight.

...Ah no not that. It would just be the same as the regular gradient, except not optimized for some label.

...Ahhh, that gives me some insight!

In my own scheme I will be replacing the outright loss with -1 and 1 weighted implicitly by the sampling probability.

That will actually end up measuring the actual sensitivity, so I'll get the method in this paper automatically.

Mhhh, this is quite good!

Well, it is not exactly the same thing...I'd have to measure it against the class labels that aren't used.

Agh, nevermind.

No, the recommend the gradients of the squared l2 norm of the outputs.

5:35pm. They test the local version of the rule as well which corresponds to Hebbian learning and find that it helps. Yes, this is it. Besides initialization, this is what HL could be useful for.

> In this paper, we argued that, given a limited model capacity and unlimited evolving tasks, it is not possible to preserve all the previous knowledge. Instead, agents should learn what (not) to forget. Forgetting should relate to the rate at which a specific piece of knowledge is used. This is similar to how biological systems are learning. In the absence of error signals, synapses connecting biological neurons strengthen or weaken based on the concurrence of the connected neurons activations.

I liked this paper. It had some clean insight and it improved my understanding of ML.

Let me take a break here.

5:55pm. I am back.

https://brainscan.uwo.ca/research/cores/computational_core/uploads/11May2020-Lillicrap_NatNeuroRev_2020.pdf
Backpropagation and the brain

Let me finish things off today with this. I'll skip EqProp.

6pm. Neuroscience is too glued on Hebbian learning just because they can see it, and I let the video by Simon Thorpe unsettle me. It does not matter that the brain can find repeating patterns which HL is good at. ANNs can't do this easily. Just optimizing for the average layer norm is not enough to give insights for memory.

Once I get good enough hardware, I swear I will solve this mystery. But let me not fall into a hole.

To optimize, you need an objective function. Doing local norm optimization will not make learning magically happen at the grand scale the brain is capable of.

6:10pm. Ok, enough. I will stop for the day on time for once.

The long term goal is to get order of magnitude better neuromorphic hardware which will allow me to implement self improving agents.

I should not be unsettled by the things I can't do yet. The things Simon Thorpe showed in the video is definitely due to salience. Repeating patterns are due to salience. That is what makes them interested enough for the brain to store in long term memory.

The stacked GAN ideas I came up with are closer to that principle than anything else that exists today so I should not give up yet.

Who is to say that in the future I won't come up with even better memory systems? I should not assume that just because the brain does HL that it is the principle behind its memory capabilities.

6:15pm. Coming up with better memory systems should be left for the future.

Tomorrow, I will focus on programming. I will focus on accomplishing small goals that will eventually get me to the finish line. I've hit the limits of what is possible with my own research. I already can't try the GAN ideas without my GPU going up in flames.

6:20pm. Ahhh, it is wonderful. These research excursions have been fun. I've learned quite a bit.

But I should not forget where the power comes from. In the present, from implementing my own ideas and bringing those agents to life. In the future, from getting my hands on better hardware.

I should hold those two dreams close to my heart.

It is possible to get to the brain level efficiency. Once those memristor devices get below 10nm they should be 4 orders of magnitude potential improvement. Spikes should add 2 orders to that. That is what I have to look forward to in the 30s.

6:25pm. Though my ML skills have gone up an entire level in the last month, my programming has gone astray. I need to get back to the fundamentals. Small goals, one after another. I should not worry about how much work there is in total. I should worry about making the next step.

Surely I can do the uniform player? I should focus on that and then think about the linear player. I should make one step after the other and that will get me to where I want to go.

6:30pm. Right now, let me have fun. I am still fresh, and instead of beating myself to get better at ML, I should have fun reading Hellrage while in the background I prime myself to get into programming again. From ML at least, I should relax from learning new things for a year or two.

Time for lunch."

---
## [phanthetue2309/Python-Fun-Family@b9ec59e38b...](https://github.com/phanthetue2309/Python-Fun-Family/commit/b9ec59e38b39927c383db0a9c1e59e392a46ae81)
##### 2021-05-16 17:18:01 by Phan Thế Tuệ

Somthing funny and memories

Code valentine  for my love ,HPBD my sister

---
## [newstools/2021-my-broadband@159411a9e3...](https://github.com/newstools/2021-my-broadband/commit/159411a9e3794e344233ea2431900f4b603d3114)
##### 2021-05-16 20:30:56 by Billy Einkamerer

Created Text For URL [mybroadband.co.za/news/energy/396265-hello-darkness-my-old-friend.html]

---

# [<](2021-05-15.md) 2021-05-16 [>](2021-05-17.md)

