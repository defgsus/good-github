# [<](2021-02-16.md) 2021-02-17 [>](2021-02-18.md)

2,791,753 events, 1,390,641 push events, 2,222,740 commit messages, 175,170,957 characters


## [saitcakmak/botorch@17ad4fe55b...](https://github.com/saitcakmak/botorch/commit/17ad4fe55bae04fc590ca183ec7404c53f41926c)
##### 2021-02-17 03:10:11 by Neeraj Pradhan

Apply transform to constrain RBFKernel lengthscale in LCEMGP (#643)

Summary:
## Motivation

This adds a transform to `UniformPrior` in `LCEMGP` class to convert real values to constrained values in `[0, 2]`. Otherwise, with distribution validation enabled (which will be the default once https://github.com/pytorch/pytorch/pull/48743 is merged), this throws an error in `Uniform.log_prob` method. We were facing this issue in an internal FB test that uses botorch.

While this fixes the specific issue, my thinking is that this transform should ideally be applied automatically within `gpytorch.priors`. That said, my understanding of the codebase is very limited, so would love to hear others' thoughts on this.

### Have you read the [Contributing Guidelines on pull requests](https://github.com/pytorch/botorch/blob/master/CONTRIBUTING.md#pull-requests)?

Yes

Pull Request resolved: https://github.com/pytorch/botorch/pull/643

Test Plan:
Turned `Distribution.set_default_validate_args(True)` and succesffully ran `test_contextual_multioutput.py: ContextualMultiOutputTest.testLCEMGP` with a fixed seed and increased `maxiter` (this test fails without the fix).

cc Balandat

Reviewed By: qingfeng10

Differential Revision: D25699129

Pulled By: Balandat

fbshipit-source-id: 0485bbaa5db551fcab122119acd53549b9a5f166

---
## [Sabenator/JumpStart@8493524a51...](https://github.com/Sabenator/JumpStart/commit/8493524a515c04027e0cb85b96b55b431c77be73)
##### 2021-02-17 06:57:24 by Sabenator

Fucking redemption mod

I was using the wrong mod object itemtype. i hate my life, and i hate you.

---
## [AudeizReading/C00@588ccbc30b...](https://github.com/AudeizReading/C00/commit/588ccbc30b76c342275c2994eb58c256e779cea2)
##### 2021-02-17 16:38:31 by alellouc

Correcting my cheating -> not really cheating just a silly girl who has forgotten to delete her debug library and debug functions.... silly girl

---
## [Fargowilta/FargowiltasSouls@89e3d7ce47...](https://github.com/Fargowilta/FargowiltasSouls/commit/89e3d7ce47f813845df04cccc8900c29752505e5)
##### 2021-02-17 16:47:37 by terrynmuse

champion of life p2 buffs
 beetles fly in denser lines
 less delay between fireball barrages
skeletron, skeletron prime's guardians leave behind gores
magic missile, flamelash, rainbow rod die after 5sec in emode
golem head will stop deathray sweep if you're fighting in temple and it leaves the temple
plantera
 p1 crystal leaves no longer insta attack on spawn
 p1 periodically puts dicer mines on you
 clears spiky balls and p1 mines when going into p2
 p2 crystal leaves undulate faster
 fixed dicer mines not being able to spread through walls
tim's concoction allows black recluses to drop dangersense potions
slight dusts for devi deathrays at their origins
devi ray hearts are slightly translucent
wof ichor damage buffed to do same damage as cursed flame
fixed abom arena doing twice his contact damage
the lightning rod nerfed, does half damage when held
standardized all solar enemies to inflict on fire and burning
eater of souls, eater of worlds cursed fireballs inflict 4sec cursed inferno always
spirit champ will not despawn if you are in ug desert, even if you aren't standing in front of a bg wall
pillars only do their auras during celestial invasion (i.e. usually not when spawned with outsiders portal)
a lot of replaced dust rings/other fx with solid light rings:
 eoc p3 transition
 qb bee swarm telegraph
 deviantt shadowbeams
 wof eye vulnerability switch
 retinazer ray spin
 cultist p2 fireball ring
 ml p1 support attacks
 eridanus p2 transition
 will champ phase transitions
 earth champ phase transition
 life champ phase transition
 spirit champ hallow reflector
new shadow champ telegraph for the dashes
timber champ head has a delay after snowball rain before it moves to next attack so it doesnt track its snowballs onto you
skeltron prime p2 limb swipe glows red when they attack
low ground will un-actuate nearby platforms too

---
## [mrakgr/The-Spiral-Language@379293bed2...](https://github.com/mrakgr/The-Spiral-Language/commit/379293bed258de6a51d5bf991ceea784bc0ded86)
##### 2021-02-17 17:53:39 by Marko GrdiniÄ‡

"2:10pm. Done with breakfast and chores. Let me chill just a bit and then I will resume.

2:30pm. Let me resume. After the day is done, now that I am done with Kumo, I think I'll pick up Higurashi Gou.

2:35pm. Focus me. What is on the agenda for today?

2:40pm. Those server errors, especially the exception really bother me, but I need to leave it out of mind. I should focus on the game today.

Let's see...I have the way to serialize inputs. And I have the way to deserialize outputs. Now I have everything I need to take advantage of the net.

Let me check the email...nothing. Ok.

2:45pm. Let me turn off the damn router. Instead of programming, I've started browsing /pol/. There is never anything good there. As expected, the American civil war was a dud.

2:50pm. Let me take some time to gather my thoughts. Yesterday after my rant, I really fell into it. If ranting is what it takes to build up motivation so be it.

...This loneliness...I'll miss the journal being online after I go into the shadows.

I regret not being able to go straight to interviews. It seems I cannot do anything I mean to do straight away. I always do things through a telescope.

2:55pm. I am absolutely must do it. My skills are good enough to make these players and to make the UIs and the ML pipeline for them. What I can't do are reverse UIs. I absolutely must level that up.

Anything else, the only way to be a programmer and get paid would be to get a job. I could do games, but I am not into that even though I like playing them.

I absolutely must break into my chosen profession!

I simply must. A path is different from a job. A path is a great plan that tells you how to get all the way from a mortal to the level of the Transcendi. It allows you to continually improve without limit.

The reason why I was a weakling in school is because I did not have a path. The vast, vast majority of humans do not. Right now I have a deep foundation in programming, but I need just one - just one more skill in order to get tangible benefits off this!

I need to master UI automation.

I've gone beyond languages with Spiral. But what I need to do next is to go beyond the OS. I need to virtualize it and serve it to my agents on a platter. I need to grant them freedom within a cage of my own design.

After that, I will be a fully fledged rank 5.

Yeah, it is absurd. I cannot call myself the appex of humanity when I do not have the ability to make even single cent. A true programmer should be able to make money whenever he needs it. It should come to him as a consequence of his own self development.

3pm. So focus on this me. Let me get the random agent to work on Leduc poker. Then I'll make the UI for that so that I can play against it. Then comes the agent training. Then comes the same for HU NL Holdem.

After I have that, I am good to go.

3:05pm. I'll feel better after I am at the point where I am training agents on HU NL Holdem.

I'll have DREAM, the UI for the game, and the training pipeline done.

I think all of this should be doable by the end of next month at most. It should not take more that a few weeks. I can do it, if I apply myself. I can get all the pieces (except the reverse UI) done in the next few weeks.

At that point I will have strong agents at the game of my choosing.

It is at that point that I can let myself feel freedom again. I can track down those language bugs, I can work on the reverse UI, I can do the faux job applications, I can write articles for the ML sub.

3:15pm. I'll have time. While the agents are doing their own thing, the last thing I'd want is distrupt them.

I need to graduate from constantly programming myself. No more of running the agent for 5m and then trying something else. I'll make a proper ensemble and the winner of that. I'll do that thing Hinton suggested with in the Dark Knowledge video which is have the ensemble generate the labels. I'll train an ensemble on the side, but the actual player will be a singleton. Maybe I'll even run it on the CPU.

I always feel the fatigue, lethargy and inertia. Let me try to get something done today in order to overcome it.

Let me make an abstract agent first.

3:40pm. I am having some ideas. Let me roll them in my mind.

Now that I have the sparse serializer, how would I go about making the perfect hash function for Dudo'd game tree?

3:45pm. Forget the perfect hash function. It would take too much effort. Game trees are too complex for the sparse serializer to deal with. Though if it is just Leduc or Dudo, I could do it. That would enable me to sidestep the difficulty of making dictionaries. And I would get excellent tabular performance.

I'll keep the idea in mind, but nevermind it for now.

For very complex games I could always codegen it. But very complex games would have too much to fit into memory anyway.

3:50pm. Ok, let me write down what my thoughts are lingering on.

I've been thinking about policy gradient training, and then started wondering what I should do if instead of sampling like in MC training I instead enumerated the game tree like in CFR. I realized that I would not need the value network in that case. I would be able to get perfect reward distribution in that case, wouldn't I?

For some reaosn despite having that small poker game last time, something like this never occured to me. But this is the logical first step. Before sampling, I should be able to do an PG agent that enumerates. Then I can use that as the basis to implement proper CFR and compare it with PG training.

I could control for network parameters and get an unbiased comparison of the benefits of different kinds of training.

3:55pm. But if I want to play against the random agent, I need sampling. Definitely.

These are two different ways of traversing the game tree. I am going to need different code for both.

For taking samples from Numpy arrays for example, I think I will just convert them into PyTorch tensors and then into a categorical distribution.

This way will be easier than doing my own sampling function.

Though, doing it on my own would be faster. So why don't I import it?

...Ah, but then I need the random number generator. And that would slow things again.

No, forget it. I'll do it as PyTorch wills it.

...Let me turn on the router. Let me take a short break and I will see if Cython has anything for RNG.

Actually, I remember something being in the Numpy docs about that.

4:30pm. I just wanted some time to think. Let me take a look at Cython random numbers.

The Cuda sampling function that I once did for old Spiral took a lot of effort to make so I do not want to repeat that effort.

https://scicomp.stackexchange.com/questions/3206/random-number-generation-from-cython

https://stackoverflow.com/questions/16138090/correct-way-to-generate-random-numbers-in-cython

> Oh, apparently msvc's is 2**15-1. That's awful.

http://hplgit.github.io/teamods/MC_cython/main_MC_cython.html

https://groups.google.com/forum/#!topic/cython-users/9UGMi_b3tVo

> The topic of random number generation seems to come up pretty frequently. The usual responses mainly seem to suggest using GSL or Numpy's Cython code.

https://github.com/twiecki/CythonGSL

Ah, this is not the same as the C standard library.

I'll go with the Numpy stuff.

```
cdef np.ndarray[np.int_t,
                ndim=2,
                negative_indices=False,
                mode='c'] eyes = \
                np.random.random_integers(1, 6, (N, ndice))
```

Ah, see what they are doing here. But I am doing all my indexing with unsigned ints so that should not matter.

https://github.com/Noctem/cyrandom

Here is a fast random package. Enough of this.

This won't be an overhead. I just wanted to make a tour.

https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html

```py
>> np.random.choice(5, 3, replace=False)
array([3,1,0]) # random
>> #This is equivalent to np.random.permutation(np.arange(5))[:3]
```

The stuff here is pretty powerful.

Let me play with it a bit.

```
import numpy as np
q = np.array([1,2,3,4,5])
np.random.shuffle(q)
q
```

Ok, I have the shuffle down.

```
np.random.randint(1,3,3)
```

Here is how to generate random ints. What about floats?

```
np.random.rand()
```

This creates number in the [0,1) range.

It can also create arrays of the specified shape.

How do I copy an array?

```
q = np.array([1,2,3,4,5])
q2 = np.copy(q)
np.random.shuffle(q2)
print(q,q2)
```

I should make use of these functions. Since Cython supports Numpy I might as well take advantage of it.

There is no need to trouble myself too much over this.

5pm. Ok...a part of programming simply getting use to basic tools. Here I am getting used to numpy. Some things are rare, but other things are always used.

Forget how I implemented the sampling function last time. Forget the Cuda stuff. That should not even be a minute concern. I do not need to think about making things generic. If I want to port this code to the C backend, I will take care of that then. I do not need to think about adding SML modules to the language in order to make things better.

Let me make a sampling traversal through the first game.

```
inl game {sample_all draw action terminal} = join
```

Focus me. Implement these 3.

Ok, sample all.

```
array card -> (card -> 'a) -> 'a
```

Its type is this. Focus me.

```
inl sample_all forall k. (dist : array k) next =
    inl x = $"numpy.random.choice(!dist)" : k
    next x
```

This first one is easy enough. I won't bother keeping track of observations just yet.

```
inl sample_all forall k. (dist : array k) next = next ($"numpy.random.choice(!dist)" : k)
```

Even like so, things are still fairly abstract. I can wrap around the next and do my magic that way.

Let me do the next. I am starting to get into it now.

Next is draw.

```
u8 -> array card -> (card * array card -> 'a) -> 'a
```

So it takes in a player and then samples with replacement.

For the abstract version, I won't bother with the player id.

```
np.array([1,2,3,4])[1:]
```

No, this is not good. Shuffling it, taking the first one, and then taking the tail is just spew.

https://stackoverflow.com/questions/19286657/index-all-except-one-item-in-python

```
a = np.arange(9, -1, -1)     # a = array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])
b = a[np.arange(len(a))!=3]  # b = array([9, 8, 7, 5, 4, 3, 2, 1, 0])
```

No wait. This is not good. This would create a range and then filter it. What the hell.

```
inl draw forall k. (dist : array k) next =
    inl len = a64.length dist
    inl i = $"np.random.randint(0,!len)" : u64
    inl x = a64.index dist i
    inl dist = a64.init (len-1) (fun i' => a64.index dist (if i <= i' then i'+1 else i'))
    next (x, dist)
```

This should suffice for draw.

Now what is next?

```
u8 -> array action -> (action -> 'a) -> 'a
```

This one is action.

This one will be a straight up sample.

Focus me. What is next?

```
u8 * u32 -> 'a
```

The terminal. This one I will skip in sampling traversal.

Now let me do an enumerating traversal.

5:30pm. Ah, no. Enumeration I might not necessarily want to abstract away. There isn't much useful work to be done.

```
inl sample_all forall k. (dist : array k) = $"numpy.random.choice(!dist)" : k
inl draw forall k. (dist : array k) =
    inl len = a64.length dist
    inl i = $"np.random.randint(0,!len)" : u64
    inl x = a64.index dist i
    inl dist = a64.init (len-1) (fun i' => a64.index dist (if i <= i' then i'+1 else i'))
    x, dist
inl action forall k. (dist : array k) =
    inl len = a64.length dist
    inl i = $"np.random.randint(0,!len)" : u64
    a64.index dist i

inl main () = ()
```

Let me modify the stuff here. I do not need the next.

```
inl action forall k. (dist : array k) =
    inl len = a64.length dist
    inl i = $"np.random.randint(0,!len)" : u64
    a64.index dist i
```

Ah, what am I doing. The action is the same as the sample here.

Let me take a look at the other game.

It seems the server crashed.

```
inl game forall r. {sample action_response action_init terminal} : r = join
```

This one also has sample and action. Since I am not keeping track of histories, that is a given.

5:40pm. I am thinking of doing some functions that I do not need. Focus me.

5:45pm. I have this abstract agent as a goal, but nothing is coming to me.

Forget abstract. Focus on the concrete. I'll abstract when I notice the patterns.

Random player, random player...think about the random player.

...I am thinking about the binary search. Think about the player.

I have sample and draw right now. I have everything I need to implement the random player. Let me start a module that is Leduc test.

```
inl main() = ()
```

First, let me create the net.

```
inl main() =
    !!!!Import("torch")
    !!!!Import("torch.nn")
    !!!!Import("torch.distributions")
    !!!!Import("nets")
    inl nets_small (c,b,a : u64 * u64 * u64) : net = $"nets.small(!c,!b,!a)"
    inl dims = {
        intro = serialization.dense.array.size PlayerView
        mid = 32
        out = serialization.sparse.int.size Action
    }
    inl input =
        {stack_self=(MaxStack-1)/2; stack_opp=(MaxStack-1)/2; pot=MaxStack-1; hand=(0,1),(12,3)}
        |> serialization.dense.array.serialize PlayerView
    inl net = nets_small (dims.intro, dims.mid, dims.out)
    inl dist = forward net (fromSerialized input) |> categorical
    inl x = sample dist
    open serialization.sparse.int
    match deserialize Action (serialized $"!x.item()") with
    | Raise: x => $"f\"Raise: {!x}\""
    | Call => $"f\"Call\""
    | Fold => $"f\"Fold\"" : string
```

I already did that thing here. Let me take this apart.

Now, I need to think about the inputs. The actual inputs to the net.

I have actions and cards.

6pm. Now I am obsessed with how to do masking when doing PG training. I just can't seem to do anything in proper order.

6:05pm. Think about it, how do I readjust the index. I had this problem and its solution while thinking about how to generalize draw.

But for that I need the masked out values.

Can I project out the value backwards.

```
f[x] = 0
f[y] = 1
f[z] = 2
```

Therefore...

```
f[0] = x
f[1] = y
f[2] = z
```

It is actually super easy!

I just have to index back into original permuations array.

For an array of actions, all I will do is serialize them to ints.

`;[Call;Fold]` would be `;[3;4]`. I'll use that as indices into the output of the final layer and project that to a new tensor that has 2d. I'll turn that intro a distro, sample from it, and index back into the permuation array and recover the original index. Then I can deserialize it.

This is great!

6:10pm. Ok. I see how to do training. In my own game, the one in the old Spiral I mean, I did not need to apply a mask.

6:40pm. Had to take a break.

I am still thinking about it. Right now I am thinking how to process inputs. Let me stop here as I am hungry.

I really meant to get the random agent done today, but given the hour, that is not going to be happening. Now that I've planned it out, I should do it at my own leisure tomorrow.

I've thought about how to do the game, and various aspects of it.

I'll separate that from what should come in and out of the network itself.

First I will take care of the net. Then I will take care of integrating it with the game itself.

By take care of the net, I want to make a function that takes in a net and returns a function that takes in a tensor and returns the output action. I also want to make a function that takes in the input, processes it and maps it to a tensor.

So what I need to do is make a function that takes in a net, takes in a trace of observation and produces the output action. That is what is truly important. Let me stop here."

---

# [<](2021-02-16.md) 2021-02-17 [>](2021-02-18.md)

