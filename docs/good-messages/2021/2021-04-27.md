# [<](2021-04-26.md) 2021-04-27 [>](2021-04-28.md)

3,171,519 events, 1,595,707 push events, 2,543,089 commit messages, 193,595,218 characters


## [Official-Ayrton990/android_kernel_xiaomi_sm8250](https://github.com/Official-Ayrton990/android_kernel_xiaomi_sm8250)@[4fbd718004...](https://github.com/Official-Ayrton990/android_kernel_xiaomi_sm8250/commit/4fbd718004e04c79ac9642d6b136ed3a3278b853)
#### Tuesday 2021-04-27 00:47:05 by Peter Zijlstra

sched/core: Fix ttwu() race

Paul reported rcutorture occasionally hitting a NULL deref:

  sched_ttwu_pending()
    ttwu_do_wakeup()
      check_preempt_curr() := check_preempt_wakeup()
        find_matching_se()
          is_same_group()
            if (se->cfs_rq == pse->cfs_rq) <-- *BOOM*

Debugging showed that this only appears to happen when we take the new
code-path from commit:

  2ebb17717550 ("sched/core: Offload wakee task activation if it the wakee is descheduling")

and only when @cpu == smp_processor_id(). Something which should not
be possible, because p->on_cpu can only be true for remote tasks.
Similarly, without the new code-path from commit:

  c6e7bd7afaeb ("sched/core: Optimize ttwu() spinning on p->on_cpu")

this would've unconditionally hit:

  smp_cond_load_acquire(&p->on_cpu, !VAL);

and if: 'cpu == smp_processor_id() && p->on_cpu' is possible, this
would result in an instant live-lock (with IRQs disabled), something
that hasn't been reported.

The NULL deref can be explained however if the task_cpu(p) load at the
beginning of try_to_wake_up() returns an old value, and this old value
happens to be smp_processor_id(). Further assume that the p->on_cpu
load accurately returns 1, it really is still running, just not here.

Then, when we enqueue the task locally, we can crash in exactly the
observed manner because p->se.cfs_rq != rq->cfs_rq, because p's cfs_rq
is from the wrong CPU, therefore we'll iterate into the non-existant
parents and NULL deref.

The closest semi-plausible scenario I've managed to contrive is
somewhat elaborate (then again, actual reproduction takes many CPU
hours of rcutorture, so it can't be anything obvious):

					X->cpu = 1
					rq(1)->curr = X

	CPU0				CPU1				CPU2

					// switch away from X
					LOCK rq(1)->lock
					smp_mb__after_spinlock
					dequeue_task(X)
					  X->on_rq = 9
					switch_to(Z)
					  X->on_cpu = 0
					UNLOCK rq(1)->lock

									// migrate X to cpu 0
									LOCK rq(1)->lock
									dequeue_task(X)
									set_task_cpu(X, 0)
									  X->cpu = 0
									UNLOCK rq(1)->lock

									LOCK rq(0)->lock
									enqueue_task(X)
									  X->on_rq = 1
									UNLOCK rq(0)->lock

	// switch to X
	LOCK rq(0)->lock
	smp_mb__after_spinlock
	switch_to(X)
	  X->on_cpu = 1
	UNLOCK rq(0)->lock

	// X goes sleep
	X->state = TASK_UNINTERRUPTIBLE
	smp_mb();			// wake X
					ttwu()
					  LOCK X->pi_lock
					  smp_mb__after_spinlock

					  if (p->state)

					  cpu = X->cpu; // =? 1

					  smp_rmb()

	// X calls schedule()
	LOCK rq(0)->lock
	smp_mb__after_spinlock
	dequeue_task(X)
	  X->on_rq = 0

					  if (p->on_rq)

					  smp_rmb();

					  if (p->on_cpu && ttwu_queue_wakelist(..)) [*]

					  smp_cond_load_acquire(&p->on_cpu, !VAL)

					  cpu = select_task_rq(X, X->wake_cpu, ...)
					  if (X->cpu != cpu)
	switch_to(Y)
	  X->on_cpu = 0
	UNLOCK rq(0)->lock

However I'm having trouble convincing myself that's actually possible
on x86_64 -- after all, every LOCK implies an smp_mb() there, so if ttwu
observes ->state != RUNNING, it must also observe ->cpu != 1.

(Most of the previous ttwu() races were found on very large PowerPC)

Nevertheless, this fully explains the observed failure case.

Fix it by ordering the task_cpu(p) load after the p->on_cpu load,
which is easy since nothing actually uses @cpu before this.

Fixes: c6e7bd7afaeb ("sched/core: Optimize ttwu() spinning on p->on_cpu")
Reported-by: Paul E. McKenney <paulmck@kernel.org>
Tested-by: Paul E. McKenney <paulmck@kernel.org>
Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Signed-off-by: Ingo Molnar <mingo@kernel.org>
Link: https://lkml.kernel.org/r/20200622125649.GC576871@hirez.programming.kicks-ass.net
Signed-off-by: Adam W. Willis <return.of.octobot@gmail.com>

---
## [applewood524/applewood524](https://github.com/applewood524/applewood524)@[0977b8d848...](https://github.com/applewood524/applewood524/commit/0977b8d8489b3c16329ba0fc45d2fd490c080be8)
#### Tuesday 2021-04-27 00:56:46 by Galaxy Song

Update readme

It's easy to find people promising everything and delivering almost nothing.
My major strengths are in giving realistic promises, being responsive and responsible, concentrating on business needs and communications. So I am not a pure geek thinking about technology only but, first of all, a making-things-happen person.

About me:
A Software engineer.
Senior Developer with over 15 years of experience in developing web applications.
Expertise is handling end-to-end projects

Programming skills include:

Blockchain: 3 years of experience
Laravel: 7 years of experience
MERN stack: 5 years of experience
WordPress: 5 years of experience
... ... ...

Other skills include API integrations in a system like Blockchain, Social network APIs, Payment Gateway APIs (Stripe,Authorize.NET, CCAvenue, Paypal)
Why choose me over my competitors:
Warranty for applications I’ve developed if they are unmodified.
Creative, thoughtful, reliable, responsive, and responsible.
Always available via freelancer platform. You can expect me answering you ASAP, thinking about your needs, giving suggestions and helping you.
My price is pretty affordable for a Senior Developer.
Ready to introduce you to my clients of previous projects so you can learn more about me from them by asking them how they felt i delivered on their projects.
I have a team of developers around who are ready to work on complex projects. Thus, specialization, quality, and team expansion are not issues at all.

---
## [applewood524/applewood524](https://github.com/applewood524/applewood524)@[883757ca50...](https://github.com/applewood524/applewood524/commit/883757ca503548ef3b4f5d948e63cd3857dc9b5a)
#### Tuesday 2021-04-27 01:00:01 by Galaxy Song

update

It's easy to find people promising everything and delivering almost nothing.
My major strengths are in giving realistic promises, being responsive and responsible, concentrating on business needs and communications. So I am not a pure geek thinking about technology only but, first of all, a making-things-happen person.

About me:

A Software engineer.

Senior Developer with over 15 years of experience in developing web applications.
Expertise is handling end-to-end projects

Programming skills include:

Blockchain: 3 years of experience

Laravel: 7 years of experience

MERN stack: 5 years of experience

WordPress: 5 years of experience

... ... ...

Other skills include API integrations in a system like Blockchain, Social network APIs, Payment Gateway APIs (Stripe,Authorize.NET, CCAvenue, Paypal)
Why choose me over my competitors:
Warranty for applications I’ve developed if they are unmodified.
Creative, thoughtful, reliable, responsive, and responsible.
Always available via freelancer platform. You can expect me answering you ASAP, thinking about your needs, giving suggestions and helping you.
My price is pretty affordable for a Senior Developer.
Ready to introduce you to my clients of previous projects so you can learn more about me from them by asking them how they felt i delivered on their projects.
I have a team of developers around who are ready to work on complex projects. Thus, specialization, quality, and team expansion are not issues at all.

---
## [applewood524/applewood524](https://github.com/applewood524/applewood524)@[e25ca9775a...](https://github.com/applewood524/applewood524/commit/e25ca9775abc507ebe5cafeb8dc487472a8ed31e)
#### Tuesday 2021-04-27 01:02:04 by Galaxy Song

update

It's easy to find people promising everything and delivering almost nothing.

My major strengths are in giving realistic promises, being responsive and responsible, concentrating on business needs and communications. 

So I am not a pure geek thinking about technology only but, first of all, a making-things-happen person.

---------------------------------------------------------------------------------------------------------------------------------------------

About me:

A Software engineer.

Senior Developer with over 7 years of experience in developing web applications.

Expertise is handling end-to-end projects

Programming skills include:

Blockchain: 3 years of experience

Laravel: 7 years of experience

MERN stack: 5 years of experience

WordPress: 5 years of experience

... ... ...

---------------------------------------------------------------------------------------------------------------------------------------------

Other skills include API integrations in a system like Blockchain, Social network APIs, Payment Gateway APIs (Stripe,Authorize.NET, CCAvenue, Paypal)
Why choose me over my competitors:
Warranty for applications I’ve developed if they are unmodified.
Creative, thoughtful, reliable, responsive, and responsible.
Always available via freelancer platform. You can expect me answering you ASAP, thinking about your needs, giving suggestions and helping you.
My price is pretty affordable for a Senior Developer.
Ready to introduce you to my clients of previous projects so you can learn more about me from them by asking them how they felt i delivered on their projects.
I have a team of developers around who are ready to work on complex projects. Thus, specialization, quality, and team expansion are not issues at all.

---
## [jidongfang/pelikan](https://github.com/jidongfang/pelikan)@[98a56533c7...](https://github.com/jidongfang/pelikan/commit/98a56533c7d7a6a5120fca6d8aa0ff82b8a5bab9)
#### Tuesday 2021-04-27 04:11:34 by Jonathan D. Simms

CDB with an FFI-friendly implementation

straight copy-pasta of src/server/{twemcache => cdb}

checkpoint - squash

remove flag

checkpoint

create cdb workspace so shared libs link properly

gah i need someone who knows cmake

failling, about to try rando CMakeRust module

got further with this Rust macro stuff

omg, actual progress

oops, add the macros

rearrange and clean up dependencies

clean up cruft

compiles and links on debian

beginning pelikan side of integration

checkpoint

generate both static and shared targets

shared library building ftw?

this is fine.

checkpoint - string still getting truncated

fix build

check

try and fix build

debugging cmake vars

checkpoint

hi wil

revert

change to system calling scheme, no diff

finally seems to have linked properly

checkpoint

checkpoint

ignore cdb files

squash

add compile_commands.json to gitignore

squash

squash

remove redundant return

hook up cdb_get, munge a response and cleanup

missed two places for raw_val

need to rework storage strategy

shit, revert this mess

Revert "shit, revert this mess"

This reverts commit e369bd7769281393c38f50119f3b650890ed294a.

gahhhhhh

ugh, this is sketchy

bindgen is compiling and linking

compiles again, finally

---
## [pankajsharmacs18/hackerrank](https://github.com/pankajsharmacs18/hackerrank)@[1857b465af...](https://github.com/pankajsharmacs18/hackerrank/commit/1857b465af28414dd0f46b6fba6e70c45d9fb83b)
#### Tuesday 2021-04-27 08:03:34 by pankaj sharma

https://www.hackerearth.com/practice/basic-programming/input-output/basics-of-input-output/practice-problems/algorithm/vowels-love/

Problem
Bob's crush's name starts with a vowel. That's the reason Bob loves vowels too much. He calls a string "lovely string" if it contains either all the lowercase vowels or all the uppercase vowels or both, else he calls that string "ugly string". 

For more clarification, see the sample testcase explanation.

Input

First line contains T, the number of test cases.
Next T lines contain a single string S.

Output

For each test case, print "lovely string" or "ugly string"  (without quotes)  according to the definition of Bob.

Constraints

string contains only lowercase and uppercase Latin letters. 



Sample Input
3
omahgoTuRuLob
OmAhgotUrulobEI
aeKORONAoiBATCHu
Sample Output
ugly string
lovely string
lovely string
Time Limit: 1
Memory Limit: 256
Source Limit:
Explanation
In first string, neither all five lowercase vowels are present nor all five uppercase vowels.

In second string, all five uppercase vowels are present.

In third string ,  all five lo

---
## [PDP-10/its](https://github.com/PDP-10/its)@[ebac4198bd...](https://github.com/PDP-10/its/commit/ebac4198bd260d8e166c3a734f5bcc5c788ebc45)
#### Tuesday 2021-04-27 09:49:26 by Lars Brinkhoff

6502 assembler written in Logo.

Courtesy of the author, Leigh Klotz.

Klotz wrote in https://news.ycombinator.com/item?id=23064346

> The assembler [for Apple II Logo] was already chosen, probably by
> Steve Hain or Gary Drescher.  I believe it was CROSS.  It annoyed me
> that I would get phase errors if I edited during the first pass
> which was like 10 or 15 minutes at night so I wrote a one-pass
> assembler in MacLisp, but it was slower to finish than the first
> pass of CROSS so I translated it to Logo and Hal said to put it on
> the utilities disk.  I can't remember who added .output and .input
> but Logo had had them before the Apple II, I think 11Logo had it.

---
## [chklauser/prx](https://github.com/chklauser/prx)@[b09047bf3a...](https://github.com/chklauser/prx/commit/b09047bf3acbeeede2776e9ac3d4666bb493232d)
#### Tuesday 2021-04-27 11:05:22 by Christian Klauser

PRX-49 Dot-separated meta values

This PR is a BREAKING with regards to how `.<identifier>` is parsed globally (namespaced names, but also member access). Previously, there was a lexer-level hack that issued multiple tokens when `.<identifier>` was recognized. This has two problems:

 1. you can't put noise (whitespace) between the dot and the identifier. Not that anyone should ever do this, but Prexonite Script follows the general convention that you can put whitespace pretty much everywhere
 2. it fails miserably if you need to do `.$"identifier with spaces"`. This requires state tracking. And while the lexer _does_ support state transitions, this stuff should be handled by the parser if we want to keep the lexer sane.

With this PR, we now explicitly allow pretty much all identifiers and keywords following immediately on a dot. While I was initially a bit reluctant to give up all of that nice "design real-estate" (I mean `.this`, `.new`, `.as` could be used in interesting ways), we don't really control the libraries that Prexonite Script wants to call into. And reserving words that are pretty common identifiers in C# sounds like a bad idea (e.g., `.And`)

The PR also tweaks how meta data entries are represented to make use of the new dot-separated format. As an adjacent change, we now also render version numbers without quotes (and by extension "real" numbers). All of these are stored as text anyway.

Also:
 - Automatically generate `Resources.Designer.cs` (to not depend on Visual Studio)
 - Update PSR 2 to use dot-separated module names

---
## [VickeTrossing/kekbook](https://github.com/VickeTrossing/kekbook)@[60a116a0b8...](https://github.com/VickeTrossing/kekbook/commit/60a116a0b8d033df355197c642aeb7475a9c6628)
#### Tuesday 2021-04-27 11:23:30 by VickeTrossing

firebase added, some fetch stuff added. Can now post a status. Still problems with the god DAMNED CSS WHY IS IT SO FUCKING IMPOSSIBLE

---
## [Criamos/oeh-search-etl](https://github.com/Criamos/oeh-search-etl)@[21850a3d8e...](https://github.com/Criamos/oeh-search-etl/commit/21850a3d8e1ad149b2c31f008118c103597fee2c)
#### Tuesday 2021-04-27 13:03:12 by Criamos

remember kids: sourceID != sourceId

(I've wasted how many goddamn hours of troubleshooting because of this goddamn typo?)

---
## [vvchauit/vvchauit](https://github.com/vvchauit/vvchauit)@[195a744ef7...](https://github.com/vvchauit/vvchauit/commit/195a744ef722a588e57e779e92e8a42ed53cbd3c)
#### Tuesday 2021-04-27 13:09:01 by VAN CHAU

Predictive Analytics: The Power to Predict Who Will Click, Buy, Lie, or Die

Q & A with Author Eric Siegel
Did Nate Silver use predictive analytics to forecast Obama's 2012 election?
No—but Obama did use predictive analytics to help get elected. Nate Silver made election forecasts for each state as a whole: which way would a state trend, overall? In the meantime, the Obama campaign was using predictive analytics to render per-voter predictions. Moving beyond forecasting, true power comes in influencing the future rather than speculating on it—the raison d'être of predictive analytics. Nate Silver publicly competed to win election forecasting, while Obama's analytics team quietly competed to win the election itself. Specifically, team Obama drove per-voter campaign decisions by way of per-vote predictions.

Why does early retirement predict a shorter life expectancy & why do vegetarians miss fewer flights?
These are two more colorful examples of the multitudes of predictive discoveries waiting within data.

University of Zurich discovered that, for a certain working category of males in Austria, each additional year of early retirement decreases life expectancy by 1.8 months. They conjecture that this could be due to unhealthy habits such as smoking and drinking following retirement.

One airline discovered that customers who preorder a vegetarian meal are more likely to make their flight, with the interpretation that knowledge of a personalized or specific meal awaiting the customer provides an incentive, or establishes a sense of commitment.

Predictive analytics seeks out such predictive connections and then works to see how they may combine together for more precise prediction.

What are the hottest trends in predictive analytics?
There have been many exciting improvements in the core technology of predictive analytics. One is "uplift modeling" (a.k.a. "persuasion modeling"), which predicts influence. ..in order to do influence. The Obama campaign used it to influence voters in the 2012 presidential election; marketing uses it to more adeptly persuade customers; and medicine uses it to better select per-patient treatments. This topic is the focus of the final chapter of this book.

Another hot trend is ensemble models. Like the collective intelligence that spawns the wisdom of a crowd of people, we see the same effect with a crowd of predictive models. Each model alone may be fairly primitive such as a few simple rules, so it gets prediction wrong a lot, as an individual person trying to predict also does. But have them come together as a group and there emerges a new level of predictive performance.

Does the NSA use predictive analytics, and how does that impact the amount of data collected on us?
It's a foregone conclusion that the world's largest spy organization employing the world's largest number of Ph.D. mathematicians considers predictive analytics a strategic priority. Predictive analytics realizes a great potential for law enforcement: The automatic discovery of new suspects. The value of this capability multiplies the incentive to collect increasing amounts of data about civilians. The NSA needs data about everyone, including those of us with no connection to crime whatsoever—not to spy on us but to establish a quantitative baseline. This in turn only amplifies the stakes of the contentious security-versus-privacy debate.

What is the coolest thing predictive analytics has done?
One of the most inspirational accomplishments of predictive analytics is IBM's "Jeopardy!"-playing Watson computer, which triumphed against the all-time human champions on the TV quiz show. The questions can be about most any topic, are intended for humans to answer, and can be complex grammatically. It turns out that predictive modeling is the way in which Watson succeeds in determining the answer to a question: it predicts, "Is this candidate answer the correct answer to this question?" It knocks off one correct answer after another—incredible.

What are companies predicting about me as a customer?
Here are just a few examples:

- Facebook predicts which of 1,500 candidate posts (on average) will be most interesting to you in order to personalize your ordered news feed.

- Microsoft helped develop technology that, based on GPS data, accurately predicts one's location up to multiple years beforehand.

- Target predicts customer pregnancy from shopping behavior, thus identifying prospects to contact with offers related to the needs of a newborn's parents.

- Tesco (UK) annually issues 100 million personalized coupons at grocery cash registers across 13 countries. Predictive analytics increased redemption rates by a factor of 3.6.

- Netflix sponsored a $1 million competition to predict which movies you will like in order to improve movie recommendations.

- One top-five U.S. health insurance company predicts the likelihood an elderly insurance policy holder will die within 18 months in order to trigger end-of-life counseling.

---
## [GerHobbelt/developer-utility-commands](https://github.com/GerHobbelt/developer-utility-commands)@[e4b77335e7...](https://github.com/GerHobbelt/developer-utility-commands/commit/e4b77335e7030d261e89aefbce66cf9bce587285)
#### Tuesday 2021-04-27 14:55:45 by Ger Hobbelt

added git_bump_version and git_tag utility scripts to help work on libraries / npm packages: bump the version by a patch number (format: major.minor.revision-PATCH) and git_tag invokes git to pick the version from package.json and tag the repository with it to mark a release.

updated a few utility scripts which concern themselves with submodules -- these are used to manage the libraries_of_interest repo, for example, but these are generic scripts which can be used on any repo.

update/fixes for various git and node/npm utility scripts

updated git_pull_push.sh script to include the base repo/directory in the progress reports: always know where we are at...

checking in some long pending work on the utility scripts: some typos, corrections and the augmentation where the add-remotes script accepts copy-pasted-from-the-internet text files (and extracts the github forks' info from them) next to the cleaner `meta` file format (which is what you get when you rip that file as it travels from github to our own web browser when you view&refresh the forks timeline chart/graph on github for a given project)

quick patch to the git_pull_push.sh script to process only the current repository and its top level asubmodules.

made the npm global package install utility scripts work again for latest node+npm

`git_pull_push.sh -c` fixed git commands which reported incorrect use of their `--prune` argument

`util/collect_git_checked_out_branch_recusively.sh` and the resulting `util/checkout_to_known_git_branches_recursive.sh`: fixed the `-c` restore action command and improved the `-l` list command: now registered git commit positions for each submodule *should* be recoverable without too much fuss -- assuming we've run the `util/collect_git_checked_out_branch_recusively.sh` command with these new script revisions, of course.

reran the git submodule commit snapshot script once again -- this script has been written to register the exact git commit/branch positions at the time of execution to 'snapshot the current overall project state' into a bash shell script. We do this because `git submodule update` isn't always what you want and this gives us total control over the git repositories when we need/wish to rewind them to a 'previously known state', e.g. when we execute a release deploy process, which is when we should note the exact git repo positions at the time so that we can rewind to that position later when we have to diagnose specific problems of that software release.

      The command:

      ```
      $ util/collect_git_checked_out_branch_recusively.sh
      ```

Note that it is run *without* the `--recursive` flag: I use that variant for registering the 'libraries of interest' internal state of all the registered public submodules; we only use the 'flattened' library code which resides in `/lib/_/...` directories so that currently all relevant repositories for any software release are 1 level deep at the `environment_root` repository, hence we can run the script far more quickly by not having to add `--recursive` when we 'snapshot' the 'deploy state' in `environment_root`.

fix important bug in generic `link_path.sh` shell script which was discovered while working with Alexander (@trousev) on deploying the new website on my Windows dev box: the command `../../../util/link_path.sh frontend ../../v2/frontend` failed to deliver when running in the `server/v3/htdocs` directory: it turned out the built-in 'heuristics' to determine which directory name in the source/reference path spec should become the symbolic link / junction was not smart enough: it produced this command, which naturally failed: `MKLINK D "." "..\..\v2"`

fix/tweak the util/link_path.sh shell script which provides a cross-platform symlink setup facility: now it will accept two paths based on the current working directory. (Fix required in conjunction with the deploy scripts in server/v3/ )

added bash scripts to sample the current git commit hash for each submodule (non-recursive) and generate a shell script containing these so that running the generated script *restores* the git commits for each of these submodules: this work is done to 'snapshot releases' in a deterministic way without depending on the rather hairy git submodule + git commit mechanics.

fixed git submodule add script: adjusted owner URI to also work correctly with repositories we own ourselves.

bugfix: openssl does not correctly pick up the default_days configuration value: again using the openssl `-days` option to fix this.   Grmbl.

added (untested) mk_sni_server_cert.sh ssl tool script to mimic the mk_client_cert.sh one, but now for 'Special Needs' SNI/SSL-based sites which require their own certificate. This is in anticipation of using EV SSL certificates in an SNI setting on the production server, once this 'special needs' approach has been verified to work (and it should generate proper CSRs (certificate request files) to send to paid-service CAs (StartSSL, Comodo, et al).

adapted the SSL scripts and Apache SSL conf file to ensure that Chrome receives the entire server certificate *chain* during the SSL handshake. This fixes the Chrome NET::ERR_CERT_AUTHORITY_INVALID nasty scare pages when loading accessing our test server nodes' sites. (At least partly! You need the *combo* of this *and* the bit in keys-and-certificates/WARNING.md to make it really happen!)

    Copy/pasta from WARNING.md:
    --------------------------

    Client Certificates Special Notes
    ---------------------------------

    The client certificates which are generated by running the initial PKI setup script `util/ssl_cert_tools/init_PKI_directory_tree.sh` or at a later time through running `util/ssl_cert_tools/mk_client_cert.sh` produce, among other formats, a PKCS12 file in the `22_client_CA/newcerts/\<username\>/private/clientcert.p12` file.

    When you *import* this file in your browser, it will automatically include the CA certificate chain, including the MBH ROOT CA certificate. This comes in handy as importing the client PKCS12 certificate file *should* immediately help counter, as a side effect, the rejection of the 'untrusted' *server* certificate which we generate through another CA chain, but rooted at the same MBH ROOT CA.

    *However*, it turns out that this does not work without some very careful attention to a very obscure detail: Chrome **must be restarted** to make it work. This is described in the answer at http://superuser.com/questions/830506/self-signed-certificate-is-not-appearing-in-chrome-after-importing/830926#830926 and took me a heck of a long time to find (previously I didn't have the problem, or so it seemed, until I went and cleaned up my entire SSL certificate store on the test machine before running another test series from scratch :-( ). The *crucial* bit:

    > [...] Upon inspection it sees that the certificate has been issued by a particular Certification Authority. [...]
    >
    > Upon doing this I closed Chrome using the `X` button. That didn't work. I did this a couple more times, and **then I used the Chrome "Exit" menu**. This worked! So lesson learned... `X` does not necessarily restart Chrome.
    >
    > This is now resolved!

    The moral of the story: after you have imported your client certificate, and *okay*-ed the dialog box which tells you that you are importing an 'untrusted' **root certificate** as well, you MUST "Exit" Chrome and restart it. Without the restart, the MBH test websites will load but throw nasty Chrome NET::ERR_CERT_AUTHORITY_INVALID error pages which are very confusing and *wrong* - once you have added the MBH ROOT CA to the Trusted Root CA store.

    ---

    See MBH/environment_root::documentation/Working.with.SSL.certificates/How.to.install.your.SSL.client.certificate.html for how to install a client certificate in your browsers.
    (TBD)

encoded all SSL certificate production into shell scripts: now `util/ssl_cert_tools/init_PKI_directory_tree.sh` will generate a complete SSL root CA + 2nd level CAs + dedicated subCAs + server certs + client certs directory layout in `__local_key_store__/keys-and-certificates/` including extract/prep code which produces a set of SSL files (certificates, chains, revocation lists, etc.) that go with our `ssl-vhosts-bulk.conf` SSL Bulk Virtual Hosting Apache configuration (which employs a SAN certificate to make it all work)

All generated certificates are restricted in use, i.e. cannot be used for other purposes than the ones indicated (to compare: our old 'client certificates' were (1) self-signed, and (2) would serve as CA certificates without a peep)

Tested OK with Apache 2.4.9+

encoding the SSL/PKI knowledge into build scripts which generate an entire SSL CA chain + default server and client certificates collection from scratch.

extra utility scripts: refactor the git remotes add script. Start using the new git info printing utility script: concentrate git knowledge in a single place. DRY.

make the git utility scripts for syncing our git repository trees a tad more user friendly. (If they did bite me before, I bet they'ld surely bite you too, for any value of 'you' ;-) )

added "ye ole clunker" as server v2 (it's also v1, which was our pre-Bush-era server in there, hence *Vergeltungswaffe Zwo*)

added the git-submodule-remove script as provided by http://davidwalsh.name/git-remove-submodule (one tweak for understandability of error report when it happens)

updated bulk virtual host config for Apache

updated the util script which checks out submodules at their 'master' branch or preconfigured other branch

---
## [willior/Action_RPG_1](https://github.com/willior/Action_RPG_1)@[0c872b8f1c...](https://github.com/willior/Action_RPG_1/commit/0c872b8f1c9387c706abfc871d405ad255b5004e)
#### Tuesday 2021-04-27 18:17:06 by willior

organization / bugfix

putting all formulas into specific subfolders in the assets/Player/Abilities folder.
fixed a bug where if a Player zoned with a formula equipped for which they did not have any the necessary ingredient(s), the ingredient display in the formulaUI would display Null.
next i'm thinking of writing a function for healing to be able to display the exact heal values on screen similar to damage values. the simplest way to do this would be to incorporate it into the damage dealing functions themselves. the actual displaying of damage values takes place in the hurtbox scripts for the player & enemies (which are discrete from one another). before that, damage calculation occurs in the Global.damage_calculation method, for both player & enemies.
now, to get heal values to display, i will have to think about and re-do how health values are applied. as of now, the heal spell doesn't go through any global damage calculation method. heal potency is calculated on a cast-by-cast basis on the Heal scene itself:

heal_amount = (10*FormulaStats.Heal[1]) * PlayerStats.magic_mod*PlayerStats.magic_mod

10 is the "base_potency", which is multiplied by the level of the Heal formula. this is then multiplied by the square of PlayerStats.magic_mod, which is 1 + magic/32. this determines the heal_amount, which is then applied directly to PlayerStats.health.
so a problem i can see without even doing anything is that the Heal formula increases health over time: it is not a lump value being applied to PlayerStats.health. rather, it is 1 health being applied every frame until a threshold is reached, heal_amount. the lazy solution would be to just display heal_amount, either at the beginning or at the end of the Heal process. some thoughts...
right now, i don't believe the heal process can get interrupted, even if you get hit. if you start a heal spell, you will get healed for its full value, even if you get hit. i might have healing be interruptable to incentivize the player to wait/find the best healing opportunities as right now it's possible to simple "tank" through any damage received while healing. this can be intentional or not - we will have to see how it feels.
i think as of now, coming up with a way to just display the total_healed value will be a good start, and then other features can be worked on/modified from there.

---
## [Harsane/game](https://github.com/Harsane/game)@[7d818049c6...](https://github.com/Harsane/game/commit/7d818049c695928279949e6ee4048648727f5fd1)
#### Tuesday 2021-04-27 19:05:09 by Harrys Kedjnane

Game Manager

-Player Manager
-NPC Manager
-Score Manager
-Round manager
-Death manager
-Fuck your mom manager

---
## [clearlinux-pkgs/gnome-backgrounds](https://github.com/clearlinux-pkgs/gnome-backgrounds)@[280e98812f...](https://github.com/clearlinux-pkgs/gnome-backgrounds/commit/280e98812f2072930018b0db029f0de61898811a)
#### Tuesday 2021-04-27 20:25:00 by Arjan van de Ven

gnome-backgrounds: Autospec creation for update from version 3.38.0 to version 40.0

Jakub Steiner (23):
      symbolics update
      README additions
      symbolics: bravely go where noone has gone before
      symbolics: dithered indexed colors
      symbolics2: go a little wild with color
      remove Symbolics2
      Refresh some photos
      two more moody photos
      replace darkness with light
      supplemental: added abstract lava shapes
      supplemental: one more abstract
      first iteration of default 40
      night: move towards red
      DepthLava: more pleasing color blends
      adwaita: bit of triangle legacy
      DepthLava: mo' saturated
      Lava: more colorful
      morning, night tweaks
      Night: lighten up, bit of purple
      Symbolics: green and wavy
      default: improve dithering
      default: OCD tweaks + optipng
      prepare for 40.rc

Jordan Petridis (3):
      meson: remove filename from backgrounds
      add basic CI
      prepare for 40.0

---
## [tock/tock](https://github.com/tock/tock)@[b91f49038e...](https://github.com/tock/tock/commit/b91f49038eb0445fd3e9ef40b303d88ea04fd854)
#### Tuesday 2021-04-27 20:33:43 by bors[bot]

Merge #2562

2562: capsules/gpio_async: enforce grant/single-process r=hudson-ayers a=ppannuto

### Pull Request Overview

This is one of the capsules blocking #2462.

In contrast to the other PRs in the #2462 series, there's not really so much
meaning to "owning" an Async GPIO peripheral, so this PR effectively
just virtualizes the peripheral rather than enforcing single-process semantics.

Current GPIO HIL semantics notify *all* processes of interrupts to any
pin with interrupts configured (and it's left to higher layers to filter
activity based on which pin generated their interrupt). For Async GPIO,
this is awkward to virtualize (or not), as there is no owning process of
a pin for activity interrupts, but there is for configuration result
interrupts.

Note, however, that the underlying hardware likely can't handle multiple
concurrent configurations from multiple apps.
For now then, this capsule tracks a configuration while it is in flight
and notifies the correct process that their configuration has succeeded.
It does not track pin "owners", and notifies all apps of events on pins
(which is the same behavior as the regular gpio capsule).
In the rare case where two apps attempt concurrent configuration
requests, the later app will receive `EBUSY`. A retry loop should be
sufficient for most apps to handle this case.


### Testing Strategy

Compiling.


### TODO or Help Wanted

Not sure I love the 'notify all apps of all GPIO events' behavior, but
I believe we made that call because assigning owners to each pin
would incur non-trivial memory overhead. Might be worth thinking
through whether the same argument holds for Aysnc GPIO, but this
PR probably isn't the best place for that discussion.

### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make prepush`.


Co-authored-by: Pat Pannuto <pat.pannuto@gmail.com>

---
## [BookStackApp/BookStack](https://github.com/BookStackApp/BookStack)@[aa6a752e38...](https://github.com/BookStackApp/BookStack/commit/aa6a752e38b73eea201ea8e6a5b994a715e24aec)
#### Tuesday 2021-04-27 20:36:18 by Dan Brown

Implemented custom select controls because apple hates web developers

They'd rather keep pushing their 2007 era strange form control styles
even though they're horribly outdated, ugly and hard to style. The
only way to override is a full nuking of the default styles, which means
we have to then implement the frigging arrow icon using hacks which would
then conflict with all other sensible browsers so we have to nuke their
styles aswell to ensure some stupid backgroud hack is used everywhere.

I bet apple don't even use their shite default control styles and nuke
them also, Lets see. Yup, First thing I see on the top of their homepage
is a locale select dropdown custom built from about 10 HTML elements. FML

For #2709

---
## [gpolonus/grifstuf](https://github.com/gpolonus/grifstuf)@[8e6ab2303b...](https://github.com/gpolonus/grifstuf/commit/8e6ab2303bedb0cdb42be82b0e857551398f2b99)
#### Tuesday 2021-04-27 21:02:15 by Grif Polonus

Adding images to process on remote host since wsl is a goddamn fucking bitch. Hey Twitter!

---
## [phoenix344/phpbb-mdt-style](https://github.com/phoenix344/phpbb-mdt-style)@[8e50eabd32...](https://github.com/phoenix344/phpbb-mdt-style/commit/8e50eabd32205b87beef31f5c665f9c652e65281)
#### Tuesday 2021-04-27 21:33:14 by phoenix344

Update readme.md

MOTHERFUCKING GOOGLE MATERIAL DESIGN GODDAMNIT!!! CURSE YOU GOOGLE!!!!!!!!! I ONLY SUPPORT IE FOR THE REST OF MY LIFE!!!!!!!

---
## [LukeShu/git](https://github.com/LukeShu/git)@[512eeaa17e...](https://github.com/LukeShu/git/commit/512eeaa17e54188a9b16d06258edd5cf578b4a39)
#### Tuesday 2021-04-27 21:42:37 by Luke Shumaker

subtree: don't fuss with PATH

Scripts needing to fuss with with adding $(git --exec-prefix) PATH
before loading git-sh-setup is a thing of the past.  As far as I can
tell, it's been a thing of the past since since Git v1.2.0 (2006-02-12),
or more specifically, since 77cb17e940 (Exec git programs without using
PATH, 2006-01-10).  However, it stuck around in contrib scripts and in
third-party scripts for long enough that it wasn't unusual to see.

Originally `git subtree` didn't fuss with PATH, but when people
(including the original subtree author) had problems, because it was a
common thing to see, it seemed that having subtree fuss with PATH was a
reasonable solution.

Here is an abridged history of fussing with PATH in subtree:

  2987e6add3 (Add explicit path of git installation by 'git --exec-path', Gianluca Pacchiella, 2009-08-20)

    As pointed out by documentation, the correct use of 'git-sh-setup' is
    using $(git --exec-path) to avoid problems with not standard
    installations.

    -. git-sh-setup
    +. $(git --exec-path)/git-sh-setup

  33aaa697a2 (Improve patch to use git --exec-path: add to PATH instead, Avery Pennarun, 2009-08-26)

    If you (like me) are using a modified git straight out of its source
    directory (ie. without installing), then --exec-path isn't actually correct.
    Add it to the PATH instead, so if it is correct, it'll work, but if it's
    not, we fall back to the previous behaviour.

    -. $(git --exec-path)/git-sh-setup
    +PATH=$(git --exec-path):$PATH
    +. git-sh-setup

  9c632ea29c ((Hopefully) fix PATH setting for msysgit, Avery Pennarun, 2010-06-24)

    Reported by Evan Shaw.  The problem is that $(git --exec-path) includes a
    'git' binary which is incompatible with the one in /usr/bin; if you run it,
    it gives you an error about libiconv2.dll.

    +OPATH=$PATH
     PATH=$(git --exec-path):$PATH
     . git-sh-setup
    +PATH=$OPATH  # apparently needed for some versions of msysgit

  df2302d774 (Another fix for PATH and msysgit, Avery Pennarun, 2010-06-24)

    Evan Shaw tells me the previous fix didn't work.  Let's use this one
    instead, which he says does work.

    This fix is kind of wrong because it will run the "correct" git-sh-setup
    *after* the one in /usr/bin, if there is one, which could be weird if you
    have multiple versions of git installed.  But it works on my Linux and his
    msysgit, so it's obviously better than what we had before.

    -OPATH=$PATH
    -PATH=$(git --exec-path):$PATH
    +PATH=$PATH:$(git --exec-path)
     . git-sh-setup
    -PATH=$OPATH  # apparently needed for some versions of msysgit

First of all, I disagree with Gianluca's reading of the documentation:
 - I haven't gone back to read what the documentation said in 2009, but
   in my reading of the 2021 documentation is that it includes "$(git
   --exec-path)/" in the synopsis for illustrative purposes, not to say
   it's the proper way.
 - After being executed by `git`, the git exec path should be the very
   first entry in PATH, so it shouldn't matter.
 - None of the scripts that are part of git do it that way.

But secondly, the root reason for fussing with PATH seems to be that
Avery didn't know that he needs to set GIT_EXEC_PATH if he's going to
use git from the source directory without installing.

And finally, Evan's issue is clearly just a bug in msysgit.  I assume
that msysgit has since fixed the issue, and also msysgit has been
deprecated for 6 years now, so let's drop the workaround for it.

So, remove the line fussing with PATH.  However, since subtree *is* in
'contrib/' and it might get installed in funny ways by users
after-the-fact, add a sanity check to the top of the script, checking
that it is installed correctly.

Signed-off-by: Luke Shumaker <lukeshu@datawire.io>

---
## [martimvalente/fishtheapp](https://github.com/martimvalente/fishtheapp)@[4ef2a28aaf...](https://github.com/martimvalente/fishtheapp/commit/4ef2a28aaf89a85a134c659fe61446ed726f7c2a)
#### Tuesday 2021-04-27 22:03:13 by Martim Valente

got rid off all the front end, fuck you angular, i'll code a framework myself

---
## [Buildstarted/linksfordevs](https://github.com/Buildstarted/linksfordevs)@[48b57fdc4a...](https://github.com/Buildstarted/linksfordevs/commit/48b57fdc4ac13776445a62c21841bab223eb2f51)
#### Tuesday 2021-04-27 22:08:44 by Ben Dornis

Updating: 4/27/2021 10:00:00 PM

 1. Added: Epistemology Wars
    (https://danielbmarkham.com/epistemology-wars/)
 2. Added: Why Going to the Doctor Sucks — Wait But Why
    (https://waitbutwhy.com/2021/04/lanby.html)
 3. Added: Don't consume news in the morning
    (https://prithviraj.me/dont-consume-news-in-the-morning/)
 4. Added: codefinger - blog
    (https://jkutner.github.io/2021/04/26/write-good-dockerfile.html)
 5. Added: Dropbox is way too clingy
    (https://utf9k.net/blog/dropbox-is-way-too-clingy/)
 6. Added: Privacy by Design is reformist: But do we need revolution?
    (https://consult.sauvik.me/posts/privacy-by-design-is-reformist/)
 7. Added: Developing Expertise at Work: A Guide
    (https://jeffammons.com/2021/04/01/developing-expertise-at-work-a-guide/)
 8. Added: Content Marketing for Bootstrappers | James Chambers
    (https://jameschambers.co.uk/saas-content-marketing)
 9. Added: My experience with sexual harassment in the Scala community
    (https://yifanxing.medium.com/my-experience-with-sexual-harassment-in-the-scala-community-9245b4a139de)
10. Added: Why dummy data matters - and how to generate it - Michael Stivala
    (https://michaelstivala.com/why-dummy-data-matters-and-how-to-generate-it/)
11. Added: Speakers | Techorama
    (https://techorama.be/speakers/session/project-reaqtor-your-rx-for-distributed-reliable-and-stateful-event-processing/)
12. Added: Webmention Analytics
    (https://mxb.dev/blog/webmention-analytics/)

Generation took: 00:08:34.2014407
 Maintenance update - cleaning up homepage and feed

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[e9277ddf54...](https://github.com/mrakgr/The-Spiral-Language/commit/e9277ddf545bc23611b48dd95958222d0863c21d)
#### Tuesday 2021-04-27 22:47:02 by Marko Grdinić

"9:25am. I figured out a new rule that will make gradient modulation in RNNs a done deal. It should be useful in regular nets as well. But first, let me study the way moving averages are updated a little.

9:40am.

```fs
//let m = 1.05
//let l = List.init 10 (fun i -> (1.1 / m) ** float i)

let t = 100.0
let rec iter n m i =
    if i < n then
        let rec loop (m,s) i =
            if i < 10 then
                let s = (1.1 / m) ** float (i+1)
                let m = (t - 1.0) / t * m + 1.0 / t * s
                loop (m,s) (i+1)
            else m,s

        let m,s = loop (m,1.1) 0
        iter n m (i+1)
    else
        m
let m = iter 100 1.0 0
```

I've been wondering what the average of an exponential series converges to, and the answer here is...

```
val m : float = 1.085496689
```

Even if I set the n to 10000 I still get the same result.

```fs
let t = 100.0
let rec iter n m i =
    if i < n then
        let rec loop (m,s) i =
            if i < 1000 then
                let s = (1.1 / m) ** float (i+1)
                let m = (t - 1.0) / t * m + 1.0 / t * s
                loop (m,s) (i+1)
            else m,s

        let m,s = loop (m,1.1) 0
        iter n m (i+1)
    else
        m
let m = iter 100 1.0 0
```

```
val m : float = 3.664979479
```

Changing the inner loop to a large number causes it to become useless.

And something like this is essentially what I've been using to normalize the RNN gradients. You can tell how shitty standard SGD was if even the KFAC managed to do the job.

```fs
        let rec loop (m,s) i =
            if i < 300 then
```

This is `val m : float = 1.105855851`. As long as i is not too big, it will go in the right direction. And this will be helpful.

But it won't converge to the value I want and do the right thing.

9:50am. A moving average rule will only converge if its inputs and outputs are unrelated.

Here is what I am going to do when it comes to RNNs. I'll constraint the gradient L1 norm of the inputs to be the same as the L1 norm for the outputs. I'll do this in the head of RL agent as well. I meant to constrain it by the norm of the weights, but matching the inputs and the outputs would be better.

10:05am. Yeah, I can trust this. A combination of buffer shaping and gradient modulation tricks will be enough to get me to the level of expertise necessary to ensure stability in RL agents.

10:10am. For now, let me wind down. Yesterday I started the interview by Tegmark. I should also watch the lecture by Deepmind.

https://youtu.be/RL4j4KPwNGM?t=4848
Max Tegmark podcast with Lex Friedman

https://www.youtube.com/watch?v=AIiwuClvH6k&list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF&index=8
DeepMind x UCL | Deep Learning Lectures | 8/12 | Attention and Memory in Deep Learning

I really like his optimism about being able to figure out deep learning. Though I am on the opposite sides of the AI safety issue and don't think the brakes are necessary in this race, I still don't mind using the steering wheel. Being able to understand deep learning better could only help my situation.

10:20am. Focus me. Let me go for the lecture by Graves. Today my stress is the smallest it has been in days. I am starting to trust the backprop + buffer shaping + gradient modulation rules.

10:30am. https://youtu.be/AIiwuClvH6k?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF&t=516

This is interesting. There are different sensitivity patterns for the data and the action networks.

11:10am. Hmmm, rather than averaging in RNNs, I should consider gradient clipping.

I am working under the theory that everything should be linearized. If so then as long as the paths are separate, I do not need to be too strict on the norms when doing the updates...

Hmmmm, I am not sure. RNNs are tricky that way.

Forget this issue for now. RNNs won't come into play until significantly later anyway.

12:15pm. https://youtu.be/AIiwuClvH6k?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF&t=4614

While the attention mechanism is simple, he recommends this blog post, the annotated transformer as the actual architure is complex.

https://youtu.be/AIiwuClvH6k?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF&t=5080

Never heard of this before. I'll keep the universal transformers in mind. I'll need something powerful for sequences when I do full poker eventually. Though just embedding the player id and using some cut off point for the betting sequence length is also an option. Sequences will be tough using GPUs.

https://youtu.be/AIiwuClvH6k?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF&t=5239

Adaptive computation time is something I've been thinking about myself on and off.

12:45pm. https://www.youtube.com/watch?v=kVU8zTI-Od0&list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF&index=5
DeepMind x UCL | Deep Learning Lectures | 5/12 | Optimization for Machine Learning

Let me take a break here. Maybe I'll go for the optimization lecture next.

2:15pm. My plan was to use the weight norm in the last layer, but now that I've gone over it so many times, the rule to just normalize the input gradients in the last layer makes a lot of sense.

Maybe it could make sense in the rest of the layers as well.

The reason for that is the sampling scheme I am using.

In usual supervised learning there is `y - x` which gives a distance, but my plan is to turn everything into a +- 1 move via sampling. So if the goal is to normizalize, in the situation couldn't I use a predictive normalizer that sets all the grads to 1?

It is worth considering. I'd still have to track the input norms for the L1 updates, but otherwise yeah.

I admit something like this had not occured to me. This possibility only emerged because I decided to do the right thing with the replay buffer for the sake of the topmost layer and nonlinearities in general.

To think that a chain of possibilities would emerge pointing in this direction. I am astounded. All of this really could work. I should definitely try it out.

5:10pm. I thought of a toy example, and it broke my mind. I am absolutely shocked, but the backprop rules make sense as a credit assignment method! Also, I now understand what credit assignment even means.

Imagine something like this...

```
X -> X'
Y -> Y'
```

Two independent factor graphs.

Those arrows both have transition weights 1.

And both X and Y have unnormalized probabilities of 1.

Suppose I sample X and Y and propagate them forward. At the end of both nodes I'd get a reward of 1. Propagating that back, X and Y would get assigned credit of 1 in even amounts.

The goal is to maintain that level, namely 2 here.

Now suppose the distribution shifts and the probability of X gets halved to 0.5. That means that the amount of times that X' will be reached will also fall to 0.5 since it depends on X.

The second goal is to maintain that reachability of 2 as well.

Due to the distributional shift, both of those goals will fall to 1.5 and miss their target.

What to do?

To adjust both the credit level and that target node levels we'll shift the weight of `X -> X'`, consider it the transition probability to 2. One can think of it as inverse frequency.

Then it actually makes sense. Both goals get reached.

The model once again reflects reality and what absolutely floored me is that going in the opposite direction when distributing the rewards by multiplying by the weights makes sense.

5:25pm. I must have been crazy to not realize this earlier.

Damn, the tabular graphs all have transition weights of 1 and their normalization factors are the way they are sampled. It was too much for me to step back and see the matrix perspective.

All this time I've been railing about the optimization, but gradients vanishing and gradients exploding is an expected consequence.

5:25pm. I just could not see it before now.

I actually did not think of it in such simple terms at first, my initial starting point was to consider what would credit assignment be like if I got rid of the nonlinearities.

8pm. https://arxiv.org/abs/1711.02257
GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks

This is like a mental disease. I am obsessing and obsessing, desperately trying to get a sliver more of insight from the depths of my own mind. Let me finally watch the Deepmind lecture. Today went much like yesterday. I have no idea when I am going to get over this and start programming.

https://vimeo.com/287812909

Ah, let me watch this first. The lecture by Martens is on stuff that I know.

8:20pm. This is crap.

Let me watch the Deepmind lecture.

9:50pm. https://youtu.be/kVU8zTI-Od0?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF&t=4573
> You can actually do this analysis based on kernel theory where you can really see with high probability what a neural network will do if you keep adding layers on top. And what you quickly observe is that the way that the neural network maps the input to its output is a function that degenerates very very fast unless you are extremely careful at how you set the weights at each layer. And the burden of having to do that, of having to set those weights carefully becomes harder and harder and harder as you keep adding more layers.

The rest I mostly knew, but here he is talking about initialization and how in the context of resnets and batch norm, the network starts very linear and then takes advantage of nonlinearity as the training goes along.

I am really wondering how did the batch norm + RNNs story go in the last few years.

https://jaywhang.com/assets/batchnorm_rnn.pdf

I am actually open to using BN at this juncture. My plan is to ditch KFAC and use large batch sizes. I'll have to compute the layerwise statistics anyway, and that includes the gradients, so I might as well go this route. I'll need it for RNNs. I keep going back and forth with the moving average idea in RNNs, but I'll really have to use a moving average for every timestep or use a larger batch size and then take the empirical average.

https://arxiv.org/pdf/1603.09025.pdf
> However, we find that simply averaging statistics over time severely degrades performance.

Yeah, that is what I'd expect.

> This causes the variance of the hidden states to be exactly zero for a long period of time. Normalizing these zerovariance activations involves dividing zero by a small number at many timesteps, which does not affect the forward-propagated activations but causes the back-propagated gradient to explode.

Rather than adding that epsilon, they'd have been better off just making a special case for zero.

https://www.youtube.com/watch?v=87kLfzmYBy8&list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF&index=6
DeepMind x UCL | Deep Learning Lectures | 6/12 | Sequences and Recurrent Networks

I always feel like doing more when the day is over. Let me take a look at this lecture. I really might need plain RNNs for Holdem. Who knows in which direction I will go here.

10:55pm. No forget it. I need to pry myself off from thinking constantly about this. It is like my mind is stuck in an infinite loop. It seems like it is one thing to tell myself that I should accept the rules and quite another to follow the idea.

Let me watch to the interview by Tegmark from where I left off yesterday.

David Silver, Mike Jordan, Ilya Sutskever. Lex Fridman has a lot of stuff.

I have a tab by Michael Litman open.

12:30pm. https://youtu.be/RL4j4KPwNGM?t=9434

Let me stop here. I am too tired. I'll resume tomorrow."

---
## [pdboddy/slime_apocalypse](https://github.com/pdboddy/slime_apocalypse)@[045f976d6e...](https://github.com/pdboddy/slime_apocalypse/commit/045f976d6e32cc4b90758a630f81bc027a5187ba)
#### Tuesday 2021-04-27 23:33:40 by pdboddy

Another try...

This is effing annoying.  Holy shit.

---
## [CaptainJellybones/Rollerbuddy](https://github.com/CaptainJellybones/Rollerbuddy)@[68cfaac05e...](https://github.com/CaptainJellybones/Rollerbuddy/commit/68cfaac05e131e67bd3ac80bd95e7e81bd5169b2)
#### Tuesday 2021-04-27 23:55:16 by CaptainJellybones

Minor work on the calculator

For the love of god, remember to change the classes and ID of the shit you copied

---

# [<](2021-04-26.md) 2021-04-27 [>](2021-04-28.md)

