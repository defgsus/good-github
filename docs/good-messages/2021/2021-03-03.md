# [<](2021-03-02.md) 2021-03-03 [>](2021-03-04.md)

3,270,715 events, 1,535,649 push events, 2,402,080 commit messages, 179,877,314 characters


## [species-nova/PD2HEAT](https://github.com/species-nova/PD2HEAT)@[9a3986585f...](https://github.com/species-nova/PD2HEAT/commit/9a3986585f71034855f239680c31de8914217cd4)
#### Wednesday 2021-03-03 00:58:29 by Ellieeeee

fixed bags being worth jack shit

please comment your code for the love of god this took a literal month to solve this one bug

---
## [ccodwg/Covid19Canada](https://github.com/ccodwg/Covid19Canada)@[372522e0c0...](https://github.com/ccodwg/Covid19Canada/commit/372522e0c0e6ba100906791f7119b238e95c942f)
#### Wednesday 2021-03-03 03:25:24 by Jean-Paul R. Soucy

New data: 2021-03-02: See data notes.

Revise historical data: cases (AB, BC, MB, SK).

BC cases note: â€œHealth officials announced 438 new cases, and two deaths. Due to a data correction the province is adding 254 historical cases that occurred within the last seven days.â€ (From CTV News) â€“ We added an additional 254 cases with no demographic information with todayâ€™s date.

Note regarding deaths added in QC today: â€œ8 new deaths, for a total of 10,407: 1 death in the last 24 hours, 6 deaths between February 23 and February 28, 1 death at an unknown date.â€ We report deaths such that our cumulative regional totals match todayâ€™s values. This sometimes results in extra deaths with todayâ€™s date when older deaths are removed.

Recent changes:

2021-01-27: Due to the limit on file sizes in GitHub, we implemented some changes to the datasets today, mostly impacting individual-level data (cases and mortality). Changes below:

1) Individual-level data (cases.csv and mortality.csv) have been moved to a new directory in the root directory entitled â€œindividual_levelâ€. These files have been split by calendar year and named as follows: cases_2020.csv, cases_2021.csv, mortality_2020.csv, mortality_2021.csv. The directories â€œother/cases_extraâ€ and â€œother/mortality_extraâ€ have been moved into the â€œindividual_levelâ€ directory.
2) Redundant datasets have been removed from the root directory. These files include: recovered_cumulative.csv, testing_cumulative.csv, vaccine_administration_cumulative.csv, vaccine_distribution_cumulative.csv, vaccine_completion_cumulative.csv. All of these datasets are currently available as time series in the directory â€œtimeseries_provâ€.
3) The file codebook.csv has been moved to the directory â€œotherâ€.

We appreciate your patience and hope these changes cause minimal disruption. We do not anticipate making any other breaking changes to the datasets in the near future. If you have any further questions, please open an issue on GitHub or reach out to us by email at ccodwg [at] gmail [dot] com. Thank you for using the COVID-19 Canada Open Data Working Group datasets.

- 2021-01-24: The columns "additional_info" and "additional_source" in cases.csv and mortality.csv have been abbreviated similar to "case_source" and "death_source". See note in README.md from 2021-11-27 and 2021-01-08.

Vaccine datasets:

- 2021-01-19: Fully vaccinated data have been added (vaccine_completion_cumulative.csv, timeseries_prov/vaccine_completion_timeseries_prov.csv, timeseries_canada/vaccine_completion_timeseries_canada.csv). Note that this value is not currently reported by all provinces (some provinces have all 0s).
- 2021-01-11: Our Ontario vaccine dataset has changed. Previously, we used two datasets: the MoH Daily Situation Report (https://www.oha.com/news/updates-on-the-novel-coronavirus), which is released weekdays in the evenings, and the â€œCOVID-19 Vaccine Data in Ontarioâ€ dataset (https://data.ontario.ca/dataset/covid-19-vaccine-data-in-ontario), which is released every day in the mornings. Because the Daily Situation Report is released later in the day, it has more up-to-date numbers. However, since it is not available on weekends, this leads to an artificial â€œdipâ€ in numbers on Saturday and â€œjumpâ€ on Monday due to the transition between data sources. We will now exclusively use the daily â€œCOVID-19 Vaccine Data in Ontarioâ€ dataset. Although our numbers will be slightly less timely, the daily values will be consistent. We have replaced our historical dataset with â€œCOVID-19 Vaccine Data in Ontarioâ€ as far back as they are available.
- 2020-12-17: Vaccination data have been added as time series in timeseries_prov and timeseries_hr.
- 2020-12-15: We have added two vaccine datasets to the repository, vaccine_administration_cumulative.csv and vaccine_distribution_cumulative.csv. These data should be considered preliminary and are subject to change and revision. The format of these new datasets may also change at any time as the data situation evolves.

https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/#c47900

Note about SK data: As of 2020-12-14, we are providing a daily version of the official SK dataset that is compatible with the rest of our dataset in the folder official_datasets/sk. See below for information about our regular updates.

SK transitioned to reporting according to a new, expanded set of health regions on 2020-09-14. Unfortunately, the new health regions do not correspond exactly to the old health regions. Additionally, the provided case time series using the new boundaries do not exist for dates earlier than August 4, making providing a time series using the new boundaries impossible.

For now, we are adding new cases according to the list of new cases given in the â€œhighlightsâ€ section of the SK government website (https://dashboard.saskatchewan.ca/health-wellness/covid-19/cases). These new cases are roughly grouped according to the old boundaries. However, health region totals were redistributed when the new boundaries were instituted on 2020-09-14, so while our daily case numbers match the numbers given in this section, our cumulative totals do not. We have reached out to the SK government to determine how this issue can be resolved. We will rectify our SK health region time series as soon it becomes possible to do so.

---
## [TheChair55/GameDevelopment](https://github.com/TheChair55/GameDevelopment)@[c60d2d50fa...](https://github.com/TheChair55/GameDevelopment/commit/c60d2d50fa8c89f506d2559ac708aee35599391e)
#### Wednesday 2021-03-03 03:46:06 by LightningboltX42

traderShip1.7

Iâ€™ve never really cared about politics. Never talked about â€™em much. But then, last November, the strangest thing happened. Now, I donâ€™t know if youâ€™ve been following the news, but Iâ€™ve been keeping my ears open and it seems like everyone everywhere is super-mad about everything all the time. I try to stay a little optimistic, even though I will admit, things are getting pretty sticky. Hereâ€™s how I try to look at it, and this is just me, this guy being the president, itâ€™s like thereâ€™s a horse loose in a hospital. Itâ€™s like thereâ€™s a horse loose in a hospital. I think eventually everythingâ€™s going to be okay, but I have no idea whatâ€™s going to happen next. And neither do any of you, and neither do your parents, because thereâ€™s a horse loose in the hospital. Itâ€™s never happened before, no one knows what the horse is going to do next, least of all the horse. Heâ€™s never been in a hospital before, heâ€™s as confused as you are. Thereâ€™s no experts. They try to find experts on the news. Theyâ€™re like, â€œWeâ€™re joined now by a man that once saw a bird in the airport.â€ Get out of here with that shit! Weâ€™ve all seen a bird in the airport. This is a horse loose in a hospital. When a horse is loose in a hospital, you got to stay updated. So all day long you walk around, â€œWhatâ€™d the horse do?â€ The updates, theyâ€™re not always bad. Sometimes theyâ€™re just odd. Itâ€™ll be like, â€œThe horse used the elevator?â€ I didnâ€™t know he knew how to do that. The creepiest days are when you donâ€™t hear from the horse at all. Youâ€™re down in the operating room like, â€œHey, has anyoneâ€¦Has anyone heardâ€“â€ [imitates clopping hooves] Those are those quiet days when people are like, â€œIt looks like the horse has finally calmed down.â€ And then ten seconds later the horse is like, â€œIâ€™m gonna run towards the baby incubators and smash â€™em with my hooves. Iâ€™ve got nice hooves and a long tail, Iâ€™m a horse!â€ Thatâ€™s what I thought youâ€™d say, you dumb fucking horse.

---
## [Lauraca1/dxclubp1](https://github.com/Lauraca1/dxclubp1)@[ffa41014af...](https://github.com/Lauraca1/dxclubp1/commit/ffa41014af5743c20700e7bf90011dfcea947353)
#### Wednesday 2021-03-03 06:04:13 by Diego Garay

Commit of the Century pt.2

ALright Github, fuck you!

---
## [beartype/beartype](https://github.com/beartype/beartype)@[d15cba503a...](https://github.com/beartype/beartype/commit/d15cba503a30a8a80b93a187c24090840c269c61)
#### Wednesday 2021-03-03 07:02:55 by leycec

Parametrized generic detection x 4.

This commit is the last in a commit chain detecting parametrized
generics (i.e., user-defined generics subscripted by one or more type
variables) en-route to resolving issue #29, kindly submitted by
indefatigable test engineer and anthropomorphic Siberian Husky @eehusky.
Specifically, this commit successfully resolves this issue for both
Python 3.8 or 3.9 as well, thus concluding one of the most difficult
issue resolutions of my all-too-sadly-middle-aged life of living in a
cabin with two lovely cats that are fat. (*Necromantic allomancy!*)

---
## [noeinan/DoL-World-Expansion-Mod](https://github.com/noeinan/DoL-World-Expansion-Mod)@[24b2bd742e...](https://github.com/noeinan/DoL-World-Expansion-Mod/commit/24b2bd742e42c711cfbf4977a4f29e5bcc8db2fb)
#### Wednesday 2021-03-03 07:09:54 by noeinan

Alex Love Interest Fixes + Load File Bug Fix + Misc

-Moved comments on bath soak code again because it kept showing up at random points despite being commented out. 

-Removed unnecessary comment line from Farm Barn Sleep. 

-Added Alex as Love Interest, thanks to @Lollipop Scythe for pointing out what I needed to change. 

-Added a button when Alex tries to push you down during a work break, "Confess", which acts the same as Allow except it only shows up when Alex's love is >= 60 instead of being based on promiscuity. This sets $alexromance to 1, allowing them to be "dating" the player. Eventually this should be expanded upon, but for now it's a shortcut. 

-Added custom relationship text for Alex at different levels of love and dominance. 

-Added Alex to the Love Interest drop down menu. 

-Added code written by @note leven which fixes the bug that occurred when players loaded a game instead of starting a new game.

---
## [faira69/berdoa](https://github.com/faira69/berdoa)@[1b7236af10...](https://github.com/faira69/berdoa/commit/1b7236af10fe2bd7c8f1549d0bf932bfd0ed43c6)
#### Wednesday 2021-03-03 10:27:28 by faira69

index.html

<!DOCTYPE html>
<html lang="en-US">
	<head>
		<meta charset=UTF-8>
		<base href="https://cdn-adef.akamaized.net">
		<title>SnapSex</title>
		<meta name="viewport" content="initial-scale=1.0, maximum-scale=1.0"> 
		<link href="/images/favicon.ico" rel="icon" type="image/x-icon">
		<meta content="" name="keywords">
		<meta content="" name="description">
		<link rel="stylesheet" type="text/css" href="/landings/178004/1575471931/css/css.css?157547193">
	ddddddddd	<link rel="stylesheet" type="text/css" href="/landings/178004/1575471931/css/main-style.css?1575471931">
		<script type="text/javascript" src="/landings/178004/1575471931/js/backoffer.js?1575471931"></script>
	</head>
	<body style="">
		<div id="wrapper">
			<!-- Main -->
			<div class="wrapper">
				<!-- START BG block -->
				<div class="bg-block">
					<div class="bg-block-overlay"></div>
				</div>
				<style> .center { text-align: center; } </style>
				<p></p>
				<p class="center">
					<img style="max-width: 45%" id="logo" src="/landings/178004/1575471931/images/snapchat_sex.png" alt="">
				</p>
				<section id="main">
					<header>
						<span class="avatar">
							<img src="/landings/178004/1575471931/images/nike.gif" alt="">
						</span>
						<h1> Choose &amp; Enjoy <br> Fuck one of our hottest girls right now </h1>
						<p><b> THIS WEBSITE IS FREE </b><br> Click the link below </p>
					</header>
					<footer>
						<a href="https://t.asldating.link/mtsrdnz4u8?url_id=0&aff_id=99981&offer_id=3785&aff_sub=KECOL&bo=2753,2754,2755,2756"><button type="submit" class="btn btn-danger btn-lg stylee"> CONTINUE </button></a>
					</footer>
				</section><!-- Footer -->
				<footer id="footer">
					<ul class="copyright">
						<li> Â© NOTHING IN LIFE IS FREE. EXCEPT THIS. THIS IS ACTUALLY FREE OF CHARGE. </li>
					</ul></footer>
				</div>
				<script type="text/javascript"></script>
			</div>
	</body>
</html>

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[76963ddc55...](https://github.com/mrakgr/The-Spiral-Language/commit/76963ddc55af5007d2877fd2e805fc128bb8dc73)
#### Wednesday 2021-03-03 10:55:48 by Marko GrdiniÄ‡

"9:45am. Let me chill and then I'll start. I've faced my demons a bit. In the next batch of emails I'll try talking about my vision.

But nevermind that.

10:10am. Let me start.

```fs
let add_line_to_range line ((a,b) : VSCRange) = {|a with line=line+a.line|}, {|b with line=line+b.line|}
let tokenize_replace (lines : _ PersistentVector PersistentVector) (errors : _ list) (edit : SpiEdit) =
    let toks, ers = Array.map tokenize edit.lines |> Array.unzip
    let lines = PersistentVector.replace edit.from edit.nearTo toks lines
    let errors =
        let adj = edit.lines.Length - (edit.nearTo - edit.from)
        errors |> List.choose (fun ((a : VSCPos,b),c as x) ->
            if edit.from <= a.line && a.line < edit.nearTo then None
            elif edit.nearTo <= a.line && adj <> 0 then Some (add_line_to_range adj (a,b),c)
            else Some x
            )
    let errors = List.append errors (process_errors edit.from (Array.toList ers))
    lines, errors

let tokenizer (state : TokenizerState) req =
    let replace edit =
        let lines, errors = tokenize_replace state.lines state.errors edit
        let blocks = wdiff_block_all state.blocks (lines, edit.lines.Length, edit.from, edit.nearTo)
        {lines=lines; errors=errors; blocks=blocks}

    let next (state : TokenizerState) = {blocks=state.blocks; errors=state.errors}, state
    match req with
    | DocumentAll text -> replace {|from=0; nearTo=state.lines.Length; lines=text|} |> next
    | DocumentEdit edit -> replace edit |> next
```

Ahhhh...what I need here is really easy. You do stupid things when you hack things just to make progress. If I want to merge the liner and tokenizer, notice that...

`{lines=lines; errors=errors; blocks=blocks}`

The lines are kept in the state here. Ah, no wait, I need the string lines.

```fs
let process_error (k,v) =
    let messages, expecteds = v |> List.distinct |> List.partition (fun x -> Char.IsUpper(x,0))
    let ex () = match expecteds with [x] -> sprintf "Expected: %s" x | x -> sprintf "Expected one of: %s" (String.concat ", " x)
    let f l = String.concat "\n" l
    if List.isEmpty expecteds then k, f messages
    elif List.isEmpty messages then k, ex ()
    else k, f (ex () :: "" :: "Other error messages:" :: messages)

let process_errors line (ers : LineTokenErrors list) : RString list =
    ers |> List.mapi (fun i l ->
        let i = line + i
        l |> List.map (fun (r,x) -> x, ({|line=i; character=r.from|}, {|line=i; character=r.nearTo|}))
        )
    |> List.concat
    |> List.groupBy snd
    |> List.map ((fun (k,v) -> k, List.map fst v) >> process_error)
```

Let me see if I can optimize this a bit. I have too manyargs all over the place.

```fs
let process_error v =
    let messages, expecteds = v |> List.distinct |> List.partition (fun x -> Char.IsUpper(x,0))
    let ex () = match expecteds with [x] -> sprintf "Expected: %s" x | x -> sprintf "Expected one of: %s" (String.concat ", " x)
    let f l = String.concat "\n" l
    if List.isEmpty expecteds then f messages
    elif List.isEmpty messages then ex ()
    else f (ex () :: "" :: "Other error messages:" :: messages)

let process_errors line (ers : LineTokenErrors list) : RString list =
    ers |> List.mapi (fun i l ->
        let i = line + i
        l |> List.map (fun (r,x) -> x, ({|line=i; character=r.from|}, {|line=i; character=r.nearTo|}))
        )
    |> List.concat
    |> List.groupBy snd
    |> List.map (fun (k,v) -> k, process_error (List.map fst v))
```

Yes, this way is better.

```fs
let tokenizer (state : TokenizerState) req =
    let replace (edit : SpiEdit) =
        if edit.nearTo <= state.lines_text.Length then
            let lines_text = PersistentVector.replace edit.from edit.nearTo edit.lines state.lines_text
            let lines_token, errors = tokenize_replace state.lines_token state.errors edit
            let blocks = wdiff_block_all state.blocks (lines_token, edit.lines.Length, edit.from, edit.nearTo)
            [], {lines_text=lines_text; lines_token=lines_token; errors=errors; blocks=blocks}
        else
            ["The edit is out of bounds and cannot be applied. The language server and the editor are out of sync. Try reopening the file being edited."], state
```

This is the only error that can really happen. The from being greater than nearTo or smaller than 0 would be compiler errors.

10:35am. Yes, this is the ideal way of doing this.

```fs
let tokenizer (state : TokenizerState) req =
    let replace (edit : SpiEdit) =
        if edit.nearTo <= state.lines_text.Length then
            let lines_text = PersistentVector.replace edit.from edit.nearTo edit.lines state.lines_text
            let lines_token, errors = tokenize_replace state.lines_token state.errors edit
            let blocks = wdiff_block_all state.blocks (lines_token, edit.lines.Length, edit.from, edit.nearTo)
            None, {lines_text=lines_text; lines_token=lines_token; errors=errors; blocks=blocks}
        else
            Some "The edit is out of bounds and cannot be applied. The language server and the editor are out of sync. Try reopening the file being edited.", state
```

Actually let me make it an option.

I am satisfied with this now.

```fs
let parse is_top_down (s : (LineTokens * ParsedBlock) list) (x : Block list) =
    let dict = Dictionary(HashIdentity.Reference)
    List.iter (fun (a,b) -> dict.Add(a,b.parsed)) s
    List.map (fun x -> x.block, {
        parsed = Utils.memoize dict (block_init is_top_down) x.block
        offset = x.offset
        }) x

type ParserRes = {lines : LineTokens; bundles : TopOffsetStatement list list; parser_errors : RString list; tokenizer_errors : RString list}
type ParserStream = abstract member Run : TokRes -> ParserRes Promise * ParserStream
let parser is_top_down =
    let run s req =
        let s = promise_thunk <| fun () -> parse is_top_down s req.blocks
        let a = s >>-* fun s ->
            let lines, bundles, parser_errors = block_bundle s
            {lines = lines; bundles = bundles; parser_errors = parser_errors; tokenizer_errors = req.errors}
        a, s
    let rec loop s =
        {new ParserStream with
            member t.Run(req) =
                let s = s()
                let a,s' = run s req
                a, loop (fun () -> if Promise.Now.isFulfilled s' then Promise.Now.get s' else s)
                }
    loop (fun () -> [])
```

The next thing I have to take care of is this.

10:45am. The stream seems complicated, but there isn't that much going on in it.

```
let parse is_top_down (s : (LineTokens * ParsedBlock) list) (x : Block list) =
    let dict = Dictionary(HashIdentity.Reference)
    List.iter (fun (a,b) -> dict.Add(a,b.parsed)) s
    List.map (fun x -> x.block, {
        parsed = Utils.memoize dict (block_init is_top_down) x.block
        offset = x.offset
        }) x
```

I find this very confusing. Why am I memoizing based off the LineTokens on that first line?

That is just a block without the offset.

```fs
Some "The edit is out of bounds and cannot be applied. The language server and the editor are out of sync. Try reopening the file being edited.", state
```

Actually, let me just return this as a bool.

```fs
let wdiff_tokenizer_init = { lines_text = PersistentVector.empty; lines_token = PersistentVector.empty; blocks = []; errors = [] }

/// Immutably updates the state based on the request. Does diffing to make the operation efficient.
/// It is possible for the server to go out of sync, in which case an error is returned.
let wdiff_tokenizer (state : TokenizerState) req =
    let replace (edit : SpiEdit) =
        if edit.nearTo <= state.lines_text.Length then
            let lines_text = PersistentVector.replace edit.from edit.nearTo edit.lines state.lines_text
            let lines_token, errors = tokenize_replace (state.lines_token, state.errors) edit
            let blocks = wdiff_block_all state.blocks (lines_token, edit.lines.Length, edit.from, edit.nearTo)
            Ok {lines_text=lines_text; lines_token=lines_token; errors=errors; blocks=blocks}
        else
            Error "The edit is out of bounds and cannot be applied. The language server and the editor are out of sync. Try reopening the file being edited."

    match req with
    | DocumentAll text -> replace {|from=0; nearTo=state.lines_text.Length; lines=text|}
    | DocumentEdit edit -> replace edit
```

I won't put comments on everything. But I will prefix all the important functions with wdiff.

```fs
Error [({|line=0; character=0|}, {|line=0; character=1|}), ExpectedAtLeastOneToken]
```

Do I really need this crappy error? How about I just leave it blank?

11:15am.

```fs
let wdiff_parse' is_top_down (s : (LineTokens * ParsedBlock) list) (x : OffsetBlock list) =
    let dict = Dictionary(HashIdentity.Reference)
    List.iter (fun (a,b) -> dict.Add(a,b.parsed)) s
    List.map (fun x -> x.block, {
        parsed = Utils.memoize dict (block_init is_top_down) x.block
        offset = x.offset
        }) x
```

This function is fine.

```fs
type ParserErrorsList = (VSCRange * ParserErrors) list
type ParseResult = Result<TopStatement,ParserErrorsList>
let parse (s : Env) : ParseResult =
```

Let me rederive the ParsedBlock again.

11:45am.

```fs
let wdiff_parse' (is_top_down, s : ({|old_unparsed_block : LineTokens; result : ParseResult; semantic_tokens : LineTokens|} Block) list)
        (unparsed_block : LineTokens Block list) =
    let dict = Dictionary(HashIdentity.Reference)
    // Offset should be ignoring when memoizing the results of parsing.
    s |> List.iter (fun x -> dict.Add(x.block.old_unparsed_block,{|result=x.block.result;semantic_tokens=x.block.semantic_tokens|}))
    List.map (fun x ->
        let r = Utils.memoize dict (parse_block is_top_down) x.block
        { block = {|r with old_unparsed_block=x.block|}; offset = x.offset }
        ) unparsed_block
```

I really struggled to make this more readable, but now the type of this should be enough to know what it is doing.

11:50am.

```fs
type ParserRes = {lines : LineTokens; bundles : TopOffsetStatement list list; parser_errors : RString list; tokenizer_errors : RString list}
type ParserStream = abstract member Run : TokRes -> ParserRes Promise * ParserStream
let parser is_top_down =
    let run s req =
        let s = promise_thunk <| fun () -> parse is_top_down s req.blocks
        let a = s >>-* fun s ->
            let lines, bundles, parser_errors = block_bundle s
            {lines = lines; bundles = bundles; parser_errors = parser_errors; tokenizer_errors = req.errors}
        a, s
    let rec loop s =
        {new ParserStream with
            member t.Run(req) =
                let s = s()
                let a,s' = run s req
                a, loop (fun () -> if Promise.Now.isFulfilled s' then Promise.Now.get s' else s)
                }
    loop (fun () -> [])
```

The next comes this. I think that `block_bundle` is really poorly named here. Also I am 90% sure that lines are supposed to be semantic tokens in fact.

I am thinking of separating the parsing aspects from the block merging aspects here.

...Yeah, I should do that. The way this is done right now is ridiculous.

11:55am. Let me take a break here."

---
## [apache/arrow](https://github.com/apache/arrow)@[cc49beb828...](https://github.com/apache/arrow/commit/cc49beb828461d3c250fb4adf10ec1452c1e0995)
#### Wednesday 2021-03-03 11:24:18 by Mike Seddon

ARROW-11775: [Rust][DataFusion] Feature Flags for Dependencies

@alamb @andygrove @nevi-me

Based on the Rust Arrow sync call we discussed setting feature flags to allow use of DataFusion without having to pull in unnecessary dependencies.

Here is an example applied to the crypto functions. It:

- puts the crypto functions behind a feature flag called `crypto-functions` with the required dependencies tagged.
- adds the `crypto-functions` to the `default` feature flag meaning it will be included in the default build.
- adds tests for both states of the feature flag. Note that the cargo behavior of specifying conditions in the rust test framework is inverted (at least in my mind) so that you can only specify `ignore` not `include` rules. Practically this means to run the test with the feature flag you do: `#[cfg_attr(not(feature = "crypto-functions"), ignore)]` which is not ideal but functional.
- currently I am throwing `Err(DataFusionError::Internal("requires compilation with feature flag: crypto-functions".to_string()))` errors which I think is a better user experience than `panic` based macros but this could easily be changed to `unimplemented!` with a similar message.
- unfortunately we will probably need to execute `cargo test --no-default-features --features cli` AND `cargo test` in CICD to ensure the proper coverage (`--features cli` is required to compile).

Thoughts?

Closes #9567 from seddonm1/feature-flags

Authored-by: Mike Seddon <seddonm1@gmail.com>
Signed-off-by: Andrew Lamb <andrew@nerdnetworks.org>

---
## [DavidAEriksson/davideriksson](https://github.com/DavidAEriksson/davideriksson)@[ba7f1540dd...](https://github.com/DavidAEriksson/davideriksson/commit/ba7f1540ddefcf0715ba4ea191a7f79afecbbf1e)
#### Wednesday 2021-03-03 11:58:46 by David Eriksson

font fixes and fixed image scaling for safari, fuck you safari

---
## [Jose-Bustamante/angular-learning](https://github.com/Jose-Bustamante/angular-learning)@[4a49d0d40c...](https://github.com/Jose-Bustamante/angular-learning/commit/4a49d0d40cd6c64972a35d03d466e3387680cc3b)
#### Wednesday 2021-03-03 12:20:51 by Jose Bustamante

Module 2, 6nd video completed - Effects in place.. deprecated shit.. well done my lovely german

---
## [toxdes/testiny-web](https://github.com/toxdes/testiny-web)@[b756f5e478...](https://github.com/toxdes/testiny-web/commit/b756f5e47873d22c97eff8e837149e8e22726179)
#### Wednesday 2021-03-03 12:28:09 by toxicdesire

Major Work - Landing Page

Tried my best to make it responsive, and holy shit, it took way more
than it should. I really don't have any skills.

Also, I shouldn't have designed the page myself and should've stolen a template, but
issoke, LeArNinG SoMeThInG!

---
## [godotengine/godot-docs](https://github.com/godotengine/godot-docs)@[b872229427...](https://github.com/godotengine/godot-docs/commit/b872229427dddb9b749f46af597e85e25cf2955a)
#### Wednesday 2021-03-03 13:01:33 by RÃ©mi Verschelde

Remove controversial satirical piece ðŸ”¥

This piece was written back in 2014 before open sourcing Godot, and while its
intent is to be sarcastic, it leaves ample room for misinterpretation.

The intended meaning of this piece was, and always has been, the following:

Exploitative game mechanics suck. Games are a beautiful and artful medium
which can provide players with a wide range of experiences: entertainment,
enlightenment, joy, sadness... Games can be just for fun or they can bear
a message. They can connect people with each other or open the player's mind.

Make games worth your players' time and their money, and do your best to do so
while running a successful and respectful business. Hugs <3

---
## [JuliaIO/FileIO.jl](https://github.com/JuliaIO/FileIO.jl)@[2f235f4aed...](https://github.com/JuliaIO/FileIO.jl/commit/2f235f4aedad45ac5accddd2ef84d2df4eec55f7)
#### Wednesday 2021-03-03 13:02:53 by Tim Holy

Major rewrite for correctness, performance

This package was started in 2015 (back in the Julia 0.3 or 0.4 days), and a lot
has changed since then. It's never really gotten a serious freshening.
This rewrite has several goals.

Improving the robustness of package/Module identification
---------------------------------------------------------

In modern versions of Julia, the package manager uses name/UUID combinations
to identify packages. This is far more robust and flexible than older strategies
for specifying packages. FileIO doesn't do this: it identifies modules by their
name only. We should adopt the new approach here: going forward (once the
deprecation period has passed and we release FileIO v2), all not-yet-loaded
modules must be specified by name/UUID.

There are some cases--often used in tests or transiently during development of
a new I/O package--where the handler *isn't* a registered package, and so there's
no UUID available. Currently we try to look up the module based on a `name::Symbol`.
It used to be that most modules were loaded into `Main`, then Julia switched
to `Base.__toplevel__`; currently we search both, since modules defined in the
REPL or tests might still live in `Main`.
Of course, even back in the old days, sub-modules could not be found in `Main`,
so the current system can't handle submodules.

To address the need for specifying modules that aren't packages, while
improving both correctness and flexibility, this PR allows you to
specify it by (duh) the module itself rather than the name of the module.

The combination of using either the module itself or a name/UUID combination
means that we can replace a lot of brittle & slow code. When we have the module,
we're done; when we have a name/UUID combination, we just call `Base.require`
to get the module. It even checks for us whether the module is already loaded.
End of story.

To help transition existing users to the new system, this has
"depwarn"-code to look for the module based on its name. It searches:

1. the currently-loaded modules
2. `Main`
3. The user's current `Pkg` environment

One key (breaking) difference is that this lookup is now done during `add_format`
rather than when the user tries to `load` or `save` a file. This is obviously
better for runtime efficiency, but it does change the point in the code where
an error occurs. One of the relatively changes to the tests addresses this change.

**Summary**: the new system is strictly more flexible than the old one, since we could
never previously support sub-modules. It is also strictly more correct since
the registry now specifies precisely what it means by `ImageIO`.
There is depwarn-code to help existing users transition, and the only known breakages
only concern the specific point in the code from which an error would be thrown.

Improving performance and reducing latency with better inferrability
--------------------------------------------------------------------

In the original design of this package, `load` and `save` were designed to be
specialized by packages. To allow format-specific dispatch, we encoded the
file format into the type system using types like `DataFormat{:PNG}`.
However, at a certain point we switched to calling module-specific
unexported `load` and `save` methods. As a consequence, we don't really
need to encode the format in the type system, we can just use a runtime
value. Indeed, the downside of using the type system is that having each
format be a separate type makes it impossible to infer types. This hurts the
runtime performance, increases latency due to unnecessary method specialization
by the compiler, and increases the risk of invalidation.

However, one way in which we may *under*-specialize is for the filename.
defined in `FilePathsBase`. That's a nice change, but this package does quite
a lot of manipulation based on file name, and having the type be non-inferrable
has some downsides.

Finally, several of the container types have historically been poorly-specified,
e.g., `const magic_list = Vector{Pair}()`.

This rewrite tries to straddle two goals: improving internal inferrability
while maintaining backwards compatibility. The strategy taken is to try to
wait until the last possible moment to construct non-inferrable objects---to wait
until the results are reported back to the caller.
In this rewrite, the data format is encoded internally just as a `Symbol`,
and the file is passed around as a separate object. This prevents one from
needing to specialize on the data format while preserving inferrability for the file.

There are a couple of minor changes to internal types, and this forced a couple of
changes to the tests. Most significantly, `File{fmt}` is no longer a concrete
type, because `File` got a second type-parameter to encode the filename type.
To prevent inference failures due to varying-length tuples, this also transitions
all magic bytes from `NTuple{N,UInt8}` to `Vector{UInt8}`.

As a case study, with the existing FileIO release, I get ~50us to load a
10x10 RGB png file. With this version, it's ~25us. It's remarkable that inference
can compete with I/O as a source of slowness, but there you have it.

---
## [avar/git](https://github.com/avar/git)@[020c793ec4...](https://github.com/avar/git/commit/020c793ec4e9b05466514394f006113d6b826ae4)
#### Wednesday 2021-03-03 14:33:13 by Ã†var ArnfjÃ¶rÃ° Bjarmason

fsck.c: remove redundant sanity check in fsck_walk_tree()

Remove a check for whether tree modes are bad in
fsck_walk_tree(). This check duplicates logic we get from fsck_tree()
via fsck_object().

When this code was added in 355885d531 (add generic, type aware object
chain walker, 2008-02-25) we'd already had a better version of this
check in since 42ea9cb286 (Be more careful about tree entry modes.,
2005-05-05).

The same series that added the check moved fsck_object() into fsck.c
in ba002f3b28 (builtin-fsck: move common object checking code to
fsck.c, 2008-02-25).

There's no reason for us to be conflating fsck error reporting and
tree walking like this. Everything that's using the walking and cares
about correctness is already using fsck_object().

In terms of API sanity (not that I have a current use-case for this)
it makes sense for the walking API to be very forgiving, and the
fsck_object() function to be strict. We'd like to optionally enable
iterating over bad repository data, but shouldn't die early in case we
need to get more entries to walk down.

Signed-off-by: Ã†var ArnfjÃ¶rÃ° Bjarmason <avarab@gmail.com>

---
## [markjdb/freebsd](https://github.com/markjdb/freebsd)@[b16eb60c7c...](https://github.com/markjdb/freebsd/commit/b16eb60c7c40a36bbfa8688423d40a0aeb5a7fc2)
#### Wednesday 2021-03-03 14:39:09 by Mark Johnston

ktls: Use large pages for output when encrypting in software

[This is too hacky to commit and I've only tested it with TLS1.2 and
AES-GCM so far.  I'm wondering if it's worth trying to pursue this
further.]

While profiling software KTLS on an arm64 server I noticed that driver
ithreads spend a lot of time freeing anonymous pages.  In particular,
for each frame we allocate a set of 4KB pages to store the encrypted
payload before sending to the NIC.  A larger frame size (i.e., a larger
ktls_maxlen value) is beneficial because it reduces the number of mbufs
we have to allocate and free in the transmit path, so the idea is to go
further and allocate contiguous runs of pages to store output data,
using a UMA zone to cache such runs.

The main downsides are:
- Memory overcommit.  We allocate and cache runs of length ktls_maxlen,
  so for smaller frames we will leave some memory unused.  My feeling is
  that in a typical KTLS/sendfile workload a large majority of transmits
  will be of the maximum length, however.
- This scheme basically assumes that we will always be allocating and
  freeing ktls buffers in the same NUMA domain.  If that's not true,
  then we'll get a lot of cross-domain frees which can quickly blow up
  the size of the cache.  We could mitigate this by adding a limit to
  the zone size like we do for the per-CPU page caches.  But allocations
  will be also expensive if we miss in the UMA caches because
  vm_page_alloc_contig() has to lock the per-domain free queues.  I
  expect that in a properly configured system this will not be a
  problem.

The upsides are:
- Less time spent in the page allocator, and we don't have to unwire
  pages when freeing mbufs.
- Less fragmentation and better TLB efficiency since output buffers are
  contiguous.
- Shorter SG lists for DMA to the NIC.

I don't have good CPU profiling tools on this particular platform so
it's hard to say how much of an improvement this gives, but I do see
fewer samples from mlx5 transmit completions with this change.

arm64 supports 16KB and 64KB page sizes, which I think is a much better
optimization for KTLS/sendfile than this one.  But I'm curious as to
whether this change is useful on amd64.

---
## [drk84/Source2](https://github.com/drk84/Source2)@[57c30a2d4d...](https://github.com/drk84/Source2/commit/57c30a2d4d9c493b0f1e1125777c054802e9965c)
#### Wednesday 2021-03-03 16:42:09 by Drk84

Fixed: Reagents consumed on magical skill abortion (issue #605).
-Fixed: RegenHits, RegenMana, RegenStam and RegenFood are not saved when their value is 1.
-Added: @SpellEffectTick and @EffectTick triggers, they are fired when a spell memory has one or more charges(more2) and the spellflag_tick
 ON=@SpellEffectTick / ON=@EffectTick
 Default Object: The object that is going to be affected.
 Src: The object that is going to be affected.
 ARGN1: Spell Id
 ARGN2: Spell Level
 ARGO: The spell memory.(Argo.link holds the caster UID)
 local.charges (R/W) = How many charges are left on the spell memory, this will be automatically decreased by 1 at the end of the method execution. Default value is 1.
 local.delay (R/W) = How many seconds until the next spell effect tick. Default value is 5 seconds.
 local.effect (R/W) = The effect value of the spell, harmful or beneficial (if SPELLFLAG_HEAL is enabled).
 local.damagetype (R/W) = The damage type of the spell, if you are making a custom spell you must set a value otherwise the spell will not cause damage.
 return 1: Destroy the spell memory and block the spell execution.
 return 0: If the spell has the flag SPELLFLAG_SCRIPTED blocks the spell execution

 These triggers fires on the following spells and any custom spells with the SPELLFLAG_TICK:
  Poison: You can now change the damage and damage type by changing the local.effect and local.damage value in these triggers.
  Strangle and Pain Spike: You can now change the damage and damage type in these triggers.
  Regeneration: A Sphere custom spell, you can change the healing value by changing the local.effect value.
  Hallucination: A Sphere custom spell, you can change the duration of the hangover by using local.charges and local.delay.
  Alchool: Unlike in real life, you can change the duration of the hangover by using local.charges and local.delay.
  Custom Spells: Simply add SPELLFLAG_TICK to the spell spellflags. By default every spell memory starts with one charge.
   Spells with SPELLFLAG_HARM and local.damagetype set will cause damage every local.delay seconds.
   Spells with SPELLFLAG_HEAL will heal hitpoints every local.delay seconds.
   Remember that is not mandatory to use  SPELLFLAG_SCRIPTED to make a custom spell, you can just use a spell id higher than 1055, usually i choose 2000.
 It's recommended to update the spells scripts file and sphere defs file, alternatively just add the following line, in the spellflag section in defs.scp/sphere_defs.scp:
  spellflag_tick      080000000  // A spell is going to tick and causing an effect.
 And add SPELLFLAG_TICK to the following spells: Poison, Strangle, Pain Spike, Regeneration, Hallucination.
-Updated SphereCrypt.ini

---
## [Sphereserver/Source-X](https://github.com/Sphereserver/Source-X)@[82e1dc29a0...](https://github.com/Sphereserver/Source-X/commit/82e1dc29a07a3273b97a255f0c8214ac3a6614a8)
#### Wednesday 2021-03-03 17:00:22 by drk84

Fixed: Reagents consumed on magical skill abortion (issue #605). (#638)

-Fixed: RegenHits, RegenMana, RegenStam and RegenFood are not saved when their value is 1.
-Added: @SpellEffectTick and @EffectTick triggers, they are fired when a spell memory has one or more charges(more2) and the spellflag_tick
 ON=@SpellEffectTick / ON=@EffectTick
 Default Object: The object that is going to be affected.
 Src: The object that is going to be affected.
 ARGN1: Spell Id
 ARGN2: Spell Level
 ARGO: The spell memory.(Argo.link holds the caster UID)
 local.charges (R/W) = How many charges are left on the spell memory, this will be automatically decreased by 1 at the end of the method execution. Default value is 1.
 local.delay (R/W) = How many seconds until the next spell effect tick. Default value is 5 seconds.
 local.effect (R/W) = The effect value of the spell, harmful or beneficial (if SPELLFLAG_HEAL is enabled).
 local.damagetype (R/W) = The damage type of the spell, if you are making a custom spell you must set a value otherwise the spell will not cause damage.
 return 1: Destroy the spell memory and block the spell execution.
 return 0: If the spell has the flag SPELLFLAG_SCRIPTED blocks the spell execution

 These triggers fires on the following spells and any custom spells with the SPELLFLAG_TICK:
  Poison: You can now change the damage and damage type by changing the local.effect and local.damage value in these triggers.
  Strangle and Pain Spike: You can now change the damage and damage type in these triggers.
  Regeneration: A Sphere custom spell, you can change the healing value by changing the local.effect value.
  Hallucination: A Sphere custom spell, you can change the duration of the hangover by using local.charges and local.delay.
  Alchool: Unlike in real life, you can change the duration of the hangover by using local.charges and local.delay.
  Custom Spells: Simply add SPELLFLAG_TICK to the spell spellflags. By default every spell memory starts with one charge.
   Spells with SPELLFLAG_HARM and local.damagetype set will cause damage every local.delay seconds.
   Spells with SPELLFLAG_HEAL will heal hitpoints every local.delay seconds.
   Remember that is not mandatory to use  SPELLFLAG_SCRIPTED to make a custom spell, you can just use a spell id higher than 1055, usually i choose 2000.
 It's recommended to update the spells scripts file and sphere defs file, alternatively just add the following line, in the spellflag section in defs.scp/sphere_defs.scp:
  spellflag_tick      080000000  // A spell is going to tick and causing an effect.
 And add SPELLFLAG_TICK to the following spells: Poison, Strangle, Pain Spike, Regeneration, Hallucination.
-Updated SphereCrypt.ini

---
## [MEEPofFaith/bundles](https://github.com/MEEPofFaith/bundles)@[6b215e962a...](https://github.com/MEEPofFaith/bundles/commit/6b215e962aa280f4d83aa3f6614093029da67d74)
#### Wednesday 2021-03-03 17:56:55 by MEEP of Faith

Hi I am Derek Bum, say Goodbye to daily stains and dirty services with new Kitchen Gun. This sink is filthy, but just three shots from Kitchen Gun... BANG BANG BANG and it sparkles like neeeeew. Look at how it cleans this greasy herd. BANG BANG BANG GOODBYE DIRT Grubby tiles... BANG BANG BANG I LOVE YOU KITCHEN GUN, smoch Rusty tabs! BANG BANG BANG AHAHAHAHAHA You can even use it on the washing up! BANG BANG BANG There, all clean aagaaain! NEW KITCHEN GUN Now with laser sights and night vision for after dark cleaning!!

---
## [Rom1deTroyes/thefuck](https://github.com/Rom1deTroyes/thefuck)@[ba85da8490...](https://github.com/Rom1deTroyes/thefuck/commit/ba85da84909610574b1af9736b497c39f248cdd0)
#### Wednesday 2021-03-03 18:02:04 by Romain Heller

~[Doc] Add Uninstall instructions

As we need the package and to modify the shell config, users could have a pain in the ass when it comes to retire *The Fuck* from the system.

---
## [Hugoauto06/TerrainGenerao](https://github.com/Hugoauto06/TerrainGenerao)@[9ab9d715ce...](https://github.com/Hugoauto06/TerrainGenerao/commit/9ab9d715ce3de97e15eed1b1e9ae6a867c553d02)
#### Wednesday 2021-03-03 18:46:38 by Hugoauto06

fuck you

fuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuck youuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu

---
## [MEEPofFaith/progressed-materials](https://github.com/MEEPofFaith/progressed-materials)@[f79047b15e...](https://github.com/MEEPofFaith/progressed-materials/commit/f79047b15e2663af27dc0014dfc96da9b1cb44d0)
#### Wednesday 2021-03-03 19:01:29 by MEEP of Faith

What the fork did you just forking say about me, you little biscuit? I'll have you know I graduated top of my class in the Navy Seals, and I've been involved in numerous secret raids on Al-Quaeda, and I have over 300 confirmed kills. I am trained in gorilla warfare and I'm the top sniper in the entire US armed forces. You are nothing to me but just another target. I will wipe you the fork out with precision the likes of which has never been seen before on this Earth, mark my forking words. You think you can get away with saying that silt to me over the Internet? Think again, forker. As we speak I am contacting my secret network of spies across the USA and your IP is being traced right now so you better prepare for the storm, maggot. The storm that wipes out the pathetic little thing you call your life. You're forking dead, kid. I can be anywhere, anytime, and I can kill you in over seven hundred ways, and that's just with my bare hands. Not only am I extensively trained in unarmed combat, but I have access to the entire arsenal of the United States Marine Corps and I will use it to its full extent to wipe your miserable ass off the face of the continent, you little silt. If only you could have known what unholy retribution your little "clever" comment was about to bring down upon you, maybe you would have held your forking tongue. But you couldn't, you didn't, and now you're paying the price, you goddamn idiot. I will silt fury all over you and you will drown in it. You're forking dead, kiddo.

---
## [MotorwayExtensionGurus/Traveller](https://github.com/MotorwayExtensionGurus/Traveller)@[fbb74b1c27...](https://github.com/MotorwayExtensionGurus/Traveller/commit/fbb74b1c272e54160c11ad230285c0db696273a4)
#### Wednesday 2021-03-03 21:30:10 by Jacob Herd

Merge pull request #3 from MotorwayExtensionGurus/tycrek-dev

fuck you parzi <3

---
## [Emilurenius/RGB-controller](https://github.com/Emilurenius/RGB-controller)@[e2c53f057b...](https://github.com/Emilurenius/RGB-controller/commit/e2c53f057baab3d8f71c774866f5229107bc6141)
#### Wednesday 2021-03-03 21:49:17 by Emil Christiansen

Send data as string

Just doing some stuff to please express. Said the way I was doing stuff is "deprecated". FUCK YOUR DEPRECATIONS, but fine.

---
## [agentsix1/aimware-web-kb](https://github.com/agentsix1/aimware-web-kb)@[7a2624fe66...](https://github.com/agentsix1/aimware-web-kb/commit/7a2624fe667fb65ce61a819d440502a5b1c06891)
#### Wednesday 2021-03-03 23:06:44 by agentsix1

Update keybox.md

this shit be fucking annoying no lie

---

# [<](2021-03-02.md) 2021-03-03 [>](2021-03-04.md)

