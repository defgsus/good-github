# [<](2021-01-13.md) 2021-01-14 [>](2021-01-15.md)

2,849,236 events, 1,411,014 push events, 2,216,884 commit messages, 178,393,310 characters


## [elyobelyob/home-assistant.io](https://github.com/elyobelyob/home-assistant.io)@[bccfd867da...](https://github.com/elyobelyob/home-assistant.io/commit/bccfd867da610eeae96aa8d7e1aee0a9bc178eea)
#### Thursday 2021-01-14 02:01:33 by elyobelyob

Update history_stats.markdown

---
title: History Stats
description: Instructions about how to integrate historical statistics into Home Assistant.
ha_category:
  - Utility
  - Sensor
ha_iot_class: Local Polling
ha_release: 0.39
ha_quality_scale: internal
ha_domain: history_stats
---

The `history_stats` sensor platform provides quick statistics about another integration or platforms, using data from the [`history`](/integrations/history/) integration.

It can track how long the integration has been in a specific state, in a custom time period.

Examples of what you can track:

- How long you were at home this week
- How long the lights were ON yesterday
- How long you watched TV today

## Configuration

To enable the history statistics sensor, add the following lines to your `configuration.yaml`:

{% raw %}

```yaml
# Example configuration.yaml entry
sensor:
  - platform: history_stats
    name: Lamp ON today
    entity_id: light.my_lamp
    state: 'on'
    type: time
    start: '{{ now().replace(hour=0, minute=0, second=0) }}'
    end: '{{ now() }}'
```

{% endraw %}

{% configuration %}
entity_id:
  description: The entity you want to track.
  required: true
  type: string
state:
  description: The states you want to track.
  required: true
  type: [list, string]
name:
  description: Name displayed on the frontend. Note that it is used by Home Assistant to generate sensor's `object_id` so it is advisable to choose a unique one and change name for frontend using [customization](/docs/configuration/customizing-devices/#friendly_name) or via [Lovelace](/lovelace/entities/#name).
  required: false
  default: unnamed statistics
  type: string
type:
  description: "The type of sensor: `time`, `ratio`, or `count`."
  required: false
  default: time
  type: string
start:
  description: When to start the measure (timestamp or datetime).
  required: false
  type: template
end:
  description: When to stop the measure (timestamp or datetime).
  required: false
  type: template
duration:
  description: Duration of the measure.
  required: false
  type: time
{% endconfiguration %}

<div class='note'>

  You have to provide **exactly 2** of `start`, `end` and `duration`.
<br/>
  You can use [template extensions](/topics/templating/#home-assistant-template-extensions) such as `now()` or `as_timestamp()` to handle dynamic dates, as shown in the examples below.

</div>

## Sensor type

Depending on the sensor type you choose, the `history_stats` integration can show different values:

- **time**: The default value, which is the tracked time, in hours
- **ratio**: The tracked time divided by the length of your period, as a percentage
- **count**: How many times the integration you track was changed to the state you track

## Time periods

The `history_stats` integration will execute a measure within a precise time period. You should always provide 2 of the following :
- When the period starts (`start` variable)
- When the period ends (`end` variable)
- How long is the period (`duration` variable)

As `start` and `end` variables can be either datetimes or timestamps, you can configure almost any period you want.

### Duration

The duration variable is used when the time period is fixed. Different syntaxes for the duration are supported, as shown below.

```yaml
# 6 hours
duration: 06:00
```

```yaml
# 1 minute, 30 seconds
duration: 00:01:30
```

```yaml
# 2 hours and 30 minutes
duration:
  # supports seconds, minutes, hours, days
  hours: 2
  minutes: 30
```

<div class='note'>

  If the duration exceeds the number of days of history stored by the `recorder` component (`purge_keep_days`), the history statistics sensor will not have all the information it needs to look at the entire duration. For example, if `purge_keep_days` is set to 7, a history statistics sensor with a duration of 30 days will only report a value based on the last 7 days of history.

</div>

### Examples

Here are some examples of periods you could work with, and what to write in your `configuration.yaml`:

**Today**: starts at 00:00 of the current day and ends right now.

{% raw %}

```yaml
    start: '{{ now().replace(hour=0, minute=0, second=0) }}'
    end: '{{ now() }}'
```

{% endraw %}

**Yesterday**: ends today at 00:00, lasts 24 hours.

{% raw %}

```yaml
    end: '{{ now().replace(hour=0, minute=0, second=0) }}'
    duration:
      hours: 24
```

{% endraw %}

**This morning (6AM - 11AM)**: starts today at 6, lasts 5 hours.

{% raw %}

```yaml
    start: '{{ now().replace(hour=6, minute=0, second=0) }}'
    duration:
      hours: 5
```

{% endraw %}

**Current week**: starts last Monday at 00:00, ends right now.

Here, last Monday is _today_ as a timestamp, minus 86400 times the current weekday (86400 is the number of seconds in one day, the weekday is 0 on Monday, 6 on Sunday).

{% raw %}

```yaml
    start: '{{ as_timestamp( now().replace(hour=0, minute=0, second=0) ) - now().weekday() * 86400 }}'
    end: '{{ now() }}'
```

{% endraw %}

**Next 4pm **: ends today at 00:00, lasts 30 days. Easy one.

{% raw %}

```yaml
    end: '{{ now().replace(hour=0, minute=0, second=0) }}'
    duration:
      days: 30
```

{% endraw %}

**Last 30 days**: ends today at 00:00, lasts 30 days. Easy one.

{% raw %}

```yaml
    end: '{{ now().replace(hour=0, minute=0, second=0) }}'
    duration:
      days: 30
```

{% endraw %}


** 4PM always in the future**: ends in the future at 16:00, starts 24 hours before.

{% raw %}

```yaml
    end: '{{ (now().replace(minute=0,second=0) + timedelta(hours=8)).replace(hour=16) }}'
    duration:
      hours: 24
```

{% endraw %}

**All your history** starts at timestamp = 0, and ends right now.

{% raw %}

```yaml
    start: '{{ 0 }}'
    end: '{{ now() }}'
```

{% endraw %}

<div class='note'>

  The `/developer-tools/template` page of your Home Assistant UI can help you check if the values for `start`, `end` or `duration` are correct. If you want to check if your period is right, just click on your component, the `from` and `to` attributes will show the start and end of the period, nicely formatted.

</div>

---
## [ccodwg/Covid19Canada](https://github.com/ccodwg/Covid19Canada)@[a5e23f969a...](https://github.com/ccodwg/Covid19Canada/commit/a5e23f969a83980de4c816a83b4f1af3004c832b)
#### Thursday 2021-01-14 03:15:03 by Jean-Paul R. Soucy

New data: 2021-01-13. See data notes for important messages.

Vaccine datasets:

- 2021-01-11: Our Ontario vaccine dataset has changed. Previously, we used two datasets: the MoH Daily Situation Report (https://www.oha.com/news/updates-on-the-novel-coronavirus), which is released weekdays in the evenings, and the “COVID-19 Vaccine Data in Ontario” dataset (https://data.ontario.ca/dataset/covid-19-vaccine-data-in-ontario), which is released every day in the mornings. Because the Daily Situation Report is released later in the day, it has more up-to-date numbers. However, since it is not available on weekends, this leads to an artificial “dip” in numbers on Saturday and “jump” on Monday due to the transition betwen data sources. We will now exclusively use the daily “COVID-19 Vaccine Data in Ontario” dataset. Although our numbers will be slightly less timely, the daily values will be consistent. We have replaced our historical dataset with “COVID-19 Vaccine Data in Ontario” as far back as they are available.
- 2020-12-17: Vaccination data have been added as time series in timeseries_prov and timeseries_hr.
- 2020-12-15: We have added two vaccine datasets to the repository, vaccine_administration_cumulative.csv and vaccine_distribution_cumulative.csv. These data should be considered preliminary and are subject to change and revision. The format of these new datasets may also change at any time as the data situation evolves.

Upcoming changes (specific dates to be announced soon):

- The data structure of time series data will change in response to user feedback. This will only consist of adding additional columns to make the data easier to work with. The core columns will remain the same, for now. More details to follow. Initially, the updated dataset will be provided alongside the new dataset. After a time, the new data format will completely replace the old format.

Recent changes:

- 2021-01-08: The directories cases_extra and mortality_extra have been moved to other/cases_extra and other/mortality_extra.

Revise historical data: cases (AB, BC, MB, ON, QC, SK); mortality (ON).

Note regarding deaths added in QC today: “The data also report 35 new deaths, but the total of deaths amounts to 8,815 due to the withdrawal of 2 deaths that the investigation has shown not to be attributable to COVID-19. Among these 35 deaths, 7 have occurred in the last 24 hours, 23 have occurred between January 6 and January 11, 4 have occurred before January 6 and 1 has occurred at an unknown date.” We report deaths such that our cumulative regional totals match today’s values. This sometimes results in extra deaths with today’s date when older deaths are removed.

https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/#c47900

Note about SK data: As of 2020-12-14, we are providing a daily version of the official SK dataset that is compatible with the rest of our dataset in the folder official_datasets/sk. See below for information about our regular updates.

SK transitioned to reporting according to a new, expanded set of health regions on 2020-09-14. Unfortunately, the new health regions do not correspond exactly to the old health regions. Additionally, the provided case time series using the new boundaries do not exist for dates earlier than August 4, making providing a time series using the new boundaries impossible.

For now, we are adding new cases according to the list of new cases given in the “highlights” section of the SK government website (https://dashboard.saskatchewan.ca/health-wellness/covid-19/cases). These new cases are roughly grouped according to the old boundaries. However, health region totals were redistributed when the new boundaries were instituted on 2020-09-14, so while our daily case numbers match the numbers given in this section, our cumulative totals do not. We have reached out to the SK government to determine how this issue can be resolved. We will rectify our SK health region time series as soon it becomes possible to do so.

---
## [jaymzh/chef](https://github.com/jaymzh/chef)@[46191a6df4...](https://github.com/jaymzh/chef/commit/46191a6df4cb9379ade0b87111a0841e84768c7f)
#### Thursday 2021-01-14 04:20:53 by Phil Dibowitz

Add support for client.d files in chef-shell

This brings chef-shell a bit closer to behaving properly. This code is
tons of copy-pasta and needs some love. Because it's not using *any* of
`Chef::Application` (not `Application` or `Application::Base` or even
it's own fork of `Application` like half the other stuff in the repo),
it doesn't have access to _any_ of the many versions of
`load_config_file` (note to self: collapse those into one).

Pulling in Application will be a significant chunk of work, so in the
mean time I did the minimal amount of work to make the `parse_opts` in
shell.rb create the right bits so that Chef::Config and Mixin::DotD can
work... so while this doesn't fix the problem that we're invoking our
own config parsing, it at least uses as much of the common code as I can
without reworking the entirety of chef-shell.

Here's an example of it working:

```
root@ldt-hardwired:~# cinc-shell -s -c /etc/chef/client.rb
loading configuration: /etc/chef/client.rb
true
Session type: solo
```

From there it loads not only `/et/chef/client.rb` but also
`/etc/chef/client.d/ohai.rb`. Neat.

None of this portion of the code is tested in the specs and frankly, I'm
not entirely certainly how to go about writing a test, but I'll poke
around.

fixes #10748

Signed-off-by: Phil Dibowitz <phil@ipom.com>

---
## [rhythm-dino/rhythm-dino](https://github.com/rhythm-dino/rhythm-dino)@[4866fd1e24...](https://github.com/rhythm-dino/rhythm-dino/commit/4866fd1e24913bb7e74890edf1e5b1d6fb1da8fa)
#### Thursday 2021-01-14 05:22:06 by AMIRIOX

[merge] fuck these mess, fuck, fuck damn it piece of shit

---
## [iovis/dotfiles](https://github.com/iovis/dotfiles)@[b1370d56a5...](https://github.com/iovis/dotfiles/commit/b1370d56a515bf0deb312d4822e01291c9fb3192)
#### Thursday 2021-01-14 05:42:24 by David Marchante

[zsh] Put asdf configuration again in zshrc

Turns out macOS has these two things called `/etc/paths` and `/etc/paths.d/*` that literally prepend themselves _after_ .zshenv, kinda defeating the whole fucking purpose of having one for that end (JOY 🎉). I was fucking with it before because my `.zprofile` was overwriting the $PATH...

This is fucking great.

Looks like asdf's script is just making sure the PATH is right (actually removing it from the PATH and prepending it if not!), but I still need it in .zshenv because that's what vim uses behind the scenes for its commands (fun fact, the PATH doesn't get messed up in that scenario).

Fucking end me now.

---
## [rzero9/mame](https://github.com/rzero9/mame)@[4acddfb638...](https://github.com/rzero9/mame/commit/4acddfb638870d8b52b62c35ca7a6b404cdd9478)
#### Thursday 2021-01-14 08:09:00 by r09

fmtowns_cd.xml: 16 new dumps, 13 replacements, 6 missing floppies added

New working software list additions
-----------------------------------

Air Warrior V1.2L11 [redump.org, wiggy2k]
Emit Vol. 1 - Toki no Maigo (Demo) [redump.org]
Engage Errands - Miwaku no Shito-tachi [redump.org]
Engage Errands II - Hikari o Ninau Mono [redump.org, wiggy2k]
Hyper Planet Shiki Vol. 2 [Maddog]
Kikai Jikake no Marian [rockleevk]
Last Armageddon CD Special (Selon reprint) [redump.org]
Lua [redump.org]
Naru Mahjong [redump.org]
Nijiiro Denshoku Musume [redump.org]
Princess Danger [rockleevk]
Tactical Tank Corps DX [redump.org]
Tensen Nyannyan [redump.org]
Winning Post [redump.org]
WonPara Wars [redump.org]

New not working software list additions
---------------------------------------

Crayonnage [redump.org]

Replaced software list items
----------------------------

Bubble Bobble [redump.org]
Dragons of Flame [redump.org]
Exciting CD '94 Summer [redump.org]
Game Technopolis Super Collection 2 [redump.org]
Jan Jaka Jan [redump.org]
Kigen - Kagayaki no Hasha [redump.org]
Lupin Sansei - Hong Kong no Mashu - Fukushuu wa Meikyuu no Hate ni
[redump.org]
Megamorph [redump.org]
Record of Lodoss War - Haiiro no Majo [redump.org]
The Horde [redump.org]
Uchuu Kaitou Funny Bee [redump.org]
Wakoku Seiha Den [redump.org]
Zen Nihon Bishoujo Mahjong Senshuken Taikai - Heart de Ron!!
[redump.org]

Software list items promoted to working
---------------------------------------

Alice no Yakata CD II [wiggy2k]
Doki Doki Vacation - Kirameku Kisetsu no Naka de [wiggy2k]
Hyper Planet for Marty [cherokee]
Ms. Detective File #1 - Iwami Ginzan Satsujin Jiken (FM Towns Marty version) [cherokee]
Sangokushi IV [akira_2020]
Sensual Angels [cherokee]

---
## [bukatea/bottletrack-app](https://github.com/bukatea/bottletrack-app)@[4a71d37a98...](https://github.com/bukatea/bottletrack-app/commit/4a71d37a989b9b3b4891d56614f3709304cc5395)
#### Thursday 2021-01-14 10:39:26 by Jonathan Lee

Add a bunch of shit (a big fuck u to whoever goes thru the commits later, sorry\!)

---
## [dependabot/dependabot-core](https://github.com/dependabot/dependabot-core)@[3fecc46369...](https://github.com/dependabot/dependabot-core/commit/3fecc463693d03929596cf5b4cd9c61abadf5da7)
#### Thursday 2021-01-14 12:28:55 by Jurre Stender

Sanitize mentions more aggressively

The current sanitization works well when directly creating PRs, however,
when a user replies to such an email, some of the markup of the original
message will be stripped out (either by GitHub, or by email providers),
which can result in a link like `<a href="https://github.com/jurre>@jurre</a>`
being turned into just `@jurre`, which will consequently mention the
user when that email reply is rendered.

This wraps the inner mention in a codeblock, which should prevent this
from happening. It looks _slightly_ funny:

<a href="https://github.com/jurre><code>@jurre</code></a>

But I think this is worth it, getting unexpected mentions by Dependabot
is a source of frustration for users, and by showing that the mention is
wrapped in a codeblock, this should make it easier to spot if it was an
actual mention or not.

Alternatively we could insert some no-space character between the `@`
and the user login, but I personally prefer this more explicit approach.

---
## [couchbasedeps/snappy](https://github.com/couchbasedeps/snappy)@[ca37ab7fb9...](https://github.com/couchbasedeps/snappy/commit/ca37ab7fb9b718e056009babb4fea591626e5882)
#### Thursday 2021-01-14 12:42:44 by jgorbe

Ensure DecompressAllTags starts on a 32-byte boundary + 16 bytes.

First of all, I'm sorry about this ugly hack. I hope the following long
explanation is enough to justify it.

We have observed that, in some conditions, the results for dataset number 10
(pb) in the zippy benchmark can show a >20% regression on Skylake CPUs.

In order to diagnose this, we profiled the benchmark looking at hot functions
(99% of the time is spent on DecompressAllTags), then looked at the generated
code to see if there was any difference. In order to discard a minor difference
we observed in register allocation we replaced zippy.cc with a pre-built assembly
file so it was the same in both variants, and we still were able to reproduce the
regression.

After discarding a regression caused by the compiler, we digged a bit further
and noticed that the alignment of the function in the final binary was
different. Both were aligned to a 16-byte boundary, but the slower one was also
(by chance) aligned to a 32-byte boundary. A regression caused by alignment
differences would explain why I could reproduce it consistently on the same CitC
client, but not others: slight differences in the sources can cause the resulting
binary to have different layout.

Here are some detailed benchmark results before/after the fix. Note how fixing
the alignment makes the difference between baseline and experiment go away, but
regular 32-byte alignment puts both variants in the same ballpark as the
original regression:

Original (note BM_UCord_10 and BM_UDataBuffer_10 around the -24% line):

  BASELINE
  BM_UCord/10                    2938           2932          24194 3.767GB/s  pb
  BM_UDataBuffer/10              3008           3004          23316 3.677GB/s  pb

  EXPERIMENT
  BM_UCord/10                    3797           3789          18512 2.915GB/s  pb
  BM_UDataBuffer/10              4024           4016          17543 2.750GB/s  pb

Aligning DecompressAllTags to a 32-byte boundary:

  BASELINE
  BM_UCord/10                    3872           3862          18035 2.860GB/s  pb
  BM_UDataBuffer/10              4010           3998          17591 2.763GB/s  pb

  EXPERIMENT
  BM_UCord/10                    3884           3876          18126 2.850GB/s  pb
  BM_UDataBuffer/10              4037           4027          17199 2.743GB/s  pb

Aligning DecompressAllTags to a 32-byte boundary + 16 bytes (this patch):

  BASELINE
  BM_UCord/10                    3103           3095          22642 3.569GB/s  pb
  BM_UDataBuffer/10              3186           3177          21947 3.476GB/s  pb

  EXPERIMENT
  BM_UCord/10                    3104           3095          22632 3.569GB/s  pb
  BM_UDataBuffer/10              3167           3159          22076 3.496GB/s  pb

This change forces the "good" alignment for DecompressAllTags which, if
anything, should make benchmark results more stable (and maybe we'll improve
some unlucky application!).

---
## [Divyanshu-Modi/Atom-X-Kernel](https://github.com/Divyanshu-Modi/Atom-X-Kernel)@[2388f2d0d9...](https://github.com/Divyanshu-Modi/Atom-X-Kernel/commit/2388f2d0d9b4e9cf2b1b9001a655b77a16c989c2)
#### Thursday 2021-01-14 13:33:20 by Peter Zijlstra

locking/rwsem: Fix down_write_killable()

The new signal_pending exit path in __rwsem_down_write_failed_common()
was fingered as breaking his kernel by Tetsuo Handa.

Upon inspection it was found that there are two things wrong with it;

 - it forgets to remove WAITING_BIAS if it leaves the list empty, or
 - it forgets to wake further waiters that were blocked on the now
   removed waiter.

Especially the first issue causes new lock attempts to block and stall
indefinitely, as the code assumes that pending waiters mean there is
an owner that will wake when it releases the lock.

Reported-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Tested-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Tested-by: Michal Hocko <mhocko@kernel.org>
Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
Cc: Chris Zankel <chris@zankel.net>
Cc: David S. Miller <davem@davemloft.net>
Cc: Davidlohr Bueso <dave@stgolabs.net>
Cc: H. Peter Anvin <hpa@zytor.com>
Cc: Jiri Olsa <jolsa@redhat.com>
Cc: Linus Torvalds <torvalds@linux-foundation.org>
Cc: Max Filippov <jcmvbkbc@gmail.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Stephane Eranian <eranian@google.com>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Tony Luck <tony.luck@intel.com>
Cc: Vince Weaver <vincent.weaver@maine.edu>
Cc: Waiman Long <Waiman.Long@hpe.com>
Link: http://lkml.kernel.org/r/20160512115745.GP3192@twins.programming.kicks-ass.net
Signed-off-by: Ingo Molnar <mingo@kernel.org>
Signed-off-by: Divyanshu-Modi <divyan.m05@gmail.com>

---
## [pthubert/useofrplinfo](https://github.com/pthubert/useofrplinfo)@[5223ba8194...](https://github.com/pthubert/useofrplinfo/commit/5223ba8194eb4a6043d8efc44b4c1f27e95734e7)
#### Thursday 2021-01-14 13:37:57 by Pascal Thubert

Subject: Re: Benjamin Kaduk's No Objection on draft-ietf-roll-useofrplinfo-42

What about :

          <t>
            The RH3 header usage described here can be abused in equivalent
            ways. An external attacker may form a packet with an RH3 that is
            not fully consumed and encapsulate it to hide the RH3 from
            intermediate nodes and disguise the origin of
            traffic. As such, the attacker's RH3 header will not be seen by
            the network until it reaches the destination, which will decapsulate
            it. As indicated in section 4.2 of <xref target="RFC6554"/>, RPL
            routers are responsible for ensuring that an SRH is only used
            between RPL routers. As such, if there is an RH3 that is not fully
            consumed in the encapsulated packet, the node that decapsulates it
            MUST ensure that the outer packet was originated in the RPL domain
            and drop the packet otherwise.
          </t>
          <t>
            Also, as indicated by section 2 of
            <xref target="RFC6554"/>, RPL Border Routers "do not allow datagrams
            carrying an SRH header to enter or exit a RPL routing domain". This
            sentence must be understood as concerning non-fully-consumed packets.
            A consumed (inert)
            RH3 header could be present in a packet that flows from one LLN,
            crosses the Internet, and enters another LLN.  As per the
            discussion in this document, such headers do not need to be
            removed.  However, there is no case described in this document
            where an RH3 is inserted in a non-storing network on traffic that
            is leaving the LLN, but this document should not preclude such a
            future innovation.
          </t>
          <t>
            In short, a packet that crosses the border of the RPL domain MAY
            carry and RH3, and if so, that RH3 MUST be fully consumed.
          </t>

From: Pascal Thubert (pthubert)
Sent: jeudi 14 janvier 2021 14:12
To: Ines Robles <mariainesrobles@googlemail.com>
Cc: Michael Richardson <mcr@sandelman.ca>; Pascal Thubert <pascal.thubert@gmail.com>
Subject: RE: Benjamin Kaduk's No Objection on draft-ietf-roll-useofrplinfo-42: (with COMMENT)

We must do that, for sure. I’m reviewing the text that’s really hard to understand…

From: Ines Robles <mariainesrobles@googlemail.com>
Sent: jeudi 14 janvier 2021 13:53
To: Pascal Thubert (pthubert) <pthubert@cisco.com>
Cc: Michael Richardson <mcr@sandelman.ca>; Pascal Thubert <pascal.thubert@gmail.com>
Subject: Re: Benjamin Kaduk's No Objection on draft-ietf-roll-useofrplinfo-42: (with COMMENT)

Thank you very much Pascal and Michael,

I am available tomorrow after 3pm UTC.

Ok,  from the discussion: " Erik recommend referring to RFC 6554 S4.2 for how to handle RH3's if the node is also a RPL-aware router and say it MUST drop the packet if segments left is non-zero and it's not a RPL-aware router." maybe we should do just that, would it be ok?

thanks,
ines.

On Thu, Jan 14, 2021 at 2:37 PM Pascal Thubert (pthubert) <pthubert@cisco.com> wrote:
I had a chat with Alvaro; he's waiting for the DISCUSS from Erik.
Sadlt 43 does not address that DISCUSS.

The offending text is
"
   The RH3 header usage described here can be abused in equivalent ways
   (to disguise the origin of traffic and attack other nodes) with an
   IPv6-in-IPv6 header to add the needed RH3 header.  As such, the
   attacker's RH3 header will not be seen by the network until it
   reaches the end host, which will decapsulate it.  An end-host should
   be suspicious about an RH3 header which has additional hops which
   have not yet been processed, and SHOULD ignore such a second RH3
   header.

   In addition, the LLN will likely use [RFC8138] to compress the IPv6-
   in-IPv6 and RH3 headers.  As such, the compressor at the RPL-root
   will see the second RH3 header and MAY choose to discard the packet
   if the RH3 header has not been completely consumed.  A consumed
   (inert) RH3 header could be present in a packet that flows from one
   LLN, crosses the Internet, and enters another LLN.  As per the
   discussion in this document, such headers do not need to be removed.
   However, there is no case described in this document where an RH3 is
   inserted in a non-storing network on traffic that is leaving the LLN,
   but this document should not preclude such a future innovation.  It
   should just be noted that an incoming RH3 must be fully consumed, or
   very carefully inspected to match a policy that applies to this
   network and is correctly processed by the leaves.
"

This text is hard to read and makes little sense for the most part since the incoming packet from the Internet will be encapsulated so there will not be 2 RH2 even if the incoming packet has one.

I'm on it, will propose a pull, but happy to discuss what we really want to say. My answer is to indicate that there is encaps and that the inner packet MUST be consumed as Erik says when processed by a Host. Since the root does not know whether the leaf is a host or an external router, there's little we can do beyond applying a policy.

Thoughts? Call?

Pascal

> -----Original Message-----
> From: Michael Richardson <mcr@sandelman.ca>
> Sent: jeudi 14 janvier 2021 13:29
> To: Pascal Thubert (pthubert) <pthubert@cisco.com>
> Cc: Ines Robles <mariainesrobles@googlemail.com>; Pascal Thubert
> <pascal.thubert@gmail.com>
> Subject: Re: Benjamin Kaduk's No Objection on draft-ietf-roll-useofrplinfo-42:
> (with COMMENT)
>
>
> Pascal Thubert (pthubert) <pthubert@cisco.com> wrote:
>     > Inès pulled and published. Can you please check the new definition in
>     > -43? We avoided the term reboot but used disruptive that was present in
>     > a reviewer suggestion.
>
> Yes, I know I'm late on reviewing.
> I'm checking -43 now.

---
## [apaszke/dex-lang](https://github.com/apaszke/dex-lang)@[ec16f029be...](https://github.com/apaszke/dex-lang/commit/ec16f029be3bad391404cb235128211d6abd8c3d)
#### Thursday 2021-01-14 13:43:58 by Adam Paszke

Parametrize runWriter by a monoid used for the reduction

This makes it possible to express (parallel) reductions over arbitrary
monoids. Thanks to this, we can start removing some nasty hacks (like
the one used for `Eq (n=>a)`) and make the (work-in-progress) FFT example
parallel!

Anyway, this whole change turned out to be surprisingly difficult, but
thanks to many chats with @dougalm, I think that we've arrived at a
particularly nice solution.

The crux of the matter is the fact that Dex, unlike most other
languages with some form of a built-in reduction operator, allows
slicing the accumulator. This poses an interesting problem: if the user
was to specify the `Monoid` instance for the full accumulator (e.g. a
matrix), then what monoid are we supposed to use for its slice?! As it
turns out, this might not even be well defined! For example, the type of square
matrices with identity matrix and matrix multiplication forms a monoid,
but there is no natural "sub-monoid" we could use in an expression
of the form `ref!i += ...`.

So, unless we're ok with giving up reference slicing (which we know we
want for sure, since this is a way to express e.g. parallel scatters and
histograms), we have to come up with a way of constructing those
sub-monoids. And here, and answer is to turn the problem around: instead
of asking the users to provide us the monoids for the full references,
we expect the monoid to refer to some _base type_ (and we call it a
_base monoid_). That is, when the `Accum` reference is of type
`n=>m=>...=>k=>a`, then any of `m=>...=>k=>a`, ..., `k=>a` and even
`a` are considered base types. While this is a bit surprising at first,
it turns out to actually be quite convenient, since it does seem more
straightforward to say "I want this to be a reduction over `(Float, 0.0, +)`"
instead of mentioning the full table type, a broadcast version of `0.0`
and a pointwise-lifted version of `+`.

Finally, because many data types have multiple valid monoids (`Float`
has at least four: `+`, `*`, `min`, `max`), the monoid argument is
explicit and those instances can be obtained via the `named-instance`
syntax added in the previous commits. Note that I've also included some
helper functions which make it possible to synthesize `Monoid` instances
automatically from `Add` and `Mul` instance for any given type (see
`AddMonoid` and `MulMonoid`).

I haven't been fully able to verify the correctness of the
parallelization change, because the CUDA backend seems to be broken
anyway (sigh...), but the code it generates looks ok.

---
## [tannerhelland/PhotoDemon](https://github.com/tannerhelland/PhotoDemon)@[68ed6d0365...](https://github.com/tannerhelland/PhotoDemon/commit/68ed6d0365e9b26ef4df1ac73c52cd299b7a88bc)
#### Thursday 2021-01-14 16:16:53 by Tanner

PSP decoder: vector shapes now render correctly, including gradient fills*

* ...for 3 out of 4 gradient shapes.  Conical fills are unfortuntely not supported natively in GDI+, so I need to substitute my own conical fill renderer.  This requires some messy work inside pd2D and I'm not quite ready for it.  But linear, square, and radial fills work beautifully!

* At some point after Corel took over Paintshop Pro, they completely changed how gradients are stored inside PSP files.  The existing spec is no longer observed, and Corel has never provided public documentation on their changes.  I don't have time to reverse-engineer their changes right now, so unfortunately, gradient fills on "modern" PSP files remain a TODO item.

With those caveats out of the way, performance of the new renderer is pretty darn amazing, and vector files load faster into PD than they do into PSP itself.  This little project proved to be a great stress-test of pd2D's vector capabilities, and I'm satisfied that the design is good enough to back similar vector tools inside PD itself.

Next up, importing text layers.  I already know that I won't be able to precisely support all of PSP's text features (style changes inside a single text layer are outside what I can reasonably implement, for example), but I hope to generate editable text layers with similar-enough properties that old PSP files can be "rescued" if you don't actually own a copy of Paintshop Pro.  (Similarly, I should be able to make text support work "well enough" that PD can export compatible text layers to PSP files, once PSP export support is added.  Fingers crossed.)

---
## [crescendosw/hymnal_pdfs](https://github.com/crescendosw/hymnal_pdfs)@[433f3e43eb...](https://github.com/crescendosw/hymnal_pdfs/commit/433f3e43eb98ed74fdb1fcaa89d31991d7721649)
#### Thursday 2021-01-14 16:22:29 by Francis Jeschke

Delete 035a - O LORD, I Love You, God, My Strength - Psalm 18.zip

---
## [justingreenwood/greenwood-kids](https://github.com/justingreenwood/greenwood-kids)@[60d42b597a...](https://github.com/justingreenwood/greenwood-kids/commit/60d42b597a045e2244d32e69cdfb391a012a227a)
#### Thursday 2021-01-14 16:28:33 by Perry Greenwood

perry is best

He helps his idiotic stupid dumb imbacile of a little sister.

---
## [kingclowndean/BigTop](https://github.com/kingclowndean/BigTop)@[5c804bfe94...](https://github.com/kingclowndean/BigTop/commit/5c804bfe949cd695d5b0860512ac575723044c47)
#### Thursday 2021-01-14 19:07:37 by kingclowndean

Create Burning Midnight Oil.png

Frequently Asked Questions about working in Second Life What is Second Life and why is it relevant for enterprises and governments? What advantages does Second Life offer that are unique among virtual platforms? Cost and Billing What does it cost to register for Second Life, and what can I expect immediately upon registration? How much does a typical Second Life work environment cost? How can I buy land? What billing options do I have? Avatars What is an avatar and how do I create mine? Can my avatar have my real name? Is it possible for my enterprise group to share one surname? Are there rules about how avatars can behave inworld? How many employees/avatars can I get into one Second Life working environment? How do I move around in Second Life? Communication and Collaboration How do avatars communicate in Second Life? What languages does Second Life support? What 3D business applications are available today for use in meetings and training environments in Second Life? How can Second Life best be used for networking and building relationships? How is collaboration in Second Life different from sharing a conference call, Webex, or video conferencing technologies? Security How secure is my data (text chat, voice, login, etc.) in Second Life? How can I control who is permitted to enter my region, workspace, or events? How do I grant estate rights to other avatars so they can collaborate on building and other aspects of sharing space? What are “griefers” and how can they be avoided? How can my organization best avoid environments and content that is inappropriate for business use? I want my employees to go directly to my organization’s space in Second Life. How do I do set this up? Technology How robust and stable is the Second Life technology platform and how can I find out about scheduled outages? What computer hardware, software, and network bandwidth requirements are necessary to run Second Life? How do I know if my organization will permit me to access Second Life within my corporate firewall? Building How easy is it to build objects in Second Life and can I train my team to do this? Do you have best practices for working with content developers regarding IP ownership? Frequently Asked Questions about working in Second Life What is Second Life and why is it relevant for enterprises and governments? Second Life, the leading 3D virtual world, was launched in 2003 as a technology platform that enables millions of consumers, represented inworld as avatars, to imagine and build immersive environments that are easy and inexpensive to create. Second Life is not only one of the oldest virtual world platforms, but it is also the largest with millions of active users residing in more than 150 countries globally. Second Life has always been used by a wide variety of individuals, businesses, educators, governments and nonprofit organizations as an environment for entertainment, education, social interaction, research, shopping, and more. Over the years, many large multi-national enterprises and government institutions have realized that Second Life is also a powerful collaboration tool for work such as: meetings, training sessions, and simulations and prototypes. What advantages does Second Life offer that are unique among virtual platforms? Second Life owns 90 percent of the virtual world market and is the most flexible, richest, and most advanced virtual work solution that exists today. Here are a few facts to consider: Largest Virtual World: Second Life, the largest virtual world platform, is roughly the size of Houston when all of the individual parcels, known as “regions” or “islands,” owned by various individuals and organizations are taken as a collective. Richest Content and Most Vibrant Digital Goods Economy: Second Life has the richest and largest library of virtual content—avatars, clothing, building elements, etc. — in existence with millions of items already created by inworld residents and more are built every day. This library allows organizations to purchase content easily and cheaply, versus having to pay thousands of dollars in services to build these items in other environments. Most Flexible: As opposed to many other virtual world companies, Second Life allows you to create multiple work solutions within the same environment. For example, you can have a virtual meeting space, a large conference center, a training simulation, and a social gathering space—all on one Region. Cost and Billing What does it cost to register for Second Life, and what can I expect immediately upon registration? Joining Second Life is free. After completing a short registration form and choosing an avatar, you can then explore Help Island —a specialized doorway into Second Life where you can to find other people from hundreds of countries around the world. Today, an organization follows the same registration process that consumers do. How much does a typical Second Life work environment cost? If you decide to become a landowner, then please email business@lindenlab.com and we'll be happy to discuss pricing and walk you through the process. In general, for one private region in Second Life (or what is sometimes called an “island”), the initial one-time set-up fee is $349 USD and then $229 USD a month in maintenance costs, per region. One region is 256 meters on each side, which is bigger than two American football fields lying end to end in the physical world. Once your organization owns virtual land, you can then create buildings, meeting spaces, and social spaces yourself (if your organization has Second Life building skills in-house). How can I buy land? Unless you’re a Second Life pro, the best way for enterprises or educational institutions to purchase land is to email business@lindenlab.com and we can help walk you through the process. What billing options do I have? You can either make your purchase on a credit card or your company can be billed directly. Avatars What is an avatar and how do I create mine? An avatar is a digital, animated representation of yourself in Second Life. When you join Second Life, you have a standard set of avatars to choose from. Once you receive your avatar, then you can go into “appearance mode” and change your hair, skin, shape, and clothing. We encourage you to personalize your inworld representation by purchasing new skin, clothes, and other accessories from thousands of Second Life retailers on the Second Life Marketplace. To view a series of video tutorials about how to create your avatar and other topics, see the official Second Life YouTube channel here. Can my avatar have my real name? Is it possible for my enterprise group to share one surname? Currently within Second Life, there are two naming options for organizations to choose from. Business enterprise group administrators can permit members to select a surname offered upon registration or choose to purchase a customized group surname from Linden Lab that allows you to set up a corporate last name that you can use to create an unlimited number of employee accounts. For example, Joe Morris is an AT&amp;T employee and can choose to use a standard Second Life name, which is a username of Joe's choice with the surname 'Resident'. Or, if AT&amp;T’s administrator purchases the corporate last names option, then Joe Morris have the name of Joe AT&amp;T, to help create a common affiliation and group among AT&amp;T employees. In the last example, everyone who works at AT&amp;T would have the same corporate last name to help employees identify themselves inworld. Regardless of what Second Life name scheme is chosen, all employees can wear inworld “name tags” that clearly display real names. We also offer Display Names which can be customized by any account holder and updated regularly, up to once a week. Are there rules about how avatars can behave inworld? When joining Second Life, every new member must agree to the Second Life Terms of Service, which outline the rules that all avatars must follow. Some businesses choose to adopt the standard Second Life Terms of Service alone and some opt to create additional terms that outline a specific group, or organization’s rules, such as prohibiting access to inappropriate materials or only allowing human avatars. How many employees/avatars can I get into one Second Life working environment? Each region can run optimally with roughly 60 avatars before performance suffers and 100 is the current maximum limit. Factors that can affect performance include how complicated the environment is and the intricacy of avatar clothing. To create an environment that can hold more people, we suggest that conference spaces are built at a four-corners area of four separate regions. Doing this, an event can hold roughly 200-300 avatars. If you require more employees to participate in an inworld event, Second Life can easily be streamed live to the web, which means that thousands of people globally can participate in an inworld event through both video and chat. How do I move around in Second Life? Although operating within the Second Life environment might be challenging at first, it’s easy to get the hang of all of the movements that you’ll be using in a business environment—walking, sitting, teleporting, etc. For more information and tips on how to get around, visit our Knowledge Base. Our new user also covers how to move your avatar and interact with the environment. If you're unsure about what to do, try right-clicking on something you can see; a menu will open, displaying available interaction options -- like sitting on a chair, or paying a vendor to purchase an item. Communication and Collaboration How do avatars communicate in Second Life? Second Life is a rich-immersive environment that enables a wide variety of communication channels, including both text chat, and 3D spatial voice. There are other more interesting and dynamic ways that teams can communicate such as virtual brainstorming tools, document sharing, whiteboarding, 3D mind mapping, and many other business tools that take full advantage of virtual workspaces. What languages does Second Life support? You’ll find members from over 150 countries and you’ll find hundreds of different languages spoken in Second Life. Linden Lab, the makers of Second Life, has customized betas of the Second Life Viewer, or the 3D browser software that allows you to enter Second Life, in the following languages: Danish, German, Spanish, French, Italian, Polish, Portuguese, Russian, Turkish, Japanese and Chinese. Once inworld, Second Life supports most languages used typically used within global organizations. Additionally, team members who speak different languages can communicate via several inworld text translation tools, including an optional translation interface built directly into the viewer which uses Bing Translate or Google Translate (at the user's preference). What 3D business applications are available today for use in meetings and training environments in Second Life? Today, there is a wide assortment of business productivity and creativity applications within Second Life. These include widgets for: running Powerpoint presentations, white boarding, brainstorming, dynamic audience polling, and many others. To find business applications, you can search the SL Marketplace. How can Second Life best be used for networking and building relationships? We all know that work is much more than meetings, training, and other more formal activities. It’s also about those “water cooler moments” where you can connect and communicate with colleagues, partners, customers, prospects, industry experts, and friends. Second Life was designed as a social networking platform and all of those capabilities are naturally part of the Second Life experience. For example, IBM held a networking event where IBMers shared virtual beers and went virtual jet skiing and hang gliding. Needless to say, experiences like these are not only memorable, but also great business networking and socializing opportunities. How is collaboration in Second Life different from sharing a conference call, Webex, or video conferencing technologies? Teleconferencing, Webex, and video conferencing technologies are all important collaboration tools that companies use every day for global and mobile teams to work together and stay connected. Second Life provides a sense of presence that many people find more engaging and compelling than many other types of conferencing, as well as providing a 3D space to share information. In addition, informal discussions are easy to have after a meeting, since your Second Life experience doesn’t end when the moderator terminates a call. When compared directly to other technologies, Second Life remains a clearly compelling addition to your overall collaboration portfolio of choices. Teleconferencing is great when Internet access is problematic, but staring at a telephone isn’t a very effective way to have a meeting. Webex is a fantastic technology for a few people to broadcast a presentation to a large audience, but falls short as a true brainstorming, planning, simulation, or visualization medium. It’s helpful to see your colleagues’ faces during a video conference session, but the quality of these meetings is often uneven and you still don’t get a sense of a shared environment—particularly helpful in training, simulation, and prototyping activities. And, none of these technologies is useful for informal “water cooler” time that we all know can be so valuable. Overall, we believe that Second Life is the next best thing to a face–to–face meeting which is usually always preferred, but not always possible due to geographic or budgetary constraints. Security How secure is my data (text chat, voice, login, etc.) in Second Life? Linden Lab does not distribute account information, per our Terms of Service. Regarding login, the Second Life Viewer login uses password-only authentication over an encrypted secure HTTPS connection. We do not have access to your password itself. Viewer 2 gives you a connection to Second Life that does not compromise your computer’s security. Linden Lab takes customer privacy and security extremely seriously, and maintains strict internal standards to protect all information involved with the Second Life service. For more specific information about the technical environment of Second Life, please contact us directly at business@lindenlab.com. One item of note: Linden Lab employees can go anywhere within Second Life, including your region. However, we make every effort to only enter your region upon request. If a Linden is in your area, the avatar name will show up in the attendee list; no one can go “invisible” in Second Life. How can I control who is permitted to enter my region, workspace, or events? Any business, or individual, can buy a Private Region as part of an Estate in the Second Life world. A single Private Region resembles a small island, and can be linked together with other Private Regions to form a larger landmass. These Regions provide a highly manageable environment for conducting private business in the virtual world of Second Life. A Region owner may choose to exercise full control over access to Private Regions in the Estate. The Region’s included administrative tools enable its owner (and designated managers) to create an access list, by individual or group, ensuring that only approved users can enter the Region. A Private Region is secure from eavesdropping. The Region is surrounded by an equivalent void space, represented by water; void space cannot be crossed by walking, running, flying, or by camera. How do I grant estate rights to other avatars so they can collaborate on building and other aspects of sharing space? The estate, land parcel, and group tools in Second Life enables you and colleagues to collaborate on content creation, editing and access to a shared space. By setting objects to group ownership, you can share editing permissions with group members based on roles you assign within that group. Estate-level controls permit region owners to give specific individuals estate manager privileges, allowing even greater control and moderation ability. Additionally, you can also set land permissions to enable or disable content creation. What are “griefers” and how can they be avoided? Second Life is not policed, in the traditional sense. Instead, we rely on the community to self-govern and report abuse when it happens. Griefers are, according to Wikipedia, “players who plays a computer game (in this case Second Life) in order to irritate and harass other players.” Griefing behavior—such as violence, bad language, hate speech, harassment, etc.—is considered a breach of the Second Life Terms of Service and can result in an expulsion from Second Life. Thankfully, organizations with Region or Estate controls can prevent griefers from entering their private space altogether. Region owners, group owners, and their designated managers have access to powerful moderation tools to control their environment. How can my organization best avoid environments and content that is inappropriate for business use? Second Life is a virtual world that successfully supports a myriad of environments, some of which mimic the physical world while others are composed of architecture and content that diverges from the laws of physics. The platform successfully hosts communities of all kinds, from business enterprise and education to those with mature themes. Each region has a rating of General, Moderate, or Adult to allow visitors to better anticipate the nature of content they might find in a region. With private regions, region owners and their designated managers can easily remove or return content that may not fit their preferred theme or concept of appropriate. I want my employees to go directly to my organization’s space in Second Life. How do I do set this up? Once your employees are registered as Second Life users, then you can send them directly to your region with a SLurl—or a Second Life URL that teleports avatars directly to a specific place (based on latitude, longitude, and altitude coordinates). It works just like a standard web URL, but instead of clicking and taking you to a web page, it takes you to a destination within Second Life. For a more in-depth and technical explanation of how this works, visit our Map API technical details page. Technology How robust and stable is the Second Life technology platform and how can I find out about scheduled outages? The Second Life technology platform is very stable and has continually made strides towards continuous uptime, with full service outages being extremely rare. We do regularly take regions down for maintenance. If you would like to view a current schedule of planned downtime, and view recent platform performance, please visit the Second Life Grid Status page. What computer hardware, software, and network bandwidth requirements are necessary to run Second Life? Your organization’s computers and network must meet a certain set of minimum requirements to run successfully Second Life. Visit the Systems Requirements page for additional details. How do I know if my organization will permit me to access Second Life within my corporate firewall? Many aspects of Second Life run on a UDP protocol, as opposed to a standard web protocol such as http or https. Sometimes, network administrators within large organizations prevent employees from accessing UDP protocols. Please check with your IT department and ask about accessing Second Life for work through the firewall via UDP ports. Building How easy is it to build objects in Second Life and can I train my team to do this? Building objects in Second Life is easy to do. Highly flexible building tools allow manipulation of geometric primitives in a simple interface. Stretch these “prims” into new shapes, change their texture and physical qualities, link them to other prims. From this easy–to–learn process, you can create objects of all kinds and sizes, from a simple box to a five hundred meter skyscraper. Then, you can overlay textures on top of these prims—such as a wood texture to make a wood box or a brick texture for a brick wall. There are may tutorials and inworld lessons that you can find—both from Lindens and inworld experts—that can help you get started. 3D Mesh content, as frequently seen in many other visual environments, can also be imported into Second Life. For technical information about uploading 3D mesh objects, visit our Knowledge Base. A great deal of excellent mesh-based content is already available, created by existing Second Life users. You can see many interesting examples that may suit your building needs on our Marketplace. Do you have best practices for working with content developers regarding IP ownership? We recommend that you are very clear about what IP (intellectual property) you own and what the developer owns. For example, if a developer builds you a chair, they should grant you IP rights to it. However, tools like voting boxes, presentation screens, or announcers are often used by developers in multiple projects and will only grant you the rights to use the tool, but not IP ownership. When in doubt, ask questions and make sure that you get specific answers, in writing when possible. Back to the Connect Second Life site. For more information, contact Linden Lab at business@lindenlab.com. ]]>
</description>
<enclosure url="//content.invisioncic.com/Mseclife/monthly_2020_03/classroom2.png.51bd8fde584b1c582e6bc232002e9bcf.png" length="783355" type="image/png"/>
<pubDate>Thu, 12 Mar 2020 12:27:38 -0700</pubDate>
</item>
<item>
<title>Name to Agent ID API</title>
<link>https://community.secondlife.com/knowledgebase/english/name-to-agent-id-api-r1566/</link>
<description>One of the challenges created by name changes is that anyone with an external database that uses name lookups must adjust by replacing or reindexing to use agent IDs. The Name to Agent ID API is a publicly available REST endpoint to which a user submits a username/last name combination (Residents with a single username have the last name "Resident" by default), and is returned the agent_id associated with that name if it exists. Documentation for usage of this tool can be found through the APIs and Web Services Portal, or directly: Name to agent ID API documentation</description>
<pubDate>Fri, 13 Dec 2019 07:35:01 -0700</pubDate>
</item>
<item>
<title>メッシュでのベイク処理</title>
<link>https://community.secondlife.com/knowledgebase/%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%83%8A%E3%83%AC%E3%83%83%E3%82%B8%E3%83%99%E3%83%BC%E3%82%B9/%E3%83%A1%E3%83%83%E3%82%B7%E3%83%A5%E3%81%A7%E3%81%AE%E3%83%99%E3%82%A4%E3%82%AF%E5%87%A6%E7%90%86-r1564/</link>
<description>
<![CDATA[ 他の言語 ベイク処理テクスチャとはどのようなもので、これがメッシュに必要なのはどうしてですか？ 主な機能 メリット 仕組み ウェアラブルなベイク処理チャンネル ユニバーサルウェアラブル ベイク処理テクスチャを使用するためのメッシュ設定 新しいチャンネルでの作業 Animesh での作業 スクリプトのサポート ステップバイステップの例 テストコンテンツ 既知の問題点 メッシュでのベイク処理 とは、システムアバターのベイク処理テクスチャをメッシュアタッチメントで表示できるようにした機能です。 ベイク処理テクスチャとはどのようなもので、これがメッシュに必要なのはどうしてですか？ 標準のシステムアバターを使用した場合、複数のテクスチャレイヤーでスキンをカスタマイズしたり、タトゥーや衣服のレイヤーを追加したりできます。処理時間を節約し、どのシステムでも全員に同じアピアランスを表示するため、これらのテクスチャは、サーバーにより単一の結合テクスチャに「ベイク処理」されます。以前であれば、カスタムメッシュボディパーツを使用して同種のカスタマイズを行う場合、ボディパーツに独自のテクスチャシステムが必要でした。 さらに、通常は、基本的な標準アバターのボディパーツに「アルファ」ウェアラブルを適用して、メッシュ部分を妨げないように隠す必要がありました。メッシュでベイク処理を行えば、システムスキンやその他のレイヤーをアバターに適用した後（アルファレイヤーは不要または望ましくない）、生成されたベイク処理テクスチャをメッシュのボディパーツに適用するようビューワに指示することができます。基礎となるシステムアバターのパーツは自動的に非表示になるため、アルファウェアラブルは必要ありません。 主な機能 メッシュオブジェクトのどの面にも、サーバーベイク処理テクスチャを使用してテクスチャを作成することができます。 いずれかのアタッチされたメッシュがベイク処理テクスチャを使用していると、システムアバターの対応領域は非表示になります。 新しいテクスチャベイク処理チャンネルの導入で、メッシュのテクスチャリング方法をより細かく制御できるようになりました。 新しい「ユニバーサルウェアラブル」に、新たなテクスチャチャンネルのサポートが追加されました。 メリット アプライヤーが必要でないため、カスタマイズのワークフローが簡単にできます。 オニオンスキンアバターが必要でないため、表示時のメッシュとテクスチャが減らせます。 フルパーマメッシュを販売する必要がありません。ユーザーは、メッシュ自体を変更せず、適切なウェアラブルを準備するだけで、「メッシュでのベイク処理」を使用するよう設定されたすべてのメッシュをカスタマイズできます。 仕組み ウェアラブルなベイク処理チャンネル アバターウェアラブルは、ベイク処理サービスにより伝統に従い、6 種類のテクスチャ（BAKE_HEAD、 BAKE_UPPER、 BAKE_LOWER、 BAKE_EYES、 BAKE_SKIRT、 BAKE_HAIR）にベイク処理されています。これらテクスチャは、アバターのさまざまなウェアラブルアイテムで対応テクスチャを合成することにより得られます。たとえば、1 枚のシャツは「上部」テクスチャを決定し、複数のレイヤーから成るシャツは最終的なテクスチャを BAKE_UPPER 仕上げることになります。 「メッシュでのベイク処理」プロジェクトには、以下の 5 つの新しいベイク処理チャンネルも追加されました。 LEFT_ARM_BAKED、 LEFT_LEG_BAKED、 AUX1_BAKED、 AUX2_BAKED、 AUX3_BAKED。オリジナルテクスチャとは異なり、システムアバターはこれらのテクスチャをいずれも使用しません。これらは、メッシュのアピアランスをより細かく制御できるようにする単なる拡張機能です。 LEFT_ARM_BAKED と LEFT_LEG_BAKED は、左右の手足のテクスチャが異なるメッシュアバターの作成をサポートするためのものです AUX チャンネルは用途が広く、（翼など）システムアバターが所有しない身体領域やその他の目的に使用できます。 全部で、テクスチャに使用するウェアラブルと、ベイク処理サービス向けに 11 チャンネルの利用が可能です。 ユニバーサルウェアラブル 新しいチャンネルは、そうしたチャンネルを使用するアイテムを装着する何らかの方法がない限り、役に立ちません。このニーズを満たすために、「ユニバーサル」と呼ばれる新しいウェアラブルタイプが追加されました。ユニバーサルウェアラブルには、新旧 11 種類のベイク処理チャンネルすべてに対応するスロットがあります。レイヤリングの順としては、ユニバーサルなウェアラブルは、皮膚やタトゥーのウェアラブルより上、その他すべてのタイプの衣服より下に重ねられます。 ベイク処理されたテクスチャを使用するためのメッシュ設定 これらのテクスチャを、以下の要領で、アバターのアタッチメントの拡散テクスチャに適用できるようになりました。 アタッチメントを右クリックして [編集] をクリックし、[面の編集] メニューからテクスチャを選択します。 拡散テクスチャアイコンをクリックして、テクスチャピッカーを開きます。 テクスチャピッカーには、サーバーベイク処理を選択するための「ベイク処理」と呼ばれる追加のラジオボタンモードがついています。「ベイク処理」ラジオボタンモードには、サーバーベイク処理テクスチャを選択できるドロップダウンがあります。 アタッチメントがベイク処理テクスチャを使用していると、システムアバターの対応する基本メッシュ領域は非表示になります。 メッシュ面がベイク処理されたテクスチャを表示するように設定されていても、アバターにアタッチされていなければ、デフォルトのベイク処理テクスチャが表示されます。メッシュでのベイク処理をサポートしていない古いビューワを使用している場合、ベイク処理テクスチャを表示するよう設定された面もデフォルトのベイク処理テクスチャとして表示され、ベースメッシュ領域は非表示に

---
## [conge/conge.github.io](https://github.com/conge/conge.github.io)@[965fa13d2c...](https://github.com/conge/conge.github.io/commit/965fa13d2c5383e986a9b53eb824246e38eb92f9)
#### Thursday 2021-01-14 19:28:38 by conge

Update 2021-01-11-book-review-design-the-life-you-love.md

---
## [nikitavoloboev/knowledge](https://github.com/nikitavoloboev/knowledge)@[7db156531c...](https://github.com/nikitavoloboev/knowledge/commit/7db156531c999b898d13b81aa95a821656bac9ca)
#### Thursday 2021-01-14 20:29:56 by Nikita Voloboev

SUMMARY analytics api generative-art bioinformatics funding aws azure cloud-computing compilers linters llvm computer-vision image-processing opengl webgl computer-science bitcoin data-visualization kafka ethereum databases postgresql prometheus redis blender design-inspiration fonts grpc basic-income university tailwind-css front-end godot games internationalization time macOS-apps sketch macOS datasets pytorch tensorflow machine-learning generative-adversarial-networks neural-networks reinforcement-learning category-theory graph-theory music-production file-sharing graphql matrix ssh nlp github-actions docker kubernetes ios linux newsletters philosophy physics quantum-computing quantum-physics bash clojure coq cpp-libraries elixir-libraries elixir phoenix go-libraries go idris js-libraries react-hooks react svelte julia-libraries common-lisp lisp perl python-libraries python rust-libraries scala swift-libraries swift tcl typescript-libraries jupyter-notebooks programming reverse-engineering semantic-versioning cypress structured-programming decision-making blogs research cryptography encryption security things social-networks vim-plugins vs-code-extensions firebase roam-research finding-home europe united-states video electron nodejs search-engines service-workers hugo web-performance web-scraping webassembly hiring

---
## [msune/libcdada](https://github.com/msune/libcdada)@[58beb97755...](https://github.com/msune/libcdada/commit/58beb97755fabec2515633f4b2743d6f43e1f1ef)
#### Thursday 2021-01-14 21:03:26 by Marc Sune

Bye bye Travis, hello Github actions

This commit moves the CI to github actions, and removes all
Travis related code.

===

This is a sad commit. Travis has been a great supporter of the
opensource community, since the very beginning. Even if their
syntax wasn't the greatest, and with all the problems related
to having to migrate from original VMs to dockers - too early, and
too late - the service was good.

The move to travis-ci.com has been _a complete disaster_. The
cronology for libcdada goes more or less like this:

* Early september 2020 pipelines start to fail, randomly. Contacted
  support, they claim resources are starting to move to travis-ci.com
  and that I should do the same thing, given that travis-ci.org will
  disappear end of 2020. That was _the first_ notice about this - no
  emails, no warnings in the UI...
* So given that, I move libcdada to travis-ci.com, and oh surprise...
  there is a limit of credits **also for OSS**. However, the blog post
  of the travis company announcing the moving to travis-ci.com still
  claims OSS will be for free "and always for free". Even subsequent
  posts in the same blog claim the same.
* Innumerable people annoyed in the travis community about this (forums,
  emails etc...)
* I run for 20 days, and ofc, the one time (wtf) budget of 10000 minutes
  is gone... no refillings
* But the worst is yet to come; contacted again the support... radio
  silence for 2 months. After that, they get back to me and they say
  "we are awaiting for instructions wrt to OSS".
* But the damage is done... We can't go back to travis-ci.org...
  Once migrated, ciao ciao. So I am stuck without being able to run pipelines
  neither in travis-ci.com nor going back to travis-ci.org.
* Funny enough, repos that hadn't yetn migrated - even though "expiration
  was 31 dec 2021",  continue to operate with no budget limit,
  albeit with problems, in travis-ci.org.

Honestly, I would have understood if Travis would have gone all paid.
They-re a company. We would all have thanked them for the
**great job they did** for a long time to the opensource community, and
we would have gone elsewhere[1]. But the communication...
ah the communication.

So Travis is dead... Long Live Travis!

[1] as I seriously doubt no one would prefer Travis to much newer and
simpler CIs (e.g. gitlab, github actions...), except, perhaps, those
projects with super complex pipelines that would require a major
invesment.

---

# [<](2021-01-13.md) 2021-01-14 [>](2021-01-15.md)

