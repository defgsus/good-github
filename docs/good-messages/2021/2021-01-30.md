# [<](2021-01-29.md) 2021-01-30 [>](2021-01-31.md)

2,093,042 events, 1,202,750 push events, 1,729,702 commit messages, 112,856,328 characters


## [SamBeaudoin/AI_Assignment_1](https://github.com/SamBeaudoin/AI_Assignment_1)@[accf1c692c...](https://github.com/SamBeaudoin/AI_Assignment_1/commit/accf1c692cf9bd425142d4e392ebbe49c7f4d128)
#### Saturday 2021-01-30 01:14:10 by Samuel B

Fixed Flight Modes, Added Flee

I got it to work! Praise be the machine god! I SHALL ANOINT THEE WITH HOLY OILS! BLESSED BE THE OMNISSIAH

---
## [thedavidchu/2021_winter](https://github.com/thedavidchu/2021_winter)@[70773d5caf...](https://github.com/thedavidchu/2021_winter/commit/70773d5caff4735363ff4ff233aa14383d8d1580)
#### Saturday 2021-01-30 01:16:35 by David Chu

Created plots for ECE421 Assignment 1, Part 1, Sections 3 and 4. Now, I have to work with Tensorflow. Urgh, the documentation makes no sense; the course is being taught in Tensorflow v1.x, which makes no sense, since it is unsupported and also just plain poorly documented. Not to mention confusing. Okay, so I could have done this in PyTorch in half the time. But no. Why? Because we have to use tensorflow. Sadness wells in my chest... and I thought I liked Professor Liang (although he's not the course coordinator, so my feelings for him aren't too harsh... I just really liked his curve in ECE355 hahaha). Thank you for coming to my TedTalk.

---
## [kwsch/PKHeX](https://github.com/kwsch/PKHeX)@[1e86fdcea8...](https://github.com/kwsch/PKHeX/commit/1e86fdcea8b7139b0e4eed16106a064abad21599)
#### Saturday 2021-01-30 01:55:46 by Kurt

Fracture the encounter matching checks to allow progressive validation (#3137)

## Issue

We want to discard-but-remember any slots that aren't a perfect fit, on the off chance that a better one exists later in the search space. If there's no better match, then we gotta go with what we got.

## Example:
Wurmple exists in area `X`, and also has a more rare slot for Silcoon, with the same level for both slots. 
* We have a Silcoon that we've leveled up a few times.

Was our Silcoon originally a Wurmple, or was it caught as a Silcoon? 
* To be sure, we have to check the EC/PID if the Wurmple wouldn't evolve into Cascoon instead.
* We don't want to wholly reject that Wurmple slot, as maybe the Met Level isn't within Silcoon's slot range.

---

Existing implementation would store "deferred" matches in a list; we only need to keep 1 of these matches around (less allocation!). We also want to differentiate between a "good" deferral and a "bad" deferral; I don't think this is necessary but it's currently used by Mystery Gift matching (implemented for the Eeveelution mystery gifts which matter for evolution moves).

The existing logic didn't use inheritance, and instead had static methods being reused across generations. Quite kludgy. Also, the existing logic was a pain to modify the master encounter yield methods, as one generation's quirks had to not impact all other generations that used the method.

---

The new implementation splits out the encounter yielding methods to be separate for each generation / subset. Now, things don't have to check `WasLink` for Gen7 origin, because Pokémon Link wasn't a thing in Gen7.

---

## Future
Maybe refactoring yielders into "GameCores" that expose yielding behaviors / properties, rather than the static logic. As more generations and side-gamegroups get added (thanks LGPE/GO/GameCube), all this switch stuff gets annoying to maintain instead of just overriding/inheritance.

## Conclusion

This shouldn't impact any legality results negatively; if you notice any regressions, report them! This should reduce false flags where we didn't defer-discard an encounter when we should have (wild area mons being confused with raids).

---
## [ccodwg/Covid19Canada](https://github.com/ccodwg/Covid19Canada)@[a85de5f851...](https://github.com/ccodwg/Covid19Canada/commit/a85de5f851b8404f0f851fe13d2124d4290cb4ef)
#### Saturday 2021-01-30 02:18:40 by Jean-Paul R. Soucy

New data: 2021-01-29: DATA RECENTLY CHANGED. SEE NOTES.

Recent changes:

2021-01-27: Due to the limit on file sizes in GitHub, we implemented some changes to the datasets today, mostly impacting individual-level data (cases and mortality). Changes below:

1) Individual-level data (cases.csv and mortality.csv) have been moved to a new directory in the root directory entitled “individual_level”. These files have been split by calendar year and named as follows: cases_2020.csv, cases_2021.csv, mortality_2020.csv, mortality_2021.csv. The directories “other/cases_extra” and “other/mortality_extra” have been moved into the “individual_level” directory.
2) Redundant datasets have been removed from the root directory. These files include: recovered_cumulative.csv, testing_cumulative.csv, vaccine_administration_cumulative.csv, vaccine_distribution_cumulative.csv, vaccine_completion_cumulative.csv. All of these datasets are currently available as time series in the directory “timeseries_prov”.
3) The file codebook.csv has been moved to the directory “other”.

We appreciate your patience and hope these changes cause minimal disruption. We do not anticipate making any other breaking changes to the datasets in the near future. If you have any further questions, please open an issue on GitHub or reach out to us by email at ccodwg [at] gmail [dot] com. Thank you for using the COVID-19 Canada Open Data Working Group datasets.

- 2021-01-24: The columns "additional_info" and "additional_source" in cases.csv and mortality.csv have been abbreviated similar to "case_source" and "death_source". See note in README.md from 2021-11-27 and 2021-01-08.

Vaccine datasets:

- 2021-01-19: Fully vaccinated data have been added (vaccine_completion_cumulative.csv, timeseries_prov/vaccine_completion_timeseries_prov.csv, timeseries_canada/vaccine_completion_timeseries_canada.csv). Note that this value is not currently reported by all provinces (some provinces have all 0s).
- 2021-01-11: Our Ontario vaccine dataset has changed. Previously, we used two datasets: the MoH Daily Situation Report (https://www.oha.com/news/updates-on-the-novel-coronavirus), which is released weekdays in the evenings, and the “COVID-19 Vaccine Data in Ontario” dataset (https://data.ontario.ca/dataset/covid-19-vaccine-data-in-ontario), which is released every day in the mornings. Because the Daily Situation Report is released later in the day, it has more up-to-date numbers. However, since it is not available on weekends, this leads to an artificial “dip” in numbers on Saturday and “jump” on Monday due to the transition between data sources. We will now exclusively use the daily “COVID-19 Vaccine Data in Ontario” dataset. Although our numbers will be slightly less timely, the daily values will be consistent. We have replaced our historical dataset with “COVID-19 Vaccine Data in Ontario” as far back as they are available.
- 2020-12-17: Vaccination data have been added as time series in timeseries_prov and timeseries_hr.
- 2020-12-15: We have added two vaccine datasets to the repository, vaccine_administration_cumulative.csv and vaccine_distribution_cumulative.csv. These data should be considered preliminary and are subject to change and revision. The format of these new datasets may also change at any time as the data situation evolves.

Revise historical data: cases (BC, MB, ON, QC, SK); recovered (NT); testing (NT, PE).

SK did not provide testing data today. They also did not update their usual daily case CSV.

Note regarding deaths added in QC today: “The data also report 50 new deaths, for a total of 9,717. Among these 50 deaths, 9 have occurred in the last 24 hours, 35 have occurred between January 22 and January 27 and 6 have occurred before January 22.” We report deaths such that our cumulative regional totals match today’s values. This sometimes results in extra deaths with today’s date when older deaths are removed.

https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/#c47900

Note about SK data: As of 2020-12-14, we are providing a daily version of the official SK dataset that is compatible with the rest of our dataset in the folder official_datasets/sk. See below for information about our regular updates.

SK transitioned to reporting according to a new, expanded set of health regions on 2020-09-14. Unfortunately, the new health regions do not correspond exactly to the old health regions. Additionally, the provided case time series using the new boundaries do not exist for dates earlier than August 4, making providing a time series using the new boundaries impossible.

For now, we are adding new cases according to the list of new cases given in the “highlights” section of the SK government website (https://dashboard.saskatchewan.ca/health-wellness/covid-19/cases). These new cases are roughly grouped according to the old boundaries. However, health region totals were redistributed when the new boundaries were instituted on 2020-09-14, so while our daily case numbers match the numbers given in this section, our cumulative totals do not. We have reached out to the SK government to determine how this issue can be resolved. We will rectify our SK health region time series as soon it becomes possible to do so.

---
## [uber/cadence](https://github.com/uber/cadence)@[f818a707ef...](https://github.com/uber/cadence/commit/f818a707ef86fb3737de791d485b16762f6d1f90)
#### Saturday 2021-01-30 04:10:28 by Steven Littiebrant

Ignore comment-formatting lints

This does not cover all of the comment-related lints, but it does cover all of the ones that currently produce warnings.
After this, 10 go away, bringing the total to 18.

**Rationale:**

Many of the comment-requiring and comment-formatting lints are focused on both:
1. Encouraging documenting public APIs.  But this repo is effectively entirely private / not intended for people to import.
2. Producing "nice" documentation in `go doc` output.  Whether this makes more readable docs or not is debatable, but I understand the goal.

When *either or both* of those don't apply, the lints just kinda suck.  Their mere existence encourages pointless stuff like:
```go
// ConvertPretty ...
<snip>
func (e *ESql) ConvertPretty(sql string, pagination ...interface{}) (dsl string, sortField []string, err error) {
```
Or this, which appears in 30 places:
```go
// Ptr is a helper function for getting pointer value
func ... Ptr() ...
```
Or this TBD pattern, in **OVER 2000** places:
```go
// WorkflowExecutionCanceledEventAttributes is an internal type (TBD...)
```

It's a waste of time, space, and mental-energy.

In my experience it also implies the code is in a "higher quality" state than it may actually be, as good code often has documentation.
While that's obviously not *actually true*, I've frequently seen people stop reading when they find a documented func regardless of what the documentation actually says, on the assumption that it's either 1) functioning correctly, or 2) intended for broader use.
2 in particular often manifests as code importing some random unrelated package because it happens to have the only documented + commonly-used pointer-conversion-func.  I've seen this in dozens of repositories, it's a plague.

Even if we (think we) aren't vulnerable to that kind of thinking when writing code, it seems worth avoiding since it clearly brings no benefit.

Document what needs documentation.
Don't add documentation that offers nothing beyond the type name (or less).
And let's delete bad docs when we see them.

---
## [rebouljc/CS5001_5002_Debugger](https://github.com/rebouljc/CS5001_5002_Debugger)@[61fa626b5b...](https://github.com/rebouljc/CS5001_5002_Debugger/commit/61fa626b5b456c358e4a1c61b4b8347bef0ddff0)
#### Saturday 2021-01-30 04:57:27 by rebouljc

Initial Commit.  Just some basic bookkeeping before I go on to start creating the text viewer window

I decided to place the Persistant_Vars in its own header file, since I was having a hell of a time trying to hunt them down when they were in the main_ui.h file.  I also placed my viewer in its own separate class.  Class definition in SourceCodeViewer.h .  I also added some #pragma once preprocessor directives to the code so that we don't have the issues of the linker including duplicate copies of header files into the final executable, which wastes space and slows down compilation.  No one can remember how many times they may have reused a header file, even if there are compiler warnings.  I will start early tomorrow morning and hopefully more coding will occur by the afternoon.  Good evening.

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[38e342b3c8...](https://github.com/mrakgr/The-Spiral-Language/commit/38e342b3c8c9bd4bf2da7134a0c7ae3f0dde53bc)
#### Saturday 2021-01-30 11:05:07 by Marko Grdinić

"9:50am. I slept well tonight. I thought I was done with the Cython backend, but it turns out it is possible to type Numpy arrays. Let me play with it.

https://stackoverflow.com/questions/14657375/cython-fatal-error-numpy-arrayobject-h-no-such-file-or-directory

I am getting the error that some header file cannot be found.

```
Error compiling Cython file:
------------------------------------------------------------
...
cdef class Tuple0:
    cdef readonly signed long v0
    cdef readonly signed long v1
    def __init__(self, signed long v0, signed long v1): self.v0 = v0; self.v1 = v1

cdef void qwe(numpy.ndarray[Tuple0, ndim=1] a): pass
                           ^
------------------------------------------------------------

cython_experiments\test3\testm.pyx:9:28: dtype must be "object", numeric type or a struct
```

Oh, I see.

10:15am.

```
import numpy
import pyximport
pyximport.install(language_level=3,setup_args={"include_dirs":numpy.get_include()})
from testm import (main)
print(main())
```
```
    cdef numpy.ndarray[double,ndim=1] a
    a = numpy.array([1,2,3],dtype=numpy.float64)
```

Ok, I figured it out. Let me implement this in the compiler.

```fs
        | YArray a ->
            import "numpy"; cimport "numpy"
            let a = match a with YPrim x -> prim x | _ -> "object"
            $"numpy.ndarray[{a},ndim=1]"
```

This should do for printing the types.

Now what comes next?

```
| TyArrayCreate(a,b) -> return' (sprintf "[None] * %s" (tup b))
```

This.

```
let numpy_ty = function
    | YPrim Int8T -> "numpy.int8"
    | YPrim Int16T -> "numpy.int16"
    | YPrim Int32T -> "numpy.int32"
    | YPrim Int64T -> "numpy.int64"
    | YPrim UInt8T -> "numpy.uint8"
    | YPrim UInt16T -> "numpy.uint16"
    | YPrim UInt32T -> "numpy.uint32"
    | YPrim UInt64T -> "numpy.uint64"
    | YPrim Float32T -> "numpy.float32"
    | YPrim Float64T -> "numpy.float64"
    | _ -> "object"
```

This should do it.

```fs
| TyArrayCreate(a,b) -> return' $"numpy.empty({tup b},dtype=${numpy_ty a})"
```

Here is the array create.

10:40am.

```fs
open arraym
inl main() =
    inl x : array (i32 * i32) = arraym.create 10
    arraym.set x 0 (1,2)
```
```
import numpy
cimport numpy
cdef class Tuple0:
    cdef readonly signed long v0
    cdef readonly signed long v1
    def __init__(self, signed long v0, signed long v1): self.v0 = v0; self.v1 = v1
cpdef void main():
    cdef numpy.ndarray[object,ndim=1] v0
    v0 = numpy.empty(10,dtype=object)
    v0[0] = Tuple0(1, 2)
```

This is an improvement on what I had before. Too bad, Numpy types can only be primitives, structs and objects.

10:55am. Updated that issue. What is next?

Let me push the patch. Done. Let me make some notes on the readme.

11:15am.

TODO: Cython: Add ops for imports and cimports.

I'll have to do this at some point. Nevermind it for now.

...No actually, let me do it now.

```fs
    // Cython imports
    | Import
    | CImport
```

Let me add these two ops.

```fs
        | EOp(_,(CImport | Import) & op,[a]) ->
            match term s a with
            | DLit (LitString _) & a -> push_op_no_rewrite s op a YB
            | a -> raise_type_error s $"Expected a string literal.\nGot: {show_data a}"
```

Let me put them into the codegen next.

```fs
        | TyOp(Import,[DLit (LitString x)]) -> import x
        | TyOp(CImport,[DLit (LitString x)]) -> cimport x
```

11:25am. I can't find anything by Googling on how to use the fast math functions.

Let me ask about that.

https://cython.readthedocs.io/en/latest/src/tutorial/external.html
https://github.com/cython/cython/tree/master/Cython/Includes/libc

Actually here are the files.

```
    float logf(float)
```

Ah, it does exist. Then why can't I run it?

```
// Natural Logarithm.
inl log forall t {float}. (x : t) : t = !!!!Log(x)
// Exponent.
inl exp forall t {float}. (x : t) : t = !!!!Exp(x)
// Hyperbolic tangent.
inl tanh forall t {float}. (x : t) : t = !!!!Tanh(x)
// Square root.
inl sqrt forall t {float}. (x : t) : t = !!!!Sqrt(x)
```

Let me put these into the core library. let me also add the float constraint.

Added it. Now the above typechecks.

```
Error compiling Cython file:
------------------------------------------------------------
...
cimport libc.math
cpdef float main():
    cdef float v0
    v0 = 10.000000
    return libc.math.logf(v0)
                   ^
------------------------------------------------------------

cython_experiments\test3\testm.pyx:5:20: cimported module has no attribute 'logf'
```

Let me ask about this.

https://stackoverflow.com/questions/65967020/why-is-the-logf-function-missing-from-libc-math

I'll get an answer at some point. Nevermind this for now.

11:45am. Let me push another patch.

11:50am. Let me wind off the morning session here. I did an impromptu improvement. Once I deal with the math imports, the Cython backend will be complete for the time being. The wishlist items can deal with themselves.

11:55am. Mornings like this are satisfying. I got up fairly early today too and had time to do the work. If I started at the usual time, it would be 3pm by the time I've finished this.

...Right now, I want to lay off the programming for a while.

12pm. Yesterday when I stopped for the day, I had full intention of spending today doing the review.

12:05pm. I want to slack for a while, but instead of just staring blankly at the screen, let me get breakfast."

---
## [okta-10/mystic-kernel-sdm660](https://github.com/okta-10/mystic-kernel-sdm660)@[e472f7082c...](https://github.com/okta-10/mystic-kernel-sdm660/commit/e472f7082c9ba81a32fd36c7ec3ae8fb16b52500)
#### Saturday 2021-01-30 13:04:16 by Petr Mladek

kthread: add kthread_create_worker*()

Kthread workers are currently created using the classic kthread API,
namely kthread_run().  kthread_worker_fn() is passed as the @threadfn
parameter.

This patch defines kthread_create_worker() and
kthread_create_worker_on_cpu() functions that hide implementation details.

They enforce using kthread_worker_fn() for the main thread.  But I doubt
that there are any plans to create any alternative.  In fact, I think that
we do not want any alternative main thread because it would be hard to
support consistency with the rest of the kthread worker API.

The naming and function of kthread_create_worker() is inspired by the
workqueues API like the rest of the kthread worker API.

The kthread_create_worker_on_cpu() variant is motivated by the original
kthread_create_on_cpu().  Note that we need to bind per-CPU kthread
workers already when they are created.  It makes the life easier.
kthread_bind() could not be used later for an already running worker.

This patch does _not_ convert existing kthread workers.  The kthread
worker API need more improvements first, e.g.  a function to destroy the
worker.

IMPORTANT:

kthread_create_worker_on_cpu() allows to use any format of the worker
name, in compare with kthread_create_on_cpu().  The good thing is that it
is more generic.  The bad thing is that most users will need to pass the
cpu number in two parameters, e.g.  kthread_create_worker_on_cpu(cpu,
"helper/%d", cpu).

To be honest, the main motivation was to avoid the need for an empty
va_list.  The only legal way was to create a helper function that would be
called with an empty list.  Other attempts caused compilation warnings or
even errors on different architectures.

There were also other alternatives, for example, using #define or
splitting __kthread_create_worker().  The used solution looked like the
least ugly.

Link: http://lkml.kernel.org/r/1470754545-17632-6-git-send-email-pmladek@suse.com
Signed-off-by: Petr Mladek <pmladek@suse.com>
Acked-by: Tejun Heo <tj@kernel.org>
Cc: Oleg Nesterov <oleg@redhat.com>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Steven Rostedt <rostedt@goodmis.org>
Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
Cc: Josh Triplett <josh@joshtriplett.org>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Jiri Kosina <jkosina@suse.cz>
Cc: Borislav Petkov <bp@suse.de>
Cc: Michal Hocko <mhocko@suse.cz>
Cc: Vlastimil Babka <vbabka@suse.cz>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Oktapra Amtono <oktapra.amtono@gmail.com>

---
## [fdw/rofimoji](https://github.com/fdw/rofimoji)@[4b5afa4c93...](https://github.com/fdw/rofimoji/commit/4b5afa4c93de2599e996d49b3226fac22eca1d68)
#### Saturday 2021-01-30 14:36:19 by Fabian Winter

Support running as a rofi mode

A much requested feature was to be able to run `rofimoji` as a rofi
"mode". With this, you could, for example, have a combi mode with
different character sets.

However, rofi unfortunately (and sometimes understandably) limits the
features of its modes. The most annoying is that you cannot call
`xdotool` to type into another window. So with the mode, the best you
can do is to copy to the clipboard.
Secondly, all the custom shortcut mappings are gone, and we must use the
default ones which are not easy to remember.
Finally, selecting more than one character is also impossible.

Is it worth it? I'm not sure, but we can try.

---
## [thechangelog/changelog.com](https://github.com/thechangelog/changelog.com)@[b2c7a2fb37...](https://github.com/thechangelog/changelog.com/commit/b2c7a2fb3747e3eb397ee766ed4c14e93c042066)
#### Saturday 2021-01-30 15:21:59 by Gerhard Lazu

Migrate from Crunchy Data to Zalando PostgreSQL

Crunchy Data has not been the best experience. Based on the initial
setup, Zalando PostgreSQL seems to be better.

What worked well with Crunchy Data:

* it didn't lose any data
* it degraded gracefully under load

What didn't work so well:

* the initial setup was complicated, with too much documentation that
  was poorly structured (no teasing, lumps of unrelated items, probably
  useful, but confusing as hell)
* default backups filled the disk and made the db become unavailable
  (not a safe default & not easy to configure)
* the pgo client approach is not GitOps friendly, I really missed the
  CRD approach
* replication stopped, pg-wal on the primary filled up, and eventually
  the primary crashed and wouldn't restart - that was a fun one to debug
  & recover from (our own custom backups saved the day)
* pods have too many labels (15+) which means that Loki running in
  Grafana Cloud rejects the db logs as they breach the maximum number of
  allowed labels 🙄
* couldn't figure out how to get metrics into Prometheus & Grafana
  dashboards into our kube-prometheus-stack setup

All in all a poor experience, too heavyweight and complicated. But it's
OSS, so we tried it, captured this feedback, and moved on because YOLO.

In closing, within the first 30 minutes of switching to a PostgreSQL
provisioned by the Zalando Operator, our 95th responses went from 313ms
avg to 228ms according to nginx logs. That's a 28% speedup by simply
switching the operator. So far, so good 😉

Signed-off-by: Gerhard Lazu <gerhard@lazu.co.uk>

---
## [Tundrabots7083/TundrabotsUltimateGoal](https://github.com/Tundrabots7083/TundrabotsUltimateGoal)@[9358f845d4...](https://github.com/Tundrabots7083/TundrabotsUltimateGoal/commit/9358f845d4810d734abe7b167c29a783150fdd50)
#### Saturday 2021-01-30 16:17:05 by KateH7105

GUYS GUYS GUSY WE KINDA HAVE AN AUTO WOWOWOWOWOWO HYPEEEEEEEE FOUR RING HAS A WEIRD PAUSE RIGHT BEFORE PARK AND SO DOES 0 RING MAYBE??? I DON'T REMEMBER.. WE SHOULD PROBABLY FIGURE THAT OUT SINCE WE BARELY MAKE THE PARK FOR 4 RING..... YEAHHHH. OK. WELL WE NEED TO TUNE THE SHOOTER SPEED AND ANGLE AND THEN WE ARE GOOD TO GO FOR SCRIM MAYBE.. NO PROBABLY GOING OT FAIL. THIS IS FINE YEAH OK COMMIT TIMEEEEEEEEEEE

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[484023b8d8...](https://github.com/mrakgr/The-Spiral-Language/commit/484023b8d8e027b1a4896ffcca195dd35f2d73ee)
#### Saturday 2021-01-30 17:51:59 by Marko Grdinić

"1:15am. Done with breakfast and chores. Let me chill for a bit. My mind feels like it is going haywire. I am in such a rush!

1:30pm. Let me start the review.

///

I spent the first 3 weeks of January doing the documentation for [Spiral](https://github.com/mrakgr/The-Spiral-Language). As far as docs go, these are lacking in thoroughness. Beginners to functional programming would be better served studying F# instead, there are lot of high quality learning resources for a mature language such as it, but I've covered all the main differences between Spiral and F#. They should be enough to pick up the language.

Just recently the Cython backend has been added to the language. Want all the benefits of functional programming, blazing fast performance, and the interop with the Python ecosystem? Give it a try now!

Ever since I started my programming journey, I've always had the idea in mind that GPUs will be superseeded by novel hardware for ML. A few years ago that was only a pipe dream, but things are moving. There are a lot of [startups](https://www.reddit.com/r/MachineLearning/comments/kzsokz/d_list_of_novel_ml_hardware_companies_january_2021/) in this field. What surprised me while doing research on them is that a quarter of the startups that support training seem to be [photonics](https://www.youtube.com/watch?v=eZSnJPDzyaI) companies.

I expected some companies to be working on neurochips, but literally none of them do.

To be honest, I am disappointed that I could not dig up any interesting material on these companies. I've been spamming the [neurochip talk by Davies](https://www.youtube.com/watch?v=jhQgElvtb1s) in these reviews. This talk really spurned my interest a year ago, but these newer entrants are uninspiring. A runner-up would be the talk by [Cornami](https://www.youtube.com/watch?v=_bNzxW90AEI). The talk is weird, as privacy in neural networks is one issue nobody actually cares about, and their solution is some kind of novel adaptible hardware which does sound interesting. Their product line hinges on quantum computers breaking currently used encription algorithms.

Adaptive hardware seems like the kind of flytrap made for me, but at this point I am honestly afraid of applying there. Intel as well, neurochips got me excited about their possibilities, but I already spent 2018 getting nowhere in ML and 2019 getting nowhere in math. And I spent 2017 working on Spiral, and 2020 studying concurrency and working on Spiral. In 2021, I am determined to get some tangible gains for myself in the form of hardware and cold, hard cash. So I do not want to grind away at speculative strategies anymore.

In the last month, many bugs fixes have been made and the language is significantly more roboust now. I have about 20 or so sponsor targets. If they would adopt Spiral, they could radically decrease the costs of their software stacks. These are all young companies, so the main purpose of Spiral - making ML libraries would be right up their alley. I thought a bit of how I would value the average sponsorship and I put it at 3k/month. This is high enough, but not high enough that they could fork the open-source language and pay somebody else to maintain it.

I am sure I could provide enough benefits to make access to their hardware and a monthly stipent worth it to all of them. This would be a huge monthly income for me if I could convince them.

1.5 weeks ago, I got pretty excited by these thoughts and took the direct approach, firing of an email to a few of these just to get a sense of things. The result is that I got no reply even today.

At first this confused me. In my future sight I saw myself getting ghosted by all 20 of the companies, and I wracked my brain and schemed how to avoid this. Eventually I started to get a handle on the situation.

Imagine you have 20 or so girls you are interested in. What these girls want is marriage, and what you want is access to their hardware instead. Going up to them and expressing that desire would be a show of will, but would not give the kind of result that you'd want.

These companies are the same. What they want is elite programmers, but not necessarily tooling improvements. In order to get some investment from them, I have to first get them to open up to conversation. For that I am going to have to feign interest in marriage and apply with them for a regular job despite having no intention of accepting their offers. Because why would I? Even getting just a few of them onboard would exceed any kind of salary I could get at a single place, and my primary goal is to become good enough at programming to the point where I am capable of transform my programming skill into superhuman abilities at [gaming](https://www.esportsearnings.com/). I can't imagine a programmer good enough to conquer the world would be too weak to beat this challenge.

I will need better hardware to move beyond simple games like poker, and I still have gotten anywhere with that.

I'll do what is needed. I'll embelish my resume, do my best at sweeping past my obvious lack of working-for-other-people experience and do my best at feigning selling myself, all for the sake of selling Spiral.

In addition to be above I also had another insight. My odds garnering sponsors, and hence my expected value from this activity is directly proportional to my fame. For the sake of raising my profile I had the idea revisiting my work from 2018 and describing it in articles. Back then I made my own language, and my own ML library from the ground up. The optimized kernels and RNNs are my best work from that time. I even used the library to do training of RL agents for a simplified poker game.

Though I burned out towards the end of 2019 for various reasons, the only real regret from that time is that .NET's GC could not deal with GPU memory. It is ironic - .NET is definitely a superior platform to Python's, but reference counting is just more versatile than heap scanning. Had I picked Python as a target, I would not have had this issue.

I started work on the Cython backend with those thoughts in mind, but now the way I see things has changed. It is not that I've changed my view on the benefits of reputation, but it would just be too harsh to spend months of my time building up the ML library just to push out a few articles on it.

Instead of spending my time working on a ML library, why don't I use what Python already has and just resume from where I was at the end of 2018? Now that I have the Cython backend, I actually have access to the entirety of Python's ecosystem with all the functional programming benefits of Spiral. I actually considered moving to Python in early 2019, but the thought of abandoning my style for an inferior one would be unbearable humiliation so I decided against it.

Now I could pick up Python through Spiral, without embarassment. If I need to implement optimized kernels, I can just make a Cuda backend again and access it through the Cython one. No doubt, the ML hardware companies will all want the Python ML crowd, and Spiral can serve as a bridge in ways no other language can. I am anticipating their need there by making the Cython backend.

By abandoning Spiral v0.09 at the end of 2018, I just lost so much initiative. It is not worth trying to recover that work. It is a real pity. v0.09 was fun and exciting, a real eye opener that showed me a completely different side of programming. I could do so much in it that I could not in F#. I fell in love with it. But ultimately, v2 is simply the better language. The year away from Spiral in 2019 served to get me over my burn out and admit what its faults were. I could admit that some of the techniques I discovered during that time are better off not being used. I was too arrogant to say that bottom-up typing is a replacement for the top-down.

My time from ML will serve the same way, to highlight to me the flaws of my earlier approach. This time around, just like I haven't improved on old Spiral directly, but instead fused it with top-down typing techniques, I won't try to replace backprop, but will instead just make it the bottom part of the whole system. At the top I'll use various ensembling techniques which are guaranteed to stabilize it and make it scale better.

This will be my main goal for 2021. It was actually what my 2016 goal was, but my position right now with the Spiral v2 being complete is incomparably better. My skills cannot be compared to back then. There should be some challenge in mastering UI automation. My attainment in that is non-existent at the moment.

If there is anything my years of life have taught me, it is that while you can count on the people around you to keep you alive, you can only count on yourself to attain wealth and power. Great deeds are one's personal accomplishment. So I won't place too much importance on selling Spiral.

I feel such relief that I do not have to start from scratch with the new Spiral. I'll restart climbing from the same height, if not the peak, that I left before.

///

1:45am. https://cython.readthedocs.io/en/latest/src/userguide/memoryviews.html#cython-arrays

It seems that Cython does have type arrays like the ones I need. I'll change from Numpy arrays to this later.

2pm. Ok, this distracted me. Let me find that photonics link.

2:30pm. I keep getting distracted with those issues.

https://stackoverflow.com/questions/65967020/why-is-the-logf-function-missing-from-libc-math?noredirect=1#comment116635696_65967020

Got the answer to this issue. It turns out the float functions aren't in the 29.x version yet.

Let me get back to the review. I'll change from numpy arrays to memory views later. Also I'll move to using doubles as well.

4:20pm. I think what I've written above is good enough.

Yeah, I do feel relief that I can get back into ML right away. That is what I will do.

Today though, let me put the last screws on the backend. Let me switch from Numpy arrays to memory views.

4:25pm. Let me focus on arrays first. I'll do the math functions after that.

```
v0 = cython.view.array(shape=(10,), itemsize=sizeof(int), format='i')
```

This is an interesting way of making an empty tuple.

4:50pm. https://stackoverflow.com/questions/18462785/what-is-the-recommended-way-of-allocating-memory-for-a-typed-memory-view

I am thinking of how to deal with these memory views.

5:25pm. Had to take a break. I think I'll just malloc them.

```
cdef view.array my_array = view.array(..., mode="fortran", allocate_buffer=False)
my_array.data = <char *> my_data_pointer

# define a function that can deallocate the data (if needed)
my_array.callback_free_data = free
```

This is so complicated.

I need to ask about one thing - does the memory view hold the reference to the object it is derived from?

Also how can I get the memory view to free up data on its own?

https://github.com/cython/cython/blob/master/Cython/Includes/cpython/array.pxd

Let me read this thing.

```
  array.pxd
  Cython interface to Python's array.array module.
  * 1D contiguous data view
  * tools for fast array creation, maximum C-speed and handiness
  * suitable as allround light weight auto-array within Cython code too
  Usage:
  >>> cimport array
  Usage through Cython buffer interface (Py2.3+):
    >>> def f(arg1, unsigned i, double dx)
    ...     array.array[double] a = arg1
    ...     a[i] += dx
  Fast C-level new_array(_zeros), resize_array, copy_array, Py_SIZE(obj),
  zero_array
    cdef array.array[double] k = array.copy(d)
    cdef array.array[double] n = array.array(d, Py_SIZE(d) * 2 )
    cdef array.array[double] m = array.zeros_like(FLOAT_TEMPLATE)
    array.resize(f, 200000)
  Zero overhead with naked data pointer views by union:
  _f, _d, _i, _c, _u, ...
  => Original C array speed + Python dynamic memory management
    cdef array.array a = inarray
    if
    a._d[2] += 0.66   # use as double array without extra casting
    float *subview = vector._f + 10  # starting from 10th element
    unsigned char *subview_buffer = vector._B + 4
  Suitable as lightweight arrays intra Cython without speed penalty.
  Replacement for C stack/malloc arrays; no trouble with refcounting,
  mem.leaks; seamless Python compatibility, buffer() optional
```

The trouble is that Cython files do not have any intellisense, so I am running blind here.

Where is `cython.pyx`?

5:55pm. I have no idea. Forget this. Until the questions I asked on the user group get answered, I can't touch them.

You know, maybe I could just regular python array and just force cast them if that is possible to hold whatever data type I want.

I have no idea. Forget this for now.

Let me fix the math functions.

6:30pm. Done with lunch.

```
cimport libc.math
cpdef float main():
    cdef float v0
    cdef float v1
    cdef float v2
    v0 = 1.000000
    v1 = libc.math.tanh(v0)
    v2 = libc.math.exp(v1)
    return libc.math.log(v2)
```

Works fine. Let me push another patch.

6:30pm. Memory views I'll leave for later. They are not that important for the time being.

6:35pm. Let me stop here for the day. It was pretty nice today.

Tomorrow I should start working on the resume, but I almost don't feel like doing that. I'll mix it up with studying Python in general. I should get PyTorch operational and take a look at the Deepmind game stuff. I remember looking into that in early 2019.

There is no need to rush. Unlike last time I won't be spending endless time on working on the language and the ML library, so my pace should be blisteringly fast.

I'll have a bit extra hassle working on my resume and applying at these companies, but I won't allow this to take up too much of my time.

I've been doing programming for a while now, so if it fine if I take some time to get other things in order. I'll have to make time to go to the bank as well.

6:45pm. Agh, what a hassle. Now that I decided what I want to do, all I want to do is program, but things are getting in my way.

I want the day to continue, and yet it must end here. I'll get that resume out of the way tomorrow, I swear."

---
## [aridoitsu/ashesoftheoldorder](https://github.com/aridoitsu/ashesoftheoldorder)@[cfbdf56861...](https://github.com/aridoitsu/ashesoftheoldorder/commit/cfbdf5686164ba6d2d68db636fc7a4aebe5072a3)
#### Saturday 2021-01-30 18:48:45 by Greenbueller

Supply Areas

The map is finally fucking almost ready damn I really wasted like two weeks of my life on this or something

---
## [Penn-Electric-Racing/m.css](https://github.com/Penn-Electric-Racing/m.css)@[915ffcbed5...](https://github.com/Penn-Electric-Racing/m.css/commit/915ffcbed545b9c38f55fac07f33ef04433863a8)
#### Saturday 2021-01-30 20:56:32 by Vladimír Vondruš

package/ci: go back to Pelican 4.2 until I find a fix.

OH GOD, one can't just leave a project alone for 6 months because every
damn thing just breaks, changes or gets removed. Kids these days, FFS.

Imagine if the standard of electrical outlets changed rapidly every two
weeks, you'd just have to constantly buy new fucking adapters and you
would HATE it. So why is it COMPLETELY FINE with software?!

---
## [enosich/trapiche](https://github.com/enosich/trapiche)@[d87085cc61...](https://github.com/enosich/trapiche/commit/d87085cc616cc40567e7f19610ffb3dfa981b070)
#### Saturday 2021-01-30 21:01:00 by Evan Nosich

ver change v1.0

What kind of idiot starts his alpha build at v1.0, not v0.1? God damn.

---
## [mama805/.github](https://github.com/mama805/.github)@[89962958dc...](https://github.com/mama805/.github/commit/89962958dc4581b6851cd5ebbab477af7d67bdfe)
#### Saturday 2021-01-30 21:31:34 by Jada Hernandez

Contributor Covenant Code of Conduct

Contributor Covenant Code of Conduct

Our Pledge

In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.

Our Standards

Examples of behavior that contributes to creating a positive environment include:

Using welcoming and inclusive language
Being respectful of differing viewpoints and experiences
Gracefully accepting constructive criticism
Focusing on what is best for the community
Showing empathy towards other community members
Examples of unacceptable behavior by participants include:

The use of sexualized language or imagery and unwelcome sexual attention or advances
Trolling, insulting/derogatory comments, and personal or political attacks
Public or private harassment
Publishing others' private information, such as a physical or electronic address, without explicit permission
Other conduct which could reasonably be considered inappropriate in a professional setting
Our Responsibilities

Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.

Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.

Scope

This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.

Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at support@github.com. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.

Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.

Attribution

This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html

For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq

---
## [solonovamax/ServerColumns-PowercordFix](https://github.com/solonovamax/ServerColumns-PowercordFix)@[688e64cdcd...](https://github.com/solonovamax/ServerColumns-PowercordFix/commit/688e64cdcd9ab22e58cdaf87e499656e5ecd56df)
#### Saturday 2021-01-30 21:42:08 by solonovamax

Fixes to make the Better Folders plugin not look like shit.
Also, there's a fix for the Online Friends Count plugin, because it looked stupid too.

---
## [ctm/Bataan-Memorial-Death-March](https://github.com/ctm/Bataan-Memorial-Death-March)@[391d64d419...](https://github.com/ctm/Bataan-Memorial-Death-March/commit/391d64d419e5f6a018cc81c2173ba8497ed6b0d7)
#### Saturday 2021-01-30 21:45:35 by Clifford T. Matthews

Includes today's 24 mile 40.4# pack "run"

I knew going into it that I had a minorly swollen left ankle and that
on Tuesday I was reduced to a walk after less than eight miles
*without a pack*, so I was pretty nervous yesterday, but this morning
I was feeling pretty good, considering.

I was hoping to be only about 15 seconds per mile slower for the
entire 24 hours. At the turnaround, I was only 9 seconds per mile
slower, albeit at an additional 4bpm HR. However, the wheels fell off
before too long.  At around 15 miles I had largely crawled to a 10:00
min/mile pace.  17.3 miles in I decided to walk due to the discomfort.
After a mile of walking I "ran" at about an 11:00 min/mile pace, but
only for half a mile. After that it was all walking, except when I
stopped at a bench, took off my pack and went behind some bushes to
take a leak.

FWIW, I chose to take 200mg of ibuprofen at 6:15 (45 minutes before
starting my run), knowing that it would wear off during the run.  I
chose not to take any emergency analgesics with me, because I figured
if I was still hurting after that initial 200mg of ibuprofen and the
six double espressos (one at wake-up, three just before I started my
run and two at the turnaround), then I should listen to my body.  I
still stand by that choice, but it did make the final 6.7 miles
*super* slow (i.e., it took me two hours, basically an 18:00 min/mile
pace).

I may wind up not running at all tomorrow, especially since I'm likely
to drink a bit this evening and get to bed late.  I'll play every day
after by ear.  I don't want to be injured going into EMBARGO (Thursday
the 4th through Saturday the 6th) or for the celebration of my aunt's
life (also on Saturday the 6th).

---
## [Ninetailed/Baystation12](https://github.com/Ninetailed/Baystation12)@[cf457bbe6f...](https://github.com/Ninetailed/Baystation12/commit/cf457bbe6f901bd33e0b831524056a5092f9963e)
#### Saturday 2021-01-30 23:20:35 by Ninetailed

Robot/Surveyor module quality of life changes

The surveyor module for the flying robot chassis was broken or at least somewhat annoying to use in a number of ways. This should hopefully improve that.

Changes:

- rscadd: Robots can now unbuckle themselves and others from things by clicking on them, just like a real boy!
- rscadd: Robots with the GPS/RPD as an active module now get coordinates in the Status box the same as humans do
- rscadd: Surveyor module now has a harvester to gather plants for the bioreactor
- tweak: Robot net gun no longer has a safety, as selecting the module for use serves the same purpose
- tweak: Vines can no longer grab you if you're flying
- bugfix: Net gun now actually fires nets instead of dropping them
- bugfix: Robot net gun now spawns with shells loaded
- bugfix: All living mobs, including robots, can break free of vines using the Resist verb, rather than this being restricted to carbon life

Fixes #25310

---

# [<](2021-01-29.md) 2021-01-30 [>](2021-01-31.md)

