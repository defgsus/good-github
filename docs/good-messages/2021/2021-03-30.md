# [<](2021-03-29.md) 2021-03-30 [>](2021-03-31.md)

4,008,604 events, 1,414,566 push events, 2,263,461 commit messages, 188,704,728 characters


## [humanetech-community/awesome-humane-tech@7e89709c75...](https://github.com/humanetech-community/awesome-humane-tech/commit/7e89709c75844f094bd3c4b010d430c2af7f60bb)
##### 2021-03-30 05:26:54 by April 4th is Deletion Day!

Add Deletion Day

- [x] I have referred the list and did not find this submission already added.
- [x] I have read the contribution guidelines [here](https://github.com/humanetech-community/awesome-humane-tech/blob/main/contributing.md)
- [x] I have read the code of conduct and I agree to adhere to the same [here](https://github.com/humanetech-community/awesome-humane-tech/blob/main/code-of-conduct.md)
- [x] I have added my entry as the latest (last dotted point) under a topic, not at the beginning, not interleaved. 

If your suggested entry is code project:

- [x] I have checked that the project is open source and has a [FSF-approved](https://www.gnu.org/licenses/license-list.html) license.

Deletion Day is [licensed under the GNU GPL v3](https://github.com/deletionday/site/blob/master/COPYING)

### Name of my software/tool/service/technology/project:

[**Deletion Day**](https://deletionday.com)

### Explain why it's a Humane Technology

Deletion Day directly opposes the privacy and security overreaches perpetrated by today’s tech industry.

### Sourcecode is available…

[…on Github](https://github.com/deletionday/site/)

### Is there a similar software/tool etc., that already exists?

I’ve found instances of one-off data deletion events, for instance:

- [The International Association of Privacy Professionals Deletion Day (2018)](https://iapp.org/news/a/data-deletion-day/)
- [Montgomery Public Schools’ “Data Deletion Week”](https://www.theguardian.com/education/2019/dec/05/schools-monitor-students-online-activity)

…but as far as I know, this is the first effort to form a recurring awareness campaign around this issue.

### Motivations, goals, and purpose

Excerpt from [deletionday.com](https://deletionday.com):

> New technologies have the power to reshape civilization. Transformative developments like the calendar and the printing press not only reorganized society; they fundamentally changed how individuals thought. Today, digital storage is cheap and abundant. As it pervades everyday life, it has shifted our expectations about permanence. In this age of internet-connectedness and cheap digital storage, we no longer need to forget.
>
> We encode our heart rates, travel plans, and friendships into permanent storage. We welcome each minor convenience, and assume that sharing and storing are positive forces – or at least, that it may come in handy later.
>
> It’s worth considering who this benefits.
>
> Industries exist with the sole purpose of scraping photos and information about you to store, analyze, and sell. Advertisers, insurance companies, and police departments profile you based on your browsing history. Photos, video, and audio recordings can be used to generate realistic “deepfakes”. Doxing and harassment campaigns are on the rise.
>
> The data you store online does not belong to you.
>
> You may be aware of this reality from the news, or just a feeling in your gut. But it can be hard to know how to respond when so much of our attention and identity are wrapped up in the Internet.
>
> On the topic of identity, it’s worth asking if uploading this much of ourselves to an unsympathetic, persistent medium was ever a good idea. As people, we grow and change. Maintaining a consistent personal brand may hamper our ability to grow as people; digital footprints don’t fade.
>
> Deletion Day challenges the prevailing notion that “more is more”. In a culture that strives for permanence, we celebrate ephemerality, growth, and change. On April 4th, a chorus of Delete keys will ring out across the world. We hope you’ll join us.

---
## [seeing-things/zwo@4bceef7ed4...](https://github.com/seeing-things/zwo/commit/4bceef7ed48d586cf7812d7b3e7749f80c573e26)
##### 2021-03-30 06:15:38 by Justin Gottula

Implement ARMv7 support (untested)

ARM Thumb mode is the most evil thing ever conceived from a reverse
engineering point of view. Not only do you (and your disassembler) never
have a goddamn clue when the code is in Thumb mode or not (leading to
confusion and wrongly-disassembled instructions); but then if you want
to hack around with this code and actually interface with it, good luck
with that, because probably half the stuff will be in regular ARM ISA
and the other half will be in Thumb and it's just a giant inconsistent
mess.

You have no idea how happy I am that ARM made the highly intelligent
decision to NOT support the Thumb instruction set(s) in AArch64.
Dropping that shit was the best decision they ever made.

---
## [thestubborn/Skyrat-tg@9e5ae55902...](https://github.com/thestubborn/Skyrat-tg/commit/9e5ae55902e7befa0926383d98d2f99e9898c4a3)
##### 2021-03-30 07:28:37 by grandwizmiller

FUCK IT, I'LL ADD THEM ALL

 I don't give a FLYING FUCK, that bitch can fuck off, I've divorced her ass three hours ago! I'm SO SICK, my body is doing THINGS - THAT THING! And you over there, SHUT UP. And you, take off my pants! YOU WANNA SEE SOME - WEIRD SHIT?

---
## [T-J-Teru/binutils-gdb@08c428aff4...](https://github.com/T-J-Teru/binutils-gdb/commit/08c428aff4a793b63c7dd2229ae172879623e3a2)
##### 2021-03-30 10:52:50 by Nick Alcock

libctf: eliminate dtd_u, part 5: structs / unions

Eliminate the dynamic member storage for structs and unions as we have
for other dynamic types.  This is much like the previous enum
elimination, except that structs and unions are the only types for which
a full-sized ctf_type_t might be needed.  Up to now, this decision has
been made in the individual ctf_add_{struct,union}_sized functions and
duplicated in ctf_add_member_offset.  The vlen machinery lets us
simplify this, always allocating a ctf_lmember_t and setting the
dtd_data's ctt_size to CTF_LSIZE_SENT: we figure out whether this is
really justified and (almost always) repack things down into a
ctf_stype_t at ctf_serialize time.

This allows us to eliminate the dynamic member paths from the iterators and
query functions in ctf-types.c in favour of always using the large-structure
vlen stuff for dynamic types (the diff is ugly but that's just because of the
volume of reindentation this calls for).  This also means the large-structure
vlen stuff gets more heavily tested, which is nice because it was an almost
totally unused code path before now (it only kicked in for structures of size
>4GiB, and how often do you see those?)

The only extra complexity here is ctf_add_type.  Back in the days of the
nondeduplicating linker this was called a ridiculous number of times for
countless identical copies of structures: eschewing the repeated lookups of the
dtd in ctf_add_member_offset and adding the members directly saved an amazing
amount of time.  Now the nondeduplicating linker is gone, this is extreme
overoptimization: we can rip out the direct addition and use ctf_member_next and
ctf_add_member_offset, just like ctf_dedup_emit does.

We augment a ctf_add_type test to try adding a self-referential struct, the only
thing the ctf_add_type part of this change really perturbs.

This completes the elimination of dtd_u.

libctf/ChangeLog
2021-03-18  Nick Alcock  <nick.alcock@oracle.com>

	* ctf-impl.h (ctf_dtdef_t) <dtu_members>: Remove.
	<dtd_u>: Likewise.
	(ctf_dmdef_t): Remove.
	(struct ctf_next) <u.ctn_dmd>: Remove.
	* ctf-create.c (INITIAL_VLEN): New, more-or-less arbitrary initial
	vlen size.
	(ctf_add_enum): Use it.
	(ctf_dtd_delete): Do not free the (removed) dmd; remove string
	refs from the vlen on struct deletion.
	(ctf_add_struct_sized): Populate the vlen: do it by hand if
	promoting forwards.  Always populate the full-size
	lsizehi/lsizelo members.
	(ctf_add_union_sized): Likewise.
	(ctf_add_member_offset): Set up the vlen rather than the dmd.
	Expand it as needed, repointing string refs via
	ctf_str_move_pending. Add the member names as pending strings.
	Always populate the full-size lsizehi/lsizelo members.
	(membadd): Remove, folding back into...
	(ctf_add_type_internal): ... here, adding via an ordinary
	ctf_add_struct_sized and _next iteration rather than doing
	everything by hand.
	* ctf-serialize.c (ctf_copy_smembers): Remove this...
	(ctf_copy_lmembers): ... and this...
	(ctf_emit_type_sect): ... folding into here. Figure out if a
	ctf_stype_t is needed here, not in ctf_add_*_sized.
	(ctf_type_sect_size): Figure out the ctf_stype_t stuff the same
	way here.
	* ctf-types.c (ctf_member_next): Remove the dmd path and always
	use the vlen.  Force large-structure usage for dynamic types.
	(ctf_type_align): Likewise.
	(ctf_member_info): Likewise.
	(ctf_type_rvisit): Likewise.
	* testsuite/libctf-regression/type-add-unnamed-struct-ctf.c: Add a
	self-referential type to this test.
	* testsuite/libctf-regression/type-add-unnamed-struct.c: Adjusted
	accordingly.
	* testsuite/libctf-regression/type-add-unnamed-struct.lk: Likewise.

---
## [mrakgr/The-Spiral-Language@495b6689e2...](https://github.com/mrakgr/The-Spiral-Language/commit/495b6689e228f372b034c05699c0779201c96e20)
##### 2021-03-30 14:27:59 by Marko Grdinić

"1:55pm. Done with breakfast. Let me chill a little and then I will do the chores.

2:40pm. Let me resume.

```
terminal : game_state -> f64 -> r
```

I think I'll make this more explicit and put in the game state for each player.

```
terminal : game_state * game_state -> f64 -> r
```

```
    inl terminal ((p1 : player),(p2 : player),card) (i,r) =
        inl r = if i = 0 then r else -r
        inl p (x : player) = {x with pot#=(+) (if p1.id = 0 then r else -r)}
        inl p1, p2 = p p1, p p2
        terminal ((p1,p2,card),(p2,p1,card)) (f64 r)
```

This is the way things should be done.

3pm. Let me try it now.

...No wait. I need the pid.

```
    inl terminal ((p1 : player),(p2 : player),card) (i,r) =
        inl r = if i = 0 then r else -r
        inl p (x : player) = {x with pot#=(+) (if p1.id = 0 then r else -r)}
        inl p1, p2 = p p1, p p2
        inl p1, p2 = if i = 0 then p1,p2 else p2,p1
        terminal ((p1,p2,card),(p2,p1,card)) (f64 r)
```

Let me just add this. Now it should be proper.

Later I'll remove this fro the game itself as it would just do a bunch of meaningless processing.

But it does not matter either way. It is not going to turn into overhead. The main overhead will be NN training. 0.01% will be the actual game processing.

Let me try running this. Then I'll try setting the human player as p2.

Damn, it I get flipping in the terminal state again.

```
    inl terminal ~((p1 : player),(p2 : player),card) ~(i,r) =
        inl p1,p2 = join
            inl r = if i = 0 then r else -r
            inl p (x : player) = {x with pot#=(+) (if p1.id = 0 then r else -r)}
            inl p1, p2 = p p1, p p2
            if i = 0 then p1,p2 else p2,p1
        terminal ((p1,p2,card),(p2,p1,card)) (f64 r)
```

This is so annoying. How oculd I have possibly gone wrong here.

```
if p1.id = 0 then p1,p2 else p2,p1
```

Yeah, I got the condition wrong.

```
inl p (x : player) = {x with pot#=(+) (if x.id = 0 then r else -r)}
```

Here as well.

3:15pm. Wonderful job me. Let me try playing as p2.

```
    let human_dispatch (((p1,p2,card : leduc.game_state),(observations, r)),dist,next) =
        inl r =
            match r with
            | Some: r => Some: if p1.id = 0 then r else -r
            | None => None
        inl trace = agent.human.show_trace (observations,r)
```

I was wondering why I kept losing all the time. Turns out it was showing the wins and losses the other way around.

```
        inl r =
            match r with
            | Some: r => Some: if p1.id = 0 then r else -r
            | None => None
```

No wait, it is showing the wrong damn thing again.

```
    | Some: (r : f64) =>
        inl p = if i = 0 then "One" else "Two"
        if 0 < r then $"f\"Player {!p} wins {!r} chips.\\n\""
        elif 0 = r then $"f\"Player {!p} draws.\\n\""
        else inl r = -r in $"f\"Player {!p} loses {!r} chips.\\n\""
        |> r64.add ar
```

Let me do it like this. This should remove the confusion.

3:30pm. I am super confused.

```
    inl terminal ((p1 : player),(p2 : player),card) (i,r) =
        inl r = if i = 0 then r else -r
        inl p1,p2 =
            inl p (x : player) = {x with pot#=(+) (if x.id = 0 then r else -r)}
            inl p1, p2 = p p1, p p2
            if p1.id = 0 then p1,p2 else p2,p1
        terminal ((p1,p2,card),(p2,p1,card)) (f64 r)
```

Ah, I messed this up here.

3:35pm. Ok, now things are perfect. I can play as p2 with no problem.

Leduc poker - UI version is complete!

3:45pm. I am taking a short breather here. What should come next?

```
    player_funs {
        action = fun _ (p : _ stateless card action) opp_prob dist next => next (net (observations p) dist,state p)
        terminal = fun s p r => ()
        }
```

I am confused. Why are observations right here, but in the trace I had to reverse them?

```
    match listm.rev l with
    | Cons: (Observation: x), x' => action (x,Nil) x' |> listm.toArray
    | _ => failwith "Expected a card."
```

Ah, I am reversing them. Ok.

3:50pm. That is one mystery down.

3:55pm. Let me think a little what I want to do here. The code feels bloated at 3k lines compiled, but I am not going to bother debugging that now.

4pm. Let me take a nap for a bit. It took me so long to get to this stage that I can hardly believe it.

Should I take the time to do a monthly review here? I am thinking of stopping those. Since it has been decided, I might as well do the last few in the batch rarther than aborting all of a sudden.

Let me do it. A few more won't kill me. Better to do this than lie in bed."

---
## [liferay/liferay-frontend-projects@bc6ff83ceb...](https://github.com/liferay/liferay-frontend-projects/commit/bc6ff83ceb3f670195367a93665dc69459167b27)
##### 2021-03-30 16:37:35 by Greg Hurrell

feat(npm-scripts): check for TS artifact staleness during CI runs

Basically does what it says on the tin. If you have touched any paths
inside a TS project then we'll run our "types" subcommand to verify that
the committed TS artifacts are up-to-date.

I don't know whether "preflight" is a great _name_ for this phase but it
does seem to be the right _place_. Currently when you run "check" (which
is what CI runs) we will run:

1.  "preflight" checks; which consist of:

    a)  checking for banned config file names

    b)  checking for banned dependencies inside package.json files (note
        that we may and probably will add more package.json checks in
        the future)

    c)  checking that TS artifacts are up to date

2.  "format" (Prettier) checks

3.  "lint" (ESLint) checks

In other words, "preflight" means "everything that isn't handled by
Prettier and ESLint".

So, as noted in the commit, this will only have effect in CI, because
that's the only place where `LIFERAY_NPM_SCRIPTS_WORKING_BRANCH_NAME`
will be defined. At least for now, this check is plenty fast (only a few
seconds). We can worry about performance later on, and we probably have
a fair bit of time before that happens because TS adoption will likely
be quite a long and drawn-out affair.

Note that we want this to work on in CI in order to keep the local
development experience snappy. If you are working in
"frontend-js-react-web", you shouldn't have to wait for a global check
to run just because you ran "yarn run check"; instead, you should be
able to rely on CI to keep `master` in a good state, and know that all
the other projects are up-to-date and that you only need worry about
your own.

Test plan:

Copy this over to liferay-portal and see `yarn run check` fail like this
when you set `LIFERAY_NPM_SCRIPTS_WORKING_BRANCH_NAME` to `master` and
have stale artifacts. If the artifacts aren't stale, or you don't have
that environment variable, you don't see an error.

    Preflight check failed:
    checkTypeScriptTypeArtifacts() failed: Error: Type generation was successful but 2 projects were out of date. Please commit updated versions of the artifacts in the projects listed above.

---
## [home-assistant/home-assistant.io@5ddb6529c1...](https://github.com/home-assistant/home-assistant.io/commit/5ddb6529c13dd4ba8f5aa364b2560740a77bf178)
##### 2021-03-30 16:58:21 by elyobelyob

I found that a 4pm or other non midnight required buffering. (#16182)

* Update history_stats.markdown

---
title: History Stats
description: Instructions about how to integrate historical statistics into Home Assistant.
ha_category:
  - Utility
  - Sensor
ha_iot_class: Local Polling
ha_release: 0.39
ha_quality_scale: internal
ha_domain: history_stats
---

The `history_stats` sensor platform provides quick statistics about another integration or platforms, using data from the [`history`](/integrations/history/) integration.

It can track how long the integration has been in a specific state, in a custom time period.

Examples of what you can track:

- How long you were at home this week
- How long the lights were ON yesterday
- How long you watched TV today

## Configuration

To enable the history statistics sensor, add the following lines to your `configuration.yaml`:

{% raw %}

```yaml
# Example configuration.yaml entry
sensor:
  - platform: history_stats
    name: Lamp ON today
    entity_id: light.my_lamp
    state: 'on'
    type: time
    start: '{{ now().replace(hour=0, minute=0, second=0) }}'
    end: '{{ now() }}'
```

{% endraw %}

{% configuration %}
entity_id:
  description: The entity you want to track.
  required: true
  type: string
state:
  description: The states you want to track.
  required: true
  type: [list, string]
name:
  description: Name displayed on the frontend. Note that it is used by Home Assistant to generate sensor's `object_id` so it is advisable to choose a unique one and change name for frontend using [customization](/docs/configuration/customizing-devices/#friendly_name) or via [Lovelace](/lovelace/entities/#name).
  required: false
  default: unnamed statistics
  type: string
type:
  description: "The type of sensor: `time`, `ratio`, or `count`."
  required: false
  default: time
  type: string
start:
  description: When to start the measure (timestamp or datetime).
  required: false
  type: template
end:
  description: When to stop the measure (timestamp or datetime).
  required: false
  type: template
duration:
  description: Duration of the measure.
  required: false
  type: time
{% endconfiguration %}

<div class='note'>

  You have to provide **exactly 2** of `start`, `end` and `duration`.
<br/>
  You can use [template extensions](/topics/templating/#home-assistant-template-extensions) such as `now()` or `as_timestamp()` to handle dynamic dates, as shown in the examples below.

</div>

## Sensor type

Depending on the sensor type you choose, the `history_stats` integration can show different values:

- **time**: The default value, which is the tracked time, in hours
- **ratio**: The tracked time divided by the length of your period, as a percentage
- **count**: How many times the integration you track was changed to the state you track

## Time periods

The `history_stats` integration will execute a measure within a precise time period. You should always provide 2 of the following :
- When the period starts (`start` variable)
- When the period ends (`end` variable)
- How long is the period (`duration` variable)

As `start` and `end` variables can be either datetimes or timestamps, you can configure almost any period you want.

### Duration

The duration variable is used when the time period is fixed. Different syntaxes for the duration are supported, as shown below.

```yaml
# 6 hours
duration: 06:00
```

```yaml
# 1 minute, 30 seconds
duration: 00:01:30
```

```yaml
# 2 hours and 30 minutes
duration:
  # supports seconds, minutes, hours, days
  hours: 2
  minutes: 30
```

<div class='note'>

  If the duration exceeds the number of days of history stored by the `recorder` component (`purge_keep_days`), the history statistics sensor will not have all the information it needs to look at the entire duration. For example, if `purge_keep_days` is set to 7, a history statistics sensor with a duration of 30 days will only report a value based on the last 7 days of history.

</div>

### Examples

Here are some examples of periods you could work with, and what to write in your `configuration.yaml`:

**Today**: starts at 00:00 of the current day and ends right now.

{% raw %}

```yaml
    start: '{{ now().replace(hour=0, minute=0, second=0) }}'
    end: '{{ now() }}'
```

{% endraw %}

**Yesterday**: ends today at 00:00, lasts 24 hours.

{% raw %}

```yaml
    end: '{{ now().replace(hour=0, minute=0, second=0) }}'
    duration:
      hours: 24
```

{% endraw %}

**This morning (6AM - 11AM)**: starts today at 6, lasts 5 hours.

{% raw %}

```yaml
    start: '{{ now().replace(hour=6, minute=0, second=0) }}'
    duration:
      hours: 5
```

{% endraw %}

**Current week**: starts last Monday at 00:00, ends right now.

Here, last Monday is _today_ as a timestamp, minus 86400 times the current weekday (86400 is the number of seconds in one day, the weekday is 0 on Monday, 6 on Sunday).

{% raw %}

```yaml
    start: '{{ as_timestamp( now().replace(hour=0, minute=0, second=0) ) - now().weekday() * 86400 }}'
    end: '{{ now() }}'
```

{% endraw %}

**Next 4pm **: ends today at 00:00, lasts 30 days. Easy one.

{% raw %}

```yaml
    end: '{{ now().replace(hour=0, minute=0, second=0) }}'
    duration:
      days: 30
```

{% endraw %}

**Last 30 days**: ends today at 00:00, lasts 30 days. Easy one.

{% raw %}

```yaml
    end: '{{ now().replace(hour=0, minute=0, second=0) }}'
    duration:
      days: 30
```

{% endraw %}


** 4PM always in the future**: ends in the future at 16:00, starts 24 hours before.

{% raw %}

```yaml
    end: '{{ (now().replace(minute=0,second=0) + timedelta(hours=8)).replace(hour=16) }}'
    duration:
      hours: 24
```

{% endraw %}

**All your history** starts at timestamp = 0, and ends right now.

{% raw %}

```yaml
    start: '{{ 0 }}'
    end: '{{ now() }}'
```

{% endraw %}

<div class='note'>

  The `/developer-tools/template` page of your Home Assistant UI can help you check if the values for `start`, `end` or `duration` are correct. If you want to check if your period is right, just click on your component, the `from` and `to` attributes will show the start and end of the period, nicely formatted.

</div>

* $pm - 4pm example implemented

* Tweak

* Update source/_integrations/history_stats.markdown

Very happy with this change ...

Co-authored-by: Franck Nijhof <frenck@frenck.nl>

* Update source/_integrations/history_stats.markdown

Co-authored-by: Franck Nijhof <frenck@frenck.nl>

---
## [mrakgr/The-Spiral-Language@ce9fdc4187...](https://github.com/mrakgr/The-Spiral-Language/commit/ce9fdc4187e8a5d1e7d8e56d907ea84978db891a)
##### 2021-03-30 17:16:45 by Marko Grdinić

"///

March highlights:

* During the first two weeks, I did a complete redesign of the editor support segment. Rather than use streams, I switched to immutable state updating functions. The streams version was too confusing and I could not figure out how to fix a lot of the bugs I've encountered. It is frequently the case that it is not possible to fix an error without changing the design from the ground up to guarantee it does not occur, and this was one of those cases. Right now, the editor support server should be extremely solid. If there are any more bugs remaining, I won't have trouble fixing them. It was a major redesign, and now I feel like I understand all major aspects of language development at a high level.

* It was an intense effort. After that I wanted to get back to working on RL agents, but ended up just playing around with UIs and Processing. While studying Kivy I was surprised how much overlap UI drawing and [Processing](https://processing.org/) had, so I played around with both. I was really supposed to be working on ML, but this somehow happened. I got some benefit out of this though. Check out the [Spiral logo](https://github.com/mrakgr/The-Spiral-Language#the-spiral-language), I wrote the code to generate it in Processing. Though it took me way too much time, I learned quite a bit about computer graphics. It was a fun little diversion, the kind of programming I did there anybody could do, and even Java's mediocre type system was not a hindrance. The typical workflow in Processing is to make a small change and then run the sketch, then see the effect of the changes. This is not my usual workflow - when redesigning Spiral's editor support for the first half of the month, I spent two weeks writing code without running the compiler even once. This is not that rare for me. In contrast, what I did here which gave me instant feedback was refreshing.

* In the last month's entry, I gave a demo of how Spiral UIs will look, but I've abandoned that plan in favor of using [Kivy's native language](https://kivy.org/doc/stable/guide/lang.html). Interfacing with Spiral and Python on a large scale is an interop nightmare and I do not want to bash my head against that wall anymore. But even more than that, I've had a shocking realization that observables are in fact the wrong abstraction for UIs. The right ones are properties. This is actually what Kivy and Svelte use, in different forms. I invested so much into learning Rx, so it is a shock that not only did I not use it for Spiral's editor support, but that I also have better alternatives when it comes to doing UIs. And even if I made a property-based UI library, I would not be able to do better than Kivy's language. The way properties are declared in classes seems like a hack, and the Kivy language seems restricted compared to what I could do with my own library or Svelte, but after thinking about it for a bit, I realized that unless the Python expressions were restricted to a subset of its language, the flow analyzer could not disambiguate the properties from regular variables. Without that pass to get property change notifications the system could not be reactive. So Kivy gets my approval. The language could be extended to allow dynamic widgets, but I do not particularly need that.

* This is convenient, as much like I do not need to write my own ML library thanks to having PyTorch, I do not need to write reactive UI library wrappers to get the necessary expressiveness out of it. It will be a huge time saver.

* Out of the last 4 months, it feels like I wasted 2. I did a little [Leduc poker game with an UI](https://github.com/mrakgr/The-Spiral-Language/blob/495b6689e228f372b034c05699c0779201c96e20/Spiral%20Compilation%20Tests/cython_experiments/ui_leduc4/ui_leduc.py). This stuff here should not have taken me more than 2-3 days. Yet I am only at the point now where I should have been in early March. Hopefully now that I've worked out all the kinks in both Spiral and Python, the flow will come to me. Now that I can play against random players, the next goal is to implement agent training and have some fun playing against trained agents after that. After that I'll move to HU NL Holdem.

* A part of what drove me to create Spiral is to make backends and ML libraries for novel AI hardware, but I'll leave that vision for the NG+ playthrough. I pick a bunch of companies, send emails to them and get no reply whatsoever. If I got some feedback I could adjust my pitch and negotiate, but this game disgusts me and I am not interested in playing it anymore. The benefits of my main path vastly outstrip those from this crappy side quest and do not want my time to be taken up what could be better spent elsewhere. I'll hold these AI chip companies in the contempt they deserve and wait for them to finish killing each other. Then I'll go with the winner in the open market. If they like C++ that much, they can have it. I believe that Spiral could be a major asset in this field, the benefits were apparent to me back in 2018. But none of that really matters if I cannot clear the very first hurdle. And I can't. I can generate ideas and think of things to say, but I can't imagine the other side's reaction. So the effort feels like I am trying out random things in hopes of cracking a password. Forget this. I won't talk about this again.

* Now that I have UIs down, and the ML library down, I am in a unique position. At this point in time, I am probably the only person in the world doing actual functional programming in Python's ecosystem. In 2018 and 2019 I was obsessed about improving my understanding of ML, but since that did not get me far enough, I'll rely on sheer programming skill cultivated over the last six years to be my edge. I'll certainly need it. Doing RL is certainly [not a piece of cake](https://andyljones.com/posts/rl-debugging.html) at this point in time. I wanted to do this back in 2016, but my skills really were not good enough back then. My hunch that I needed more training, and bigger advantages than pure Python was offering me were probably right. If I am not good enough now, I’ll never be good enough.

///

Let me put this through Google Docs.

5:10pm. ...Done.

5:15pm. Let me take a breather. I do not feel like doing anything else for the day.

5:20pm. Hmmmmm...

The flow I had in the last few days was wonderful.

Start with the UI, then make the backend. That is justice.

5:25pm. I am visualizing the UI. The amount that can be done with a single page is small, but that serves to narrow down my purpose.

5:35pm. How do I do the replay buffer? I still haven't decided on it.

6:15pm. https://www.youtube.com/channel/UCJ0xA3rAVjqaqA28XNDMD2g
Throw M. Away

This channel really has a lot of Alicesoft OSTs. Nice find.

7:10pm. Done with lunch. Let me stop here. Right now I am obsessing about the replay buffer. There are way of doing it, but the feedforward case is straightforward.

The trouble with recurrent cases is that it will be inefficient on the GPU. I could really use AI chips for that, but regardless I'll squeeze the RNNs in somehow.

For the time being, let me master feedforward nets on small games like Leduc. That won't take too long. Tomorrow, I'll start work on the UI. The main goal will be to generate the replay buffer. This is what I will use for training. And on every iteration I'll regenerate it.

7:15pm. I'll leave that for tomorrow. Let me have a different kind of fun now."

---
## [Paxilmaniac/tgstation@7b52daef41...](https://github.com/Paxilmaniac/tgstation/commit/7b52daef41ff7b771cc84aedcdebba82679e684e)
##### 2021-03-30 21:52:13 by LemonInTheDark

Makes stations more airtight (#57535)

I've gone through delta, meta, and icebox and added some choice windoors, changed some areas around, added some more doors, and changed some other miscellaneous things.

I'll list the full changes in drop downs, for both our sakes

Delta:
<details>
Splits the central hallway into fore and aft central hallways

Adds the spaces that jut out of medbay and sci into the central hallway, rather then having them be a part of
medbay and sci

Adds medbay access locked windoors to the back desk of the medbay reception area

Adds airlocks to both the upper and lower parts of the main hallway
</details>

Meta:
<details>
Gives the storage wing another set of firelocks, and two fire alarms. It didn't have any alarms in the first place, so hopefully this helps things

Adds the spaces that jut out of medbay and sci into the central hallway, rather then having them be a part of
medbay and sci

Replaces a small bit of the science area with nanite lab, to prevent a breach near xenobio causing fire alarms
at the front of sci

Adds a windoor in front of the ORM to block air

Adds a wall behind a smart fridge in chemistry
</details>

Icebox:
<details>
Added airlocks between arrivals and the port hallway, and the escape hallway and the starboard hallway

Added a windoor between the kitchen and the bar
</details>

## Why It's Good For The Game

Cuts delta's main hallway in half, with the goal of reducing fire alarm strain. Some thoughts on this would be nice, I don't want to make everything else that uses areas worse just because fire alarms are dumb, and I'm worried that's what I've ended up doing here.

I've also added the portions of medbay/sci that jut out into the main hallway into the main hallway, I think? I could make these into lobby areas, but I'm not sure if that's appropriate or not.

Adds a few windoors and airlocks to better section off portions of the station, this should reduce the amount of mass gas spreading that can occur.

My goal here is to reduce the amount of uninteresting gas movement and make firelocks less hellish when there's a breach

---
## [Buildstarted/linksfordevs@d24218e5dc...](https://github.com/Buildstarted/linksfordevs/commit/d24218e5dc5abe239817a9825ee2eb286c5515cc)
##### 2021-03-30 23:07:30 by Ben Dornis

Updating: 3/30/2021 11:00:00 PM

 1. Added: Who has the fastest F1 website in 2021? Part 1
    (https://jakearchibald.com/2021/f1-perf-part-1/)
 2. Added: Friendship Cards
    (https://philipkiely.com/essays/friendship_cards.html)
 3. Added: My Self-Taught Tech Career - Work & Life Notes
    (https://worklifenotes.com/2021/03/29/my-self-taught-tech-career/)
 4. Added: Some opinionated thoughts on SQL databases
    (https://blog.nelhage.com/post/some-opinionated-sql-takes/)
 5. Added: Those pesky pull request reviews
    (https://jessitron.com/2021/03/27/those-pesky-pull-request-reviews/)
 6. Added: A command-line grammar of graphics
    (http://reasonableapproximation.net/2021/03/30/command-line-grammar-of-graphics.html)

Generation took: 00:07:20.6762437
 Maintenance update - cleaning up homepage and feed

---

# [<](2021-03-29.md) 2021-03-30 [>](2021-03-31.md)

