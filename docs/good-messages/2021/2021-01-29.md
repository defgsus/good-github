# [<](2021-01-28.md) 2021-01-29 [>](2021-01-30.md)

2,802,182 events, 1,442,435 push events, 2,239,292 commit messages, 165,874,331 characters


## [Yrassim/CS50](https://github.com/Yrassim/CS50)@[7cb1677e27...](https://github.com/Yrassim/CS50/commit/7cb1677e273891cda499ed55033b67b9aa3e4954)
#### Friday 2021-01-29 00:13:57 by Yrassim

Implement the functions in helpers.c such that a user can apply grayscale, sepia, reflection, or blur filters to their images.

Filter
Implement a program that applies filters to BMPs, per the below.

$ ./filter -r image.bmp reflected.bmp
Background
Bitmaps
Perhaps the simplest way to represent an image is with a grid of pixels (i.e., dots), each of which can be of a different color. For black-and-white images, we thus need 1 bit per pixel, as 0 could represent black and 1 could represent white, as in the below.

a simple bitmap

In this sense, then, is an image just a bitmap (i.e., a map of bits). For more colorful images, you simply need more bits per pixel. A file format (like BMP, JPEG, or PNG) that supports “24-bit color” uses 24 bits per pixel. (BMP actually supports 1-, 4-, 8-, 16-, 24-, and 32-bit color.)

A 24-bit BMP uses 8 bits to signify the amount of red in a pixel’s color, 8 bits to signify the amount of green in a pixel’s color, and 8 bits to signify the amount of blue in a pixel’s color. If you’ve ever heard of RGB color, well, there you have it: red, green, blue.

If the R, G, and B values of some pixel in a BMP are, say, 0xff, 0x00, and 0x00 in hexadecimal, that pixel is purely red, as 0xff (otherwise known as 255 in decimal) implies “a lot of red,” while 0x00 and 0x00 imply “no green” and “no blue,” respectively.

A Bit(map) More Technical
Recall that a file is just a sequence of bits, arranged in some fashion. A 24-bit BMP file, then, is essentially just a sequence of bits, (almost) every 24 of which happen to represent some pixel’s color. But a BMP file also contains some “metadata,” information like an image’s height and width. That metadata is stored at the beginning of the file in the form of two data structures generally referred to as “headers,” not to be confused with C’s header files. (Incidentally, these headers have evolved over time. This problem uses the latest version of Microsoft’s BMP format, 4.0, which debuted with Windows 95.)

The first of these headers, called BITMAPFILEHEADER, is 14 bytes long. (Recall that 1 byte equals 8 bits.) The second of these headers, called BITMAPINFOHEADER, is 40 bytes long. Immediately following these headers is the actual bitmap: an array of bytes, triples of which represent a pixel’s color. However, BMP stores these triples backwards (i.e., as BGR), with 8 bits for blue, followed by 8 bits for green, followed by 8 bits for red. (Some BMPs also store the entire bitmap backwards, with an image’s top row at the end of the BMP file. But we’ve stored this problem set’s BMPs as described herein, with each bitmap’s top row first and bottom row last.) In other words, were we to convert the 1-bit smiley above to a 24-bit smiley, substituting red for black, a 24-bit BMP would store this bitmap as follows, where 0000ff signifies red and ffffff signifies white; we’ve highlighted in red all instances of 0000ff.

red smile

Because we’ve presented these bits from left to right, top to bottom, in 8 columns, you can actually see the red smiley if you take a step back.

To be clear, recall that a hexadecimal digit represents 4 bits. Accordingly, ffffff in hexadecimal actually signifies 111111111111111111111111 in binary.

Notice that you could represent a bitmap as a 2-dimensional array of pixels: where the image is an array of rows, each row is an array of pixels. Indeed, that’s how we’ve chosen to represent bitmap images in this problem.

Image Filtering
What does it even mean to filter an image? You can think of filtering an image as taking the pixels of some original image, and modifying each pixel in such a way that a particular effect is apparent in the resulting image.

Grayscale
One common filter is the “grayscale” filter, where we take an image and want to convert it to black-and-white. How does that work?

Recall that if the red, green, and blue values are all set to 0x00 (hexadecimal for 0), then the pixel is black. And if all values are set to 0xff (hexadecimal for 255), then the pixel is white. So long as the red, green, and blue values are all equal, the result will be varying shades of gray along the black-white spectrum, with higher values meaning lighter shades (closer to white) and lower values meaning darker shades (closer to black).

So to convert a pixel to grayscale, we just need to make sure the red, green, and blue values are all the same value. But how do we know what value to make them? Well, it’s probably reasonable to expect that if the original red, green, and blue values were all pretty high, then the new value should also be pretty high. And if the original values were all low, then the new value should also be low.

In fact, to ensure each pixel of the new image still has the same general brightness or darkness as the old image, we can take the average of the red, green, and blue values to determine what shade of grey to make the new pixel.

If you apply that to each pixel in the image, the result will be an image converted to grayscale.

Sepia
Most image editing programs support a “sepia” filter, which gives images an old-timey feel by making the whole image look a bit reddish-brown.

An image can be converted to sepia by taking each pixel, and computing new red, green, and blue values based on the original values of the three.

There are a number of algorithms for converting an image to sepia, but for this problem, we’ll ask you to use the following algorithm. For each pixel, the sepia color values should be calculated based on the original color values per the below.

  sepiaRed = .393 * originalRed + .769 * originalGreen + .189 * originalBlue
  sepiaGreen = .349 * originalRed + .686 * originalGreen + .168 * originalBlue
  sepiaBlue = .272 * originalRed + .534 * originalGreen + .131 * originalBlue
Of course, the result of each of these formulas may not be an integer, but each value could be rounded to the nearest integer. It’s also possible that the result of the formula is a number greater than 255, the maximum value for an 8-bit color value. In that case, the red, green, and blue values should be capped at 255. As a result, we can guarantee that the resulting red, green, and blue values will be whole numbers between 0 and 255, inclusive.

Reflection
Some filters might also move pixels around. Reflecting an image, for example, is a filter where the resulting image is what you would get by placing the original image in front of a mirror. So any pixels on the left side of the image should end up on the right, and vice versa.

Note that all of the original pixels of the original image will still be present in the reflected image, it’s just that those pixels may have rearranged to be in a different place in the image.

Blur
There are a number of ways to create the effect of blurring or softening an image. For this problem, we’ll use the “box blur,” which works by taking each pixel and, for each color value, giving it a new value by averaging the color values of neighboring pixels.

Consider the following grid of pixels, where we’ve numbered each pixel.

a grid of pixels

The new value of each pixel would be the average of the values of all of the pixels that are within 1 row and column of the original pixel (forming a 3x3 box). For example, each of the color values for pixel 6 would be obtained by averaging the original color values of pixels 1, 2, 3, 5, 6, 7, 9, 10, and 11 (note that pixel 6 itself is included in the average). Likewise, the color values for pixel 11 would be be obtained by averaging the color values of pixels 6, 7, 8, 10, 11, 12, 14, 15 and 16.

For a pixel along the edge or corner, like pixel 15, we would still look for all pixels within 1 row and column: in this case, pixels 10, 11, 12, 14, 15, and 16.

Getting Started
Here’s how to download this problem’s “distribution code” (i.e., starter code) into your own CS50 IDE. Log into CS50 IDE and then, in a terminal window, execute each of the below.

Execute cd to ensure that you’re in ~/ (i.e., your home directory).
Execute mkdir pset4 to make (i.e., create) a directory called pset4 in your home directory.
Execute cd pset4 to change into (i.e., open) that directory.
Execute wget https://cdn.cs50.net/2019/fall/psets/4/filter/less/filter.zip to download a (compressed) ZIP file with this problem’s distribution.
Execute unzip filter.zip to uncompress that file.
Execute rm filter.zip followed by yes or y to delete that ZIP file.
Execute ls. You should see a directory called filter, which was inside of that ZIP file.
Execute cd filter to change into that directory.
Execute ls. You should see this problem’s distribution, including bmp.h, filter.c, helpers.h, helpers.c, and Makefile. You’ll also see a directory called images, with some sample Bitmap images.
Understanding
Let’s now take a look at some of the files provided to you as distribution code to get an understanding for what’s inside of them.

bmp.h
Open up bmp.h (as by double-clicking on it in the file browser) and have a look.

You’ll see definitions of the headers we’ve mentioned (BITMAPINFOHEADER and BITMAPFILEHEADER). In addition, that file defines BYTE, DWORD, LONG, and WORD, data types normally found in the world of Windows programming. Notice how they’re just aliases for primitives with which you are (hopefully) already familiar. It appears that BITMAPFILEHEADER and BITMAPINFOHEADER make use of these types.

Perhaps most importantly for you, this file also defines a struct called RGBTRIPLE that, quite simply, “encapsulates” three bytes: one blue, one green, and one red (the order, recall, in which we expect to find RGB triples actually on disk).

Why are these structs useful? Well, recall that a file is just a sequence of bytes (or, ultimately, bits) on disk. But those bytes are generally ordered in such a way that the first few represent something, the next few represent something else, and so on. “File formats” exist because the world has standardized what bytes mean what. Now, we could just read a file from disk into RAM as one big array of bytes. And we could just remember that the byte at array[i] represents one thing, while the byte at array[j] represents another. But why not give some of those bytes names so that we can retrieve them from memory more easily? That’s precisely what the structs in bmp.h allow us to do. Rather than think of some file as one long sequence of bytes, we can instead think of it as a sequence of structs.

filter.c
Now, let’s open up filter.c. This file has been written already for you, but there are a couple important points worth noting here.

First, notice the definition of filters on line 11. That string tells the program what the allowable command-line arguments to the program are: b, g, r, and s. Each of them specifies a different filter that we might apply to our images: blur, grayscale, reflection, and sepia.

The next several lines open up an image file, make sure it’s indeed a BMP file, and read all of the pixel information into a 2D array called image.

Scroll down to the switch statement that begins on line 102. Notice that, depending on what filter we’ve chosen, a different function is called: if the user chooses filter b, the program calls the blur function; if g, then grayscale is called; if r, then reflect is called; and if s, then sepia is called. Notice, too, that each of these functions take as arguments the height of the image, the width of the image, and the 2D array of pixels.

These are the functions you’ll (soon!) implement. As you might imagine, the goal is for each of these functions to edit the 2D array of pixels in such a way that the desired filter is applied to the image.

The remaining lines of the program take the resulting image and write them out to a new image file.

helpers.h
Next, take a look at helpers.h. This file is quite short, and just provides the function prototypes for the functions you saw earlier.

Here, take note of the fact that each function takes a 2D array called image as an argument, where image is an array of height many rows, and each row is itself another array of width many RGBTRIPLEs. So if image represents the whole picture, then image[0] represents the first row, and image[0][0] represents the pixel in the upper-left corner of the image.

helpers.c
Now, open up helpers.c. Here’s where the implementation of the functions declared in helpers.h belong. But note that, right now, the implementations are missing! This part is up to you.

Makefile
Finally, let’s look at Makefile. This file specifies what should happen when we run a terminal command like make filter. Whereas programs you may have written before were confined to just one file, filter seems to use multiple files: filter.c, bmp.h, helpers.h, and helpers.c. So we’ll need to tell make how to compile this file.

Try compiling filter for yourself by going to your terminal and running

$ make filter
Then, you can run the program by running:

$ ./filter -g images/yard.bmp out.bmp
which takes the image at images/yard.bmp, and generates a new image called out.bmp after running the pixels through the grayscale function. grayscale doesn’t do anything just yet, though, so the output image should look the same as the original yard.

Specification
Implement the functions in helpers.c such that a user can apply grayscale, sepia, reflection, or blur filters to their images.

The function grayscale should take an image and turn it into a black-and-white version of the same image.
The function sepia should take an image and turn it into a sepia version of the same image.
The reflect function should take an image and reflect it horizontally.
Finally, the blur function should take an image and turn it into a box-blurred version of the same image.
You should not modify any of the function signatures, nor should you modify any other files other than helpers.c.

---
## [filfreire/filfreire.github.io](https://github.com/filfreire/filfreire.github.io)@[79c14ae66c...](https://github.com/filfreire/filfreire.github.io/commit/79c14ae66cb79fa2d4dc9cc4e92ce160448e6d3c)
#### Friday 2021-01-29 00:14:39 by Filipe Freire

good night clarity.ms, you just weren't fast enough, still less evil than google though. such is life.

---
## [maborak/iemaddon-installer](https://github.com/maborak/iemaddon-installer)@[f888c87778...](https://github.com/maborak/iemaddon-installer/commit/f888c87778f3859061c78075407a81d6d3244fa5)
#### Friday 2021-01-29 00:28:18 by Wilmer Adalid (Alienware)

Updates for: love, n.:
	When it's growing, you don't mind watering it with a few tears.

---
## [JmanThunder/HFM-Expanded](https://github.com/JmanThunder/HFM-Expanded)@[a8427c82fe...](https://github.com/JmanThunder/HFM-Expanded/commit/a8427c82fee175780ae963fe661f73fee725f5d4)
#### Friday 2021-01-29 00:57:20 by Choxflan

set up for incoming hre update

cores to minigerms
burgundy core on nevers
split up auvergne region
moravia capital fix
emden turned to swamp to make frisians based swampgerms
i relate to dat above as a swampmongol, swamps are cool, ever been covered in mosquito larvae ? i have, what about tadpoles ? i sure have too but they are annoying tickly bastards doe u cant hurt em cuz they cute as shit, thats the swamp life btw, it aint cool in the winter doe, ice in swamps aint tough

---
## [Yrassim/CS50](https://github.com/Yrassim/CS50)@[b553c66e56...](https://github.com/Yrassim/CS50/commit/b553c66e5659c4b865447881e05e29814b852446)
#### Friday 2021-01-29 01:14:47 by Yrassim

Implement a website via which users can “buy” and “sell” stocks.

C$50 Finance
Implement a website via which users can “buy” and “sell” stocks, a la the below.

C$50 Finance

Background
If you’re not quite sure what it means to buy and sell stocks (i.e., shares of a company), head here for a tutorial.

You’re about to implement C$50 Finance, a web app via which you can manage portfolios of stocks. Not only will this tool allow you to check real stocks’ actual prices and portfolios’ values, it will also let you buy (okay, “buy”) and sell (okay, “sell”) stocks by querying IEX for stocks’ prices.

Indeed, IEX lets you download stock quotes via their API (application programming interface) using URLs like https://cloud-sse.iexapis.com/stable/stock/nflx/quote?token=API_KEY. Notice how Netflix’s symbol (NFLX) is embedded in this URL; that’s how IEX knows whose data to return. That link won’t actually return any data because IEX requires you to use an API key (more about that in a bit), but if it did, you’d see a response in JSON (JavaScript Object Notation) format like this:


{  
   "symbol": "NFLX",
   "companyName": "Netflix, Inc.",
   "primaryExchange": "NASDAQ",
   "calculationPrice": "close",
   "open": 317.49,
   "openTime": 1564752600327,
   "close": 318.83,
   "closeTime": 1564776000616,
   "high": 319.41,
   "low": 311.8,
   "latestPrice": 318.83,
   "latestSource": "Close",
   "latestTime": "August 2, 2019",
   "latestUpdate": 1564776000616,
   "latestVolume": 6232279,
   "iexRealtimePrice": null,
   "iexRealtimeSize": null,
   "iexLastUpdated": null,
   "delayedPrice": 318.83,
   "delayedPriceTime": 1564776000616,
   "extendedPrice": 319.37,
   "extendedChange": 0.54,
   "extendedChangePercent": 0.00169,
   "extendedPriceTime": 1564876784244,
   "previousClose": 319.5,
   "previousVolume": 6563156,
   "change": -0.67,
   "changePercent": -0.0021,
   "volume": 6232279,
   "iexMarketPercent": null,
   "iexVolume": null,
   "avgTotalVolume": 7998833,
   "iexBidPrice": null,
   "iexBidSize": null,
   "iexAskPrice": null,
   "iexAskSize": null,
   "marketCap": 139594933050,
   "peRatio": 120.77,
   "week52High": 386.79,
   "week52Low": 231.23,
   "ytdChange": 0.18907500000000002,
   "lastTradeTime": 1564776000616
}
Notice how, between the curly braces, there’s a comma-separated list of key-value pairs, with a colon separating each key from its value.

Let’s turn our attention now to this problem’s distribution code!

Distribution
Downloading
$ wget https://cdn.cs50.net/2019/fall/tracks/web/finance/finance.zip
$ unzip finance.zip
$ rm finance.zip
$ cd finance
$ ls
application.py  helpers.py        static/
finance.db      requirements.txt  templates/
Configuring
Before getting started on this assignment, we’ll need to register for an API key in order to be able to query IEX’s data. To do so, follow these steps:

Visit iexcloud.io/cloud-login#/register/.
Enter your email address and a password, and click “Create account”.
On the next page, scroll down to choose the Start (free) plan.
Once you’ve confirmed your account via a confirmation email, sign in to iexcloud.io.
Click API Tokens.
Copy the key that appears under the Token column (it should begin with pk_).
In a terminal window within CS50 IDE, execute:
$ export API_KEY=value
where value is that (pasted) value, without any space immediately before or after the =. You also may wish to paste that value in a text document somewhere, in case you need it again later.

Running
. Start Flask’s built-in web server (within finance/):

$ flask run
Visit the URL outputted by flask to see the distribution code in action. You won’t be able to log in or register, though, just yet!

Via CS50’s file browser, double-click finance.db in order to open it with phpLiteAdmin. Notice how finance.db comes with a table called users. Take a look at its structure (i.e., schema). Notice how, by default, new users will receive $10,000 in cash. But there aren’t (yet!) any users (i.e., rows) therein to browse. + Here on out, if you’d prefer a command line, you’re welcome to use sqlite3 instead of phpLiteAdmin.

Understanding
application.py
Open up application.py. Atop the file are a bunch of imports, among them CS50’s SQL module and a few helper functions. More on those soon.

After configuring Flask, notice how this file disables caching of responses (provided you’re in debugging mode, which you are by default on CS50 IDE), lest you make a change to some file but your browser not notice. Notice next how it configures Jinja with a custom “filter,” usd, a function (defined in helpers.py) that will make it easier to format values as US dollars (USD). It then further configures Flask to store sessions on the local filesystem (i.e., disk) as opposed to storing them inside of (digitally signed) cookies, which is Flask’s default. The file then configures CS50’s SQL module to use finance.db, a SQLite database whose contents we’ll soon see!

Thereafter are a whole bunch of routes, only two of which are fully implemented: login and logout. Read through the implementation of login first. Notice how it uses db.execute (from CS50’s library) to query finance.db. And notice how it uses check_password_hash to compare hashes of users’ passwords. Finally, notice how login “remembers” that a user is logged in by storing his or her user_id, an INTEGER, in session. That way, any of this file’s routes can check which user, if any, is logged in. Meanwhile, notice how logout simply clears session, effectively logging a user out.

Notice how most routes are “decorated” with @login_required (a function defined in helpers.py too). That decorator ensures that, if a user tries to visit any of those routes, he or she will first be redirected to login so as to log in.

Notice too how most routes support GET and POST. Even so, most of them (for now!) simply return an “apology,” since they’re not yet implemented.

helpers.py
Next take a look at helpers.py. Ah, there’s the implementation of apology. Notice how it ultimately renders a template, apology.html. It also happens to define within itself another function, escape, that it simply uses to replace special characters in apologies. By defining escape inside of apology, we’ve scoped the former to the latter alone; no other functions will be able (or need) to call it.

Next in the file is login_required. No worries if this one’s a bit cryptic, but if you’ve ever wondered how a function can return another function, here’s an example!

Thereafter is lookup, a function that, given a symbol (e.g., NFLX), returns a stock quote for a company in the form of a dict with three keys: name, whose value is a str, the name of the company; price, whose value is a float; and symbol, whose value is a str, a canonicalized (uppercase) version of a stock’s symbol, irrespective of how that symbol was capitalized when passed into lookup.

Last in the file is usd, a short function that simply formats a float as USD (e.g., 1234.56 is formatted as $1,234.56).

requirements.txt
Next take a quick look at requirements.txt. That file simply prescribes the packages on which this app will depend.

static/
Glance too at static/, inside of which is styles.css. That’s where some initial CSS lives. You’re welcome to alter it as you see fit.

templates/
Now look in templates/. In login.html is, essentially, just an HTML form, stylized with Bootstrap In apology.html, meanwhile, is a template for an apology. Recall that apology in helpers.py took two arguments: message, which was passed to render_template as the value of bottom, and, optionally, code, which was passed to render_template as the value of top. Notice in apology.html how those values are ultimately used! And here’s why. 0:-)

Last up is layout.html. It’s a bit bigger than usual, but that’s mostly because it comes with a fancy, mobile-friendly “navbar” (navigation bar), also based on Bootstrap. Notice how it defines a block, main, inside of which templates (including apology.html and login.html) shall go. It also includes support for Flask’s message flashing so that you can relay messages from one route to another for the user to see.

Specification
register
Complete the implementation of register in such a way that it allows a user to register for an account via a form.

Require that a user input a username, implemented as a text field whose name is username. Render an apology if the user’s input is blank or the username already exists.
Require that a user input a password, implemented as a text field whose name is password, and then that same password again, implemented as a text field whose name is confirmation. Render an apology if either input is blank or the passwords do not match.
Submit the user’s input via POST to /register.
INSERT the new user into users, storing a hash of the user’s password, not the password itself. Hash the user’s password with generate_password_hash Odds are you’ll want to create a new template (e.g., register.html) that’s quite similar to login.html.
Once you’ve implemented register correctly, you should be able to register for an account and log in (since login and logout already work)! And you should be able to see your rows via phpLiteAdmin or sqlite3.

quote
Complete the implementation of quote in such a way that it allows a user to look up a stock’s current price.

Require that a user input a stock’s symbol, implemented as a text field whose name is symbol.
Submit the user’s input via POST to /quote.
Odds are you’ll want to create two new templates (e.g., quote.html and quoted.html). When a user visits /quote via GET, render one of those templates, inside of which should be an HTML form that submits to /quote via POST. In response to a POST, quote can render that second template, embedding within it one or more values from lookup.
buy
Complete the implementation of buy in such a way that it enables a user to buy stocks.

Require that a user input a stock’s symbol, implemented as a text field whose name is symbol. Render an apology if the input is blank or the symbol does not exist (as per the return value of lookup).
Require that a user input a number of shares, implemented as a text field whose name is shares. Render an apology if the input is not a positive integer.
Submit the user’s input via POST to /buy.
Odds are you’ll want to call lookup to look up a stock’s current price.
Odds are you’ll want to SELECT how much cash the user currently has in users.
Add one or more new tables to finance.db via which to keep track of the purchase. Store enough information so that you know who bought what at what price and when.
Use appropriate SQLite types.
Define UNIQUE indexes on any fields that should be unique.
Define (non-UNIQUE) indexes on any fields via which you will search (as via SELECT with WHERE).
Render an apology, without completing a purchase, if the user cannot afford the number of shares at the current price.
You don’t need to worry about race conditions (or use transactions).
Once you’ve implemented buy correctly, you should be able to see users’ purchases in your new table(s) via phpLiteAdmin or sqlite3.

index
Complete the implementation of index in such a way that it displays an HTML table summarizing, for the user currently logged in, which stocks the user owns, the numbers of shares owned, the current price of each stock, and the total value of each holding (i.e., shares times price). Also display the user’s current cash balance along with a grand total (i.e., stocks’ total value plus cash).

Odds are you’ll want to execute multiple SELECTs. Depending on how you implement your table(s), you might find GROUP BY HAVING SUM and/or WHERE of interest.
Odds are you’ll want to call lookup for each stock.
sell
Complete the implementation of sell in such a way that it enables a user to sell shares of a stock (that he or she owns).

Require that a user input a stock’s symbol, implemented as a select menu whose name is symbol. Render an apology if the user fails to select a stock or if (somehow, once submitted) the user does not own any shares of that stock.
Require that a user input a number of shares, implemented as a text field whose name is shares. Render an apology if the input is not a positive integer or if the user does not own that many shares of the stock.
Submit the user’s input via POST to /sell.
You don’t need to worry about race conditions (or use transactions).
history
Complete the implementation of history in such a way that it displays an HTML table summarizing all of a user’s transactions ever, listing row by row each and every buy and every sell.

For each row, make clear whether a stock was bought or sold and include the stock’s symbol, the (purchase or sale) price, the number of shares bought or sold, and the date and time at which the transaction occurred.
You might need to alter the table you created for buy or supplement it with an additional table. Try to minimize redundancies.
personal touch
Implement at least one personal touch of your choice:

Allow users to change their passwords.
Allow users to add additional cash to their account.
Allow users to buy more shares or sell shares of stocks they already own via index itself, without having to type stocks’ symbols manually.
Require users’ passwords to have some number of letters, numbers, and/or symbols.
Implement some other feature of comparable scope.
Testing
Be sure to test your web app manually too, as by

inputting alpabetical strings into forms when only numbers are expected,
inputting zero or negative numbers into forms when only positive numbers are expected,
inputting floating-point values into forms when only integers are expected,
trying to spend more cash than a user has,
trying to sell more shares than a user has,
inputting an invalid stock symbol, and
including potentially dangerous characters like ' and ; in SQL queries.
Staff’s Solution
You’re welcome to stylize your own app differently, but here’s what the staff’s solution looks like!

https://finance.cs50.net/

Feel free to register for an account and play around. Do not use a password that you use on other sites.

It is reasonable to look at the staff’s HTML and CSS.

Hints
Within cs50.SQL is an execute method whose first argument should be a str of SQL. If that str contains named parameters to which values should be bound, those values can be provided as additional named parameters to execute. See the implementation of login for one such example. The return value of execute is as follows:

If str is a SELECT, then execute returns a list of zero or more dict objects, inside of which are keys and values representing a table’s fields and cells, respectively.
If str is an INSERT, and the table into which data was inserted contains an autoincrementing PRIMARY KEY, then execute returns the value of the newly inserted row’s primary key.
If str is a DELETE or an UPDATE, then execute returns the number of rows deleted or updated by str.
If an INSERT or UPDATE would violate some constraint (e.g., a UNIQUE index), then execute returns None. In cases of error, execute raises a RuntimeError.

Recall that cs50.SQL will log to your terminal window any queries that you execute via execute (so that you can confirm whether they’re as intended).
Be sure to use named bind parameters (i.e., a paramstyle of named) when calling CS50’s execute method, a la WHERE name=:name. Do not use f-strings, format or + (i.e., concatenation), lest you risk a SQL injection attack.
If (and only if) already comfortable with SQL, you’re welcome to use SQLAlchemy Core or Flask-SQLAlchemy (i.e., SQLAlchemy ORM) instead of cs50.SQL.
You’re welcome to add additional static files to static/.
Odds are you’ll want to consult Jinja’s documentation when implementing your templates.
It is reasonable to ask others to try out (and try to trigger errors in) your site.
You’re welcome to alter the aesthetics of the sites, as via
https://bootswatch.com/,
https://getbootstrap.com/docs/4.1/content/,
https://getbootstrap.com/docs/4.1/components/, and/or
https://memegen.link/.
FAQs
ImportError: No module named ‘application’
By default, flask looks for a file called application.py in your current working directory (because we’ve configured the value of FLASK_APP, an environment variable, to be application.py). If seeing this error, odds are you’ve run flask in the wrong directory!

OSError: [Errno 98] Address already in use
If, upon running flask, you see this error, odds are you (still) have flask running in another tab. Be sure to kill that other process, as with ctrl-c, before starting flask again. If you haven’t any such other tab, execute fuser -k 8080/tcp to kill any processes that are (still) listening on TCP port 8080.

How to Submit
Execute the below from within your finance directory, logging in with your GitHub username and password when prompted. For security, you’ll see asterisks (*) instead of the actual characters in your password.

submit50 cs50/problems/2020/x/tracks/web/finance

---
## [Yrassim/CS50](https://github.com/Yrassim/CS50)@[bdcf306645...](https://github.com/Yrassim/CS50/commit/bdcf306645aa31fb82bf8a25f519a7df5828ccbb)
#### Friday 2021-01-29 01:29:28 by Yrassim

Implement a program that applies filters to BMPs

…cale, sepia, reflection, or blur filters to their images.

Filter
Implement a program that applies filters to BMPs, per the below.

$ ./filter -r image.bmp reflected.bmp
Background
Bitmaps
Perhaps the simplest way to represent an image is with a grid of pixels (i.e., dots), each of which can be of a different color. For black-and-white images, we thus need 1 bit per pixel, as 0 could represent black and 1 could represent white, as in the below.

a simple bitmap

In this sense, then, is an image just a bitmap (i.e., a map of bits). For more colorful images, you simply need more bits per pixel. A file format (like BMP, JPEG, or PNG) that supports “24-bit color” uses 24 bits per pixel. (BMP actually supports 1-, 4-, 8-, 16-, 24-, and 32-bit color.)

A 24-bit BMP uses 8 bits to signify the amount of red in a pixel’s color, 8 bits to signify the amount of green in a pixel’s color, and 8 bits to signify the amount of blue in a pixel’s color. If you’ve ever heard of RGB color, well, there you have it: red, green, blue.

If the R, G, and B values of some pixel in a BMP are, say, 0xff, 0x00, and 0x00 in hexadecimal, that pixel is purely red, as 0xff (otherwise known as 255 in decimal) implies “a lot of red,” while 0x00 and 0x00 imply “no green” and “no blue,” respectively.

A Bit(map) More Technical
Recall that a file is just a sequence of bits, arranged in some fashion. A 24-bit BMP file, then, is essentially just a sequence of bits, (almost) every 24 of which happen to represent some pixel’s color. But a BMP file also contains some “metadata,” information like an image’s height and width. That metadata is stored at the beginning of the file in the form of two data structures generally referred to as “headers,” not to be confused with C’s header files. (Incidentally, these headers have evolved over time. This problem uses the latest version of Microsoft’s BMP format, 4.0, which debuted with Windows 95.)

The first of these headers, called BITMAPFILEHEADER, is 14 bytes long. (Recall that 1 byte equals 8 bits.) The second of these headers, called BITMAPINFOHEADER, is 40 bytes long. Immediately following these headers is the actual bitmap: an array of bytes, triples of which represent a pixel’s color. However, BMP stores these triples backwards (i.e., as BGR), with 8 bits for blue, followed by 8 bits for green, followed by 8 bits for red. (Some BMPs also store the entire bitmap backwards, with an image’s top row at the end of the BMP file. But we’ve stored this problem set’s BMPs as described herein, with each bitmap’s top row first and bottom row last.) In other words, were we to convert the 1-bit smiley above to a 24-bit smiley, substituting red for black, a 24-bit BMP would store this bitmap as follows, where 0000ff signifies red and ffffff signifies white; we’ve highlighted in red all instances of 0000ff.

red smile

Because we’ve presented these bits from left to right, top to bottom, in 8 columns, you can actually see the red smiley if you take a step back.

To be clear, recall that a hexadecimal digit represents 4 bits. Accordingly, ffffff in hexadecimal actually signifies 111111111111111111111111 in binary.

Notice that you could represent a bitmap as a 2-dimensional array of pixels: where the image is an array of rows, each row is an array of pixels. Indeed, that’s how we’ve chosen to represent bitmap images in this problem.

Image Filtering
What does it even mean to filter an image? You can think of filtering an image as taking the pixels of some original image, and modifying each pixel in such a way that a particular effect is apparent in the resulting image.

Grayscale
One common filter is the “grayscale” filter, where we take an image and want to convert it to black-and-white. How does that work?

Recall that if the red, green, and blue values are all set to 0x00 (hexadecimal for 0), then the pixel is black. And if all values are set to 0xff (hexadecimal for 255), then the pixel is white. So long as the red, green, and blue values are all equal, the result will be varying shades of gray along the black-white spectrum, with higher values meaning lighter shades (closer to white) and lower values meaning darker shades (closer to black).

So to convert a pixel to grayscale, we just need to make sure the red, green, and blue values are all the same value. But how do we know what value to make them? Well, it’s probably reasonable to expect that if the original red, green, and blue values were all pretty high, then the new value should also be pretty high. And if the original values were all low, then the new value should also be low.

In fact, to ensure each pixel of the new image still has the same general brightness or darkness as the old image, we can take the average of the red, green, and blue values to determine what shade of grey to make the new pixel.

If you apply that to each pixel in the image, the result will be an image converted to grayscale.

Sepia
Most image editing programs support a “sepia” filter, which gives images an old-timey feel by making the whole image look a bit reddish-brown.

An image can be converted to sepia by taking each pixel, and computing new red, green, and blue values based on the original values of the three.

There are a number of algorithms for converting an image to sepia, but for this problem, we’ll ask you to use the following algorithm. For each pixel, the sepia color values should be calculated based on the original color values per the below.

sepiaRed = .393 * originalRed + .769 * originalGreen + .189 * originalBlue
sepiaGreen = .349 * originalRed + .686 * originalGreen + .168 * originalBlue
sepiaBlue = .272 * originalRed + .534 * originalGreen + .131 * originalBlue
Of course, the result of each of these formulas may not be an integer, but each value could be rounded to the nearest integer. It’s also possible that the result of the formula is a number greater than 255, the maximum value for an 8-bit color value. In that case, the red, green, and blue values should be capped at 255. As a result, we can guarantee that the resulting red, green, and blue values will be whole numbers between 0 and 255, inclusive.

Reflection
Some filters might also move pixels around. Reflecting an image, for example, is a filter where the resulting image is what you would get by placing the original image in front of a mirror. So any pixels on the left side of the image should end up on the right, and vice versa.

Note that all of the original pixels of the original image will still be present in the reflected image, it’s just that those pixels may have rearranged to be in a different place in the image.

Blur
There are a number of ways to create the effect of blurring or softening an image. For this problem, we’ll use the “box blur,” which works by taking each pixel and, for each color value, giving it a new value by averaging the color values of neighboring pixels.

Consider the following grid of pixels, where we’ve numbered each pixel.

a grid of pixels

The new value of each pixel would be the average of the values of all of the pixels that are within 1 row and column of the original pixel (forming a 3x3 box). For example, each of the color values for pixel 6 would be obtained by averaging the original color values of pixels 1, 2, 3, 5, 6, 7, 9, 10, and 11 (note that pixel 6 itself is included in the average). Likewise, the color values for pixel 11 would be be obtained by averaging the color values of pixels 6, 7, 8, 10, 11, 12, 14, 15 and 16.

For a pixel along the edge or corner, like pixel 15, we would still look for all pixels within 1 row and column: in this case, pixels 10, 11, 12, 14, 15, and 16.

Getting Started
Here’s how to download this problem’s “distribution code” (i.e., starter code) into your own CS50 IDE. Log into CS50 IDE and then, in a terminal window, execute each of the below.

Execute cd to ensure that you’re in ~/ (i.e., your home directory).
Execute mkdir pset4 to make (i.e., create) a directory called pset4 in your home directory.
Execute cd pset4 to change into (i.e., open) that directory.
Execute wget https://cdn.cs50.net/2019/fall/psets/4/filter/less/filter.zip to download a (compressed) ZIP file with this problem’s distribution.
Execute unzip filter.zip to uncompress that file.
Execute rm filter.zip followed by yes or y to delete that ZIP file.
Execute ls. You should see a directory called filter, which was inside of that ZIP file.
Execute cd filter to change into that directory.
Execute ls. You should see this problem’s distribution, including bmp.h, filter.c, helpers.h, helpers.c, and Makefile. You’ll also see a directory called images, with some sample Bitmap images.
Understanding
Let’s now take a look at some of the files provided to you as distribution code to get an understanding for what’s inside of them.

bmp.h
Open up bmp.h (as by double-clicking on it in the file browser) and have a look.

You’ll see definitions of the headers we’ve mentioned (BITMAPINFOHEADER and BITMAPFILEHEADER). In addition, that file defines BYTE, DWORD, LONG, and WORD, data types normally found in the world of Windows programming. Notice how they’re just aliases for primitives with which you are (hopefully) already familiar. It appears that BITMAPFILEHEADER and BITMAPINFOHEADER make use of these types.

Perhaps most importantly for you, this file also defines a struct called RGBTRIPLE that, quite simply, “encapsulates” three bytes: one blue, one green, and one red (the order, recall, in which we expect to find RGB triples actually on disk).

Why are these structs useful? Well, recall that a file is just a sequence of bytes (or, ultimately, bits) on disk. But those bytes are generally ordered in such a way that the first few represent something, the next few represent something else, and so on. “File formats” exist because the world has standardized what bytes mean what. Now, we could just read a file from disk into RAM as one big array of bytes. And we could just remember that the byte at array[i] represents one thing, while the byte at array[j] represents another. But why not give some of those bytes names so that we can retrieve them from memory more easily? That’s precisely what the structs in bmp.h allow us to do. Rather than think of some file as one long sequence of bytes, we can instead think of it as a sequence of structs.

filter.c
Now, let’s open up filter.c. This file has been written already for you, but there are a couple important points worth noting here.

First, notice the definition of filters on line 11. That string tells the program what the allowable command-line arguments to the program are: b, g, r, and s. Each of them specifies a different filter that we might apply to our images: blur, grayscale, reflection, and sepia.

The next several lines open up an image file, make sure it’s indeed a BMP file, and read all of the pixel information into a 2D array called image.

Scroll down to the switch statement that begins on line 102. Notice that, depending on what filter we’ve chosen, a different function is called: if the user chooses filter b, the program calls the blur function; if g, then grayscale is called; if r, then reflect is called; and if s, then sepia is called. Notice, too, that each of these functions take as arguments the height of the image, the width of the image, and the 2D array of pixels.

These are the functions you’ll (soon!) implement. As you might imagine, the goal is for each of these functions to edit the 2D array of pixels in such a way that the desired filter is applied to the image.

The remaining lines of the program take the resulting image and write them out to a new image file.

helpers.h
Next, take a look at helpers.h. This file is quite short, and just provides the function prototypes for the functions you saw earlier.

Here, take note of the fact that each function takes a 2D array called image as an argument, where image is an array of height many rows, and each row is itself another array of width many RGBTRIPLEs. So if image represents the whole picture, then image[0] represents the first row, and image[0][0] represents the pixel in the upper-left corner of the image.

helpers.c
Now, open up helpers.c. Here’s where the implementation of the functions declared in helpers.h belong. But note that, right now, the implementations are missing! This part is up to you.

Makefile
Finally, let’s look at Makefile. This file specifies what should happen when we run a terminal command like make filter. Whereas programs you may have written before were confined to just one file, filter seems to use multiple files: filter.c, bmp.h, helpers.h, and helpers.c. So we’ll need to tell make how to compile this file.

Try compiling filter for yourself by going to your terminal and running

$ make filter
Then, you can run the program by running:

$ ./filter -g images/yard.bmp out.bmp
which takes the image at images/yard.bmp, and generates a new image called out.bmp after running the pixels through the grayscale function. grayscale doesn’t do anything just yet, though, so the output image should look the same as the original yard.

Specification
Implement the functions in helpers.c such that a user can apply grayscale, sepia, reflection, or blur filters to their images.

The function grayscale should take an image and turn it into a black-and-white version of the same image.
The function sepia should take an image and turn it into a sepia version of the same image.
The reflect function should take an image and reflect it horizontally.
Finally, the blur function should take an image and turn it into a box-blurred version of the same image.
You should not modify any of the function signatures, nor should you modify any other files other than helpers.c.

---
## [weiji14/phdthesis](https://github.com/weiji14/phdthesis)@[0fe0dccba9...](https://github.com/weiji14/phdthesis/commit/0fe0dccba9c7a7c426b24a88b10e1f2c5c180eae)
#### Friday 2021-01-29 02:40:40 by Wei Ji

:memo: Thesis snapshot on 26 Jan 2021

This is (nearly) it. After multiple revisions (read: blood, sweat and literal tears), I'm committing this draft to git history. The original plan was to have multiple snapshots over time as I worked on it but the git diff would just be incomprehensible anyway. A big thank you to my supervisor Huw Horgan for not fainting at some of the earlier drafts. I'm nearly there, this is the final stretch, so let's survive this.

Title: The subglacial landscape and hydrology of Antarctica as mapped from space
Chapter 1 - Introduction
Chapter 2 - DeepBedMap: a deep neural network for resolving the bed topography of Antarctica
Chapter 3 - The role of subglacial topography on Antarctic ice flow
Chapter 4 - Automated classification of active subglacial lakes in Antarctica from ICESat-2/ATLAS laser altimetry (2018--2020)
Chapter 5 - Conclusions

Figures will come next time, as will more revisions.

---
## [edwardckeith/edwardckeith](https://github.com/edwardckeith/edwardckeith)@[b1b3a03779...](https://github.com/edwardckeith/edwardckeith/commit/b1b3a037796678991284824094319b35c59e4fb3)
#### Friday 2021-01-29 03:16:51 by Edward Keith

Update README.md

Hello👋🏾! I'm Edward, but you can call me Eddie😉.
🏫I go to school at Missouri S&T and major in Information Science and Technology, with a minor in Business Management Systems.
🤠I am the marketing lead for PickHacks, organizing and facilitating internal and external outreach efforts for the largest Hackathon event in the midwest.
♠I've been passionate about tech since I was little, and would love to find myself using tech to improve the lives of other people:)

---
## [ddiblis/FlashCards](https://github.com/ddiblis/FlashCards)@[94828a17cf...](https://github.com/ddiblis/FlashCards/commit/94828a17cf28bbcd4a1b85b2d0d9345e02e48e5d)
#### Friday 2021-01-29 03:24:11 by Wafiq

fix(Fixed-the-fucking-id-overlap-issue): Fuck you fight me if you have a problem with how it's done, 1000 cards per deck should be more than enough for literally anyone

---
## [ccodwg/Covid19Canada](https://github.com/ccodwg/Covid19Canada)@[3fb7ff7261...](https://github.com/ccodwg/Covid19Canada/commit/3fb7ff726142efab695d062852a4f452692b9ba4)
#### Friday 2021-01-29 03:27:18 by Jean-Paul R. Soucy

New data: 2021-01-28: DATA RECENTLY CHANGED. SEE NOTES.

Recent changes:

2021-01-27: Due to the limit on file sizes in GitHub, we implemented some changes to the datasets today, mostly impacting individual-level data (cases and mortality). Changes below:

1) Individual-level data (cases.csv and mortality.csv) have been moved to a new directory in the root directory entitled “individual_level”. These files have been split by calendar year and named as follows: cases_2020.csv, cases_2021.csv, mortality_2020.csv, mortality_2021.csv. The directories “other/cases_extra” and “other/mortality_extra” have been moved into the “individual_level” directory.
2) Redundant datasets have been removed from the root directory. These files include: recovered_cumulative.csv, testing_cumulative.csv, vaccine_administration_cumulative.csv, vaccine_distribution_cumulative.csv, vaccine_completion_cumulative.csv. All of these datasets are currently available as time series in the directory “timeseries_prov”.
3) The file codebook.csv has been moved to the directory “other”.

We appreciate your patience and hope these changes cause minimal disruption. We do not anticipate making any other breaking changes to the datasets in the near future. If you have any further questions, please open an issue on GitHub or reach out to us by email at ccodwg [at] gmail [dot] com. Thank you for using the COVID-19 Canada Open Data Working Group datasets.

- 2021-01-24: The columns "additional_info" and "additional_source" in cases.csv and mortality.csv have been abbreviated similar to "case_source" and "death_source". See note in README.md from 2021-11-27 and 2021-01-08.

Vaccine datasets:

- 2021-01-19: Fully vaccinated data have been added (vaccine_completion_cumulative.csv, timeseries_prov/vaccine_completion_timeseries_prov.csv, timeseries_canada/vaccine_completion_timeseries_canada.csv). Note that this value is not currently reported by all provinces (some provinces have all 0s).
- 2021-01-11: Our Ontario vaccine dataset has changed. Previously, we used two datasets: the MoH Daily Situation Report (https://www.oha.com/news/updates-on-the-novel-coronavirus), which is released weekdays in the evenings, and the “COVID-19 Vaccine Data in Ontario” dataset (https://data.ontario.ca/dataset/covid-19-vaccine-data-in-ontario), which is released every day in the mornings. Because the Daily Situation Report is released later in the day, it has more up-to-date numbers. However, since it is not available on weekends, this leads to an artificial “dip” in numbers on Saturday and “jump” on Monday due to the transition between data sources. We will now exclusively use the daily “COVID-19 Vaccine Data in Ontario” dataset. Although our numbers will be slightly less timely, the daily values will be consistent. We have replaced our historical dataset with “COVID-19 Vaccine Data in Ontario” as far back as they are available.
- 2020-12-17: Vaccination data have been added as time series in timeseries_prov and timeseries_hr.
- 2020-12-15: We have added two vaccine datasets to the repository, vaccine_administration_cumulative.csv and vaccine_distribution_cumulative.csv. These data should be considered preliminary and are subject to change and revision. The format of these new datasets may also change at any time as the data situation evolves.

Revise historical data: cases (BC, MB, ON, SK).

SK did not provide testing data today. They also did not update their usual daily case CSV.

Note regarding deaths added in QC today: “The data also report 39 new deaths, but the total of deaths amounts to 9,667 due to the withdrawal of 2 deaths that the investigation has shown not to be attributable to COVID-19. Among these 39 deaths, 8 have occurred in the last 24 hours, 24 have occurred between January 21 and January 26, 5 have occurred before January 21 and 2 have occurred at an unknown date.” We report deaths such that our cumulative regional totals match today’s values. This sometimes results in extra deaths with today’s date when older deaths are removed.

https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/#c47900

Note about SK data: As of 2020-12-14, we are providing a daily version of the official SK dataset that is compatible with the rest of our dataset in the folder official_datasets/sk. See below for information about our regular updates.

SK transitioned to reporting according to a new, expanded set of health regions on 2020-09-14. Unfortunately, the new health regions do not correspond exactly to the old health regions. Additionally, the provided case time series using the new boundaries do not exist for dates earlier than August 4, making providing a time series using the new boundaries impossible.

For now, we are adding new cases according to the list of new cases given in the “highlights” section of the SK government website (https://dashboard.saskatchewan.ca/health-wellness/covid-19/cases). These new cases are roughly grouped according to the old boundaries. However, health region totals were redistributed when the new boundaries were instituted on 2020-09-14, so while our daily case numbers match the numbers given in this section, our cumulative totals do not. We have reached out to the SK government to determine how this issue can be resolved. We will rectify our SK health region time series as soon it becomes possible to do so.

---
## [pinkuchoudhury69/Python-1](https://github.com/pinkuchoudhury69/Python-1)@[14896bad3a...](https://github.com/pinkuchoudhury69/Python-1/commit/14896bad3a364385d5041f6ac757cd91c58d4a1d)
#### Friday 2021-01-29 04:18:18 by Kranti Kumar Choudhury

Update JARVIS.py

1. Female voice added.
2. while you run the program it will first wish the user according to time (like good morning, good afternoon and good evening) and then asks the user to say something.

---
## [Duder5000/cmpt135-a01](https://github.com/Duder5000/cmpt135-a01)@[a65f74d475...](https://github.com/Duder5000/cmpt135-a01/commit/a65f74d4758ac4b5f66888371408b85f3c1e713c)
#### Friday 2021-01-29 07:59:49 by Alex

WHAT THE FUCK IS str_list???

I hate SFU & I hate myself

---
## [elvencache/ec-sss](https://github.com/elvencache/ec-sss)@[28e825a0ec...](https://github.com/elvencache/ec-sss/commit/28e825a0ecea3daf15532de0234a79ec2403c1cd)
#### Friday 2021-01-29 08:11:57 by elvencache

percentage closer style soft screen space shadows

pcsssssssssssssssssssssssss

saw percentage closer soft shadows come up. didn't know or at least didn't remember how they worked. it sounded kinda like how i was already calculating soft screen space shadows, and wanted to see what would happen calculating pcss screen space shadows.

oops! i didn't think far enough ahead to realize that i didn't have anything to do with the penumbra. without shadow map. not going to trigger more ray marches through depth.

instead, just visualizing penumbra width and assuming greater width would be lighter shadow.

it doesn't really work, and already had information to do something very much like this. but, leaving in place in case i get inspiration on how to handle penumbra.

---
## [jyshin0926/Algorithm](https://github.com/jyshin0926/Algorithm)@[62aa803460...](https://github.com/jyshin0926/Algorithm/commit/62aa803460100a6fffbf1ded884f2099c37ef07f)
#### Friday 2021-01-29 15:09:08 by jyshin0926

210128_string_StrongPassword
https://www.hackerrank.com/challenges/strong-password/problem

Louise joined a social networking site to stay in touch with her friends. The signup page required her to input a name and a password. However, the password must be strong. The website considers a password to be strong if it satisfies the following criteria:

Its length is at least .
It contains at least one digit.
It contains at least one lowercase English character.
It contains at least one uppercase English character.
It contains at least one special character. The special characters are: !@#$%^&*()-+
She typed a random string of length  in the password field but wasn't sure if it was strong. Given the string she typed, can you find the minimum number of characters she must add to make her password strong?

---
## [silont-project/android_kernel_xiaomi_sdm660](https://github.com/silont-project/android_kernel_xiaomi_sdm660)@[05726dbedf...](https://github.com/silont-project/android_kernel_xiaomi_sdm660/commit/05726dbedf72cb81dba485b91a719f7d2452c545)
#### Friday 2021-01-29 16:26:23 by Reinazhard

arm/dts: fix derp

i fucking hate work at night

Signed-off-by: Reinazhard <muh.alfarozy@gmail.com>

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[af27cdf54d...](https://github.com/mrakgr/The-Spiral-Language/commit/af27cdf54def7153fda5e09fbed2234a72a8bb10)
#### Friday 2021-01-29 17:12:19 by Marko Grdinić

"2:55pm. Let me catch my breath. I've been in a programming frenzy for the last few days, and with this I should finally be done. Hopefully this should be the last of the bugs in the Cython backend.

I did a good job. I can pat myself on the back here.

3:05pm. I am taking a break here. What comes next?

Really, there is so much stuff left to do. I feel like am absolutely buried in work now.

How about I open a few more feature requests on the Cython side.

4:10pm. https://github.com/cython/cython/issues/

Opened issue 3992 along with two more. This is my wishlist for Cython.

4:15pm. With that I've tied up the loose ends in the Cython repo. If I am lucky maybe this will spur the devs to implement tuples, fixed arrays and stack unions. But even if nothing happens, it is not a big deal. Right now I need Python for its ML libraries. A few years down the road I might go back to .NET.

Let me make a TODO list on the Spiral issue page. Here is the current one:

TODO: Optimize Cython primitive arrays. Compile them to fast numeric ones.
TODO: Cython backend: Use the fast C math library for the inbuilts rather than the Python one. Right now I don't know how to access `logf` though. I don't know how to find out the contents of a Cython module either. Unlike for Python's `dir` does not work.
TODO: Monadic syntax.
TODO: Autocomplete.
TODO: Highlight unused vars.
TODO: List and array patterns and literals.
TODO: Guard against stack overflows in the partial evaluator. Try running it on a separate thread.
TODO: Make literal suffices (such as `i64`) be highlighted differently from the rest of the number.
TODO: Make a VS Code theme for Spiral.
TODO: Spiral build option: Compile monomorphic functions in file. This will allow modules to be compiled as C style libraries. Monomorphic functions would be compiled without name mangling.

...Actually no, I do not want to be responsible for keeping it in two different places. The top of my journal is enough.

There is really a shitload of things to do and I do not feel like tackling any of it right now. Apart from bugs, I'll move my attention away from the compiler for the time being.

It is almost the end of the month, and now that I've reached this milestone it is time to do a review.

4:30pm. First let me tally up my gains for the month.

* The language has seen a lot of bug fixing and is finally in an roboust state.
* I implemented a Cython backend for it.

After my initial failed email burst to potential sponsors 9 days ago, I've decided that I need to raise my profile and will be going down that path. Though now that I actually have a Cython backend, do I feel like doing a repeat of 2018 and reimplementing parts of PyTorch on my own again?

Yes, the v0.09 ML library was an impressive accomplishment, but there has to be a better way to use my time rather than spend a lot of effort and time building it up again just to write a few articles on it. Now that I have the Cython backend, I am not going to be using it. Of course that I'll take the smarter approach and just use what Facebook engineers and the ML community have spent years building up.

So spending a lot of time building up the ML library only to jetisson it afterwards is not my idea of fun. There have to be better profile raising moves. I should do something new. Maybe I can meet an unfulfiled need in the current ecosystem with Spiral rather than retrace old steps? That would be a more effective move anyway.

I just lost way too much initiative working so much on v0.09 only to abandon it in the end. That hurt me greatly. I can't recover from this anymore.

But I don't need to.

Whereas in the past I've would have been embarassed to use Python, using Python through Spiral is the patrician move. It is tolerable. It has potential.

4:40pm. Right now my position is extremely strong. It is way stronger than it was in 2018 even at its peak. I will no longer be trying to fight the Python community, instead I will be able to piggy back on their work.

What I intend to do is get back into ML right away!

Since I have access to Python ML libraries + Spiral's efficiency, I can get to work on the poker games and agents right away.

5:05pm. Had to take a break.

Yes, raising my profile and getting sponsors is the right move. But the earnings potential from regular work pales in comparison to using superhuman abilities in gaming.

I don't really need novel hardware just yet. I can make do with GPUs if it is just poker.

I will need novel hardware eventually, but I do not need it enough to sacrifice my cultivation in skills that I actually need.

Right now Spiral still does not have some essential things like library compilation. It would be good if it develops at a natural pace, much like v0.09, instead of me having to scramble to please some faceless randos at hardware companies.

5:15pm. Fatigue is really hitting me like a brick right now. I've been under stress for a long while, pulled in different directions.

Let me just rant here. I'll save the review for tomorrow.

Let me talk about the sponsors.

At first I was confused how to approach the situation. I made that email, fired it to a few companies and got ghosted and was left puzzled at how to interpret the situation.

Imagine you have 20 or so cute girls you are interested. Then imagine you come up to a few of them an express your desire to have sex with them. You've put in an effort, but won't get the results you want. Why?

Consider the girl's goals. What they want is marriage. They are laser focused on that and won't even consider anything else.

The way to approach persuasion is to always consider the perspective of the other side first. If I want to move them to something more appropriate to my own goals, I need to feign interest in what they want first. That is the way to play the opener.

5:25pm. What do these novel hardware companies want? Workforce. They want elite programmers. They could greatly benefit from adopting Spiral and improving their tooling, but they are not looking for tools at the moment. They want the people.

So to move them to open up access to their hardware and funds, the basic is to feign interest in working for them.

There might be a small chance that one of them would be up to sponsoring Spiral straight up, but I have no interest in pursuing the direct approach anymore. I need to use wisdom and scheme my way to success here.

Yes, it is annoying enough to look for a job in the first place. It is even more annoying to look for a job when you don't want it. But it is for the greater good.

I am going to feign interest and start 'looking' for a job at the companies. Inevitably their offers will be too low to interest me...'but hey look, I made this language that would be great for ML especially for a young company like you. You could cut your costs drastically by becoming a sponsor for just 3k per month? Won't you give it a try?'

5:30pm. This is the way to go here. I'll go with this approach.

It is not like the offers themselves are useless. I will be able to play them one against the other. In case of tragedy, it would to have them on the table.

5:35pm. Back then I made the email message and was not sure how to improve on it. But with a different plan, the results will be different. At the very least, I really doubt I will be ghosted.

5:40pm. Oh yeah, since I am applying, I am going to have to make a resume. This won't be too hard. I am just going to have to embelish my programing work in the past 5.5 years. This won't be too hard.

Really, my problem only is that I have no experience working for other people. But that is only a problem when trying to go through HR checkbox ticker drones. At smaller companies the devs themselves will look at the resume and think about it.

5:50pm. But ultimately, rellying on other people is plan B. Plan A will be to cultivate my ML skills directly once again.

Compared to the last time when I had my hands full making the library, studying ML and trying out my own ideas, I will be running on jet fuel. When I am not bogged down by my own insecurities and diving into random things in order to build up experience, my progress will be much smoother.

5:55pm. I will get all the benefits of Python, and with Spiral on my hands I will never end up in a situation where I can't extract the performance that I need or implement abstractions that I want.

Over the past years, my programming skills have gone way up.

Absolutely nothing will stop me this time. This will be the true beginning that I've sought long ago.

All the potential challenges that I can face will be solved by combination of Spiral + outside libraries. Spiral has the greatest combination of efficiency, expressiveness and interop capabilities in the world.

6pm. My stress is sky high. Tomorrow I will pare the above rant into a review. Then I'll start preparing the resume and the next volley of emails to send out.

After that I'll leave those concerns aside and start February with a clean slate.

Doing the Cython backend was the right move. With it, I suddenly have every library in Python at my disposal. I do not have to do my own thing anymore. I'll take advantage of the work of others and make my own way based on that.

6:05pm. The main challenge will be UI automation.

Like how a year away from Spiral in 2019 built up the inspiration in the background, this time I know enough to make the ML stable right away.

I'll use backprop - I could not beat that, but I'll be borrowing ideas from other fields, in addition to my own, in order to stabilize it. I am going to get absolute roboustness that way.

I'll implement the latest and greatest of CFR and move past this. No more fiddling around with algorithms and parameters for months. I have every intention of making ML the easy part of the process this time around.

The effect of this will be remarkable. Last time this defeated me, and not getting hung up on it will allow me to make really rapid progress.

6:10pm. Let me close here as I am dying trying to keep going. It is time for a real rest."

---
## [bazelbuild/rules_kotlin](https://github.com/bazelbuild/rules_kotlin)@[15dd1de6dd...](https://github.com/bazelbuild/rules_kotlin/commit/15dd1de6dd1431c5d2f7d2d7f1179a951d63a328)
#### Friday 2021-01-29 17:13:45 by Christian Edward Gruber

Expose kotlinc's -Xfriend-paths to all jvm/android kt rules under the attribute 'assocates=' (#465)

Associates lets a library associate it self to other libraries, making them part of the same module. This is constrained such that while multiple libraries may be associated, they must all shard the same module, and so cannot associate to anything that is part of a different module. These module relationships are in the bazel build graph, not the contents of the jars as such.

This module membership is transitive (within the above-mentioned constraint), though strict-deps would stop that. Also, only kotlin targets can be associated.

Per discussions across several media, the name "associates" was chosen over "friends" (despite the kotlinc flag being -Xfriend-paths) as that is the terminology used in the gradle kotlin plugin, which is kotlin's primary delivery vehicle, and to avoid confusion with the C++ friends concepts. The pre-existing "friends" attribute is preserved for backward compatibility with a warning. Future PR will add a flag to turn off that support, and then we'll delete it.

kt_jvm_import does not include this facility, but these can just set their module_name in common to participate.

Android should work, but because kt_android_* is a macro not a rule, the implicit target //my/android/library:mytarget_kt should be friended, since it has a KtJvmInfo. The //my/android/library will macro-resolve into an android_library. Until the android rules get the right kind of love, such that we can make a rule that has KtJvmInfo AND android-whatever providers, this simply is a known limitation we'll have to live with.

Also, the prior implementation shoved the full transitive closure (all jars, kotlin or no) of the friend= into the -Xfriends-paths flag, which is awful. This PR does break that, in case people were relying on that by some oddity. The fix is to just add the targets directly.

Fixes #211

---
## [MetaluNetProjects/Schoolscape](https://github.com/MetaluNetProjects/Schoolscape)@[2ebdde5b50...](https://github.com/MetaluNetProjects/Schoolscape/commit/2ebdde5b504f91f6f3747d5c953f4f1c7c6bdb28)
#### Friday 2021-01-29 17:42:04 by Antoine Rousseau

ugly hacks to workaround which seems to be nasty Android bugs

When encoding to AAC, Android AAC MediaCodec inserts wrong blank frames at the beginning of the sound and trims the end.
The workaround: don't write the first 2 buffers from the encoder, and append 2048 0-samples at the end of the PCM stream which feeds the encoder.

Alternatively I also could be a stupid coder, not sufficiently helped by what exists as documentation, and I do it all wrong.

---
## [mehulagg/gitlab](https://github.com/mehulagg/gitlab)@[c6590e57ee...](https://github.com/mehulagg/gitlab/commit/c6590e57eed80bc2b6313c5cc14187788cc07598)
#### Friday 2021-01-29 18:00:09 by Lin Jen-Shin

Hack `Prependable` class methods for `override`

`ActiveSupport::Concern` uses an unusual way to chain class methods,
which does not exactly follow how Ruby chains the classes.

In particular, it's like Concern reinvents the object model and
builds the ancestors chain in runtime, rather than at the compile time.
This for sure introduced a lot of culprits.

This fix is aiming for restoring the class methods for the module
which is defining the class methods. To be specific, consider this case:

``` ruby
module Base
  extend ActiveSupport::Concern

  class_methods do
    def f
    end
  end
end

module Derived
  include Base
end
```

What would you expect for this?

``` ruby
Base.f    # => NoMethodError
Derived.f # => nil
```

With this hack, it'll allow `Base.f` to work, which can make `override`
check for class methods. Before this hack it'll not work due to this
disparity.

Since so far the only place we really need this is when we're checking
`override` with those class methods, we don't have to take the risk to
change how it works in production, but just how we check `override`.

This hack is needed for `override` because we're checking `prepend` at
where it's defined, not at where it's eventually included into a class,
and that's where Concern does the magic.

If one day we can stop using `ActiveSupport::Concern`, and just do
plain old good Ruby, we'll be free from all those wild hacks.

See original bug report: https://gitlab.com/gitlab-org/gitlab/-/issues/23932

---
## [pytorch/pytorch](https://github.com/pytorch/pytorch)@[a3c66f7403...](https://github.com/pytorch/pytorch/commit/a3c66f7403264787f202e0e5f12cacae5883079b)
#### Friday 2021-01-29 20:00:30 by Brian Hirsh

Update on "Plumbing TLS keys through the dispatcher"

Table of contents because this description is too long:
- Overview
- High-level changes
- What order to look at things in
- What I don't like about this PR / things I want to change
- Benchmarking results
- Takeaways

### Overview
Benchmarks have shown that reading from TLS (thread-local scope) in the dispatcher is a noticeable source of framework overhead. The TLS read comes from the fact that some dispatch keys are stored using TLS, and these keys must be read from and aggregated to calculate a single dispatch key, which the dispatcher uses to determine which kernel to dispatch to. The logic for that lives [here](https://github.com/pytorch/pytorch/blob/55b431b17aba504ae7b75f6f97b4437101e50f38/aten/src/ATen/core/dispatch/DispatchKeyExtractor.h#L50). The overhead mainly comes from the fact that calling an operator often results in multiple trips through the dispatcher, and the dispatch keys are read and re-aggregated on every trip.


### High-level changes
This PR attempts to reduce that overhead by "plumbing" the set of keys that the dispatcher computed through (opted-in) kernels. The only kernels currently opted in are the codegen'd autograd + tracing kernels. Kernels can opt into this plumbing by:
- Accepting a DispatchKeySet as their first argument, and manually calculating the new dispatch key set to pass back to the dispatcher
- registering themselves to the dispatcher with a slightly different API

This is accomplished by changing the calling convention inside the dispatcher:
- The dispatcher now expects all kernels registered to have a first argument of type DispatchKeySet.
- There are now two parallel registration paths in the dispatcher
- There are two versions of the functor in `make_boxed_from_unboxed_functor.cpp`. Both versions now also take in a DispatchKeySet argument. One does nothing with it, and the other passes it to the registered kernel.


### What order to look at things in
- In `make_boxed_from_unboxed_functor.h`, look at `make_boxed_from_unboxed_functor_withKeys` and `wrap_kernel_functor_unboxed_withKeys`. This is the core part of the updated calling convention in the dispatcher for unboxed kernels - one functor passes the keys through to the kernel and the other does not. I also added static asserts to make sure that you register your kernel with the right API (only use the new API if your kernel has a first argument of type DispatchKeySet)
- The equivalent version of that for boxed kernels is `KernelFunction_impl.h:make_boxed_function_withKeys()`. This isn't actually used anywhere, and won't be unless we write/update a boxed fallback to plumb TLS keys.
- `KernelFunction.h`, `KernelFunction_impl.h`, `KernelFunction.cpp` and `library.h` all contain the alternate registration path, starting with `Library::impl_withKeys()` and ending in `make_boxed_from_unboxed_functor.h`.
- `Dispatcher.h`, `KernelFunction_impl.h` and `boxing.h` also have changes for the new calling convention: versions of `callWithDispatchKey()` and `redispatch()` that take in a DispatchKeySet. they pass it along to `KernelFunction::call()`, which now always takes in a DispatchKeySet.
- `gen_variable_type.py` and `gen_trace_type.py` are where the change is actually used- the tracing and autograd kernels now accept DispatchKeySet as their first argument, remove the autograd keys from it and forward it back to the dispatcher. They register themselves using the new registration path
  - I also modified the autograd kernels to use `redispatch()` rather than `call()` - originally to avoid making another API, but it turned out to also have perf benefits. See the benchmarking section.
- `op_registration.h`, `CppSignature.h`, `Metaprogramming.h` changes are due to some hoops I had to jump through in the new registration path. They generate a version of CppSignature and FunctionSchema that ignore the first argument to the passed-in function pointer. Reasoning:
  - FunctionSchema expects all of its arguments to be convertible to ivalues, which isn't the case for DispatchKeySet (we probably want to totally hide it from jit-land)
  - OperatorEntry expects the CppSignature of all of its kernels to match, which is technically no longer the case. I could break that invariant, but instead I chose to hide the DispatchKeySet argument so they would all match (I'm open to either though).
- `gen_unboxing_wrappers.py`, `generated_unboxing_wrappers.cpp`, `OperatorEntry.h/cpp` required changes because the unboxing wrapper that we generate now has a different calling convention depending on whether or not the corresponding unboxed kernel takes in a DispatchKeySet. This is a hack on top of a hack, and should go away when we're totally c10-full. I manually hardcoded the fact that only autograd/tracing use the new calling convention, inside of `OperatorEntry.cpp`.


### What I don't like about this PR / things I want to change / where further work is needed
There's a bigger question here of "do the benefits of this PR warrant it landing given it's complexity" that I try to address more in the benchmarking section.
Here though I just want to point out some parts of the PR that are incomplete / can hopefully be cleaned up. I wanted more general feedback on the PR as a whole before spending time cleaning it up further.

1) The new registration path is bad; it's implemented as a giant chain of duplicate functions, all ending in `_withKeys`, spread throughout `library.h`, `KernelFunction[_impl].[h|cpp]`, `make_boxed_from_unboxed_functor.h`, `CppSignature.h`, `op_registration.h` and `Metaprogramming.h`. The `_withKeys` suffix is also subject to change, I just left it as a placeholder so I could easily find all the call-sites. I think that I can write this all more cleanly with templated bools, but I ran into some issues trying that- when I tried merging the pairs of structs in `make_boxed_from_unboxed_functor.h`, the compiler looked like it was complaining about the fact that I was passing in different types in different branches of a `guts::if_constexpr`.
- One way I could fix it- maintain two copies of the structs in `make_boxed_from_unboxed_functor.h`, but template everything else on a boolean. The functions that create those structs can use `if_constexpr` to choose which struct to extract the `call` operator from.

2) `callWithDispatchKey`, `redispatch` and `callBoxed` now each have two variants, one taking in a DispatchKey and one taking in a DispatchKeySet (callBoxed's first variant doesn't take in anything). They are functionally similar, and I need the second variant, but I kept the first around to avoid being BC-breaking. Still, that gives us two pretty much repeated functions. I could write the first variant to call the second, I'd just need to benchmark it to ensure it gets inlined properly.

3) Need to confirm whether it's acceptable that autograd kernels no longer sample RecordFunction (see the notes in the benchmarking section). We get a bit of extra perf by not having to do this but I can add it back in if necessary.

4) The logic I added in `Metaprogramming.h` to remove the first argument of a function is pretty hacky. The only alternative that I see is to special-case the error-checks in FunctionSchema and OperatorKernel to ignore a first argument of type DispatchKeySet. Not sure that that's necessarily cleaner though.

5) I updated 3 of the kernels in `VariableTypeManual.cpp` to plumb dispatch keys, and it looks like all 3 of them are failing to compile on windows in phabricator because they aren't matching a BoxedKernelWrapper specialization ([here](https://www.internalfb.com/intern/ci/signal_trampoline/?phabricator_version_fbid=214217710245195&ci_signal_id=c2FuZGNhc3RsZV9pbnN0YW5jZV9hbGlhczpidWlsZC1vdnItc2VydmVy)). I need to dig into it more.

6) Need to re-write the autograd codegen with the new model on top of Jiakai's changes

7) Need to add unit tests


### Benchmarking results
Recap: This PR adds a lot of complexity to the dispatcher, and probably isn't worth landing unless there's a clear perf improvement.

One noticeable shortcoming of this PR - especially when tracing is disabled, it has a greater effect on "base operators" over "composite operators". Composite ops result in multiple dispatch chains, and all that this PR tries to guarantee is a single TLS read per dispatch chain. I tried printing out the number of times that TLS keys are read from for a number of simple operators before/after this PR, which I dumped [in this quip](https://fb.quip.com/MNBJAbUq0jEW#RSDACAxyNAu).
So for example, I'd expect this PR to improve `a += 1` (tls reads go from 7 -> 6) less than it improves `c = a + b` (tls reads go from 2 -> 1).

One (unpopular) option would be to pick a small number of simple/commonly used composite ops and implement the plumbing for them too. Although that would add even more complexity and doesn't provide a clear win without more measuring (e.g. since that would probably require adding yet another argument to the calling convention).


I tested 5 benchmarks using torch.Timer's C++ snippets:
```
    stmt="t3 = t1 + t2;",
    setup="auto t1 = torch::randn({1}); auto t2 = torch::randn({1}); auto t3 = torch::zeros({1});",

    stmt="t = torch::empty(size);",
    setup="auto t = torch::zeros({1, 2, 3}); auto size = t.sizes();",

    stmt="t = t1.view(-1);",
    setup="auto t = torch::zeros({1, 2, 3}); auto t1 = torch::zeros({1, 2, 3});",

    stmt="t += 1;",
    setup="auto t = torch::zeros({1, 2, 3});",

    stmt="t.resize_(0);",
    setup="auto t = torch::randn({1});",
```


**wall time results (ran each test for 10 minutes)**
| Test | Before | After | Delta |
| ------------- | ------------- | ------------- | ------------- |
| add_out  | 1.67 +- 0.02 us | 1.36 +- 0.01 us | -18.6% |
| empty | 427.50 +- 2.38 ns | 403.01 +- 2.78 us | -5.7% |
| view | 784.70 +- 10.35 ns | 707.76 +- 15.13 ns | -9.8% |
| add_inplace | 4.42 +- 0.02 us | 4.45 +- 0.02 us | +0.7% |
| resize_inplace | 195.12 +- 0.74 ns | 108.44 +- 0.49 ns | -45.4% |

Due to my paranoia I ran the tests again for 60 minutes each overnight on my devfair.


**wall time results (ran each test for 60 minutes)**
| Test | Before | After  | Delta |
| ------------- | ------------- | ------------- | ------------- |
| add_out | 1.70 +- 0.02 us | 1.41 +- 0.02 us | -17.10% |
| empty | 397.17 +- 2.16 ns | 395.37 +-2.19 us | -0.50% |
| view | 774.42 +- 2.41 us | 666.66 +- 7.91 us | -13.90% |
| add_inplace | 4.40 +- 0.04 | 4.22 +- 0.09 us | -4.10% |
| resize_inplace | 188.82 +- 0.96 ns | 107.05 +- 0.22 ns | -43.30% |

resize_inplace, add_out and view all performed much better than empty and add_inplace. That held up with the expectation I put above, since those 3 all halve the number of tls reads (2->1), while empty has the same number of tls reads (3->3) and adds_inplace goes from 7->6. Importantly, empty and add_inplace didn't get noticeably slower.

I couldn't get a matching benchmark from AIBench though. It actually showed large regressions, specifically in the `add_out` and `empty` tests. That's why I explicitly tests those in my benchmarks - I matched the snippet that was run by AIBench in my local tests. I don't have a good explanation for why I couldn't replicate the results in AIBench, although I'd like to think that the 60 minute tests that I ran locally are more representative. Two examples are [here](https://www.internalfb.com/intern/aibench/details/757195478/) and [here](https://www.internalfb.com/intern/aibench/details/3404018999/).


**instruction count results**
| Test | Before (instruction count) | After (instruction count) | diff in instructions | diff in __tls_get_addr_ count | delta |
| ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |
| add_out | 628461 | 610210 | -18251 | -4400 | -2.90% |
| empty | 218216 | 218116 | -100 | 0 | ~0% |
| view | 324816 | 304016 | -20800 | -4400 | -6.40% |
| add_inplace | 1558265 | 1541325 | -16940 | -4400 | -1.10% |
| resize_inplace | 67314 | 47414 | -19900 | -4400 | -29.60% |

And here's an example instruction count delta. This one is for `resize_inplace`. Sorry, I ran `before.delta(after)`, so positive numbers are good :)
```
rows: 41
<torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7fe0f3d54940>
    4400  /build/glibc-OTsEL5/glibc-2.27/elf/../sysdeps/x86_64/tls_get_addr.S:__tls_get_addr
    4200  VariableTypeManual.cpp:torch::autograd::VariableType::()::resize_(at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    3700  Dispatcher.h:at::Tensor& c10::Dispatcher::callWithDispatchKey<at::Tensor&, at::Tensor&, Ar<l ... oryFormat>)> const&, c10::DispatchKey, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>) const'2
    3700  Dispatcher.h:at::Tensor& c10::Dispatcher::callWithDispatchKey<at::Tensor&, at::Tensor&, Ar<l ... emoryFormat>)> const&, c10::DispatchKey, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>) const
    2400  record_function.cpp:at::shouldRunRecordFunction(bool*)
    2400  DispatchKeyExtractor.h:c10::impl::dispatchTypeId(c10::DispatchKeySet, c10::DispatchKeySet)
    2000  TensorMethods.cpp:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const'2
    1600  Dispatcher.h:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const'2
    1400  LocalDispatchKeySet.cpp:c10::impl::tls_local_dispatch_key_set()
    1200  DispatchKeySet.h:c10::impl::dispatchTypeId(c10::DispatchKeySet, c10::DispatchKeySet)
    1000  llvmMathExtras.h:c10::impl::dispatchTypeId(c10::DispatchKeySet, c10::DispatchKeySet)
    1000  KernelFunction_impl.h:at::Tensor& c10::Dispatcher::callWithDispatchKey<at::Tensor&, at::Tens ... oryFormat>)> const&, c10::DispatchKey, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>) const'2
    1000  KernelFunction_impl.h:at::Tensor& c10::Dispatcher::callWithDispatchKey<at::Tensor&, at::Tens ... emoryFormat>)> const&, c10::DispatchKey, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>) const
     500  record_function.cpp:at::()::manager()
     500  WrapFunctionIntoFunctor.h:c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFun ... 0::MemoryFormat>)>::call(c10::OperatorKernel*, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
     500  RegisterCPU.cpp:c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoF ... 0::MemoryFormat>)>::call(c10::OperatorKernel*, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
     300  TensorBody.h:torch::autograd::VariableType::()::resize_(at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
     300  LegacyTypeDispatch.h:torch::autograd::VariableType::()::resize_(at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
     200  stl_vector.h:at::shouldRunRecordFunction(bool*)
     200  make_boxed_from_unboxed_functor.h:c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail: ... 0::MemoryFormat>)>::call(c10::OperatorKernel*, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
     200  OperatorEntry.h:c10::impl::OperatorEntry::lookup(c10::DispatchKey) const
     200  KernelFunction_impl.h:c10::impl::OperatorEntry::lookup(c10::DispatchKey) const
     200  /usr/include/c++/7/array:c10::impl::OperatorEntry::lookup(c10::DispatchKey) const
     100  LocalDispatchKeySet.h:c10::impl::tls_local_dispatch_key_set()
    -100  stl_list.h:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -100  Dispatcher.h:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const
    -200  make_boxed_from_unboxed_functor.h:c10::impl::wrap_kernel_functor_unboxed_withKeys_<c10::impl ... all(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -200  WrapFunctionIntoFunctor.h:c10::impl::wrap_kernel_functor_unboxed_withKeys_<c10::impl::detail ... all(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -200  OperatorEntry.h:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const
    -300  TensorBody.h:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -300  LegacyTypeDispatch.h:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -400  make_boxed_from_unboxed_functor.h:c10::impl::wrap_kernel_functor_unboxed_withKeys_<c10::impl ... all(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -400  RegisterCPU.cpp:c10::impl::wrap_kernel_functor_unboxed_withKeys_<c10::impl::detail::WrapFunc ... all(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -700  llvmMathExtras.h:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const
    -700  DispatchKeySet.h:c10::DispatchKeySet c10::DispatchKeyExtractor::getDispatchKeyUnboxed<*, long>(c10::DispatchKeySet, * const&, long const&) const
    -800  TensorMethods.cpp:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const
    -900  llvmMathExtras.h:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
   -1000  DispatchKeyExtractor.h:c10::DispatchKeySet c10::DispatchKeyExtractor::getDispatchKeyUnboxed<*, long>(c10::DispatchKeySet, * const&, long const&) const
   -1100  KernelFunction_impl.h:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const
   -1600  KernelFunction_impl.h:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
   -4300  VariableTypeManual.cpp:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)

Total: 19900
```

Some observations:
- Aside from empty (no change), the other benchmarks all have a similar drop in total instruction counts (~18k), which seems reasonable since they're all removing one tls read, from the autograd kernel, on every op call.
  - That probably means that this PR will primarily be useful in training and tracing use cases- not for inference (once `torch.no_grad` lands).
- The instruction count deltas are all smaller than the wall-time deltas. That's probably due to __tls_get_addr being an expensive instruction
- In all cases where fewer tls reads occurred, we dropped instructions in more places than just __tls_get_addr. Taking the above as an example:
  - __ttls_get_addr (-4400). No surprises here.
  - dispatchTypeId (-4600). dispatchTypeId does other bitwise calculations in addition to the tls read, which we now only do once (plus the single mask in the autograd kernels)
  - tls_local_dispatch_key_set (-1400). This is a tiny functions that basically just checks a global flag and calls __tls_get_addr. Maybe that flag checking added up to 1400?
  - callWithDispatchKey (-9400). This is because I updated the autograd kernels to use `redispatch()` rather than `call()`. It looks like `callWithDispatchKey` isn't getting inlined, but `redispatch` is (see below)
  - shouldRunRecordFunction (-2200). Now that we call `redispatch` instead of `callWithDispatchKey` from autograd kernels, we don't use RecordFunction during the redispatch. I **think** that's the right behavior, since we've already used RecordFunction in the original `call()`, and it's not clear to me why we'd want to use RecordFunction multiple times in a single dispatch chain in only some cases. Other than that, `redispatch` and `callWithDispatchKey` aren't too different, so I'm not too sure why the delta for `callWithDispatchKey` is so high.
  - resize_ (+2000). My guess is that this is because the autograd kernels now do a bit more work, to manually mask the DispatchKeySet before calling back into the dispatcher

I'm also particularly confused by `add_out` from AIBench vs. my benchmarks, since locally I see both a wall-time and an instruction count drop, but the two AIBench runs I posted both show a regression. The same goes for `empty`, although I see mostly no change in my local benchmarks, vs. a regression in AIBench 


### Takeaways
For this PR to merit landing, we want to see:
- substantial benchmark wins. i.e. in the majority of benchmarks, we want to see that (gain from plumbing TLS keys) > (loss due to extra register usage)
- Limited code complexity increase. Specifically, that (value of benchmark wins) > (size of code complexity increase)

If my local benchmarks are trustworthy, I think we see some pretty sizable wins in most cases, and more importantly, no major regressions in the cases where this PR doesn't help (`empty`).

I think the PR is pretty unwieldy as is, but there are some steps I can take to make it better (namely, hopefully templating the op registration path so we don't have two sets of functions everywhere).

But open to other suggestions/opinions!


Differential Revision: [D25614042](https://our.internmc.facebook.com/intern/diff/D25614042)

[ghstack-poisoned]

---
## [njp0008/pie_game](https://github.com/njp0008/pie_game)@[f156bc736e...](https://github.com/njp0008/pie_game/commit/f156bc736ef8df3b36b5d146a7c616ae03e4f655)
#### Friday 2021-01-29 20:36:41 by Nick Perry

More about the pie game

I've been learning Python for a few weeks now and I wanted to do something to challenge myself. So, I create a fun game by creating a while loop inside of a function. I created 2 functions, one function "my_program" will ask for your name and then read it back to you and then tell the rules of the game. 
I create a second function "chances" when the function is called, the while loop inside of it will commence and from there the user will have 6 attempts to try to guess my favorite flavor of pie. 
I thought it would be cleaner and a little more challenging to combine the function and while loop. This took me a few hours to create and because I'm still learning and to enjoy challenges, as a condition of the if statement, if the user guesses the right flavor, regardless if the guess can be in all caps, lower case or begin with an uppercase letter, it will still be correct. This particular piece was challenging and it took some trial and error and practice to get it correct. Initially, the the loop stopped even when the guess was incorrect. I still have so much to learn still, but this felt so satisfying to finish and see that it works how it  should. I now see what I've been reading how programmers feel when they code and see their finished product after having trial and error and some headbanging moments. It's so worth it to work through it. I wanted to break out of "tutorial hell" and start to create more things and I learned a lot about Python and myself in just creating this game.

I gladly welcome any feedback and happy coding, friends! :)

---

# [<](2021-01-28.md) 2021-01-29 [>](2021-01-30.md)

