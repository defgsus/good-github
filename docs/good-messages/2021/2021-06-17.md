# [<](2021-06-16.md) 2021-06-17 [>](2021-06-18.md)

3,421,935 events, 1,571,526 push events, 2,539,841 commit messages, 195,189,700 characters


## [kernel-patches/bpf@f72614b366...](https://github.com/kernel-patches/bpf/commit/f72614b366e402f5e8dc885f0035421568ff579e)
##### 2021-06-17 00:31:21 by Maciej Żenczykowski

bpf: do not change gso_size during bpf_skb_change_proto()

This is technically a backwards incompatible change in behaviour,
but I'm going to argue that it is very unlikely to break things,
and likely to fix *far* more then it breaks.

In no particular order, various reasons follow:

(a) I've long had a bug assigned to myself to debug a super rare kernel
crash on Android Pixel phones which can (per stacktrace) be traced back
to bpf clat ipv6 to ipv4 protocol conversion causing some sort of ugly
failure much later on during transmit deep in the GSO engine, AFAICT
precisely because of this change to gso_size, though I've never been able
to manually reproduce it.
I believe it may be related to the particular network offload support
of attached usb ethernet dongle being used for tethering off of an
IPv6-only cellular connection.  The reason might be we end up with more
segments than max permitted, or with a gso packet with only one segment...
(either way we break some assumption and hit a BUG_ON)

(b) There is no check that the gso_size is > 20 when reducing it by 20,
so we might end up with a negative (or underflowing) gso_size or
a gso_size of 0.  This can't possibly be good.
Indeed this is probably somehow exploitable (or at least can result
in a kernel crash) by delivering crafted packets and perhaps triggering
an infinite loop or a divide by zero...
As a reminder: gso_size (mss) is related to mtu, but not directly
derived from it: gso_size/mss may be significantly smaller then
one would get by deriving from local mtu.  And on some nics (which
do loose mtu checking on receive, it may even potentially be larger,
for example my work pc with 1500 mtu can receive 1520 byte frames
[and sometimes does due to bugs in a vendor plat46 implementation]).
Indeed even just going from 21 to 1 is potentially problematic because
it increases the number of segments by a factor of 21 (think DoS,
or some other crash due to too many segments).

(c) It's always safe to not increase the gso_size, because it doesn't
result in the max packet size increasing.  So the skb_increase_gso_size()
call was always unnecessary for correctness (and outright undesirable, see
later).  As such the only part which is potentially dangerous (ie. could
cause backwards compatibility issues) is the removal of the
skb_decrease_gso_size() call.

(d) If the packets are ultimately destined to the local device, then
there is absolutely no benefit to playing around with gso_size.
It only matters if the packets will egress the device.  ie. we're
either forwarding, or transmitting from the device.

(e) This logic only triggers for packets which are GSO.  It does not
trigger for skbs which are not GSO.  It will not convert a non-GSO mtu
sized packet into a GSO packet (and you don't even know what the mtu is,
so you can't even fix it).  As such your transmit path must *already* be
able to handle an mtu 20 bytes larger then your receive path (for ipv4
to ipv6 translation) - and indeed 28 bytes larger due to ipv4 fragments.
Thus removing the skb_decrease_gso_size() call doesn't actually increase
the size of the packets your transmit side must be able to handle.
ie. to handle non-GSO max-mtu packets, the ipv4/ipv6 device/route mtus
must already be set correctly.  Since for example with an ipv4 egress mtu
of 1500, ipv4 to ipv6 translation will already build 1520 byte ipv6 frames,
so you need a 1520 byte device mtu.  This means if your ipv6 device's
egress mtu is 1280, your ipv4 route must be 1260 (and actually 1252,
because of the need to handle fragments).  This is to handle normal non-GSO
packets.  Thus the reduction is simply not needed for GSO packets,
because when they're correctly built, they will already be the right size.

(f) TSO/GSO should be able to exactly undo GRO: the number of packets
(TCP segments) should not be modified, so that TCP's mss counting works
correctly (this matters for congestion control).
If protocol conversion changes the gso_size, then the number of TCP segments
may increase or decrease.  Packet loss after protocol conversion can result
in partial loss of mss segments that the sender sent.  How's the sending
TCP stack going to react to receiving ACKs/SACKs in the middle of the
segments it sent?

(g) skb_{decrease,increase}_gso_size() are already no-ops for GSO_BY_FRAGS
case (besides triggering WARN_ON_ONCE). This means you already cannot
guarantee that gso_size (and thus resulting packet mtu) is changed.
ie. you must assume it won't be changed.

(h) changing gso_size is outright buggy for UDP GSO packets, where framing
matters (I believe that's also the case for SCTP, but it's already excluded
by [g]).  So the only remaining case is TCP, which also doesn't want it
(see [f]).

(i) see also the reasoning on the previous attempt at fixing this
(commit fa7b83bf3b156c767f3e4a25bbf3817b08f3ff8e) which shows
that the current behaviour causes TCP packet loss:

  In the forwarding path GRO -> BPF 6 to 4 -> GSO for TCP traffic, the
  coalesced packet payload can be > MSS, but < MSS + 20.

  bpf_skb_proto_6_to_4() will upgrade the MSS and it can be > the payload
  length. After then tcp_gso_segment checks for the payload length if it
  is <= MSS. The condition is causing the packet to be dropped.

  tcp_gso_segment():
    [...]
    mss = skb_shinfo(skb)->gso_size;
    if (unlikely(skb->len <= mss)) goto out;
    [...]

Thus changing the gso_size is simply a very bad idea.
Increasing is unnecessary and buggy, and decreasing can go negative.

Cc: Dongseok Yi <dseok.yi@samsung.com>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Willem de Bruijn <willemb@google.com>
Fixes: 6578171a7ff0 ("bpf: add bpf_skb_change_proto helper")
Signed-off-by: Maciej Żenczykowski <maze@google.com>

---
## [freebsd/freebsd-ports-kde@4ea20bee50...](https://github.com/freebsd/freebsd-ports-kde/commit/4ea20bee50630eb895f1e50c59cc71d2c04fe5e4)
##### 2021-06-17 04:50:42 by Tobias C. Berner

x11/plasma5-plasma: Update KDE Plasma Desktop to 5.22

Plasma 5.22 is here, and it is more reliable and stable than ever. By
cleaning up and refactoring code in the background, the Plasma desktop
gives you greater responsiveness and performance, helping you become
even more productive without hiccups or surprises. Enjoy a smoother
experience with KDE’s Plasma 5.22 desktop.

Plasma 5.22 has become more pleasurable to use through improvements to
the design and greater smoothness and consistency in transparencies,
blurs, icons, and animations. Moving things to accessible locations,
offering hints and visual cues, and creating new settings allows you to
customize your work environment to make it fit perfectly to your needs.
Following the true KDE spirit, the push for a more stable and attractive
desktop does not mean you have to renounce control over how you want it
to look or behave. Plasma 5.22, as always, packs all the flexibility and
tools for customization you have come to expect and love, and some more
to boot.

Meanwhile, the push to move Plasma in its entirety to Wayland (the
display protocol of the future) continues in full swing. So much so that
popular distros are starting to ship Plasma with Wayland by default. By
using Wayland behind the scenes, Plasma is able to include features and
bug fixes not possible to implement on X11, offering you a better
experience and more stability.

Full announcement and changelog:
	https://kde.org/announcements/plasma/5/5.22.0/

---
## [atsut97/fzf.fish@0fa7c34c4e...](https://github.com/atsut97/fzf.fish/commit/0fa7c34c4e0a32d958264bb18cdf6402c841d0e6)
##### 2021-06-17 10:29:38 by Patrick

Overhaul custom key bindings to be a first-class feature (#172)

Setting custom key bindings is horrible experience. It's time to give it a make over!

## Background and motivation
fzf.fish ships with default key bindings that are mnemonic and have minimal conflicts with existing fish key bindings. However, for users who want to change them, the process of customizing them is frustrating and confusing at best. This frustration has culminated in a steady stream of issues, discussions, PRs, and Wiki sections around key bindings (#17, #89, #99, #108, #103, #153, #162, [Wiki section](https://github.com/PatrickF1/fzf.fish/wiki/Cookbook/60b24ade20395cab07148c87c14966046ccbe8e9#how-can-i-customize-only-one-key-binding)). Here are the shortcomings of making custom bindings DIY:
- Besides not installing the default bindings if `fzf_fish_custom_keybindings` is set, the plugin provides _zero_ assistance to the user when it comes to installing the custom bindings. Users have to study `config/fzf.fish`, `bind` documentation, and maybe even learn some fish syntax to learn how to set their own key bindings. This is a quite daunting task. Furthermore, users have to reference functions clearly denoted private (`__fzf_search_*`)., which feels and use hacky. Ideally, 
 the plugin does not require typical users to dive into its code and will abstract private functions away completely.
-  `fzf_fish_custom_keybindings` is all or nothing; users have to opt out of ALL default key bindings and re-bind them themselves even if they only want to change one. This is tedious, verbose, and unwieldy. A good plugin should allow tweaking the key binding while maintaining the rest of the defaults.
- Because the `fzf_fish_custom_keybindings` has to be set before `config/fzf.fish` is executed, it has to be created as a universal variable. Unfortunately, universal variables are a [very confusing point for new fish users](https://github.com/fish-shell/fish-shell/issues/7317#issuecomment-701165897).
- And because it needs to be universal, it's [bad practice to add it to one's `config.fish`](https://gitter.im/fish-shell/fish-shell?at=60c3880fbed13a2dba7acd55).  This makes it more difficult for one's `fzf.fish` configuration to be [checked into git](https://github.com/PatrickF1/dotfiles/tree/master/.config/fish).

As the plugin author, I have also felt the pain of working around this DIY custom binding mechanism:
- Because custom bindings are so painful to use, user forego custom bindings and get stuck with the defaults, which puts a lot of pressure on me (subconsciously and through the many issues opened) to make the default bindings suitable for _everyone_. Unfortunately, the goal of having a default set of key bindings that is suitable for even 80% of users while being easy to learn (or mnemonic) is nigh impossible, requiring a thorough understanding of the multitudes of CLIs and terminals people use, the ways they use them, and they key binding. I've concluded this task is ultimately futile because key bindings are very idiosyncratic. Therefore, custom key bindings should be a first class feature that is well supported, completely documented, flexible, painless to use, and directly encouraged.
- Any change, even an addition (such as a new feature), to the default key bindings is an outsized, monumental event because it's not transparent and hard to communicate to users. In fisher, there isn't a mechanism for precisely warning users of backwards incompatible changes. Furthermore, the only place where the default key bindings are officially listed is on the readme. The best I can do is to cut a new major release and post on Reddit and Gitter to announce any and all key binding changes. But still, most users will probably be left in the dark when their key bindings silently break on the next update. If more users customized their key bindings and (which they don't because again, it's not well supported) and there was an interface to quickly view the default key bindings, this would be a much smaller problem.
- Because users have to hardcode in the function names for their custom key bindings, fzf.fish's internal functions are not really private and I cannot rename them as they morph. This is important to me as the names of some features, and therefore the ideal function name, have shifted since their inception.
- Finally, `fzf_fish_custom_keybindings` has an annoying typo: key binding is two words, not one.

## The new solution
A new function called `fzf_configure_bindings` solves or mitigates all of the aforementioned problems. It:
- serves as a wrapper around the key bindings and fzf.fish's private functions so that they are properly abstracted away under a lightweight interface.
- allows customizing the key binding for each feature through namesake options (e.g. `--directory` controls the search directory key binding). Bindings can be overridden or, if the user doesn't want to use the feature, even disabled.
- uses mnemonic key sequences by default for features that the user chooses to not customize. This means that to change the key bind for a single feature, only one option needs to be specified.
- comes with great, easy-to-read help documentation that prints if used incorrectly.
- includes the default key bindings in its help message so users can easily and quickly find them.
- is robust and thoroughly tested.
- will include command completion (to be implemented later).

---
## [mrakgr/The-Spiral-Language@71aed5633e...](https://github.com/mrakgr/The-Spiral-Language/commit/71aed5633ef0fcacde5737a88adfe5ba4185ded7)
##### 2021-06-17 14:39:16 by Marko Grdinić

"2:30pm. Done with breakfast. Let me do some reading and then I'll go for the second half of the session.

3pm. Done with chores. I do not seem to be reading much, instead I seem to be spending most of my time in thoughts, but still let me finish the chapter and then I will resume.

3:20pm. Let me resume. I'll leave the new Kumo chapter for later.

Ah yeah. I forgot to fix the raise to 0 bug that I realized yesterday.

```
raise_to = if raise_min = 0 then $"False" else fun raiseTo => next (Log_prob_one,(RaiseTo:)) |> loop
```

Let me just do this.

3:35pm. Hmmm, it seems that sometimes raising causes the opponent to act instead of my own player. Where is this bug coming from?

3:40pm. The pattern is Call Raise Call after which I'll get a chance to act as the opponent. I need to figure this out.

```
inl vs_human game human_pid p =
    let rec loop = function
        | Terminal: _ as g => g
        | Action: player_state,game_state,pid,actions,next as g =>
            if pid = human_pid then g
            else
                inl cs,_ = p (am.singleton (player_state,game_state,pid,actions))
                next (index cs 0)
    loop game
```

Is the problem here?

```
        | Action: player_state, (p1,p2,(community_card,_)), pid, actions, next =>
            inl trace = show_trace (pl2_observations player_state human_pid)
```

Or maybe here somewhere. Ah maybe...

```
inl vs_human game human_pid p =
    let rec loop = function
        | Terminal: _ as g => g
        | Action: player_state,game_state,pid,actions,next as g =>
            if pid = human_pid then g
            else
                inl cs,_ = p (am.singleton (player_state,game_state,pid,actions))
                loop (next (index cs 0))
    loop game
```

Maybe I just need to try looping again. This should be the solution.

3:55pm. Playing against the random player is pretty boring, but it is revealing a bunch of bugs. Just now I had a flush, but it thinks it is a pair.

Let me hack the deck again.

```
    inl swap a b =
        inl q = index deck a
        inl w = index deck b
        set deck a w
        set deck b q

    swap 0 (4+26)
    swap 1 (3+26)
    swap 2 0
    swap 3 (10+39)

    swap 4 (3+13)
    swap 5 (9+26)
    swap 6 (7+26)
    swap 7 8
    swap 8 (5+26)
```

I think this should be the correct hand.

```
    swap 0 0
    swap 1 (10+39)
    swap 2 (4+26)
    swap 3 (3+26)

    swap 4 (3+13)
    swap 5 (9+26)
    swap 6 (7+26)
    swap 7 8
    swap 8 (5+26)
```

No actually it is this. Now I'll be able to investigate this bug.

```
                inl state =
                    if has_card' hand (suit:0 rank:) then q0+1, q1, q2, q3
                    elif has_card' hand (suit:1 rank:) then q0, q1+1, q2, q3
                    elif has_card' hand (suit:2 rank:) then q0, q1, q2+1, q3
                    elif has_card' hand (suit:3 rank:) then q0, q1, q2, q3+1
                    else state
```

Wait, this might be wrong. I might not have just a single suit of a particular rank.

```
    inl flush() =
        inl find_hand ~suit =
            let rec loop rank (h,c as state) =
                inl (h,c as state) =
                    if has_card' hand (suit:rank:) then update5 h c (full (suit:rank:)),c+1
                    else state
                if c = 5 then hand_score {score=Score.flush; hand=h}
                else loop (rank-1) state
            loop (NumRanks-1) ((-1, -1, -1, -1, -1), 0)
        let rec find_suit rank (q0,q1,q2,q3 as state) =
            if 0 <= rank then
                inl f suit = has_card hand (suit:rank:)
                inl q0,q1,q2,q3 = q0 + f 0, q1 + f 1, q2 + f 2, q3 + f 3
                match state with
                | 5u8,_,_,_ => find_hand 0 | _,5u8,_,_ => find_hand 1
                | _,_,5u8,_ => find_hand 2 | _,_,_,5u8 => find_hand 3
                | _ => find_suit (rank-1) state
            else straight()
        find_suit (NumRanks-1) (0,0,0,0)
```

Let me do it like this.

```
        let rec find_suit rank (q0,q1,q2,q3 as state) =
            if 0 <= rank then
                inl f suit = has_card hand (suit:rank:)
                match q0 + f 0, q1 + f 1, q2 + f 2, q3 + f 3 with
                | 5u8,_,_,_ => find_hand 0 | _,5u8,_,_ => find_hand 1
                | _,_,5u8,_ => find_hand 2 | _,_,_,5u8 => find_hand 3
                | state => find_suit (rank-1) state
            else straight()
```

Whops, I was too hasty. Let me do this.

4:10pm. Great, now flushes work. Let me get rid of that deck hack.

```
    inl swap a b =
        inl q = index deck a
        inl w = index deck b
        set deck a w
        set deck b q

    swap 0 0
    swap 1 (10+39)
    swap 2 (4+26)
    swap 3 (3+26)

    swap 4 (3+13)
    swap 5 (9+26)
    swap 6 (7+26)
    swap 7 8
    swap 8 (5+26)
```

I'll back it up here.

All this just underscores how necessary testing is. And having an UI makes things a lot easier. Imagine if I tried playing from the command line.

It would have been horrible if I just skipped straight to training without testing it out for a while.

4:30pm. This is quite boring. Let me do 5 more hands and then I am done. I'll start the review after that.

...Ok, it works. If it does not, I'll get more feedback once I train a proper agent and play against it. The uniform player is just an aggrodonk. I do not feel like playing anymore.

4:35pm. Compared to when I started testing, I found a large number of bugs and dealt with them. Now the game is ready to be used for agent training.

It will piece of cake to make use of it for its intended purpose.

Let me commit here."

---
## [Livie123/emerge_project_fixed@e249e45b6c...](https://github.com/Livie123/emerge_project_fixed/commit/e249e45b6c32e7a7c95e20a0fd819a51533619cb)
##### 2021-06-17 17:36:21 by Livie123

Update gallery2.html

 Add 
<section class="project-section">


        <div class="project-wrapper">
          <img src="./assets/Images/Luo_image_02.magic_pose.jpg">
          <div class="project-description">
    
            <h2>Magic Pose</h2>
            <p>Magic Pose is part of my Shoujo Instagram series. Check it out by pressing the link.</p>
            <a href="https://www.instagram.com/p/B-aSv3LhnsL/"></a>
          </div>
        </div>
        
       <div class="project-wrapper">
          <img src="./assets/Images/IMG_3073.heic">
          <div class="project-description">

            <h3>Katalog Of Dream Morpheus (Ink Drawings), 2021</h3>
            <p>Inspired by KATALOG OF DREAM MORPHEUS which is a hand drawn animation that explores dreams through lines, scribbles, and figures drawn in black ink.
              The irrational and illogical nature of dreams is represented through a series of seemingly random cuts and transitions.
            </p>
          </div>
        </div> 
        
        
       <div class="project-wrapper">
          <img src="./assets/video/katalog_dream_morpheus.mp4">
          <div class="project-description">
   
            <h4>KATALOG OF DREAM MORPHEUS, 2021, animated video, 1 minute</h4>
            <p>KATALOG OF DREAM MORPHEUS is a hand drawn animation that explores dreams through lines, scribbles, and figures drawn in black ink.
              The irrational and illogical nature of dreams is represented through a series of seemingly random cuts and transitions.</p>
          </div>
        </div> 
        
        <div class="project-wrapper">
          <img src="./assets/video/student_ani.mp4">
          <div class="project-description">
   
            <h5>A Student, 2020, animated video, 1:36 minute</h5>
            <p>This animation is about anxieties and worries that many students are struggling with. These anxieties caused by many factors creates 
              this physical manifestation of anxieties which is the black scribbles.</p>
          </div>
        </div> 
        
      <section>

---
## [mrakgr/The-Spiral-Language@c966fe8a3f...](https://github.com/mrakgr/The-Spiral-Language/commit/c966fe8a3f62ec5200d90223503f0584a4006e50)
##### 2021-06-17 18:09:49 by Marko Grdinić

"4:40pm. Now let me make the half yearly review for my special place.

///

At the time of the previous report [Spiral v0.2](https://github.com/mrakgr/The-Spiral-Language) was very raw, and it was not until about mid March when I did the editor support redesign that it could be considered stable. Much like in 2018 I've been programming in it and fixing bugs as I go along. Right now, it is in very good shape. Whatever complains I could make, they would be about Cython not being good enough to support a functional language like Spiral, but overall the situation is quite good. And whatever flaws Python has, PyTorch makes it worth using it. I did not opt to do a ML library like last time since I know from experience that it would eat up all my time.

It is not really worth it to make one for GPUs anymore. It would have been different in early and maybe even mid 10s, but right now the established frameworks have too much of a lead and I see no need to sacrifice my lifespan for this again.

If I could get my hands on neurochips I'd seriously consider it.

Months ago, I did take stock of [the landscape](https://www.reddit.com/r/MachineLearning/comments/kzsokz/d_list_of_novel_ml_hardware_companies_january_2021/) and send out a bunch of emails to those that I saw as most promising, but I barely got a reply and the whole experience soured me on these companies. In my mind, I see that these companies would benefit greatly by ditching the usual C + Python combo in favor of a language that would suit their hardware. I imagined what kind of back and forth I could have to convince them to sponsor Spiral, but once I actually tried I realized that I do not know how to get them to even engage with me.

It is really a pity. To think I'd need to have fame and reputation just to put my foot through the door.

An ideal situation for me and the ML community at large would be to have a bunch of sponsors paying me 3k a month just to do the backends for their hardware and giving me samples free of charge, but I've made my resolve to just buy what I need on the open market. Without Spiral these chips will need more time to develop, but it is not like it would slow me down personally. I am not going to go out of my way to do these people favors by screaming outside their window in order to get their attention. If they know what is good for them they can come to me. I promise I'll at least be willing to talk.

Right now I am finally working on my old plan. In fact, if I made my start 4 months ago and said I wanted to conquer online poker through reinforcement learning, my actions since then would have actually made sense. I did not do something crazy like work on a ML library and a language for years instead of my stated goal.

This time around I have some good results. Compared to 2018, I've changed my thinking about backprop and the new perspective gave me a steady stream of inspiration. The [monthly PL sub reviews](https://www.reddit.com/r/ProgrammingLanguages/comments/nqjmnv/june_2021_monthly_what_are_you_working_on_thread/h0exwqh?utm_source=share&utm_medium=web2x&context=3) showcase the evolution of my thinking.

My grasp on both deep learning and tabular RL is finally strong enough that I've managed to infer a [reward-scale invariant RL algorithm](https://github.com/mrakgr/The-Spiral-Language/blob/34834344b90de3ca3ec684580eb2d36b5c777e2b/Spiral%20Compilation%20Tests/cython_experiments/ui_leduc18%20(signSGD%20%2B%20infNorm%20%2B%20EM%20value%20nets)/control.py#L33) that combines all the strengths of tabular RL and deep learning. I've bencharked it against a tabular CFR player it gets close to its performance in roughly the same amount of training cycles. In the [May monthly review](https://www.reddit.com/r/ProgrammingLanguages/comments/n2orrx/may_2021_monthly_what_are_you_working_on_thread/gwn0wge/?context=3) I had a bunch of complicated ideas for how to do policy averaging using dropout with key sharing. At that time I had not heard about stochastic weight averaging and now I that I've tried it out I can confirm personally that for NNs averaging in weight space is enough to average in policy space.

When self play training is done, unlike in supervised learning the policy tends to have large oscilations. This happens even in the tabular case. And the way to dampen that is to do averaging of policies. It is a relief that for NNs it is enough to average the weights since I won't have to pay the huge expense of keeping old policy nets around.

The algorithm I've linked needs to be used together with signSGD, rescaling by the infinity norm of the layer, or a variant of Adam that tracks the infinity norm instead of the variance for the reward scale invariance property to hold. Personally I'll just stick to signSGD and have the batch size be a hyperparameter that needs tuning. In all cases I expect setting the actor learning rate to something sensible like 2 ** -8 or 2 ** -9 to work.

I've tested it thoroughly on Leduc and have confidence in using on Holdem next. In fact, the [HU Holdem game](https://github.com/mrakgr/The-Spiral-Language/blob/34834344b90de3ca3ec684580eb2d36b5c777e2b/Spiral%20Compilation%20Tests/cython_experiments/ui_holdem1/ui_holdem.py#L196) is done with testing, and I just have to start training agents on it using the algorithm I've showcased.

I've been seeking something like this for years. Even before 2018 when I touched deep RL for the first time, I remember thinking that value function learning using NNs makes no sense. And now I've finally resolved this inner conflict. Since my 2019 attempt at learning formal proofs did not take me in the direction I wanted, I am not going to write a paper, but it should be worth a blog post at some point at least. This is my reward for spending so much time on tabular RL instead of skipping straight to deep architectures.

At this point, I am sure that I am only a few weeks of steady training away from having a superhuman HU Holdem agent. I'll start out by training a relatively small and shallow one, and iterate towards deeper and wider architectures. In theory I could go straight to training the deepest and widest player I can afford, but using the old masters as baselines will allow me to tell how good the players are. HU Holdem is complex enough that I do not actually have a of gauging how good the players being trained are so I am going to have to do this.

It won't be too hard to beat even the best humans using such an agent, but who knows where the absolute limits of the game lie and how the training would have to be to reach it. Given the complexity of Holdem, most likely it will continue to get better for as long as I keep training it.

It is time to find out the truth of whether there is any point to cultivating my ML skills. Lately I've been getting wary of the social aspects of living in this world. Not long after DeepBlue beat Kasparov the machines became dominant at the game. But who are those deriving benefits from chess? It is not the AI researchers making new versions of StockFish who are lauded, but human players like Magnus Carlsen.

This is similar to poker. If you want to actual get the kind of money the best players in the world make, trying to do that via AI would quickly get one barred as a cheater from online sites. The cultural force normalizes reality so that humans are the top even when they shouldn't be.

On the surface today, AI works is being done in the open, but if you look at it more closely, the incetives are only there for the academics to publish papers in the open. I've finally made a significant algorithmic innovation, but consider the obstacles to publishing:

* I'd need to spent at least a month or two doing thorough testing. Leduc is enough to convince me, but other people would want to see more.
* All the ML papers I've seen have those useless proofs taking up space and I'd need to do them to be taken seriously, but as trite as they are, I cannot do them. I do not know how to prove literally anything of interest in deep learning.
* Even if I somehow succeed and gain academic credit, just what use is that to me? It is not like I am getting paid for that. Trading the academic credit for a job in ML might net me money, but all jobs would have me be a wage slave no matter how highly paid they are.
* Success in academic circles means eroding my own edge in the real world. I'd be spending valuable time harming myself.

I am being quite generous by putting the algorithm out in the open, but it is fairly simple and other people would have figured out the ingredients for it eventually. And I want the field to go faster. The sooner the Singularity gets here, the better.

I have some thoughts on how to do deep exploration properly. In the past my main ideas were to somehow make ensembles work and I haven't actually tried that, but I do have better ideas now. Instead of ensembles it might be possible to make use of [upside down RL](https://arxiv.org/abs/1912.02875), in particular [the decision transformers](https://arxiv.org/abs/2106.01345) and combine it with [the duality gap GAN training](https://arxiv.org/abs/2103.12685). The the GAN generator itself could then be used to derive the exploration policy by generating sequences that serve as a stand in for it. This makes some sense as living beings should not do their exploration in the real world where their actions might get them killed. Instead they'd do them through their dreams and internal simulations.

I have an inkling how to do long term credit assignment too. I can now sense that training a NN using Hebbian learning would give it the property of being reversible. Rather than keeping traces which backprop requires, it makes a lot more sense to reconstruct the inputs based on the outputs and do credit assignment that way. I do not know how to make this work, and I won't even try until I get access to neurochips. Then it will be a matter of doing enough experimentation to find the right recipe to make this work.

All in all, my position as far as ML understanding is concerned is solid and will only get better as more interesting algorithms get discovered. The poker agents are not far from being summoned into existence. I've also made my peace with backprop.

But I am wary. I've once read that a great agent without an interface is worth a fortune, but an interface without an agent is worthless, but I am not sure how seriously to take that. Given how much difficulty proving the value of Spiral to anybody, but myself is I am starting to get concerned that the Turing-test passing, 'social' aspects of AI might be my undoing. Training the agents will be so easy, that I can't help but think that the obstacles to their use will be huge. My luck when it comes to making money has been quite bad. Will it really turn around here?

I am completely sure that ML won't be the problem, so the universe will have to find some other way to make me fall flat.

This sense of danger and trepidation is somehow invigorating and motivating. It seems unimaginable for a loser such as myself to finally win at something, but if I can connect this next part, the benefits will be unimaginable. I'll wash away my dull and mediocre past and replace it with a shining, golden future. Perhaps I am just going there to die, but the safety of the present is always illusory.

I do not know whether it was worth it to take the time to make a language and cultivate my programming skills. But the lead up was all for this. If I can make superhuman agents at the foremost gambling games in the world, and yet cannot find a way to turn a profit on that, then the difficulty level of this game is really too high. I'll accept that normies are really hard to beat and will stop looking down on them. I'll give up on this madness that has been guiding me.

But if I can win I swear that I will tear up this reality and replace it with my own. I will go through my rite of passage, and return to cultivating the arts. And rather than just for playing games, I will have the agents of post-humanity assist me in making them.

///

5:15pm. `def state_probs_grad(): # Prediction errors modulate the state probabilities. The cool part is the centering.`

I am not doing the centering at all. Stale comments suck. Let me remove that last sentence.

8:05pm. Done with the review. Let me finally close for the day here. I'll put this through a spell checking tool later. Let me have some fun here."

---
## [pixaxeofpixie/prometheus-tech@f7f0afc014...](https://github.com/pixaxeofpixie/prometheus-tech/commit/f7f0afc014773c17274cef470413498450f9d9fe)
##### 2021-06-17 20:13:53 by stormtrooper145

da da da da daaaa
it's tha motha fuckin' D oh double G (Snoop dogg)
da da da da daaaa
You know im mobbin' with the D.R.E
yeah yeah yeah
you know who's back up in this mothafucker *echoes*
What what what what
so blaze the weed out there
Blaze it up
Blaze that shit up nigga
Yeah waz up snoop
Top dogg buy them all nigga burn this shit up
D-P-G-C my nigga turn that shit up
CPT, LBC yeah we hookin' back up
N' when they bang this in the club baby you gotta get up
thug niggas, drug dealers yeah they givin' it up
low life, your life boy we livin' it up
take a chance thats why we dancin'
in the party fo' sho'
slip my ho a fourty four n' she crept in it back do'
bitches lookin' at me strange but you know i don't care
step up in this mothafucker just to swingin' my hair
Bitch quit talkin' Crip walk
If you down with the set
Take a Bullet with some dick
take this dope from this jet
outta town put it down for father of rap
n' if your ass get crack bitch shut your trap
come back get back thats the part of success
n' if you believe the X then you'll relievin' your stress
music in between
da da da da daaaa
it's the mothafuckin' D-R-E
Dr. Dre mothafucker [Snoop] what what what what
da da da da daaaa
you know im mobbing with the D oh double G
Straight off the fuckin' street's of CPT
King of the beats n' you ride to em' in your fleet (Fleetwood) wood
or Coupe DeVille rollin on dubs
How you feel?
Whoopty whoop nigga what?
Dre n' snoop chronic'ed out
In the 'llac with doc in the back
Sippin' 'gnac, clip in the strap
Dippin' through hoods
What hoods? Compton, longbeach, ingelwood
South central out to the westside (westside)
It's california love this california bud
Got a nigga gang of pub
I'm on one, I might bail up in the Century Club
With my jeans on n' my team's strong
Get my drink on n' my smoke on
Then go home with somethin' to poke on (waz up bitch)
Loc' it's on for the two tripple oh
Comin' real it's the next episode *Echoes*
Music in between
hold up.. heeeeey
For my niggas who be thinkin' we soft
We don't.. plaaaay
We gonna rockin' til the weels fall of
Hold up.. heeeeey
For my niggas who be acting to bold
Take a.. seeeeat
Hope you ready for the next episode heeeeeey

---

# [<](2021-06-16.md) 2021-06-17 [>](2021-06-18.md)

