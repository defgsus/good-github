# [<](2021-07-08.md) 2021-07-09 [>](2021-07-10.md)

2,718,899 events, 1,362,972 push events, 2,250,801 commit messages, 166,025,439 characters


## [ajstorm/cockroach](https://github.com/ajstorm/cockroach)@[bf0539e0b1...](https://github.com/ajstorm/cockroach/commit/bf0539e0b143bad8d6de2b7e2beb9360cb6bbdf7)
#### Friday 2021-07-09 00:17:40 by craig[bot]

Merge #65126 #65140 #65609 #65883

65126: ui: cluster-ui integration  r=koorosh a=koorosh

Note: Most of the commits are transferred "as is" from "cockroachdb/ui" repository and only two
last commits (be2cf6f and 7391346) include changes related to actual integration of package and adjusting
build tools.

Initially db-console referenced to `cluster-ui` package as an external package that
is hosted in another repository and required to update version of this package
every time new changes are made.

Now, when `cluster-ui` package is extracted from `cockroachdb/ui` repository and
moved in this repo (under `pkg/ui/cluster-ui`), it is possible to reference to
this package as a linked dependency and immediately observe all changes.

To do this following changes were made:
- db-console references to cluster-ui as a linked dependency and doesn't rely
on specific version
- `cluster-ui` package relies on local version of crdb-protobufjs-client package
instead of specific version
- Make commands related to db-console are extended to take into account nested
`cluster-ui` package. It runs tests, linting and watch commands for both packages.

One notable workaround has to mentioned... yarn installation for db-console
fails during first run because it cannot properly consume symlinked `cluster-ui`
dependency and only with second attempt it passes without issues (this is known
issue in yarn project).

Depends on: https://github.com/cockroachdb/yarn-vendored/pull/73


65140: ui: rework data handling for the job details page r=dhartunian,nihalpednekar a=oeph

Rework the data fetching for the job details page in the admin ui in order to
prevent cases, where the jo details page was stuck showing a loading indicator.

This was caused by the combined data handling of the job table and the details,
leading to loading issues if the job was not listed in the table and therefore
could not be shown in the detail page. (see #64281 for reproduction steps)

The job details page now uses a dedicated api endpoint to fetch the job details
for the given job_id.

Release note: None

Fixes #64281

65609: kvserver: remove replica GC heuristic for quiesced followers r=tbg a=erikgrinaker

In #65062 we added a condition to the replica GC queue that quiescent
followers with a single unavailable voter would be considered suspect.
This was added to try to detect followers who were partitioned away from
the Raft group during its own removal from the range. However, this case
has a very high false positive rate, and on second thought it is probably
higher than it is worth.

There is already a secondary condition that considers followers who have
lost touch with their leader suspect, which would be somewhat sufficient
in this case, and with a far lower false positive rate. Even though this
heuristic is vulnerable to race conditions, it seems a better fit
considering that in the worst case the replica will always be GCed
within 12 hours anyway. We have also since moved range-level metrics
to the leaseholder, which reduces the impact of these stale replicas.

This patch therefore removes the quiescent replica condition, and
reduces `ReplicaGCQueueSuspectCheckInterval` from 5 to 3 seconds since
we now expect far fewer false positives.

Touches #65202.

Release note: None

/cc @cockroachdb/kv 

65883: docs: update Life of a Query r=tbg a=erikgrinaker

[Rendered](https://github.com/erikgrinaker/cockroach/blob/life-of-a-query/docs/tech-notes/life_of_a_query.md)

This is a first pass at updating the Life of a Query document. It
primarily focuses on updating links and descriptions to the current code
base, and rewriting sections that no longer apply. It has not added
new sections on significant new concepts that have since been
introduced (except where necessary).

Parts of the SQL sections have not been updated -- in particular
"Notable planNodes" -- as the SQL execution engine has undergone
significant changes recently that are better described by members of the
SQL team. Instead, a note has been left informing the reader about
this.

A second pass is planned for later, which will add missing concepts,
expand on existing concepts, and tighten up the prose to make it more
cohesive.

Touches #65196.

Release note: None

/cc @cockroachdb/kv 

Co-authored-by: David Hartunian <davidh@cockroachlabs.com>
Co-authored-by: Andrii Vorobiov <and.vorobiov@gmail.com>
Co-authored-by: Nathan Stilwell <nathanstilwell@cockroachlabs.com>
Co-authored-by: Andrii Vorobiov <undeclarede@gmail.com>
Co-authored-by: Alfonso Subiotto Marques <alfonso@cockroachlabs.com>
Co-authored-by: Alfonso Subiotto Marqués <alfonso@cockroachlabs.com>
Co-authored-by: oeph <me@philippoeh.me>
Co-authored-by: Erik Grinaker <grinaker@cockroachlabs.com>

---
## [posting-humanism/posting-humanism.github.io](https://github.com/posting-humanism/posting-humanism.github.io)@[a9df09ae86...](https://github.com/posting-humanism/posting-humanism.github.io/commit/a9df09ae86a283ce2964a99aaa025b2e85812c20)
#### Friday 2021-07-09 00:51:57 by smargendorf

resetting this god damn repo

fucking hugo man jesus christ

---
## [Raenllanthos/car_inventory_flask](https://github.com/Raenllanthos/car_inventory_flask)@[884dc200da...](https://github.com/Raenllanthos/car_inventory_flask/commit/884dc200da253439db98484ffe6edd679b84e301)
#### Friday 2021-07-09 02:46:38 by raenllanthos

cullen is a fucking numpee ass idiot stupid butthole dirty

---
## [mininmobile/sneedacity.org](https://github.com/mininmobile/sneedacity.org)@[08d3642d7d...](https://github.com/mininmobile/sneedacity.org/commit/08d3642d7df89bd0fcbddb222a4d190446333ee4)
#### Friday 2021-07-09 03:20:42 by sophie

perform changes
- make indentation consistent (converted all that wasn't tabs to tabs)
- added a sentence to README
- removed all non-necessary js & made mobile menu work w/o js
- misc (ie. holy shit this website was made by a fucking tard)

---
## [BlueManedHawk/Ex-Nihilo](https://github.com/BlueManedHawk/Ex-Nihilo)@[9980993301...](https://github.com/BlueManedHawk/Ex-Nihilo/commit/9980993301ad28b9ee2fca8b988f33a196f7dacc)
#### Friday 2021-07-09 03:46:46 by BlueManedHawk

Ruined Everything

Hello.  I've just made a Tumblr post that also contains this info:
https://bluemanedhawk.tumblr.com/post/656201241705299968

I started this project a few months ago, and I had had the idea for it
long before then.  When I first began the project, I was deeply naive.
I thought that I would be able to create this game by having the
program draw to the screen directly, with support for X11 being a side
thing.  I though that I'd be able to deal with the differences
between every user's computer.  I thought that I'd somehow be able to
do 3D graphics in this project with zero knowledge on how to do so.
I thought I'd be able to create a heavy compression algorithm designed
specifically for this game to compress the assets.  Looking back, I
cannot believe how stupid I was.

Over time, I would eventually tone down my plans.  I decided to use
Simple DirectMedia Layer to draw to the screen within a window, and to
help deal with the differences between all the possible computers.  I
decided to keep the game 2D, with a vague possibility of 3D in the
future.  I ended up deciding to use BMPs and WAVs, since those options
were built in to SDL.  Nonetheless, I stayed adamant on a few things,
such as keeping the screen resolution as 4:3 480p, continuing with
exclusively using the keyboard, keeping with C with no game engine,
using simple digital audio to complement the low-resolution graphics,
having the game be plug-and-play, and not overcomplicating things with
multiple source files.

However, after that, I found myself unable to work on the project, and
I decided to put it on temporary hiatus.  I'm not going to go into
details as to why this is, partially because the details aren't really
that relevant to this, but mostly because it would require me to
disclose personal information.  What's important is that this caused
me to not have anywhere near enough energy to be able to work on this
project, but I nevertheless had plenty of time to think about it,
during which time I made some decisions that I deeply regret.

I have now resumed work on the project, and I have implemented the
regretable decisions I made:

- I decided to do mouse support.
- I ended up creating an `include/` directory and a Makefile.
- I decided to use recorded audio for the sound.
- I used some SDL extensions.
- I probably did some other things I'm forgetting, too.

However, there are still some things that I shall stand like a statue
on:

- I will continue to use C for this project.
- I will not use a game engine for this project.
- I will keep the screen resolution as 4:3 480p.
- I will keep the game fairly plug-and-play.
- I will probably also do some other things I'm forgetting.

I hope that I can still make _Ex Nihilo_ into the great game that I
believe it can be.

Thank you.

---
## [cockroachdb/cockroach](https://github.com/cockroachdb/cockroach)@[cdc64cff8b...](https://github.com/cockroachdb/cockroach/commit/cdc64cff8bae31a2a90ca11e36b68fe83cc35f06)
#### Friday 2021-07-09 03:47:31 by craig[bot]

Merge #66359 #66800 #66870 #67316 #67331 #67340 #67371 #67390 #67393

66359: sql: add partial redactability to logs r=knz a=THardy98

Prior to this change, enabling log redaction redacted entire SQL
statements. Consequently, troubleshooting efforts were hindered   by the
limited SQL statement information available in the redacted logs. This
change introduces partial redaction to log SQL statements, wherein only
sensitive information is redacted. As a result, more information is
available to those using redacted logs for troubleshooting.

Changes were introduced to the statement formatter. The formatter now
checks where the redaction flag is set. If so, redaction markers are
placed are specific node types in the statement's AST (namely, the
Datum, Constant, Name, and Unrestricted Name types).

Virtual schemas/tables are not redacted. The `public` schema is also not
redacted.

Note: redaction markers are ‹ and ›. Terms between the redaction markers are redacted.

**Redaction Marker Examples:**

```
1) SELECT city, revenue FROM rides LIMIT 10;

Before: ‹SELECT city, revenue FROM rides LIMIT 10›
After: SELECT ‹city›, ‹revenue› FROM ‹\"\"›.‹\"\"›.‹rides› LIMIT ‹10›
```

```
2) SELECT key FROM crdb_internal.node_statement_statistics LIMIT 10;

Before: ‹SELECT key FROM crdb_internal.node_statement_statistics LIMIT 10›
After: SELECT ‹key› FROM crdb_internal.node_statement_statistics LIMIT ‹10›
```

**Redaction Examples:**
```
1) SELECT city, revenue FROM rides LIMIT 10;

Before: ‹×›
After: SELECT ‹×›, ‹×› FROM ‹×›.‹×›.‹×› LIMIT ‹×›
```

```
2) SELECT key FROM crdb_internal.node_statement_statistics LIMIT 10;

Before: ‹×›
After: SELECT ‹×› FROM crdb_internal.node_statement_statistics LIMIT ‹×›
```

Resolves: #65401

Release note (bug fix): Added partial redactability to log SQL
statements. This change provides greater visibility to SQL usage in the
logs, enabling greater ability to troubleshoot.

66800: changefeedccl: support interval columns in avro changefeeds r=[stevendanna,otan] a=HonoreDB

We'd delayed implementing interval types in avro, unlike other
time types, because in theory there's an avro spec for durations
but no tooling. However the spec is a bit too limiting, so rather
than wait for tooling, we're just going to encode it as a string,
using the [ISO standard for durations](https://en.wikipedia.org/wiki/ISO_8601#Durations).

Adding in @otan since I'm touching the duration util package, and to check my assumption that it makes sense to keep truncating to the microsecond level.

Release note (bug fix): Interval columns are supported in avro changefeeds

66870: changefeedccl: support special decimals in avro feeds r=[miretskiy] a=HonoreDB

Previously, changefeeds on a decimal column would error when encountering
NaN or infinite values, but those are valid in SQL.
This PR changes the schema type to a union of decimal and string, so that
special values won't break the feed.

Planning on using the same strategy with infinite dates, since apparently that's a thing.

This should be backwards compatible in most cases, but might be best to leave this one out of any backports.

Release note (bug fix): avro feeds support special decimals like Infinity

67316: opt: fix infinite loop in ColumnStatistics.Less r=rytaft a=mgartner

Previously, `EXPLAIN (OPT)` could hang forever on some queries because
of an infinite loop in `ColumnStatistics.Less`. The column statistics
are sorted for display, which can induce this infinite loop.

This bug has been present in the code for years, but it was only
encountered recently because #64976 made it possible for relational
expression statistics to contain column statistics with overlapping
columns.

Fixes #67041

There is no release note because this bug is not present in any previous
releases.

Release note: None

67331: sql: store plan as jsonb in system.statement_statistics r=maryliag a=Azhng

Previously, we store statement plan as a byte blob column in
system.statement_statistics. As of #65782 we now support JSON
encoding for the plan.
This commit change the column type for plan from BYTES to JSONB
in system.statement_statistics.

Release note (sql change): using JSONB to store statement plan
 instead of BYTES in system.statement_statistics.

67340: opt: fix FoldEqZeroSTDistance with use_spheroid argument r=otan a=mgartner

The `FoldEqZeroSTDistance` normalization rule normalizes expressions in
the form `st_distance(a, b) = 0` to `st_intersects(a, b)`. This
normalization rule is important because it allows an inverted index to
be used for more queries.

Previously, `FoldEqZeroSTDistance` did not handle the third argument of
`st_distance` for the geography overload, `use_spheroid`. The optimizer
panicked when a user supplied this third argument because it attempted
to find an `st_intersects` overload with the three arguments and no such
overload exists.

In addition to the panic, this rule was incorrectly firing in cases
where it shouldn't have.

From the [`ST_Distance` PostGIS docs](https://postgis.net/docs/ST_Distance.html):

> For geography types defaults to return the minimum geodesic distance
> between two geographies in meters, compute on the spheroid determined
> by the SRID. If use_spheroid is false, a faster spherical calculation
> is used.

From the [`ST_Intersects` PostGIS docs](https://postgis.net/docs/ST_Intersects.html):

> For geography, this function has a distance tolerance of about 0.00001
> meters and uses the sphere rather than spheroid calculation.

In summary, `st_distance` calculates on a spheroid by default, and only
on a sphere if `use_spheroid` is explicitly false. `st_intersects`
calculates on the sphere always. Therefore, this rule can only apply for
geography types if `use_spheroid=false` is explicitly passed.

This commit ensures that `FoldEqZeroSTDistance` only matches
`st_distance` functions with geography arguments if `use_spheroid=false`
is included in the function call. The panic is fixed by stripping the
`use_spheroid` argument from the list of arguments used to lookup the
`st_intersects` overload.

Fixes #67235

Release note (bug fix): Two bugs have been fixed which affected
geospatial queries with the `st_distance` function. The first caused
errors for filters of the form `st_distance(g1, g2, use_spheroid) = 0`.
The second could cause incorrect results in some cases. It incorrectly
transformed filters in the form `st_distance(g1, g2) = 0` when `g1` and
`g2` are geographies to `st_instersects(g1, g2)`. This is not a valid
transformation because `st_distance` makes spheroid-based calculations
by default while `st_intersects` only makes sphere-based calculations.


67371: dev: move `dev` back to `cockroach` r=rail a=rickystewart

We don't seem to be getting any benefit out of having it in its own
repo, and having it in the same repo gives us more flexibility.

Closes #67339.

Release note: None

67390: roachtest: fix ruby-pg roachtest r=rafiss a=RichardJCai

Helper file was moved but path was not updated.

Release note: None

67393: roachtest: fix gorm by installing test deps r=RichardJCai a=rafiss

fixes https://github.com/cockroachdb/cockroach/issues/66825

I think this started failing with the move to go1.16.
I added these steps to match what gorm does in its own test suite.

Release note: None

Co-authored-by: Thomas Hardy <thomas.hardy@cockroachlabs.com>
Co-authored-by: Aaron Zinger <zinger@cockroachlabs.com>
Co-authored-by: Marcus Gartner <marcus@cockroachlabs.com>
Co-authored-by: Azhng <archer.xn@gmail.com>
Co-authored-by: Ricky Stewart <ricky@cockroachlabs.com>
Co-authored-by: richardjcai <caioftherichard@gmail.com>
Co-authored-by: Rafi Shamim <rafi@cockroachlabs.com>

---
## [necrohell/github-slideshow](https://github.com/necrohell/github-slideshow)@[00fe1ad561...](https://github.com/necrohell/github-slideshow/commit/00fe1ad561ee76eb96350f5232c178055d19ca6d)
#### Friday 2021-07-09 04:06:08 by Abbas Jaffary

Merge pull request #3 from necrohell/my_slideshow

go fuck your mother

---
## [Armanmalek/songbot](https://github.com/Armanmalek/songbot)@[62dd51942e...](https://github.com/Armanmalek/songbot/commit/62dd51942ebbadf2fe19d0095fd4b1f0a489e4f6)
#### Friday 2021-07-09 04:36:00 by Armanmalek

adding FUCKING ANNOYING ASS NODE CONFIG FUCK THE FE

---
## [electrickiwi23/cwdplugin](https://github.com/electrickiwi23/cwdplugin)@[1af5273f68...](https://github.com/electrickiwi23/cwdplugin/commit/1af5273f6808d24d0a51da1fe95911c84bd1ca92)
#### Friday 2021-07-09 04:53:49 by Kiwi

Fixed typo in /assignteams
Added sound to berserker lunge, quick build, builder tower, TNT line, Fire Bolt, Air needles, Protector armor,
Made Builder tower decay
Added a bit of color to item for paint grenade
Fixed inventory click glitch
Zombie's created by zombie spawn now die after 30 seconds
Blood bolt no longer gains health for non players and you can no longer team attack
Fire bolt's fire now is on the face it hits
Slightly buffed air needle damage.
Reduced time to trigger heal ult from 3 seconds to 2.
Heal ult now charges faster.
Berserker ult now correctly gives kb to sword.
Slight menu item changes.

---
## [DataDog/dd-trace-rb](https://github.com/DataDog/dd-trace-rb)@[84947ca072...](https://github.com/DataDog/dd-trace-rb/commit/84947ca0729bd3fb2e6fd5c47785c32723faf960)
#### Friday 2021-07-09 11:02:07 by Ivo Anjo

[PROF-3425] Bootstrap profiling native extension

My current plan is to use the profiling native extension to:

* Enable use of libddprof, a (native) shared library which allows
  datadog profilers to share common code.

  One of the main advantages of this library is that it will include
  its own profile encoding implementation, which will enable us to
  drop profiler's dependency on the `google-protobuf` gem.
  Right now, we need to tell customers to manually it when onboarding,
  see <https://docs.datadoghq.com/tracing/profiler/enabling/?code-lang=ruby>,
  which is annoying.

* Call Ruby VM APIs that are otherwise unavailable or costly when
  called from Ruby code.

But in this commit, I decided to scale it way, way, way back to
just the basics: add an empty native extension, and the
scaffolding to load and test it.

Thus, I hope that by releasing the next version of dd-trace-rb
with the empty native extension we can to validate the approach,
or otherwise root out corner cases that we may have missed.

Furthermore, I'll point out that if our plans of a "big gem" go
forward, having this kind of non-trivial addition on the gem
is supposed to be the norm, not the exception ;)

---

EVEN SO, because this is a non-trivial change, here's my notes on
possible concerns, in Q&A form:

**Q1**: Will requiring customers to compile a native extension during
        `gem install ddtrace` cause issues?

**A1**: No, because of our dependencies. dd-trace-rb currently has
two dependencies: `ffi` and `msgpack`. Both of those gems rely on
native components, and neither of them (as of this writing) ships
pre-compiled extensions (*except on Windows), as can be seen on
rubygems.org:

* <https://rubygems.org/gems/ffi/versions>
* <https://rubygems.org/gems/msgpack/versions>

This fortunate state of affairs means that customers already need
to have a working setup for building native extensions, and so our
addition of a native extension does not make it any harder for them
to onboard.

**Q2**: Will this cause problems for Windows users?
**A2**: The `ffi` and `msgpack` gem ship precompiled binaries for
Windows, so the reasoning from A1 doesn't apply to these users.

For Windows, it's possible that customers that previously
were getting by without needing an environment to build Ruby native
extensions will no longer be able to install dd-trace-rb.
But:

* `gem install rails` on Windows pulls at least one native
  extension that needs to be compiled, so if you can't build
  dd-trace-rb, you can't install `rails` either
* Recent versions of `msgpack` (since 1.4.2, from 2021-02-01)
  don't provide binaries either. This means that, out of the
  box, even before this change, `gem install ddtrace` fails
  on Windows if you don't have a build environment, because
  rubygems tries to download the latest version of `msgpack`.
  (Rather than picking an older version that ships a precompiled
  build.)

So my assertion is, I don't believe we'll have any customers
that A) run on Windows and B) don't have a setup for building
native extensions.

BUT, if this assertion turns out to be wrong, we have the option
of doing the same thing that `ffi` and `msgpack` do: ship
prebuilt versions of `ddtrace` for Windows users.

**Q3**: Should we provide precompiled versions of the gem right now instead?
**A3**: Precompiled versions of the gem introduce complexity into
our release process (now we have several artifacts, that may
need to be generated on multiple machines); it also may pose
compatibility issues, given our Ruby 2.1 to 3.0 support Matrix.

So, given the fortunate state we're in (see A1), I think we should
avoid them as much as possible.

**Q4**: Why write the extension in C and not Rust?
**A4**: The Ruby VM APIs and headers are written in C. They cannot be
directly used from Rust (e.g. a few things are actually implemented
as preprocessor macros), and thus, to write an extension using Rust,
we'd need to rely on community-built bindings that translate the
Ruby VM headers into Rust.

I've investigated the state of these bindings, and the only two
that are still maintained are:

* https://crates.io/crates/rosy
* https://crates.io/crates/rutie

Unfortunately, there don't seem to be a lot of gems using them and
support for older Rubies, 32-bit OSs and Windows seems spotty.
So... not in a great state at the moment for our usage.

The second issue is that using Rust pushes us into needing to
provide binary builds through rubygems.org -- we definitely can't
assume that customers will have a working Rust compiler around.

We plan on implementing libddprof (the profiling shared library)
using Rust, but because it doesn't need to talk to Ruby VM APIs
(we'll wrap them with some C code in this profiling native extension),
we don't need to worry about bindings, and also we get a bit more
flexibility on binary builds, since we don't need to link to the
Ruby VM from Rust code.

**Q5**: Can you use dd-trace-rb without the native extension?
**A5**: Yes...ish. The extension must get built during `gem install`,
but we handle any issues that may happen while loading it.
So, if you're working on the gem, or the extension gets built
but doesn't load properly, there should be no impact to the rest
of the library; only the profiler will refuse to work.

**Q6**: Will this impact JRuby users?
**A6**: No. We'll skip trying to compile and load the native
extension on JRuby. (Profiling is anyway not supported on JRuby).

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[0e0dab79ed...](https://github.com/mrakgr/The-Spiral-Language/commit/0e0dab79edbcc78977583b6835b918635c5f7534)
#### Friday 2021-07-09 11:05:53 by Marko Grdinić

"11:15am. I slept for a while today. Let me think a bit.

I might have given up too fast yesterday. There are some things that disturb me about how the whole thing went. There is no doubt that just slapping the linear AC on top of the action predictor features does not work. But look at it from another angle - if that does not work why would I expect that GAN trained predictor would work either?

Maybe the correct choice would have been to combine full training of the actor and the action predictor. One step for the first and one stop for the other. What about the value net? Who knows.

It is clear to me that there are clashes in the methods. I thought that things would smoothly work together, but I was completely wrong. For combining the action predictor features, it is clear that things have to be made to work together and that is not good.

11:25am. https://openreview.net/forum?id=cvNYovr16SB
Unsupervised Active Pre-Training for Reinforcement Learning

Abbeel is the second author of this. I'll read this paper.

12pm. Damn it, this is so difficult. Yes, I know the duality gap GAN method, but all this is so complicated. I managed to master tabular CFR and extended to NNs, but I do not have a coherent perspective on how it should all be brought together.

I should learn the lesson from this. If I want to do research, I should focus on that. Maybe if I did that for months and years I'd managed to figure out a coherent framework for combining GAN training with RL.

12:05pm. No, it is not enough. The paper I've linked to is complex, but my own stuff would not be much better.

I have a intuition that prediction training would help things because the brain does it, but I do not have intuition for how to best compose it with RL. I want to do things because the brain does it without actually knowing or understanding how or why the brain actually does things.

12:15pm. In the story of the wizard I am thinking of, he started off with spells to intimiately read the activity of souls before moving on to modifications.

I can struggle and persevere, but could I have come to the present level on my own? By that I mean probably just the current tabular CFR algorithm. Probably not.

And I absolutely can't come anywhere to contructing agents with even animal level intelligence on my present level.

More knowledge would help. More understanding would help. More computation would help. More intelligence would help.

I can't break to 4/5 in ML just yet. What I have now is the quintessential 3/5 - I know how to do naive RL with NNs and not much more beyond that. I do not know how to augment it with unsupervised learning and deep exploration. Not that there aren't hints pointing in that direction, but that is a far cry from having a coherent mental framewrok of how things shuold work.

12:30pm. I am fighting on too many fronts. Maybe the hints I have are enough to speculate, but they aren't enough to dive in.

Instead now that I've come to this point how about I firmly set my foot down and just fight economically?

I can see that once I put in the transformers, trying to make unsupervised GAN training work with it would be hugely time consuming.

It is not just a matter of programming, it is clear enough how long it takes me to run the experiments. To get good data here, Leduc would not be enough, I'd have to run it on Holdem for a lot longer.

12:35pm. Algorithms are derived from the understanding of structure. I do not understand the problem of optimizing high dimensional objects so it is no wonder I can only do this much.

I am sure that the actual algorithm that bridges all the gaps will be profound. I do not feel it will be particularly complex. It will certainly be a lot simpler than piling hack after hack in hopes of getting things to work.

12:40pm. I am not that desperate for it just yet. It is fine if I could reach the appex of the present mountain.

For all I know, maybe just transformers would be enough to crack Holdem even without a need for a curriculum. And if not I'll just do the curriculum.

12:45pm. I need power. 3/5 should be enough to crack any of these simple betting games. I should not lose sight of my present goal.

Crack these games, make money off them, get the neurochips. That will allow me to train on 1,000x more rounds in the same amount of time that I can do now. I should do that, and completely raze the online gambling dens to the ground using my superhuman gambling machines.

Maybe this will take me all of my time, and I won't have time to play around with GANs and research new algorithms. If so that is fine. In the timeframe I have set out, there is not much time for me to do any great research myself.

12:50pm. Succeeding at what I've set out to do here would be enough of an accomplishment on its own. Eventually, the neuroscience guys will stop being useless and figure out what the brain itself is doing. No way can I do that with the sheer power of my imagination.

I have no doubt that much better, lower variance ways of doing what I am trying to do now will be found out.

The depths of skill and capability that I have now cannot be compared to what will be possible in the post-Singularity era.

12:55pm. I am just a human, the power of my imagination is not enough to make the world turn where I want it.

1pm. I do not have a great wellsprint of wisdom to draw out the relevant algorithms.

It would be for the best that I focus on stealing them instead. Right now I am just competing against the world and nature instead of being smart about it. If I had a billion dollars and want to figure things out at all cost, I'd put that money into brain recording.

1:05pm. At any given point in time, there should be ways of making money of existing ML and programming technology and I should just focus on that. Today board and betting games are what is viable. Tomorrow, it will be games like Dota and Starcraft. I need to live in today."

---
## [d15ky/first_flutter_app](https://github.com/d15ky/first_flutter_app)@[9f6409c305...](https://github.com/d15ky/first_flutter_app/commit/9f6409c3054bd95956319eae6f504670e73da324)
#### Friday 2021-07-09 12:27:55 by Oleksii Martynovskyi

Timer added, WIP. Several issues:
1) Timer is not connected to current task (it's global for the list view of tasks). Use database to avoid? Local List/Map? Keys?
2) Too many setState calls. Probably, needs to be changed to Provider for the task list view and then be updated accordingly. One thing to investigate is FutureBuilder which takes data from db working along with provider. Is it even possible to make it stateless? How does it work anyway?
3) Nothing saved to database. However, database structure is ready.
4) home_page_screen filename is too generic and file itself is huge. Task list, task tile, timer might need to be moved elsewhere.

Design sucks but that bothers me the least atm :)

Also, since it's already a huge commit message, I'll share some of my thoughts on flutter and mobile dev in general:

Messy and "workaroundly". Too many prebuild ways to do the same/similar thing. Too much like frontend development. No foundations, no alignment on code logic style — every framework does it whatever way it likes. I've taken a look on several fairly popular libraries code source and each was written in different code style. For one I had most problems with (sqflite) I didn't even succeed to understand how it works and why it can't execute more than one SQL statements per call and how to make it just pass whatever I write right to SQLite engine instead of processing it by itself so I had to use another library just for that one particular thing. Moving slowly and feeling dissapoitment mixed with disguist. However, community is ok, I guess.. Flutter team needs to make a good comprehensive tutorial on Flutter instead of relying on community. That's the main thing Flutter lacking in my opinion: a quick language capabilities walkthrough on an example of building an app (which actually doing something and not just showing the UI). Something like Boring Development show but much less explanatory and therefore long. If someone doesn't understand, they can always turn to Boring show in order to listen to explanations and thinking behind.

---
## [jappeace/intersperse](https://github.com/jappeace/intersperse)@[a080dd278c...](https://github.com/jappeace/intersperse/commit/a080dd278cc4204e919d63997c27d666409bd02b)
#### Friday 2021-07-09 13:27:37 by Jappie Klooster

Import the template

Initial template

Disable tests as they don't work for some reason

Initial commit

run is broken and sdist should update cabal

Some more warnings

Ship license

Shell regeneartes default.nix before doing any cabal stuff

Now detect native dependencies

yes this is the whole point of using nix..

Better project description

mtl is better for libs

Use default extensions

watch more files

Stylish haskell works now with default lang imports

Now we can handle dependnecies, but lost cabal as build input

Get rid of dependency that we can manage

todo items

fix sdist

don't set a default github, it's wrong and should be updated on

publishing

Figured out how to unfree

Remove pin to seperate file

Update pin

REMOTE BUILD FARM FRAMEWORK

Also watch pin

HAX for dir selection

Better pin syntax, upgrade pin

Add ghcid and a test suite, Add overriding shell cabalities

Better readme

Even better readme

Add cabal install too shell

Independent nix-shell for update, more robuust

Add etags to ghcid

Use a seperate stable hpack shell for generating default.nix

This breaks the dependency upon default.nix for generating
it in the first place.

The ability to run is nice as well

Add all badges so we can just remove whatever neccisary

(branding by default, which is good because I'll definitly forget).

Add ghci command using the cabal repl

Allow easy building with travis

Adding a badge

Move build status away from branding

Excplicitly mention file name

Move badge next to the other ones

Link badge to builds

Add discord link

Add cachix support for faster builds!

Add checks for formattign

Fixup hlint issues

Don't depend on pin for cachix, it won't get the env variable & slow

Maybe we need findutils to find stuff

Explain why these shells

Explain what this shell is doing

Better description of what this does

This should fix britanny issue

Add brittany management spells

Apply formatting everywehre

Add autoamtic hlint refactor

Bump year

Add haddock hackage

Add gitignoreSource

Fix library tool depends

Use callCabal2Nix and move nix expressions to subfolder

Make logos smaller

Simplify setup for testing, make ghic work reliably

Give readme some more love

Generate etags from hpack shell

Don't need that send script anymore

Haven't used this in ages

Add more rigor to sdist

Fix hercules CI sha

Add changelog

Add testing against various ghc versions for CI

Reduce the amount of supported compilers

Add rudementary description of how to use the template

Better describe templates in git idea

LInke to project example

Add github actions for more lazy building

Make template checklist

Add github actions badge

Fixup readme checklist

Add bundle support

Upgrade nix install blah

Upgrade pin

Fix ci build

Add stack based ci.

I can't test this locally so on the branch it goes.

---
## [sengyh/unsw_handscraper](https://github.com/sengyh/unsw_handscraper)@[069b5fc80b...](https://github.com/sengyh/unsw_handscraper/commit/069b5fc80b0f6f7d21d0a9530f31612e9bade6ed)
#### Friday 2021-07-09 15:09:51 by Seng Yong Hoo

program scraper completed
yes, every fucking edge case has been covered. i shit you not
babied this program until 1 in the morning

---
## [LumberKing/Tianxia](https://github.com/LumberKing/Tianxia)@[8072511c8c...](https://github.com/LumberKing/Tianxia/commit/8072511c8c8202df69e2d43d890f8cea69c4fbe3)
#### Friday 2021-07-09 15:24:40 by Silversweeper

Balance/optimization/polishing (part 1 of ???) + Imperial Family additions (part 1 of ???)

Artefact spawns:
- Changed the Sarira to spawn for has_dharmic_religion_trigger = yes characters, rather than indian_group characters, which should make it less likely to show up in weird places.
- The Heirloom Seal of the Realm is no longer guaranteed to spawn after 936 (TODO: Re-discovery).
- The Seven-Branched Sword now spawns for the character owning c_yamato rather than the Tenno, seeing as it is stored in Isonokami Shrine in Nara Prefecture (and also isn't part of the Imperial Regalia).
- Sugari no Ontachi now spawns for the character owning c_ise rather than the Tenno, seeing as it is stored at Ise Grand Shrine (and also isn't part of the Imperial Regalia).
- Simplified the logic for the Tenno's artefact spawns.
- Fixed issue where extra copies of The Tale of Genji spawned instead of The Pillow Book.
- Renamed the Murasaki Shikibu Diary Emaki to the Murasaki Shikibu Nikki Emaki.
- The Murasaki Shikibu Nikki Emaki is now more likely to spawn for women.
- The Murasaki Shikibu Nikki Emaki no longer is more likely to spawn for Minamotos.
- Cura Si Manjakini should now spawn for the holder of c_temasek in 1299 or later regardless of their primary title.

Artefacts:
- Changed the Sarira to only be usable by Buddhists rather than all Eastern (indian_group) characters, since that's more accurate.
- Fixed incorrect "buddjist" flag on the Sarira.
- Changed the Tooth of Buddha to be Buddhist rather than indian_group.
- Lowered Kusanagi's Japanese/Yamato opinion boost to +2.
- Lowered Yata no Kagami's Japanese/Yamato opinion boost to +2.
- Lowered Yasakani no Magatama's Japanese/Yamato opinion boost to +2.
- Lowered Sugari no Ontachi's Japanese/Yamato opinion boost to +2.
- Sugari no Ontachi is no longer incorrectly flagged as part of the Imperial Regalia of Japan, and can once more be stored in Great Works (if you want to).
- Ryukyuan and Reformed (non-Dogmatic) Ryukyuan characters can now use and be gifted the Totsuka-no-Tsurugi.
- Ganjiang and Moye can now be used regardless of culture and religion.
- The Seven-Branched Sword is now usable by everyone that's not the Tenno (he should of course use the Imperial Regalia instead).
- Kogarasu Maru no longer gives Shinto opinion.
- Dojigiri no longer gives Shinto opinion.
- Onimaru no longer gives Shinto opinion.
- Mikazuki no longer gives Shinto opinion.
- Odenta no longer gives Shinto opinion.
- Lowered Juzumaru's Buddhist opinion boost to +5.
- Juzumaru no longer gives Shinto opinion.
- The Dragon-Phoenix Blade now gives vassal opinion rather than general opinion.
- Lowered the Chinese opinion boost given by the Dragon-Phoenix Blade to +5.
- The Heirloom Seal of the Realm no longer gives vassal opinion.
- Various religious opinion boosts from the Heirloom Seal of the Realm are now +5.
- The King of Na Gold Seal's Chinese opinion boost is now +5.
- Lowered the Cura Si Manjakini's vassal opinion boost to +5.
- Hellenic and Reformed Hellenic characters can now use the Cura Si Manjakini (if Malay, Greek, or member of an Alexander bloodline).
- Sang Sapurba's bloodline now makes you eligible to use Cura Si Manjakini.
- Lowered Vijaya's Hindu opinion boost to +5.
- Gram now gives +1 combat rating.
- The Ornate Holy Symbol artefact can now be gifted to someone with the same religion rather than true_religion, as it otherwise reveals someone's secret religion.
- Lowered the PCS given by most Tianxia weapon artefacts; Kusanagi, Vijaya, Thuan Thien, the Tenka-Goken, and the Hungering Blade are now +20, rest are +16 or less.

Bloodlines:
- All Chinese Imperial bloodlines (including pretenders) now have a better picture.
- All historical Tianxia bloodlines (and their generic versions) now have
- Removed easier Shogunate creation from the Hachimantaro bloodline; it had rather too much going for it.
- Various regency bloodlines no longer give Shinto opinion.

Buildings:
- Ainu pagans (reformed and unreformed) can now build the tb_defensive_fortifications_NUMBER buildings in tribal holdings. Might also be added elsewhere as part of the religion rework.
- Cleaned up commented out "empty" tribal pillars for Tianxia pagans.
- Malayo-Polynesian castle buildings should no longer be deleted on holder culture change due to not being Japanese castle buildings.
- Malayo-Polynesian tribal buildings should no longer be deleted on holder culture change due to not being Japanese tribal buildings.

Combat tactics:
- Moved the glorious Ainu tactic to a new file and deleted the vanilla file since it was unnecessary to override it.

Council patterns:
- Cleaned up duplicate 04_malcontent_pattern.

Cultures:
- Minor cleanup in 01_cultures_soh and 03_cultures_mr.
- Set Buryat culture as used_for_random = no, seeing as it currently doesn't exist anywhere.
- Deleted the Kashmiri culture, seeing as it has been irrelevant since 2.8.
- Set Papuan culture as used_for_random = no, seeing as it's offmap until/unless the Treasure Fleet zails east/SRI happens and is unlikely to end up landed even when those things happen.
- Set Papuan culture as seafarer = yes. They'll need all the help they can get.

Death text:
- Updated vanilla holy warrior condition, including fixing some vanilla issues.

Execution methods:
- Improved on the logic for several methods, e.g. allowing elephants to be used in some of our areas.

Governments:
- Minor cleanup.
- Shoguns can no longer get the roman_imperial_government government type, seeing as that breaks stuff.

Heir text:
- Updated vanilla holy warrior condition, including fixing some vanilla issues.

Minor titles:
- Adjusted which titles are(n't) available to Tianxia characters slightly.
- Removed old Chinese eunuch minor title; it's not been relevant for a few versions...
- Changed Council Eunuchs to no longer require high Learning. Should make it more likely that eunuchs sent as tribute can be appointed.
- Removed irrelevant Shogun and Shikken minor titles.

Nicknames:
- Improved logic for a few vanilla nicknames relevant to us.
- Improved logic for a few of our nicknames.

History:
- Added early/legendary emperors of Japan.
- Added some family members of the above, e.g. Empress Jingu's patrilineal ancestors.
- Added a certain someone from the Moon.
- Added some missing children of emperors prior to Tenji.
- Fixed some dates for emperors (mostly issues arising from the lunar calendar and reigns for early ones).
- Emperor Juntoku is now properly set as the father of his children, as they weren't his brother's.
- Fixed some assorted issues with the Imperial Family.

Other
- Apparently restored a bunch of files that *somehow *didn't get committed the last time. No idea how they didn't get committed, seeing as they were definitely present on my computer...

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[ade023ebae...](https://github.com/mrakgr/The-Spiral-Language/commit/ade023ebaed184901922917aecf487713decdf87)
#### Friday 2021-07-09 16:48:54 by Marko Grdinić

"1:50pm. Done with breakfast. Let me chill a little.

2:30pm. Somebody posted Fabiniku on Nello and I am catching up.

It is so difficult. I can see the hints, but trying to take a step forward and reasoning out what the improved algorithms are is like trying to move a mountain.

The upside dwon RL experiment killed my aspirations of going to 4/5. Just having good features is not enough. Having GAN training will not be enough. I need to figure out how to compose RL with unsupervised learning.

I do not have any good ideas. I want to say that iterating training the actor and the critic and the state predictor would be enough, but it was not for the action predictor.

Letting the gradients flow all the way through might be a solution. But it feels like a coop out.

No, I won't accept this kind of framework. It would be a different story if the action predictor idea worked well, but it gives me a window into how the state predictor idea with the GAN training would end up.

2:40pm. I've made up my mind. Maybe it is a mistake to not spend time on it here, but I am going to demand a piece of insight more before I'll consider investigating it.

I want a plan how to realistically compose RL and unsupervised learning before I try to improve my methods. This will be for breaking into 4/5.

5/5 would be completely scalable, stable and low variance learning algorithms regardless of the game. They would be something capable of training an intelligent mind from the ground up.

It could be implemented on today's computers if we knew what they were.

2:45pm. Mhhh, let me chill a bit more. It does not seem like I will be doing much today, but deciding to drop GANs, means I only have to master transformers and nothing else before my ML journey is done. There is a lot less work to tackle and as a result the reward/risk ratio feels a lot more favorable. I feel more motivated.

2:55pm. But at the same time I feel regret. I am sure that having to rely on either other or nature to give me the secrets of intelligence will gnaw at me as I go along.

3pm. Without a doubt, figuring out the secrets of intelligence is the most important thing in the world. And in the past 6.5 years, my inability to do it has not changed.

Not being able to do the things that are important. That is means to be inferior. I am just whitling away the time, waiting for the chance to come to me. Is that how I live?

3:15pm. Now that things have come to this point, I've thought of an old idea. When I studied the Hopfield nets, I thought that in addition to the inputs, I could associate a reward to it before storing it in the buffer.

And this would in fact suffice to do RL at the linear level. It could be pretty good.

But for it to be really useful, it would have to be generalized into being a hierarchical rather than a linear method. Then it would be possible to do everything through associations.

The principle of intelligence being in this direction sound a lot more likely than trying to make backprop scale. Making Hopfield nets hierarchical and having them do compression, it does seem like a viable path.

But Hopfield net comes out of the field. I have no idea how the linear updates could be extrapolated to hierarchical ones. It is not like backprop where you could put in any differentiable structure and it would give back its learning rules.

The vision I have in mind would be the immutable counterpart to backprop's mutation optimization.

3:20pm. Compared to NNs, there are different principles at play in Hopfield nets.

3:25pm. What does all of this have to do with Hebbian learning. I already can't compose two different methods to learn the actor.

Just how is Hebbian learning composable with whatever else goes on inside the brain?

Composing all the different possible way of doing learning, just how is it possible?

3:30pm. Well, I am a programmer, so I know well the power of immutability in enabling composition. I always found it strange how backprop violates every sound prinicple of composition with its mutation.

Just for the sake of the argument, how would a method that only adds connections look like?

Would that be something like a random forest - I do not know anything about those methods.

3:35pm. https://www.youtube.com/watch?v=v2GRWzIhaqQ
Meta-Learning through Hebbian Plasticity in Random Networks (Paper Explained)

Let me watch this for a bit, and then I will study random forest methods for a bit

3:55pm. Yannic is actually quite good at explaining. Though I already know most of what he is talking about.

4:40pm. https://www.youtube.com/watch?v=BhUWvQmLzSk
ReBeL - Combining Deep Reinforcement Learning and Search for Imperfect-Information Games (Explained)

Let me take a break and then I'll watch this.

Yeah, I had enough of hardship. The kind of math grasping AI requires is way beyond my ability or probably any human's. That is how it feels like. Step on the path of evil and steal the insight from God himself. That is the way to go here.

I should cheat and plow a lot of money into that. And to do that, I need to make it first.

I have my trading skills. And I'll soon have the agent once I finish the transformers.

4:45pm. I think I am too arrogant. Maybe I do not understand the soul of technology itself. Maybe in the future, the Inspired could carry everything on their own individual shoulders. But being a human means having to borrow the power of other humans to get ahead.

I should make my resolve to do that.

When I trained the Holdem agent and it failed I went off on a tangent trying to grasp a better algorithm. It is never that easy.

The only really good thing that I've done is figure out the semi tabular Q updates. And the cube and square activations. And bringing in CFR.

But those things were long hanging fruit and it made me arrogant.

5:05pm. Let me watch the Rebel vid while I have lunch. I should have checked out this paper before but I am reluctant to bring in tree search.

https://www.youtube.com/watch?v=mCldyXOYNok
Combining Deep Reinforcement Learning and Search for Imperfect-Information Games

Actually, let me watch this vid by Noam Brown directly. Yannic's explanations are too droning and I know most of it already.

5:35pm. https://youtu.be/mCldyXOYNok?t=855

It might be interesting to seriously consider search. I never thought about it seriously because it did not make sense to me in imperfect information games. But who knows, maybe there is a way to make a gain there.

5:40pm. https://youtu.be/mCldyXOYNok?t=1092

This is an interesting idea, but that means that the player has to output action probabilities for 52*51 possible cards. Factoring in the amount of actions for a 10/20(1000) games is something like ~980*52*51=2.5M. Yikes.

6:10pm. I admit the talk by Brown did fire up my imagination. The notion of giving the player belief states over the cards instead them directly is worth keeping in mind. It might be a way of countering the crazy variance of regular Holdem. But the amount of extra memory this would require is also crazy.

Let me just check out what fictitious play is.

https://youtu.be/mCldyXOYNok?t=1092
Fictitious Play and Smooth Fictitious Play in Repeated Games

What a snoozefest.

6:25pm. Forget FP. It is super complicated and I do not feel like studying it. Rebel is an interesting idea, but it has its flaws.

If the algorithms I have now were sound I could have just let it train on Hodlem for however long and had it improve. But 3/5 is always short of grasping the world.

I am going to go with my own plan, put in the transformers and then use a curriculum. If it can learn to read hands properly, it will be able to learn to play properly as well after that. In theory there should be no reason why just training it on the game straightforwardly should fail. I just need to find the right architecture.

6:30pm. Actually now that I think about it more deeply, updating the belief states is not that easy. I mean how would one partition the distributions so that the opponent and the self do not believe they are holding the same cards? I'd have to think about the Bayes theorem more in depth for that.

Forget it. For the sake of getting truly superhuman performance I'd want to train the net with a full spectrum of actions eventually. It is a certainty that in the Rebel paper they restricted them otherwise it would have been too expensive to train.

6:35pm. Let me close here for the day.

I am going to try an push ahead with transformers tomorrow. I will bet everything on them, and if both transformers and the curriculum idea fall flat I am not sure what I will do then. Maybe I'll abandon the goal of making money through RL, and play with GANs while working a regular job on the side.

I won't let it come to that.

Even on full holdem, I can do a trick like just learning on the last episode until hand reading is learnt. And then I would be able to progressively extend from there.

If in that situtation it fails to learn then I can consider looking at the overall architecture and signSGD as an optimizer all over again.

6:40pm. But I think the transformers should do the trick. There is a reason why they and not MLP are the dominant language models right now. And that reason is the same as why the MLP is dying on Holdem.

I need to push forward with this. Tomorrow, I swear I will start playing around with transformer layers. Bit by bit, I'll go from there and increase my familiarity.

6:45pm. This is the right path. Take in the evidence and narrow down the goals until they are sure to succeed. If they fail, then that is a powerful signal to change directions.

Let me have some fun here. Tomorrow, I am going to press into it. I will not let this go by without a fight."

---
## [piotrcurious/arduino-ni-mh-charger](https://github.com/piotrcurious/arduino-ni-mh-charger)@[2c6175f6b7...](https://github.com/piotrcurious/arduino-ni-mh-charger/commit/2c6175f6b7bd5e0029d41f8928f9d9bec50b0a04)
#### Friday 2021-07-09 19:44:23 by piotrcurious

added dual thermistor version

This version uses charges single battery. 
It uses dual thermistor setup - two for battery and two for ambient temp.
Temperature is averaged, reducing influence of ADC noise, drift, etc. 
it uses two layers of kalman filter, but it's still simple kalman so no proper model or nonlinearity is factored in. 

This is work in progress and in theory dual channel operation should be still supported, still it's brutally chopped off here and there. 
So far I've noticed that one channel influences readings of the other via supply voltage.
In future I plan to develop version not reading voltages at all (maybe only current) , and using transistor on minus side of battery 
Voltage reading is not really usefull for charging, temperature is enough. 
Transistor on minus side allows better protection against reverse polarity battery insertion. 

This version is transition version, done quickly because I have no time for it yet, but I needed reliable device to charge small batteries. 
It works very good . 
Some hacks are implemented to double sensitivity - theshold of Tslope (over 0.005 , set in weird place in code)
Also stabilisation period at start of charge got improved - not only Tslope is muted, but also dT is silenced during period of fan spinning and equalising temperature. 
It still uses old circuit, though I updated this sketch to different values of components . They are not optimal - just found in junk box. 

Also added voltage debug - use it to tune Your voltage divider for Vbat , and Vcc constant  - just throw any resistors and Vcc voltage regulator,
then connect decent voltmeter to measure voltage on A0 and A1 pins and voila. 
You need to adjust pwm_level in the debug code directly - sorry. In future it will react to knob position to make things easier. 

Also note NTC skew code is bit iffy, I usually lock up KALMAN_AUTOSKEW_FREEZE and probe values by hand - otherwise it oscillates too much. 
if You manage to go below 0.5C temp difference (10bit ADC is Really the limit) it's good. 
In future i'll add better code to probe thermistors without ADC - bit banging to discharge and measure rate of charge of capacitor. 
It is way slower, but seems only sane method to go down 16bit of resolution and THEN trying to filter out noise.

---

# [<](2021-07-08.md) 2021-07-09 [>](2021-07-10.md)

