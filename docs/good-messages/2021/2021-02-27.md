# [<](2021-02-26.md) 2021-02-27 [>](2021-02-28.md)

2,040,792 events, 1,156,965 push events, 1,664,734 commit messages, 105,886,453 characters


## [GerHobbelt/mupdf](https://github.com/GerHobbelt/mupdf)@[d81bc8920a...](https://github.com/GerHobbelt/mupdf/commit/d81bc8920acf53f196ea1145b5abe2f2a52b3ad2)
#### Saturday 2021-02-27 00:23:57 by Ger Hobbelt

complete fix for the run-away outline loading for https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4835977/ and other PDFs which have arbitrary deep outline levels of single nodes with same-named single children.

Notes:

we check both parent AND grandparent for title, page and URI identity before we decide to 'ignore' the current single node, as it would only add another *useless* outline level.
We check both parent AND grandparent to prevent any possible match with *sane* PDF outline structures: some *legal* PDFs have outline structures where the parent and *first child* have the same title, page and (internal) uri -- these PDFs usually have multiple children at that second level, but we are better safe then sorry while we 'ignore' outline nodes.

Added benefit of this fix/tweak is that both the call stack and exception stack depths are significantly reduced. Nevertheless, we decided to keep the (exception) stack adjustments made in the previous commit.

The result is a reasonably "sane" outline, while some of the "insanity" remains visible, but that's okay in my book: the user/reader can still observe a hint of trouble in the original PDF that way, without run-away outlines / viewers (Foxit Reader shows it like it is which makes for a very weird outline view side panel; Chrome also doesn't seem to like this sort of thing as the CPU was cooking for a while before rendering the PDF pages...)

N.B.: of course one can still game the system with specially crafted attack PDFs, e.g. one where the titles for parent and child are alternated to thwart `are_outline_nodes_equal()` but this at least cleans up after crufty PDFs which have been found in the wild.

# Conflicts:
#	source/pdf/pdf-outline.c

---
## [ccodwg/Covid19Canada](https://github.com/ccodwg/Covid19Canada)@[58fb4c6628...](https://github.com/ccodwg/Covid19Canada/commit/58fb4c662844a2afb474d74771ccdd96e16fc2c9)
#### Saturday 2021-02-27 03:10:52 by Jean-Paul R. Soucy

New data: 2021-02-26: See data notes.

Revise historical data: cases (ON, PE, SK); mortality (AB, ON).

Various BC sources contradicted each other today, our numbers reflect those of the provincial CSV.

Note regarding deaths added in QC today: “11 new deaths, for a total of 10,372: deaths in the last 24 hours, 8 deaths between February 19 and February 24, 3 deaths before February 19,” We report deaths such that our cumulative regional totals match today’s values. This sometimes results in extra deaths with today’s date when older deaths are removed.

Recent changes:

2021-01-27: Due to the limit on file sizes in GitHub, we implemented some changes to the datasets today, mostly impacting individual-level data (cases and mortality). Changes below:

1) Individual-level data (cases.csv and mortality.csv) have been moved to a new directory in the root directory entitled “individual_level”. These files have been split by calendar year and named as follows: cases_2020.csv, cases_2021.csv, mortality_2020.csv, mortality_2021.csv. The directories “other/cases_extra” and “other/mortality_extra” have been moved into the “individual_level” directory.
2) Redundant datasets have been removed from the root directory. These files include: recovered_cumulative.csv, testing_cumulative.csv, vaccine_administration_cumulative.csv, vaccine_distribution_cumulative.csv, vaccine_completion_cumulative.csv. All of these datasets are currently available as time series in the directory “timeseries_prov”.
3) The file codebook.csv has been moved to the directory “other”.

We appreciate your patience and hope these changes cause minimal disruption. We do not anticipate making any other breaking changes to the datasets in the near future. If you have any further questions, please open an issue on GitHub or reach out to us by email at ccodwg [at] gmail [dot] com. Thank you for using the COVID-19 Canada Open Data Working Group datasets.

- 2021-01-24: The columns "additional_info" and "additional_source" in cases.csv and mortality.csv have been abbreviated similar to "case_source" and "death_source". See note in README.md from 2021-11-27 and 2021-01-08.

Vaccine datasets:

- 2021-01-19: Fully vaccinated data have been added (vaccine_completion_cumulative.csv, timeseries_prov/vaccine_completion_timeseries_prov.csv, timeseries_canada/vaccine_completion_timeseries_canada.csv). Note that this value is not currently reported by all provinces (some provinces have all 0s).
- 2021-01-11: Our Ontario vaccine dataset has changed. Previously, we used two datasets: the MoH Daily Situation Report (https://www.oha.com/news/updates-on-the-novel-coronavirus), which is released weekdays in the evenings, and the “COVID-19 Vaccine Data in Ontario” dataset (https://data.ontario.ca/dataset/covid-19-vaccine-data-in-ontario), which is released every day in the mornings. Because the Daily Situation Report is released later in the day, it has more up-to-date numbers. However, since it is not available on weekends, this leads to an artificial “dip” in numbers on Saturday and “jump” on Monday due to the transition between data sources. We will now exclusively use the daily “COVID-19 Vaccine Data in Ontario” dataset. Although our numbers will be slightly less timely, the daily values will be consistent. We have replaced our historical dataset with “COVID-19 Vaccine Data in Ontario” as far back as they are available.
- 2020-12-17: Vaccination data have been added as time series in timeseries_prov and timeseries_hr.
- 2020-12-15: We have added two vaccine datasets to the repository, vaccine_administration_cumulative.csv and vaccine_distribution_cumulative.csv. These data should be considered preliminary and are subject to change and revision. The format of these new datasets may also change at any time as the data situation evolves.

https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/#c47900

Note about SK data: As of 2020-12-14, we are providing a daily version of the official SK dataset that is compatible with the rest of our dataset in the folder official_datasets/sk. See below for information about our regular updates.

SK transitioned to reporting according to a new, expanded set of health regions on 2020-09-14. Unfortunately, the new health regions do not correspond exactly to the old health regions. Additionally, the provided case time series using the new boundaries do not exist for dates earlier than August 4, making providing a time series using the new boundaries impossible.

For now, we are adding new cases according to the list of new cases given in the “highlights” section of the SK government website (https://dashboard.saskatchewan.ca/health-wellness/covid-19/cases). These new cases are roughly grouped according to the old boundaries. However, health region totals were redistributed when the new boundaries were instituted on 2020-09-14, so while our daily case numbers match the numbers given in this section, our cumulative totals do not. We have reached out to the SK government to determine how this issue can be resolved. We will rectify our SK health region time series as soon it becomes possible to do so.

---
## [makingglitches/CensusScripts](https://github.com/makingglitches/CensusScripts)@[378339beef...](https://github.com/makingglitches/CensusScripts/commit/378339beef20546b4ff849bb1b5c78308eadf578)
#### Saturday 2021-02-27 03:49:21 by Magical Marvelous MADMADMAD Mister Mim !

Grabbed PFAF miner again since these idiots deleted this apparnetly along with the world before and keep backing me into a corner they created by gradually stealing years of my life to begin with without valid reason in the first place simply because my piece of shit father was a garbage chomo piece of shit connected to them.

---
## [CarloLj/software-product-sprint](https://github.com/CarloLj/software-product-sprint)@[e084483296...](https://github.com/CarloLj/software-product-sprint/commit/e084483296bd79ce62b9a248029dec0fb5049536)
#### Saturday 2021-02-27 10:49:14 by Carlo Lujan

Newest version, index page finished, about me finished, added social media sticker at the middle left with animations, just a very cool uptate
It just need contact page to actually submit the form, add photos what I love (optional) put css all over the projects page.

---
## [mawenxi2112/Studio-Project-4](https://github.com/mawenxi2112/Studio-Project-4)@[c68cc7c19a...](https://github.com/mawenxi2112/Studio-Project-4/commit/c68cc7c19a2801885c24e660ba631a2c4634b328)
#### Saturday 2021-02-27 10:53:25 by mawenxi2112

Added a fucking shit hacky way to fix coin and health piock up

---
## [JCPasillas/DangerVeryClose](https://github.com/JCPasillas/DangerVeryClose)@[67486224fb...](https://github.com/JCPasillas/DangerVeryClose/commit/67486224fb78cde1a99473ae1aac2b7ec62ac485)
#### Saturday 2021-02-27 12:54:16 by punaauia18

Ranged/Shooter AI version 0.1

*****Notes:
1) I was initially making it a child class of our original AI but shits came up and i ended up dropping it all and start over using a blackboard&behavior tree and two blueprints (one for the character and one for its controller)
2) i needed to add the animation starter pack to the project to get a shooter AI animation already set up
3) I'll be adding comments to everything soon (probably Sunday evening)*****

Current workflow:
Right now the AI goes to random locations on the map until it sees the player. Once it sees us, it shoots at us until he doesn't see us anymore. When he can't see us, he goes to a search location which is computed using the player's last seen location. And it basically keeps searching until it sees us again etc

It can receive damage and die but can't inflict damage nor kill the player yet. Also, it shoots accurately every single time.

Improvements I'll be implementing this week:
- implement damage player behavior
- make the AI maintain a range from the player
- make the AI shooting skills less accurate (make it not shoot at us perfectly every time)

---
## [copperwater/xNetHack](https://github.com/copperwater/xNetHack)@[3129a6f2b4...](https://github.com/copperwater/xNetHack/commit/3129a6f2b4b2b833e398caa57ea7424e0d2b31b3)
#### Saturday 2021-02-27 15:19:36 by copperwater

Merge remote-tracking branch 'upstream/NetHack-3.7' into 6.0-savebreaking

The Vanilla Merge From Hell, February 2021 Edition.

There were an astronomical number of conflicts, but since it's only been
2-3 months since the last vanilla merge, not a lot of them were
difficult conflicts. Most of these were conceptually simple, if
time-consuming, to resolve. They fell into a few categories:

1. Moving away from K&R FDECL-style function declarations, which
   conflicted on every function whose signature I've touched at any
   point.
2. The new monster gender system.(Again, they largely didn't *logically*
   conflict with xNetHack features. Good thing I never tried to create
   or port a different implementation of monster gender.)
3. The original getobj patch created by FIQ that xNetHack pulled in,
   which is finally being ripped out and replaced with the getobj
   refactor I created and got merged into vanilla.

Other conflict notes:
- The MG_STAIRS and MG_PEACEFUL constants are changed to keep the
  vanilla MG constants together. This shouldn't really affect anything.
- Patchlevel bumped to 6.0.0-0 and development status changed to BETA.
  This commit is NOT the actual 6.0 release, hence it being in beta
  status.
- Revert K2's externifying of rank() - this was a leftover from the
  former_rank code that was a precursor to ebones.
- Callback functions related to query_objlist(), which the getobj patch
  changed to return int, are reverted to return bool.
- Revert mkstairs to vanilla, with an unused mkroom* argument.
- xNetHack-specific parts of the getobj patch, such as thiefstone_ok()
  and the getobj call that used it, are revised into the new getobj
  system.
- I still don't like "amorous demon" as a monster name, but since it's
  the PM_ constant it's not worth attempting to change.
- DUMPHTML removed in config.h; it is now not always-on. DUMPLOG is
  still always on.
- The fuzzer logging functions are changed to use const char* due to
  stricter gcc warnings.
- In order to make it compile, I had to port several changes to html
  dumplog code that were added to the 370-hdf branch already. Example:
  html_print_glyph instead of html_dump_glyph. This is not necessarily a
  full port of html dumplogs, and they may be broken.
- sentient_arise() lacked any declaration; I added this and made it
  static.
- Fixed a few bugs that arose from warnings, such as shadowed variables.
- Had to declare read_simplemail as static and forward declare it. Noted
  this to the devteam and they've already fixed it by the time I'm
  committing this merge, so that will be a conflict to clean up in the
  future.
- add_mon_info() uses the neuter monster name; passing down the actual
  name seen or typed by the user which might be a gendered version is
  too difficult. (It's very possible for a typed name, but not if using
  the / command).
- The 'silent' argument is dropped from able_to_loot, changing it back
  to vanilla, because the only place silent was TRUE was in code for the
  getobj patch interacting with floor containers, which has been
  deleted.
- Found a bug in the getobj patch I submitted to the devteam which has
  been merged. Latent in vanilla, not fixed as of this commit so I can
  send them a patch to fix it upstream.
- Setup for struct ebones still determines its role based on comparing
  the male names urole.name.m to roles[].name.m. It doesn't appear that
  a neutral name was added to the role struct.
- Vanilla has implemented global visibility for monster wounds, with
  less interesting messages. I have removed most of their
  implementation:
  - Monster injury status will show up in the death message like for
    vanilla, though the adjectives are xNetHack's. Hallucinatory
    statuses are suppressed in the death message.
  - Only healers are able to see the injury status in farlook and get
    messages in-game. A key goal of the wounds patch was to give healers
    a nice role benefit, so vanilla giving this to everyone didn't align
    with that.
  - Farlook wounds print like vanilla's (not as a comma after the
    monster name). E.g. "slightly wounded invisible jackal".
  - mon_wounds has additional arguments to cover the new circumstances
    it's used in.
- The linux-debug hints file is changed to linux-debug.2021, which is
  based on the modernized linux.2020 hints file.
- Fixed linux-x11 hints file not passing HACKDIR to the compiler.

---
## [crawl/crawl](https://github.com/crawl/crawl)@[b9714ae4ff...](https://github.com/crawl/crawl/commit/b9714ae4ffb485d0aa57cb81685dab814fc5f86d)
#### Saturday 2021-02-27 16:30:57 by Edgar A. Bering IV

Reforge the Chains VII: Grouped skill bonuses

After initial playtesting feedback, completely random skills had some
interesting upsides (when the stars aligned and a triply-cursed skill
could also be utlized it was a good moment) they were also frustrating
and had bad gamefeel:

- multiple melee skills when a player is probably only using one (maybe
  two)
- hard to roll relevant magic skills
- occasionally taking a "useless" or "not that useful" curse was fun but
  it was happening too often.

This commit changes the skill bonuses to be granted in the following
skill groupings, more fine grained than the old ash skill categories but
not as broad as totally random skilling:

Melee: all melee combat skills
Ranged: all ranged combat skills
Fortitude: Armour and Shields
Cunning: Dodging and Stealth
Elements: Air, Earth, Fire, and Ice Magic
Alchemy: Transmutations and Poison Magic
Beguiling: Conjurations, Hexes, and Translocations
Companions: Necromancy and Summonings
Self: Fighting and Spellcasting
Evocations: Evocations.

Each curse offers two out of these ten categories chosen at random and
without weight. This will hopefully allieviate some of the bad feelings
from totally random skill boosts while retaining the character shaping
aspects of the narrower bonus granting.

In lieu of save compatibility, since this has only been live on trunk
briefly, this commit just switches to a new prop key for the new curses.

---
## [tosato3/pdf.js](https://github.com/tosato3/pdf.js)@[ca719ecaa4...](https://github.com/tosato3/pdf.js/commit/ca719ecaa4b39e08b5ea31e01f82ca6db19a8845)
#### Saturday 2021-02-27 17:04:18 by Jonas Jenwald

Add local caching of `Function`s, by reference, in the `PDFFunctionFactory` (issue 2541)

Note that compared other structures, such as e.g. Images and ColorSpaces, `Function`s are not referred to by name, which however does bring the advantage of being able to share the cache for an *entire* page.
Furthermore, similar to ColorSpaces, the parsing of individual `Function`s are generally fast enough to not really warrant trying to cache them in any "smarter" way than by reference. (Hence trying to do caching similar to e.g. Fonts would most likely be a losing proposition, given the amount of data lookup/parsing that'd be required.)

Originally I tried implementing this similar to e.g. the recently added ColorSpace caching (and in a couple of different ways), however it unfortunately turned out to be quite ugly/unwieldy given the sheer number of functions/methods where you'd thus need to pass in a `LocalFunctionCache` instance. (Also, the affected functions/methods didn't exactly have short signatures as-is.)
After going back and forth on this for a while it seemed to me that the simplest, or least "invasive" if you will, solution would be if each `PartialEvaluator` instance had its *own* `PDFFunctionFactory` instance (since the latter is already passed to all of the required code). This way each `PDFFunctionFactory` instances could have a local `Function` cache, without it being necessary to provide a `LocalFunctionCache` instance manually at every `PDFFunctionFactory.{create, createFromArray}` call-site.

Obviously, with this patch, there's now (potentially) more `PDFFunctionFactory` instances than before when the entire document shared just one. However, each such instance is really quite small and it's also tied to a `PartialEvaluator` instance and those are *not* kept alive and/or cached. To reduce the impact of these changes, I've tried to make as many of these structures as possible *lazily initialized*, specifically:

 - The `PDFFunctionFactory`, on `PartialEvaluator` instances, since not all kinds of general parsing actually requires it. For example: `getTextContent` calls won't cause any `Function` to be parsed, and even some `getOperatorList` calls won't trigger `Function` parsing (if a page contains e.g. no Patterns or "complex" ColorSpaces).

 - The `LocalFunctionCache`, on `PDFFunctionFactory` instances, since only certain parsing requires it. Generally speaking, only e.g. Patterns, "complex" ColorSpaces, and/or (some) SoftMasks will trigger any `Function` parsing.

To put these changes into perspective, when loading/rendering all (14) pages of the default `tracemonkey.pdf` file there's now a total of 6 `PDFFunctionFactory` and 1 `LocalFunctionCache` instances created thanks to the lazy initialization.
(If you instead would keep the document-"global" `PDFFunctionFactory` instance and pass around `LocalFunctionCache` instances everywhere, the numbers for the `tracemonkey.pdf` file would be instead be something like 1 `PDFFunctionFactory` and 6 `LocalFunctionCache` instances.)
All-in-all, I thus don't think that the `PDFFunctionFactory` changes should be generally problematic.

With these changes, we can also modify (some) call-sites to pass in a `Reference` rather than the actual `Function` data. This is nice since `Function`s can also be `Streams`, which are not cached on the `XRef` instance (given their potential size), and this way we can avoid unnecessary lookups and thus save some additional time/resources.

Obviously I had intended to include (standard) benchmark results with these changes, but for reasons I don't really understand the test run-time (even with `master`) of the document in issue 2541 is quite a bit slower than in the development viewer.
However, logging the time it takes for the relevant `PDFFunctionFactory`/`PDFFunction ` parsing shows that it takes *approximately* `0.5 ms` for the `Function` in question. Looking up a cached `Function`, on the other hand, is *one order of magnitude faster* which does add up when the same `Function` is invoked close to 2000 times.

---
## [b420036/Meta_Coders](https://github.com/b420036/Meta_Coders)@[5ce2c43769...](https://github.com/b420036/Meta_Coders/commit/5ce2c43769634f8fd88ce1628e25e0dcb7e2aced)
#### Saturday 2021-02-27 17:32:02 by Zad-100

Added the folder made by me

The score.txt file already contains some data that were my test runs.
NOTE: The character scanning is working only when I wrote my first name only.  My first name is 5 characters long. Please, see into the issue if you can.
But the rest is all good!
The file is being written and all and even showing the scores when called upon.
Please, upload the edited or the final program so that I can write the scripts for the three of us. Please try to do it before 10 tomorrow morning.
Thanks, Brother! We got this! Chill hai ek dam!

---
## [acdlite/react](https://github.com/acdlite/react)@[f3fd5119b9...](https://github.com/acdlite/react/commit/f3fd5119b934c86f9434bc670cde6ce945f45baf)
#### Saturday 2021-02-27 18:47:44 by Andrew Clark

[Experiment] Lazily propagate context changes

When a context provider changes, we scan the tree for matching consumers
and mark them as dirty so that we know they have pending work. This
prevents us from bailing out if, say, an intermediate wrapper is
memoized.

Currently, we propagate these changes eagerly, at the provider.

However, in many cases, we would have ended up visiting the consumer
nodes anyway, as part of the normal render traversal, because there's no
memoized node in between that bails out.

We can save CPU cycles by propagating changes only when we hit a
memoized component — so, instead of propagating eagerly at the provider,
we propagate lazily if or when something bails out.

Most of our bailout logic is centralized in
`bailoutOnAlreadyFinishedWork`, so this ended up being not that
difficult to implement correctly.

There are some exceptions: Suspense and Offscreen. Those are special
because they sometimes defer the rendering of their children to a
completely separate render cycle. In those cases, we must take extra
care to propagate *all* the context changes, not just the first one.

I'm pleasantly surprised at how little I needed to change in this
initial implementation. I was worried I'd have to use the reconciler
fork, but I ended up being able to wrap all my changes in a regular
feature flag. So, we could run an experiment in parallel to our other
ones.

I do consider this a risky rollout overall because of the potential for
subtle semantic deviations. However, the model is simple enough that I
don't expect us to have trouble fixing regressions if or when they arise
during internal dogfooding.

---

This is largely based on [RFC#118](https://github.com/reactjs/rfcs/pull/118),
by @gnoff. I did deviate in some of the implementation details, though.

The main one is how I chose to track context changes. Instead of storing
a dirty flag on the stack, I added a `memoizedValue` field to the
context dependency object. Then, to check if something has changed, the
consumer compares the new context value to the old (memoized) one.

This is necessary because of Suspense and Offscreen — those components
defer work from one render into a later one. When the subtree continues
rendering, the stack from the previous render is no longer available.
But the memoized values on the dependencies list are. This requires a
bit more work when a consumer bails out, but nothing considerable, and
there are ways we could optimize it even further. Conceptually, this
model is really appealing, since it matches how our other features
"reactively" detect changes — `useMemo`, `useEffect`,
`getDerivedStateFromProps`, the built-in cache, and so on.

I also intentionally dropped support for
`unstable_calculateChangedBits`. We're planning to remove this API
anyway before the next major release, in favor of context selectors.
It's an unstable feature that we never advertised; I don't think it's
seen much adoption.

Co-Authored-By: Josh Story <jcs.gnoff@gmail.com>

---
## [rust-lang-ci/rust](https://github.com/rust-lang-ci/rust)@[ea25d69b4f...](https://github.com/rust-lang-ci/rust/commit/ea25d69b4f541a9b667f37fb212716386b7f9a54)
#### Saturday 2021-02-27 18:59:07 by bors

Auto merge of #79309 - davidhewitt:module-in-block, r=<try>

resolve: allow super in module in block to refer to block items

This PR attempts to resolve #79260 by changing the way the resolver interprets `super` in `mod` items that are children of blocks.

Most notably, this means that doctests with modules which use other items from the snippet can now compile:

```
//! ```rust
//! struct Foo;
//!
//! mod foobar {
//!     use super::*;
//!
//!     fn bar() -> Foo { Foo }
//! }
//!
//! ```
```

At the moment this doctest will fail to compile. ([playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2018&gist=5be71c537adbcd1a84b9c62d3027c555))

### Background

At the moment, when an inline module is inside a block, the `super` keyword refers to the parent module of the block. The result of this is that the inline module has no way to refer to its sibling items inside the block.

```rust
fn foo() {
    const FOO: u64 = 0;
    mod foo {
        pub use super::FOO; //~ ERROR no `Foo` in the root
    }
}
```

([playground](https://play.rust-lang.org/?version=stable&mode=debug&edition=2018&gist=2339d8e979dc45a25735b87ad1f85602))

The current interpretation of the `super` keyword is theoretically pure, however I want to argue it has practical drawbacks. As well as issues with doctests as per the first example, it means that in general code of the following form is interpreted differently depending on whether it is inside a block:

```rust
const FOO: u64 = 0;
mod foo {
    pub use super::FOO;
}
```

In isolation it seems fair to me to assume that most readers would state this code compiles and that `foo::FOO` can resolve. However, if this code is actually inside a block, it doesn't compile.

### Proposed Design

This PR modifies the behaviour of the `super` keyword in examples like the above such that usage inside a module which is a child of (one of more) blocks will attempt to resolve items from those blocks as well as the parent module of those blocks.

Ambiguity is resolved by always preferring items that are closer to the module in the hierarchy. E.g. in the following example:

```rust
const FOO: u64 = 0;
fn main() {
    const FOO: u64 = 1;
    mod foo {
        pub use super::FOO;
    }
}
```

the item `foo::FOO` will resolve to have the value `1`.

### ⚠️ Breakage ⚠️

This example just above is unfortunately also an example where current code could break under these changes. Today the compiler would not see the `FOO` constant which is the child of `main` from its sibling `mod foo`, and so the item `foo::FOO` today would instead resolve to have the value `0`.

(Assuming, of course, that the snippet just above were not itself wholly inside a block, in which case the compiler today would not consider the `FOO` on the first line either 🙃)

I would argue inline modules inside blocks are rare. (I myself only found this case while testing a macro which created a module and discovering it did not compile when inside a block.) So this breakage is not likely to be widespread. Nevertheless we should assess carefully.

If we were to take a conservative approach it should be possible to change this PR to be backwards compatible. I'd propose in that case to push the complete change to the proposed design in this PR via an edition boundary, with a lint to warn of cases that will change.

### Alternatives

I'm quite happy to throw this PR away in favour of an alternative design. I'll try to list them here as I see them:

- `@petrochenkov` has proposed that a `#[transparent] mod foo` could behave as if it did not create a name boundary, which would allow these modules in blocks to share scope with their parent block. (See https://github.com/rust-lang/rust/issues/79260#issuecomment-731773625)
- `@Aaron1011` wrote a pre-RFC on a `fn` modifier in use statements. (See https://internals.rust-lang.org/t/pre-rfc-add-fn-path-qualifier/10900)
- Also in that thread was the proposal of plain `use;`. I'd personally prefer it was a new keyword e.g. `use scope::*;` or `use scope::foo;` - that probably needs a new edition though as a new keyword.

### TODO

- [ ] I think it's quite likely a change like this could be worthy of a wider design review. Please feel free to ask me to first present this as an RFC. (I started with the implementation so I could learn about this design and play with it.)
- [ ] Feature gate? (I 100% assume this change will need one.)
- [ ] Make a decision on the backwards-compatibility story, especially if it might want to become part of the 2021 edition.
- [ ] Refactoring in the implementation of this PR - at the moment I kept to the most direct implementation I could find because I'm not familar with the `rustc_resolve` codebase. Please be unafraid to encourage me to rewrite this PR multiple times to get the cleanest result!

---
## [al1216/ydms_HackVerse2.0](https://github.com/al1216/ydms_HackVerse2.0)@[f1be5f286f...](https://github.com/al1216/ydms_HackVerse2.0/commit/f1be5f286ff7ce1fc6fdd4592dda56537fe12921)
#### Saturday 2021-02-27 20:05:07 by Aditya Kumar Gupta

Add files via upload

Title of the hack - YOUR DATABASE MANAGEMENT SYSTEM

Description-
1) While taking into the consideration the impact of this cute, sweet project on society that each person can make a track of his daily routine essential works such as learning coding, dieting, earning money (each day), physical fitness, one's knowledge each day with date. Anyone can keep track of it and improve themselves as they want in any spheres of their life.
2) in this hack , I (the admin) makes contribution on writing the codes in "frontend.py" and structuring the website (using HTML) in which we are going to host the our code and output of each option we created in our Project.
My teammate Himanshu handles the coding in "backend.py" and beautifying our website using CSS and Bootstrap and makes his fabulous contribution in this project.
3) The main challenges we face is to connect frontend and backend, and deleting the records if user wants to delete it. But soon after we both are able to figure it out  the bug and did what we planned successfully.
4) The system design implementation includes tkinter and sqlite3 with Python Coding. We basically connects the frontend and backend using connect() command and stores the information in rountine.db for later use. We try to make it as sweet and cute as possible. 

Tech stack used in the hack- 
Python, tkinter, sqlite3

Libraries and dependencies-
module- tkinter and sqlite3

Installation steps: -
just install 3 files given namely "frontend.py", "backend.py" and "routine.db" and run in any preferred idle such as Visual Studio Code, Pythons'Idle etc.
After installing just enter the information that asked there and select "ADD" button or you if you entered wrong details just select "Delete date" or want to search something select "Search" with anyone of the field you want and enjoy our project.

---
## [lgritz/oiio](https://github.com/lgritz/oiio)@[a165956c36...](https://github.com/lgritz/oiio/commit/a165956c361b317349884487092a9764cc85f5a6)
#### Saturday 2021-02-27 20:27:19 by Larry Gritz

Changes to accommodate upcoming Imath vector conversion changes

I have submitted a PR to Imath that adds "interopability" constructors
and assignment, that use some templates to allow seamless
construction, assignment, and passing of "foreign" vector types to
Imath vectors. This makes it easier library A that uses Imath vector
types in its API to interact with app or library B that has a custom
internal vector type, without a ton of ugly casts and copies.
(See https://github.com/AcademySoftwareFoundation/Imath/pull/91)

These created a few minor conflicts with OIIO's internal SIMD classes
and their construction and casting from Imath types. This patch cleans
up the ambiguities:

* Make Imath::V4f -> simd::vfloat4 and Imath::M44f -> simd::matrix44
  constructor `explicit`.

* Make the simd types `simd()` method (returning the underlying raw SIMD
  type) also have a variety that returns a ref to a non-const vector,
  to ensure proper working of the _MM_TRANSPOSE4_PS macro.

Now I am going to commit a sin. This MUST get backported to OIIO 2.2
in order for it to not break against the upcoming Imath 3.0.  This
doesn't break ABI compatibility, nor change OIIO's primary advertised
public APIs, but it does change the technically/informally public APIs
of simd.h in ways that introduce the possibility that an app using
those simd vector classes *might* need minor source code editing if
they relied on those implicit constructors. Such software might need
certain `simd::vector4 foo = imath_bar` to become `foo = vector4(bar)`
and the same for certain matrix44 assignments.  It is usually a big
no-no to backport any change that could require editing of source
code.  But since the alternative is not being able to use the new
Imath, I think this is the lesser evil, and maybe nobody out there is
doing the thing that would need to be changed?

---
## [canine0/zigcrawl](https://github.com/canine0/zigcrawl)@[1ff9099091...](https://github.com/canine0/zigcrawl/commit/1ff9099091c81dbc8979062db5110e3dedf99ec6)
#### Saturday 2021-02-27 21:08:03 by canine

New spell: Pandemonium Form (L9 Transmutations)

The L9 Tmut every Crawl player "wants." Pandemonium Form transforms the player into a panlord, melding all equipment, weapons, and jewelry. The player gains +20% HP, 12 base UC damage, flight, chaos-branded UC, rN+++, rElec, rPois, rMiasma, and randomly determined rC and rF (can be resistance or vulnerability). The player also gains one or several breath weapons, the ability to blink (identical to the mutation) or even damnation (identical to the demonspawn mutation). This spell isn't very balanced, but the ""drawbacks"" are that it's uncancellable once you cast the spell, so you have to wait for it to run out before casting again and rerolling your resistances and abilities, you can't consume potions, and with demonic holiness, the player becomes vulnerable to holy energy and silver. It replaces Haunt in the Grand Grimoire, and Haunt has been moved to its rightful place in the Necronomicon. Also Xom can do this to you at very high tension.

---
## [SantiagoVega95/Beaver-Beginnings](https://github.com/SantiagoVega95/Beaver-Beginnings)@[50682fcd15...](https://github.com/SantiagoVega95/Beaver-Beginnings/commit/50682fcd15169c23ec4425334b954f9f46b925a4)
#### Saturday 2021-02-27 21:28:30 by RichardDerkman

Revert "love life my mini map"

This reverts commit d9c6de2efa3fb5404a2914140973bb1ac6108bb3.

---
## [0suddenly0/null-gui](https://github.com/0suddenly0/null-gui)@[77ab164197...](https://github.com/0suddenly0/null-gui/commit/77ab1641972d0a6e7521a6dbd77268bb737fbf17)
#### Saturday 2021-02-27 22:18:52 by suddenly

[+] minor fixes
[+] added rounding for multicolor filled rect
[+] reworkinged push_var (xz chto za daun pisal staryy push_var)
[+] deleted spacing_checkbox_size settings (I don't really want to fuck with these dimensions, so if anyone wants to make an extra digression for the elements, then fuck yourself with this shit. If you still did it, you can put it in the "Pull requests" and maybe I'll add it to the main branch)
[+] added check mark for checkbox and arrow for multicombo/combo
[+] reworked button size (in further updates, the dimensions of the remaining elements will be redesigned)
[+] added setting the rounding for some elements, in the future will be added for the rest

---

# [<](2021-02-26.md) 2021-02-27 [>](2021-02-28.md)

