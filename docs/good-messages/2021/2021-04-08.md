# [<](2021-04-07.md) 2021-04-08 [>](2021-04-09.md)

3,554,162 events, 1,584,593 push events, 2,807,787 commit messages, 195,033,451 characters


## [shvedoff98/_Code_Wars_@24daaeea9d...](https://github.com/shvedoff98/_Code_Wars_/commit/24daaeea9d4098476c3dbf9ba3f1bfdcb57e8c96)
##### 2021-04-08 04:09:39 by Kirill Shvedov

Add files via upload

Description:

Paul is an excellent coder and sits high on the CW leaderboard. He solves kata like a banshee but would also like to lead a normal life, with other activities. But he just can't stop solving all the kata!!

Given an array (x) you need to calculate the Paul Misery Score. The values are worth the following points:

kata = 5
Petes kata = 10
life = 0
eating = 1

The Misery Score is the total points gained from the array. Once you have the total, return as follows:

< 40 = 'Super happy!'
< 70 >= 40 = 'Happy!'
< 100 >= 70 = 'Sad!'
> 100 = 'Miserable!'

---
## [AresKernel/Ares_7904@794d979459...](https://github.com/AresKernel/Ares_7904/commit/794d9794591e6b3764cefd28fe835d837c7f8a16)
##### 2021-04-08 09:56:27 by googyanas

fs/sync: Make sync() satisfy many requests with one invocation

Dave Jones reported RCU stalls, overly long hrtimer interrupts, and
amazingly long NMI handlers from a trinity-induced workload involving
lots of concurrent sync() calls (https://lkml.org/lkml/2013/7/23/369).
There are any number of things that one might do to make sync() behave
better under high levels of contention, but it is also the case that
multiple concurrent sync() system calls can be satisfied by a single
sys_sync() invocation.

Given that this situation is reminiscent of rcu_barrier(), this commit
applies the rcu_barrier() approach to sys_sync().  This approach uses
a global mutex and a sequence counter.  The mutex is held across the
sync() operation, which eliminates contention between concurrent sync()
operations.  The counter is incremented at the beginning and end of
each sync() operation, so that it is odd while a sync() operation is in
progress and even otherwise, just like sequence locks.

The code that used to be in sys_sync() is now in do_sync(), and
sys_sync()
now handles the concurrency.  The sys_sync() function first takes a
snapshot of the counter, then acquires the mutex, and then takes another
snapshot of the counter.  If the values of the two snapshots indicate
that
a full do_sync() executed during the mutex acquisition, the sys_sync()
function releases the mutex and returns ("Our work is done!").
Otherwise,
sys_sync() increments the counter, invokes do_sync(), and increments
the counter again.

This approach allows a single call to do_sync() to satisfy an
arbitrarily
large number of sync() system calls, which should eliminate issues due
to large numbers of concurrent invocations of the sync() system call.

Changes since v1 (https://lkml.org/lkml/2013/7/24/683):

o	Add a pair of memory barriers to keep the increments from
	bleeding into the do_sync() code.  (The failure probability
	is insanely low, but when you have several hundred million
	devices running Linux, you can expect several hundred instances
	of one-in-a-million failures.)

o	Actually CC some people who have experience in this area.

Reported-by: Dave Jones <davej@redhat.com>
Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Cc: Alexander Viro <viro@zeniv.linux.org.uk>
Cc: Christoph Hellwig <hch@lst.de>
Cc: Jan Kara <jack@suse.cz>
Cc: Curt Wohlgemuth <curtw@google.com>
Cc: Jens Axboe <jaxboe@fusionio.com>
Cc: linux-fsdevel@vger.kernel.org

Signed-off-by: Paul Reioux <reioux@gmail.com>

---
## [cockroachdb/cockroach@fb9f72220e...](https://github.com/cockroachdb/cockroach/commit/fb9f72220e5af7cda5e6683df29ea8e4e2098ddf)
##### 2021-04-08 09:59:21 by craig[bot]

Merge #62728 #63073 #63214

62728: roachtest: don't call t.Fatal in FailOnReplicaDivergence r=erikgrinaker a=tbg

In #61990 we had this method catch a stats divergence on teardown in an
otherwise successful test. The call to `t.Fatal` in that method
unfortunately prevented the logs from being collected, which is not
helpful.

Release note: None


63073: roachtest: retire `bank` tests r=nvanbenschoten,andreimatei a=tbg

The `bank` roachtests are a basic form of Jepsen test. We were hoping
that they could provide additional benefit due to being less complex
than a full Jepsen test. In my opinion, this calculus has not worked
out. We've spent many hours staring at this test deadlocked when it
wasn't CockroachDB's fault at all. Besides, it's not adding anything
meaningful on top of our Jepsen tests plus KVNemesis plus the TPCC
invariant checks, so we are removing the `bank` family of tests here.

Should we want to reintroduce these tests, we should do it at the level
of TestCluster, or at least augment the `bank` workload to incorporate
these invariant checks instead.

Closes #62754.
Closes #62749
Closes #53871.

Release note: None


63214: kvserver: reduce ReplicaGCQueueInactivityThreshold to 12 hours r=ajwerner a=erikgrinaker

`ReplicaGCQueueInactivityThreshold` specifies the interval at which the
GC queue checks whether a replica has been removed from the canonical
range descriptor, and was set to 10 days. This is a fallback for when we
fail to detect the removal and GC the replica immediately. However, this
could occasionally cause stale replicas to linger for 10 days, which
surprises users (e.g. by causing alerts if the stale replica thinks the
range has become underreplicated).

This patch reduces the threshold to 12 hours, which is a more reasonable
timeframe for users to expect things to "sort themselves out". The
operation to read the range descriptor is fairly cheap, so this is not
likely to cause any problems, and the interval is therefore not jittered
either.

Resolves #63212, touches #60259.

Release note (ops change): Replica garbage collection now checks
replicas against the range descriptor every 12 hours (down from 10 days)
to see if they should be removed. Replicas that fail to notice they have
been removed from a range will therefore linger for at most 12 hours
rather than 10 days.

Co-authored-by: Tobias Grieger <tobias.b.grieger@gmail.com>
Co-authored-by: Tobias Schottdorf <tobias.schottdorf@gmail.com>
Co-authored-by: Erik Grinaker <grinaker@cockroachlabs.com>

---
## [mrakgr/The-Spiral-Language@54bba62fba...](https://github.com/mrakgr/The-Spiral-Language/commit/54bba62fbac0f53c010269919ff19fe0168fc8b5)
##### 2021-04-08 10:44:10 by Marko Grdinić

"10:10am. I got little sleep last night. It was one of those days where I lie in bed and instead of falling asleep start thinking even harder. But I did resolve some things. My regrets - though my rational mind says different, they all stem because I believe in outdated values of self improvement. To be more precise, though I figured out the self improvement loop, my rational mind is in conflict with what I wanted as a kid.

Eventually, I am going to overcome it and completely internalize this new way of thinking.

Rationally, there is no way a path to power would ever care about past failures or victories. It is all about the future. That I do care, is proof that I am half-normie and that my drive is half posturing. As a kid, I believed that a real man should always keep winning, but as I lived, I was constantly forced to make compromises in order to cultivate the actual path.

Me becoming a programmer was more of a desperation move than a premediated choice.

I do regret that being a 'real' man is not only emotional manipulation from the outside, but it is outright incompatible with a lot of requirements of the actual path. Trying to live up to wrong expectations just results in meaningless suffering.

I am good in this respect to some amount compared to other people, but I have weaknesses I have to resolve.

Ultimately, even I myself do not have a perfect image of how the post human should behave. I do not buy the rational ubermench image of characters like Fang Yuan completely. It is just too easy to have characters act a certain way and win in fiction.

10:25am. Let me chill a bit here and I will start.

Yesterday I tried out Rance Quest Magnum. At first I had issues with game screen being cut off near the bottom that I fixed by modifying the text scaling in the Windows settings, but after that I was surprised by how much fun I was having. Rance's chad antics put a constant grin on my face and made me laugh. Considering it is a plain jRPG at its core, I thought it would be a lot more boring than it actually is. It is not like I am unilaterally a Rance fan, I actually dropped Rance 4 due to it being boring. And Rance 2 wasn't that interesting even though I finished it. Kichikou and Sengoku are exceptions and they were both grand strategy RPGs.

10:45am. Maybe I did get some rest last night, even though throughout it felt I was awake the whole time.

I am not as tired as I expected. Let me start here.

10:50am. I've slacked for long enough. I'll finish today at 6pm so I can get some extra gaming time.

Until then let me just focus on the work in front of me.

10:55am. Let me get some thinking done. I need to decide what concrete steps I should take.

During the night, I've figured out how to parallelize the sample collection. Yesterday I said that CPSing is an absolute requirement, but I do not have enough. I am going to have to turn the game into an union type. Instead of having the game operate on the players, I will make it so that it returns the action nodes with a continuation. In essence I am going to compile the game to an union type.

This will make it easy to have an arbitrary number of instance run in parallel. Right now I can't do that. Even the CPS'd version that I have now does not return a continuation, instead for the human player it just calls the dispatcher.

I might have to redesign the whole thing to get this capability, but that is fine. If I did it like this, it would have the benefit of completely generalizing the other two ways.

11am. The reason why I'd want to do this is because GPUs suck for online learning. Running a single sample through the system would be 128 times slower than running 128 of them in parallel. And NN evaluation on the GPU is where the majority of the runtime overhead will be.

When I was running those PG in 2018 on a single sample, yes, I was doing something pretty stupid.

11:10am. Close down /g/ focus on the task at hand. It is time to get serious here. Though I feel really fatigued, I should give it my best shot for the day as usual. I can't give excuses and start slacking off because of things like my fatigue state.

...

Let me think. Yesterday I did the tabular CFR agent. Today I need to run it.

11:15am. Focus me. I already have the general outline.

What are the specific steps I have to take?

11:20am. The graph is troublesome as it requires a separate non-updating pass with just the average policy being used on both ends.

Nonetheless, let me go for it. Let me do a step of optimization, and a step of showing the value to me.

I should also try implementing linear CFR, since it has been mentioned to give two order of magnitude of speedup.

11:25am. Graph UI, graph UI... That is what I should focus on. Once I decided that I absolutely want to do something, things become easier.

Then instead of thinking what I want to do in addition to have to do things, I can just focus on the later. This gives me the ability to think more deeply about the subject. When one is one the fence, there is always the hesitation of expending too much mental energy on something that is fruitless.

I should do a number of training steps followed by a sampling step.

11:30am. Now I am thinking about GANs. Forget that, focus on the task at hand.

11:45am. Oh yeah, I was wrong about predictive coding being useless. I had an idea where those local targets could be used to make the replay buffer for each individual layer. That would also give me reward scaling invariance without any of the top level layer hacks.

But is more complicated and not as advantageous as my own scheme on the GPU.

12:25pm. I am thinking about that UI right now. I am narrowing down what my reqirements are. I am going to get rid of the kind of random replay buffer that I had in `ui_replay`.

Instead for trained tabular agents, I should just display the dictionary.

12:30pm. I am not going to bother with that step when it comes to flop poker.

https://gregoryszorc.com/blog/2021/04/06/surprisingly-slow/
https://www.thenewatlantis.com/publications/welcoming-our-new-robot-overlords

Let me stop here. The first article is interesting.

12:35pm. I want to think more. I am not eager to start just yet. After running the task through my mind enough times, I'll build up the motivation where I can't stop myself from starting.

One of the first things I will have to do is master some new widgets. For the next part, buttons and labels won't cut it. I am going to have to do some experimentation how to do tabs, and also those tree view like controls. I need to master showing and hiding widgets.

I've figured out how the recycle view works. Along with the charts, it is time to put those lessons to bear."

---
## [mrakgr/The-Spiral-Language@aed861a302...](https://github.com/mrakgr/The-Spiral-Language/commit/aed861a302264517ae4338b7167c5ab7c07dd290)
##### 2021-04-08 16:13:26 by Marko Grdinić

"2:10pm. Done with breakfast and chores. Let me finish the second article and I will do some work.

It is my life I am spending here, so I want to go fast, a lot faster than this. But there is no choice, but to be patient and thorough. Trying to sprint through this would just get me lost. I am already going as fast as I can.

2:40pm. Let me resume instead of reading articles on the Rance wiki.

Ok, first of all, how do I do tabs in Kivy. Then how do I do articles that can be opened and closed. As the UIs get more complex beyond what can be fit on a single page, that becomes necessary.

https://kivy.org/doc/stable/api-kivy.uix.tabbedpanel.html

Oh, interesting. Here is the tab.

https://kivy.org/doc/stable/api-kivy.uix.treeview.html

Oh, I said I wanted something like a tree view, but looking at this, a tree view is exactly what I need.

https://kivy.org/doc/stable/api-kivy.uix.actionbar.html

Let me do a little browse of the uix widgets.

https://kivy.org/doc/stable/api-kivy.uix.accordion.html

Ohhhh! This is even better than a tree view for my purpose! Yeah, accordion is what I should try out.

https://kivy.org/doc/stable/api-kivy.uix.bubble.html

Maybe I could use this for displaying validation errors. There was something on validation in the TextInput doc page. I should look into that.

https://kivy.org/doc/stable/api-kivy.uix.filechooser.html

I should keep these in mind. All of these are useful.

https://kivy.org/doc/stable/api-kivy.uix.progressbar.html

This one is something I should have for the sake of keep track of the iteration count.

https://kivy.org/doc/stable/api-kivy.uix.splitter.html

Oh, it has splitters.

3pm. https://kivy.org/doc/stable/api-kivy.uix.textinput.html

Now let me do this final thing. There was something on validation if I recall. What was it?

3:15pm. Had to take a break. Let me start.

I will need the tab, the accordion and the progress bar.

It is time to start playing with each in turn. I'll also want a text input box that allows only numbers.

Hmmmm...speaking of only numbers, Spiral has fixed size integers and Python does not. I am going to have to do a little check to make sure it is not more than the u64 max.

3:25pm. So harsh, so hard. Life is that way. But I must keep going forward. I have to dedicate myself to doing this UI.

https://kivy.org/doc/stable/api-kivy.uix.dropdown.html
https://kivy.org/doc/stable/api-kivy.uix.spinner.html

I'll use this for picking between player one and player two for humans.

Agents should train against themselves, but I'll also want to pit agents of different stripes against each other.

I will want to pit CFR+ agents against the sampling based ones.

3:30pm. When it comes to doing MC CFR let me just take a look at something.

```
let f alpha x = x + alpha * (2.0 - x)
let g = f 0.1
g (g (g 1.0))

0.9 ** 3.0
```

Ohhh, this is wonderful. This is exactly how I should rescale the alpha.

That is...

```fs
let f alpha x = x + alpha * (2.0 - x)
let g = f 0.1
let g' n = f (1.0 - (1.0 - 0.1) ** n)
let (=.) a b = abs (a - b) <= 0.000001
g (g (g 1.0)) =. g' 3.0 1.0
```

This is what I meant.

Unlike with regrets I cannot just rescale them willy nilly by diving by the current player probability. That would unhinge the targets. But what I can do is simulate the effect of doing the application numerous times.

...No, actually this is not good.

3:45pm. Yeah, the moving average does exactly what is supposed to, but I want the weigthed updates to be decayed differently than normal.

https://www.fidelity.com/learning-center/trading-investing/technical-analysis/technical-indicator-guide/wma

Yeah, a weighted moving average is what I need to update the Q values in the sampling scheme.

Unlike in the regular one, I can't just decay the tail value. I am going to have to keep not only the sum of the values, but also the sum of the weights.

The tail will then be `sum values / sum weights`. The value update will be `((1-a) * sum values * sum weights + a * new_value * new_weight) / (1-a)`...

Damn it, this is complicated. Let me just say it is...`(1-a) * x + a * y`.

```
inl (+) a b = {value=a.value*a.weight + b.value*b.weight; weigth=a.weight + b.weight}
```

It is somewhat similar to adding fractions.

```
inl (*) a v = {a with value#=(*) v; weight#=(*) v}
```

This is how I will define the addition of two weighted floats, and a float and a regular one.

I could also make the update be...

```
x + a * (y - x)
```

Yes, this is what I should do. Instead of the usual Q values being floats, they should be these weighted floats. That will make things smooth.

4:05pm. Doing the exponential rescaling of the moving average would make the Q values sensitive to reward scaling. The above weight float scheme is what would get me the behavior if I had used a replay buffer. It is a more rational way of keeping track of data.

Ok, good.

I don't want the learning rates to vary extremely for the deep nodes compared to the outer ones. If they end up being too high for the deep nodes, that will defeat the point of using moving averages in the first place, every single data point will decay the old one completely. That is not what I want.

What I am talking about here is something I will need for tabular MC CFR. The deep one will just use a weighted replay buffer with the norm magnitude trick.

...Ah, no wait this is wrong.

```
inl weight value weight = {weight value=value*weight}
inl (+) a b = {value=a.value + b.value; weigth=a.weight + b.weight}
inl unweight {value weight} = if weight = 0 then 0 else value / weight
```

This is how I should define the operations.

What about the numerical stability of this...I wonder...

Actually, it should do fine. Let me not worry about this too much...

4:15pm. Ok, now I should have enough insight to implement the sampling Q update. This is not what is in the paper, but it is what I should be doing.

Now what is next?

Do I finally want to start work on the UI, or do I want to think about something else?

4:30pm. I am thinking about the value update.

Let me code it up.

```fs
let f alpha x = x + (2.0 - x) / alpha
List.map (fun x -> f x 1.0 * x) [0.0..0.02..1.0]
```

```
val it : float list =
  [nan; 1.02; 1.04; 1.06; 1.08; 1.1; 1.12; 1.14; 1.16; 1.18; 1.2; 1.22; 1.24;
   1.26; 1.28; 1.3; 1.32; 1.34; 1.36; 1.38; 1.4; 1.42; 1.44; 1.46; 1.48; 1.5;
   1.52; 1.54; 1.56; 1.58; 1.6; 1.62; 1.64; 1.66; 1.68; 1.7; 1.72; 1.74; 1.76;
   1.78; 1.8; 1.82; 1.84; 1.86; 1.88; 1.9; 1.92; 1.94; 1.96; 1.98; 2.0]
```

I've been trying to run this through my mind, and looking at this ahead of time, the result is not at all what I expected.

I was sure that at some point the value would go beyond 2, but this is a more straightforward moving average than I expected.

If I was not aiming for divison how would I implement this?

```fs
let f alpha x = x + (2.0 - x) / alpha
let g alpha x = x + alpha * (2.0 - x)
let a = List.map (fun alpha -> f alpha 1.0 * alpha) [0.0..0.02..1.0]
let b = List.map (fun alpha -> g alpha 1.0) [0.0..0.02..1.0]
```
```
val f : alpha:float -> x:float -> float
val g : alpha:float -> x:float -> float
val a : float list =
  [nan; 1.02; 1.04; 1.06; 1.08; 1.1; 1.12; 1.14; 1.16; 1.18; 1.2; 1.22; 1.24;
   1.26; 1.28; 1.3; 1.32; 1.34; 1.36; 1.38; 1.4; 1.42; 1.44; 1.46; 1.48; 1.5;
   1.52; 1.54; 1.56; 1.58; 1.6; 1.62; 1.64; 1.66; 1.68; 1.7; 1.72; 1.74; 1.76;
   1.78; 1.8; 1.82; 1.84; 1.86; 1.88; 1.9; 1.92; 1.94; 1.96; 1.98; 2.0]
val b : float list =
  [1.0; 1.02; 1.04; 1.06; 1.08; 1.1; 1.12; 1.14; 1.16; 1.18; 1.2; 1.22; 1.24;
   1.26; 1.28; 1.3; 1.32; 1.34; 1.36; 1.38; 1.4; 1.42; 1.44; 1.46; 1.48; 1.5;
   1.52; 1.54; 1.56; 1.58; 1.6; 1.62; 1.64; 1.66; 1.68; 1.7; 1.72; 1.74; 1.76;
   1.78; 1.8; 1.82; 1.84; 1.86; 1.88; 1.9; 1.92; 1.94; 1.96; 1.98; 2.0]
```

Wow, I am really dumb not to realize these are the same. My off the cuff calculation were completely wrong.

```
(x + (2.0 - x) / alpha) * alpha
alpha * x + 2.0 - x
(1.0 - alpha) * x + 2.0
```

Just how is this possible? They can't be the same mathematically.

```fs
let y = 2.0
let x = 1.0
let f alpha = x + (y - x) / alpha
let g alpha = x + alpha * (y - x)
let g' alpha = (1.0 - alpha) * x + alpha * y
let a = List.map (fun alpha -> f alpha * alpha) [0.0..0.02..1.0]
let b = List.map (fun alpha -> g alpha) [0.0..0.02..1.0]
let b' = List.map (fun alpha -> g' alpha) [0.0..0.02..1.0]
```
```
val y : float = 2.0
val x : float = 1.0
val f : alpha:float -> float
val g : alpha:float -> float
val g' : alpha:float -> float
val a : float list =
  [nan; 1.02; 1.04; 1.06; 1.08; 1.1; 1.12; 1.14; 1.16; 1.18; 1.2; 1.22; 1.24;
   1.26; 1.28; 1.3; 1.32; 1.34; 1.36; 1.38; 1.4; 1.42; 1.44; 1.46; 1.48; 1.5;
   1.52; 1.54; 1.56; 1.58; 1.6; 1.62; 1.64; 1.66; 1.68; 1.7; 1.72; 1.74; 1.76;
   1.78; 1.8; 1.82; 1.84; 1.86; 1.88; 1.9; 1.92; 1.94; 1.96; 1.98; 2.0]
val b : float list =
  [1.0; 1.02; 1.04; 1.06; 1.08; 1.1; 1.12; 1.14; 1.16; 1.18; 1.2; 1.22; 1.24;
   1.26; 1.28; 1.3; 1.32; 1.34; 1.36; 1.38; 1.4; 1.42; 1.44; 1.46; 1.48; 1.5;
   1.52; 1.54; 1.56; 1.58; 1.6; 1.62; 1.64; 1.66; 1.68; 1.7; 1.72; 1.74; 1.76;
   1.78; 1.8; 1.82; 1.84; 1.86; 1.88; 1.9; 1.92; 1.94; 1.96; 1.98; 2.0]
val b' : float list =
  [1.0; 1.02; 1.04; 1.06; 1.08; 1.1; 1.12; 1.14; 1.16; 1.18; 1.2; 1.22; 1.24;
   1.26; 1.28; 1.3; 1.32; 1.34; 1.36; 1.38; 1.4; 1.42; 1.44; 1.46; 1.48; 1.5;
   1.52; 1.54; 1.56; 1.58; 1.6; 1.62; 1.64; 1.66; 1.68; 1.7; 1.72; 1.74; 1.76;
   1.78; 1.8; 1.82; 1.84; 1.86; 1.88; 1.9; 1.92; 1.94; 1.96; 1.98; 2.0]
```

The code can't be wrong. My mental calculations have to be.

```
(x + (2.0 - x) / alpha) * alpha
alpha * x + 2.0 - x
(1.0 - alpha) * x + 2.0
```

Did I miss a reduction step in there somewhere.

```
(x + (2.0 - x) / alpha) * alpha
alpha * x + 2.0 - x
(alpha - 1.0) * x + 2.0
```

Yes, I missed one. Then...

```fs
let r = List.map (fun alpha -> (alpha - 1.0) * x + 2.0) [0.0..0.02..1.0]
```
```
val r : float list =
  [1.0; 1.02; 1.04; 1.06; 1.08; 1.1; 1.12; 1.14; 1.16; 1.18; 1.2; 1.22; 1.24;
   1.26; 1.28; 1.3; 1.32; 1.34; 1.36; 1.38; 1.4; 1.42; 1.44; 1.46; 1.48; 1.5;
   1.52; 1.54; 1.56; 1.58; 1.6; 1.62; 1.64; 1.66; 1.68; 1.7; 1.72; 1.74; 1.76;
   1.78; 1.8; 1.82; 1.84; 1.86; 1.88; 1.9; 1.92; 1.94; 1.96; 1.98; 2.0]
```

So this is right. Then how do I...

```
let y = 3.0
let x = 1.0
let l = [0.0..0.02..1.0]
let a = List.map (fun alpha -> (x + (y - x) / alpha) * alpha) l
let b = List.map (fun alpha -> x + alpha * (y - x)) l
let b' = List.map (fun alpha -> (1.0 - alpha) * x + alpha * y) l
let r = List.map (fun alpha -> (alpha - 1.0) * x + y) l
```
```
val a : float list =
  [nan; 2.02; 2.04; 2.06; 2.08; 2.1; 2.12; 2.14; 2.16; 2.18; 2.2; 2.22; 2.24;
   2.26; 2.28; 2.3; 2.32; 2.34; 2.36; 2.38; 2.4; 2.42; 2.44; 2.46; 2.48; 2.5;
   2.52; 2.54; 2.56; 2.58; 2.6; 2.62; 2.64; 2.66; 2.68; 2.7; 2.72; 2.74; 2.76;
   2.78; 2.8; 2.82; 2.84; 2.86; 2.88; 2.9; 2.92; 2.94; 2.96; 2.98; 3.0]
val b : float list =
  [1.0; 1.04; 1.08; 1.12; 1.16; 1.2; 1.24; 1.28; 1.32; 1.36; 1.4; 1.44; 1.48;
   1.52; 1.56; 1.6; 1.64; 1.68; 1.72; 1.76; 1.8; 1.84; 1.88; 1.92; 1.96; 2.0;
   2.04; 2.08; 2.12; 2.16; 2.2; 2.24; 2.28; 2.32; 2.36; 2.4; 2.44; 2.48; 2.52;
   2.56; 2.6; 2.64; 2.68; 2.72; 2.76; 2.8; 2.84; 2.88; 2.92; 2.96; 3.0]
val b' : float list =
  [1.0; 1.04; 1.08; 1.12; 1.16; 1.2; 1.24; 1.28; 1.32; 1.36; 1.4; 1.44; 1.48;
   1.52; 1.56; 1.6; 1.64; 1.68; 1.72; 1.76; 1.8; 1.84; 1.88; 1.92; 1.96; 2.0;
   2.04; 2.08; 2.12; 2.16; 2.2; 2.24; 2.28; 2.32; 2.36; 2.4; 2.44; 2.48; 2.52;
   2.56; 2.6; 2.64; 2.68; 2.72; 2.76; 2.8; 2.84; 2.88; 2.92; 2.96; 3.0]
val r : float list =
  [2.0; 2.02; 2.04; 2.06; 2.08; 2.1; 2.12; 2.14; 2.16; 2.18; 2.2; 2.22; 2.24;
   2.26; 2.28; 2.3; 2.32; 2.34; 2.36; 2.38; 2.4; 2.42; 2.44; 2.46; 2.48; 2.5;
   2.52; 2.54; 2.56; 2.58; 2.6; 2.62; 2.64; 2.66; 2.68; 2.7; 2.72; 2.74; 2.76;
   2.78; 2.8; 2.82; 2.84; 2.86; 2.88; 2.9; 2.92; 2.94; 2.96; 2.98; 3.0]
```

No there are differences between this and the original.

```fs
let y = 6.0
let x = 1.5
let l = [0.0..0.02..1.0]
let a = List.map (fun alpha -> (1.0 - alpha) * x + alpha * y) l
let b = List.map (fun alpha -> (alpha - 1.0) * x + y) l
```

```
val a : float list =
  [1.5; 1.59; 1.68; 1.77; 1.86; 1.95; 2.04; 2.13; 2.22; 2.31; 2.4; 2.49; 2.58;
   2.67; 2.76; 2.85; 2.94; 3.03; 3.12; 3.21; 3.3; 3.39; 3.48; 3.57; 3.66; 3.75;
   3.84; 3.93; 4.02; 4.11; 4.2; 4.29; 4.38; 4.47; 4.56; 4.65; 4.74; 4.83; 4.92;
   5.01; 5.1; 5.19; 5.28; 5.37; 5.46; 5.55; 5.64; 5.73; 5.82; 5.91; 6.0]
val b : float list =
  [4.5; 4.53; 4.56; 4.59; 4.62; 4.65; 4.68; 4.71; 4.74; 4.77; 4.8; 4.83; 4.86;
   4.89; 4.92; 4.95; 4.98; 5.01; 5.04; 5.07; 5.1; 5.13; 5.16; 5.19; 5.22; 5.25;
   5.28; 5.31; 5.34; 5.37; 5.4; 5.43; 5.46; 5.49; 5.52; 5.55; 5.58; 5.61; 5.64;
   5.67; 5.7; 5.73; 5.76; 5.79; 5.82; 5.85; 5.88; 5.91; 5.94; 5.97; 6.0]
```

5:05pm. Had to do some chores.

But basically, with this now I know what the update is doing.

```
let y = 6.0
let x = 6.0
let l = [0.0..0.02..1.0]
let a = List.map (fun alpha -> (1.0 - alpha) * x + alpha * y) l
let b = List.map (fun alpha -> (alpha - 1.0) * x + y) l
```

```
val a : float list =
  [6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0;
   6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0;
   6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0;
   6.0; 6.0; 6.0; 6.0; 6.0; 6.0]
val b : float list =
  [0.0; 0.12; 0.24; 0.36; 0.48; 0.6; 0.72; 0.84; 0.96; 1.08; 1.2; 1.32; 1.44;
   1.56; 1.68; 1.8; 1.92; 2.04; 2.16; 2.28; 2.4; 2.52; 2.64; 2.76; 2.88; 3.0;
   3.12; 3.24; 3.36; 3.48; 3.6; 3.72; 3.84; 3.96; 4.08; 4.2; 4.32; 4.44; 4.56;
   4.68; 4.8; 4.92; 5.04; 5.16; 5.28; 5.4; 5.52; 5.64; 5.76; 5.88; 6.0]
```

This value for b makes not even a lick of sense to me. Is this how it really was in the paper?

Yes it was. Keep in mind these are suppose to be Q surrogates.

```fs
let y = 6.0
let x = 0.0
let l = [0.0..0.02..1.0]
let a = List.map (fun alpha -> (1.0 - alpha) * x + alpha * y) l
let b = List.map (fun alpha -> (alpha - 1.0) * x + y) l
```
```
val a : float list =
  [0.0; 0.12; 0.24; 0.36; 0.48; 0.6; 0.72; 0.84; 0.96; 1.08; 1.2; 1.32; 1.44;
   1.56; 1.68; 1.8; 1.92; 2.04; 2.16; 2.28; 2.4; 2.52; 2.64; 2.76; 2.88; 3.0;
   3.12; 3.24; 3.36; 3.48; 3.6; 3.72; 3.84; 3.96; 4.08; 4.2; 4.32; 4.44; 4.56;
   4.68; 4.8; 4.92; 5.04; 5.16; 5.28; 5.4; 5.52; 5.64; 5.76; 5.88; 6.0]
val b : float list =
  [6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0;
   6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0;
   6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0; 6.0;
   6.0; 6.0; 6.0; 6.0; 6.0; 6.0]
```

Wow, this is crazy. The paper has to be wrong. VR MC CFR's bootstraping rule is complete nonsense.

5:15pm. No, I absolutely can't use it. But I do believe in the general idea of how bootstrapping is done here.

What I am going to replace it with is simply letting the value from above fall through.

```
let c = List.map (fun alpha -> alpha * y) l
```

There is no need to think about what the original estimate is given that I have a much more accurate one based on the trace.

Let me read the original VR MCCFR paper.

5:50pm. No the ablation study in the original paper does not depend on the rule I find troubling. I can replace it. State action dependence just makes sure that values and multiplied by the policy probs before propagating. And bootstrapping is just boostraping from nearby nodes.

Damn it. This is why doing ML is so stressful. You can't just trust what you read in the papers outright. Even good results might have nonsensical algorithmic decisions that happen to work due to the vagaries of optimization.

I am definitely going to make all of this work.

5:55pm. I should have been working on UIs rather than obsessing about the sampling algorithm, but it is worth it.

It does not feel like 2018 anymore. If feels like all the ideas are coming together for me, and my skill level is steadily rising. My actual understanding itself is going up.

My focus is different from 2018. Back then I was laser focused on credit assignment and backpropagation itself. Right now, I am just thinking of how to deal with the replay buffer in the most efficient manner. With a different approach, my results are different.

6:05pm. I need to have courage and do what I think is right. If it fails to work for me then I will go with the speculative approach in the paper itself.

I can't apply random rules I find in the wild if I want to be successful long term. I need to optimize for beauty, elegance and understanding. If ML was a mature field, it would make sense to give authors the benefit of the doubt, but not when I have a sense for how things would be better and when my own translation of a parent enumerative algorithm to the sampling regime is pushing me in a different direction then that direction is the one I should take.

I must follow my own way even if leads to my destruction.

In the worst case, I will waste a few extra months before giving up on my own stuff and trying the things in the paper.

Forget about this.

Tonight, I am going to get some proper sleep and ready myself for the work on the UIs. Today I just could not get going.

Tomorrow, I am absolutely going to sketch out that UI at least, and then get the tabular enumerative CFR to work. Then I will do the sampling CFR."

---
## [Skyrat-SS13/Skyrat-tg@da2215fb0d...](https://github.com/Skyrat-SS13/Skyrat-tg/commit/da2215fb0d023a299ad4bcf62184063b57ccbf4e)
##### 2021-04-08 21:03:43 by SkyratBot

[MIRROR] Empty graves can now be spawned (#4755)

* Empty graves can now be spawned (#58200)

* i walked along the no mans road

POV: you got fucked on a previous branch from something stupid

* Update code/modules/ruins/lavalandruin_code/elephantgraveyard.dm

Co-authored-by: Fikou <piotrbryla@ onet.pl>

* Update code/modules/ruins/lavalandruin_code/elephantgraveyard.dm

Co-authored-by: Mothblocks <35135081+Mothblocks@ users.noreply.github.com>

Co-authored-by: Fikou <piotrbryla@ onet.pl>
Co-authored-by: Mothblocks <35135081+Mothblocks@ users.noreply.github.com>

* Empty graves can now be spawned

Co-authored-by: ishitbyabullet <deathzombine@outlook.com>
Co-authored-by: Fikou <piotrbryla@ onet.pl>
Co-authored-by: Mothblocks <35135081+Mothblocks@ users.noreply.github.com>

---

# [<](2021-04-07.md) 2021-04-08 [>](2021-04-09.md)

