# [<](2021-10-02.md) 2021-10-03 [>](2021-10-04.md)

2,320,712 events, 1,357,845 push events, 1,945,401 commit messages, 109,855,203 characters


## [ChoGGi/SurvivingMars_CheatMods](https://github.com/ChoGGi/SurvivingMars_CheatMods)@[0a7f00cae4...](https://github.com/ChoGGi/SurvivingMars_CheatMods/commit/0a7f00cae4f82e3dd2f876822ffcb7c84415b44a)
#### Sunday 2021-10-03 01:07:29 by ChoGGi

Lib:

### Examine:
- Examine shows map_id for cities.
- Tooltips show map_id object is in.

Mods:

Add Planetary Anomaly Breakthroughs 0.2:
Picard update.

Add Sol Birth Name 0.2:
Picard city time update.

Base Walls 0.5:
Added mod option to remember skin.

Build Mystery Rewards 0.6:
Log spam (thanks requiemfang).

Change Rocket Skin 0.9:
Compatible with Coloured Depots.

Delay New Game Milestone 0.2:
Picard city time update.

Expeditions Use Nearest 0.5:
Added some fixes from SkiRich.

Game Rule Random Breakthroughs 0.3:
Picard update.

Game Rules Breakthroughs 0.8:
Picard update.

Game Rules Permanent Disasters 1.1:
Added SavegameFixups to restart threads for dustdevils/etc.
v1.0
Disappearing dust devils (thanks blade).

POI Spawn Rate 0.8:
Picard city time update.

Real Time Clock 0.9:
Fixed 12h clock.

Rocket Turn Off Rare Export 0.3:
Added built rockets (thanks strudo76).

Set Speed Keys 0.4:
Change 4/5 speeds in mod options.

Show Consumption Resources 0.3:
Picard update.

Show Drones Working On Building 0.5:
Highlights drones going to a depot of a building.

Specialist By Experience 1.1:
Picard city time update.

Tower Defence 0.6:
Picard city time update.

github@choggi.org

---
## [saxenalab-neuro/controlled-movement](https://github.com/saxenalab-neuro/controlled-movement)@[1be167098e...](https://github.com/saxenalab-neuro/controlled-movement/commit/1be167098e83e7e597627f3a63d312c174ff176b)
#### Sunday 2021-10-03 02:18:14 by Jaxton Willman

HIPERGATOR

WITH THE COMPUTATIONAL POWER OF HIPERGATOR, WE SHALL BE KINGS.

All craziness aside, holy crap HiPerGator is fast. Took a long time to figure out how to do arrays, assignment, ceil, floor, mod, echo, and other operations in bash. But I figured it out and now I can run job array scripts which saves my fingers from having to type!

Uploaded all my HiPerGator Matlab stuff (HPGM folder). This contains the sbatch scripts for slurm as well as other things. This folder is for HiPerGator only and is synced back and forth with Globus file manager on the web.

Also I moved all old scripts to the new Old Scripts folder so there would be less clutter. I can pull them out if needed or maybe they'll stay in that archive for a while.

Added opensim.log to git ignore so it doesn't keep updating!

Created a new comparesystems script to compare the various orders of the systems. But I'm going to have to expand on this to support the crazy new amounts of numbers the systems use.

I had to ignore all .mat files as they were > 100 MB and thus GitHub didn't like that and I don't feel like figuring out GitHub LFS tonight.

---
## [fiqri19102002/android_kernel_xiaomi_ginkgo](https://github.com/fiqri19102002/android_kernel_xiaomi_ginkgo)@[2294a180a5...](https://github.com/fiqri19102002/android_kernel_xiaomi_ginkgo/commit/2294a180a53d9eaeb87baf2423783cf703f9749d)
#### Sunday 2021-10-03 02:48:24 by George Spelvin

lib/sort: make swap functions more generic

Patch series "lib/sort & lib/list_sort: faster and smaller", v2.

Because CONFIG_RETPOLINE has made indirect calls much more expensive, I
thought I'd try to reduce the number made by the library sort functions.

The first three patches apply to lib/sort.c.

Patch #1 is a simple optimization.  The built-in swap has special cases
for aligned 4- and 8-byte objects.  But those are almost never used;
most calls to sort() work on larger structures, which fall back to the
byte-at-a-time loop.  This generalizes them to aligned *multiples* of 4
and 8 bytes.  (If nothing else, it saves an awful lot of energy by not
thrashing the store buffers as much.)

Patch #2 grabs a juicy piece of low-hanging fruit.  I agree that nice
simple solid heapsort is preferable to more complex algorithms (sorry,
Andrey), but it's possible to implement heapsort with far fewer
comparisons (50% asymptotically, 25-40% reduction for realistic sizes)
than the way it's been done up to now.  And with some care, the code
ends up smaller, as well.  This is the "big win" patch.

Patch #3 adds the same sort of indirect call bypass that has been added
to the net code of late.  The great majority of the callers use the
builtin swap functions, so replace the indirect call to sort_func with a
(highly preditable) series of if() statements.  Rather surprisingly,
this decreased code size, as the swap functions were inlined and their
prologue & epilogue code eliminated.

lib/list_sort.c is a bit trickier, as merge sort is already close to
optimal, and we don't want to introduce triumphs of theory over
practicality like the Ford-Johnson merge-insertion sort.

Patch #4, without changing the algorithm, chops 32% off the code size
and removes the part[MAX_LIST_LENGTH+1] pointer array (and the
corresponding upper limit on efficiently sortable input size).

Patch #5 improves the algorithm.  The previous code is already optimal
for power-of-two (or slightly smaller) size inputs, but when the input
size is just over a power of 2, there's a very unbalanced final merge.

There are, in the literature, several algorithms which solve this, but
they all depend on the "breadth-first" merge order which was replaced by
commit 835cc0c8477f with a more cache-friendly "depth-first" order.
Some hard thinking came up with a depth-first algorithm which defers
merges as little as possible while avoiding bad merges.  This saves
0.2*n compares, averaged over all sizes.

The code size increase is minimal (64 bytes on x86-64, reducing the net
savings to 26%), but the comments expanded significantly to document the
clever algorithm.

TESTING NOTES: I have some ugly user-space benchmarking code which I
used for testing before moving this code into the kernel.  Shout if you
want a copy.

I'm running this code right now, with CONFIG_TEST_SORT and
CONFIG_TEST_LIST_SORT, but I confess I haven't rebooted since the last
round of minor edits to quell checkpatch.  I figure there will be at
least one round of comments and final testing.

This patch (of 5):

Rather than having special-case swap functions for 4- and 8-byte
objects, special-case aligned multiples of 4 or 8 bytes.  This speeds up
most users of sort() by avoiding fallback to the byte copy loop.

Despite what ca96ab859ab4 ("lib/sort: Add 64 bit swap function") claims,
very few users of sort() sort pointers (or pointer-sized objects); most
sort structures containing at least two words.  (E.g.
drivers/acpi/fan.c:acpi_fan_get_fps() sorts an array of 40-byte struct
acpi_fan_fps.)

The functions also got renamed to reflect the fact that they support
multiple words.  In the great tradition of bikeshedding, the names were
by far the most contentious issue during review of this patch series.

x86-64 code size 872 -> 886 bytes (+14)

With feedback from Andy Shevchenko, Rasmus Villemoes and Geert
Uytterhoeven.

Link: http://lkml.kernel.org/r/f24f932df3a7fa1973c1084154f1cea596bcf341.1552704200.git.lkml@sdf.org
Signed-off-by: George Spelvin <lkml@sdf.org>
Acked-by: Andrey Abramov <st5pub@yandex.ru>
Acked-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Cc: Geert Uytterhoeven <geert@linux-m68k.org>
Cc: Daniel Wagner <daniel.wagner@siemens.com>
Cc: Don Mullis <don.mullis@gmail.com>
Cc: Dave Chinner <dchinner@redhat.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Yousef Algadri <yusufgadrie@gmail.com>
Signed-off-by: Panchajanya1999 <panchajanya@azure-dev.live>
Signed-off-by: Fiqri Ardyansyah <fiqri15072019@gmail.com>

---
## [jhn1m/C_Sharp_algorithm](https://github.com/jhn1m/C_Sharp_algorithm)@[f854dbe7c1...](https://github.com/jhn1m/C_Sharp_algorithm/commit/f854dbe7c1b426668358822a285eb18c35357bcc)
#### Sunday 2021-10-03 06:02:09 by JAEHYEON LEE

Create alarmclock.cs

Full-time wakes up to the alarm every morning. It would be fortunate if I woke up right after hearing the alarm, but I am always late for school because I want to sleep a little longer.

Full-time tried everything, but his desire to sleep a little longer could not get rid of anything.

Chang-young, who felt sorry for such a full-time employee, recommended a way to use it.

It's "Set the alarm 45 minutes earlier."

This method is simple. It is to change the alarm to a time 45 minutes ahead of the original setting. This is because if I hear the alarm anyway, I will turn off the alarm and sleep a little more. Using this method, you can feel that you slept more every morning, and you are not late for school.

If Chang-young's method is used when given the alarm time set by the current full-time employee, write a program to find out when to fix it.

Input
The first line is given two integers H and M. (0 H H 23 23, 0 M M 5 59), and this means the alarm time H time M set by the current full-time employee.

The input time uses a 24-hour representation. In the 24-hour expression, the start of the day is 0:0 (midnight), and the end is 23:59 (one minute before midnight the next day). When representing time, unnecessary zero is not used.

Output
When full-time uses Chang-young's method in the first line, output the alarm time to be set. (You can print it out in the same form as the input.)

---
## [eatmyvenom/HyArcade](https://github.com/eatmyvenom/HyArcade)@[309765f39c...](https://github.com/eatmyvenom/HyArcade/commit/309765f39cd9dcfbd25c7c3fcbf45b8740dfb0da)
#### Sunday 2021-10-03 06:03:14 by eatmyvenom

DONT FUCKING INVERT THE IF YOU STUPID FUCKING IDIOT

---
## [Kinar-Usha/hacktoberfest-2021](https://github.com/Kinar-Usha/hacktoberfest-2021)@[382710a7fc...](https://github.com/Kinar-Usha/hacktoberfest-2021/commit/382710a7fceef96cfafcb92591a7ca30abec8753)
#### Sunday 2021-10-03 06:13:24 by kinar

Create LICENSE.md

do whatever the fuck you want license

---
## [martynovmaxim/AesirTest](https://github.com/martynovmaxim/AesirTest)@[58dbf07e2e...](https://github.com/martynovmaxim/AesirTest/commit/58dbf07e2edc638fb105feddf308821ded19bab6)
#### Sunday 2021-10-03 09:01:23 by Maksim Martynov

What do I have right before 11:00 CEST
Unfortunately, I could not make gravity on time
There is a weird bug that causes the crash
I will continue doing the task, hoping, that you (the judges) will understand me: because of the family issues (I almost broke up with my girlfriend) I spent 6 hours of doing nothing for the test task. So... Please, I want to work with you!

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[44b6a43d68...](https://github.com/mrakgr/The-Spiral-Language/commit/44b6a43d685302f1bbfcb71903ac777bc260ab02)
#### Sunday 2021-10-03 10:20:58 by Marko Grdinić

"8:45am. Went to bed past 12am, but got up at this time. I even had time to lounge around. I slept quite well.

Let me check email, and Reddit for any replies. I hope mods do not take issue with the two swear words in the PL review. Yeah, nothing. Good.

9:30am. Let me start watching some of the vector art videos.

https://www.youtube.com/watch?v=KZP6RQu_F6U
Adobe Illustrator Tutorial: Create a Vector Pizza from Sketch (HD)

9:45am. https://youtu.be/KZP6RQu_F6U?t=625

Never thought of making a heart like this.

9:55am. https://youtu.be/9EGI-FSr0Ig?t=574

Compared to processing, doing the vector art like this would have been way easier.

Hrmmm, I don't know. Can I really do this?

https://news.ycombinator.com/item?id=28733646
Generally Intelligent Is Hiring Machine Learning Research Engineers (Remote, SF)

I've been stressed about having to learn Julia on a deeper level, but I would have liked working on something that is on the intersection of PL and ML work like what was offered by Z. Just why did it all go so wrong?

A lot of the fault lies with him from taking 3 weeks to get back to me, taking 5 days to reply to my email, and then making that gaffe with the offer. It pushed my image of him in the toilet. But maybe I should not have overreacted and gotten so defensive like that.

One of my goals was to get paid decently for my work, but it is not like I can't work for 2-3k. Had he made an initial offer of 2.5k, I'd have laughed at him, sure, but there was a chance he could have persuaded me to accept if he flattered my ability and said he would raise the pay once he increased the funds.

When he said he would pay me 2.5k and reasses after 2 months, I totally thought he was looking down on me, but he might have been talking about his own money situation. I mean how could I know this? I don't know what his budget is or how many applicants he is looking at on the side besides me. When he offered me 25k/month saying it is the top of Croation contract market rate, I assumed that is what the market rate was in Croatia, instead of 2.5k. I mean, imagine I was from Africa and the market rate was 1k there. If he offered me 10k/month, I'd have assumed that was his intention as well, I certainly would not have thought he would do something like reduce it to 1k the next day.

10k would have been a lot, and he probably would have been able to get a lower price, but I'd assume that he himself knew that and was just being generous in order to motivate me.

As an example for how that reasoning works, suppose I was applying to some C# ASP.NET backend job, it is not actually in the company's own interest to pay me the least I'd accept because that just means I'd get a higher paying job in a few months and they'd be left with a hole they need to fill for weeks.

10:15am. If you want to underpay somebody and he knows it, you'd want to turn on the charm to maximum by flattering him and indicating your own sincerity to increase the pay in the future when the funds are raised.

If a worker accepts low pay while enduring a strong attitude, that indicates he is okay with being pushed around. I distinctly felt the need to push back. I actually wanted to accept 2.5k on some level, but doing it in that circumstance means I'd be okay with being pissed on.

He really should have googled 'research engineer salary' to find the usual range before coming into negotiations. How unprepared can one person be? He expected I would be super happy with 2.5k.

Lastly, doing face to face negotiations is different from one offer per day over email. In the later format, the parties would not waste as much time probing each other.

The fact that the whole thing took a month means I was already super patient with him. When I said that I wanted 6k min, this is something he should have thought about beforehand instead of asking the other party to waste even more of their time. Studying Julia for me in not like picking between a couple of identical backend .NET jobs. It would be a large change in my life's path.

10:25am. https://www.ycombinator.com/companies/generally-intelligent
> Generally Intelligent is an AI research company. We help machines learn to understand the world the way humans do. Our mission is to build human-like general machine intelligence and make it safely accessible in order to foster a more abundant, equitable, and creative human society.

> We take a first-principles approach to understanding the fundamentals of learning, starting with simple self-supervised networks solving early evolutionary problems, and increasing complexity incrementally.

Should I try applying here? Let me just wait a day or two, I need to get over the recent bout a little.

Let me watch the vector art video. The reason why these vector portraits look so unappealing to me is because of the shadowing. The technical skill is definitely there, but I do not like the style.

10:35am. I think the way I'll start that out is by tracing some of the images of Cag and building up my sense that way. I need to get some basic experience putting down lines, colors and doing shading. After I've done a bunch of that, maybe I could start thinking about doing my own.

Ok, focus me. I'll apply to the above company tomorrow or in two days. I won't really expect to get a positive response as most likely they'll be looking at ML PhDs.

https://youtu.be/9EGI-FSr0Ig?t=633

The kind of tracing being done here, I could do with some practice. I tried it once in mid school and it worked.

https://youtu.be/9EGI-FSr0Ig?t=1080

Hmmm, even though he is just tracing, I feel what he is doing here would take some skill. The way he does it pretty practiced, I could not do it anywhere was fast as him.

https://youtu.be/9EGI-FSr0Ig?t=1250

It is fine when he was doing the outline, but I am loosing track of what all this stuff here is. I am just going with the flow here.

If all portrait tutorials are like this I won't get much out of them. Maybe I should start skimming.

https://youtu.be/Pz9zE8qHcNE
Illustration Master Course - Ep. 3: PORTRAITS

Let me watch this instead. Maybe I should go from the start. And this is not in illustrator.

https://youtu.be/Pz9zE8qHcNE?t=450

Sigh, if I had this kind of skill, my life would be a lot easier. I guess the only thing to do is just patiently cultivate.

11:15am. Let me take a short break here.

11:35am. Let me resume.

https://youtu.be/Pz9zE8qHcNE?t=1141

This guy is so good that it would be impossible for me to immitate him. Isn't there a simpler vector art based style I could cultivate at the start?

11:45am. https://www.youtube.com/watch?v=Jp_g3B2AsTE
HOW TO DRAW ANATOMY (beginner to expert)

Let me watch this 15m thing.

12:05pm. Ok, new plan. Actually learning how to draw well would be way too much effort. It would be fine if I had years to spend, but I need some good initial results. Right now I am only trying to do basic characters and backgrounds.

12:10pm. To learn to trace, I basically have to understand the Adobe Illustrator tool and not too much else. It will take some practice to get familiar with all its features.

https://www.youtube.com/results?search_query=proko

I'll check out this guy later. Let me watch an ep of Son Of Ogre."

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[0d92f7573e...](https://github.com/mrakgr/The-Spiral-Language/commit/0d92f7573eabe28d356dc1909d8e34ab207b79c3)
#### Sunday 2021-10-03 16:09:59 by Marko Grdinić

"1:45pm. Let me resume. Let me watch some vids on tracing just for fun.

https://www.youtube.com/watch?v=AvFmt38Y2jg
Should artists TRACE? • Tracing, studying and referencing (examples / speed paint)

Once I get serious, instead of semi-plagiarizing other artists, I should just trace Clip studio models. That video I saw yesterday was amazing, but there is no way I would ever be able to approach his level of skill in the near term.

2:10pm. This video is so annoying, let me stop at 2/3rds.

https://youtu.be/k0ufz75UvHs
Iterative Drawing - The Fastest Way to Improve

Let me take a look at this.

2:20pm. Forget those ranty videos. They are wastes of time.

https://www.youtube.com/watch?v=wAOldLWIDSM
Quickly Draw Heads with the Loomis Method - Part 1

Let me take a look at this.

2:30pm. Ok, forget these tutorials. Let me just install Adobe Illustrator and start going over the tutorials for it.

https://youtu.be/_raUbrGdImk
Is It WRONG to TRACE Art? - Digital Artist Doubts

Let me watch this guy while the thing installs.

2:35pm. This is a pretty good video. He says that tracing a good way to train hand eye coordination.

2:50pm. https://www.youtube.com/watch?v=N-buLx_tV6U
THE BEGINNER'S GUIDE TO DRAWING

Let me take a short break, then I'll watch this, then I'll start going through the tutorials for real.

3:20pm. Let me watch this guy.

I the last 6.5 years, I think my failed RL attempts are what hurt me the most. I put the most hope there, and I got the least return.

I think to go forward in life, it is important to just keep improving. And RL did not really give me that.

I need to get back to the basics.

NP Hardness of learning is the real problem. NNs offer a way to do randomized search in a approximately memoizing fashion and constrain the search space that way.

In this time we are too used of thinking about passing a static dataset to them, because the current hardware is very hard to use in an online fashion, but that will change. Then the true arc towards the Singularity will start.

I really did not want to start applying to jobs. That is not what would fill the hole in my heart. Rather what I need to do is find a new path.

I won't aim to conquer the world, instead I just have to find my niche.

I need to get back to the basics. My great belief got me this far, and I need to find what the next step is. Maybe doing art for a few weeks will give me some inspiration.

> Going from zero to pro takes only 5 years of investment and guided studies.

I want to do this in less than a month. I can only hope that my programming ability gives me a boost. I really can't practice for 5 years before doing the art for Simulacrum.

https://youtu.be/N-buLx_tV6U

This is a pretty good guide. That information that is not needed is discarded by the brain is completely true.

3:50pm. Let me start. It is time to get grinding.

https://helpx.adobe.com/illustrator/tutorials.html

I am going to keep applying to jobs, but not with the intention of getting them. Like that HN position that was open, I'll want to send my 3 page resume and talk about my vision of ML. That is what I should be focusing on.

Yeah, I am not sure I really wanted to work any of these jobs. Rather I just want to keep improving. Because I can't improve in RL, that made me lose my sense of direction. I still haven't found it again, but I will.

I need to get back to basics.

Making games is easier than solving them.

I've made a mockery of that, and tried jumping limits. I should have been wiser.

I need to put things in perspective.

I had a conjecture and it did not turn out to be true. This is valuable experience that the me of 6.5 years ago did not have. I did learn quite a bit. Especially these latest insights on how to do counterfactual MCTS. That is not something a beginner could come up with. I've taken the algorithm and generalized it to tree search and related it to probabilistic reasoning making it act as support.

In the future this will be a small, but important part of a more general way of programming.

But now, why don't I learn to do games starting with LNs. I want to promote the path of evil. Attacking the prevailing culture is always a good way to garner attention, as long it is done in a sensible way. Last time doing the story set me on this path, but this time it will be different.

4:05pm. Let me run the illustrator for the first time.

4:10pm. Yeah, it works, no problem.

4:15pm. Focus me, let me watch the videos. Real tutorials, not that Youtube tablet stuff.

4:30pm. https://www.reddit.com/r/MachineLearning/comments/pzqgvb/d_thoughts_on_neural_nets_simulation_based/

I went to the ML sub and found this. Let me finish the zooming tutorial and then I'll listen to this.

4:50pm. Let me watch the interview with Lex on the part that was posted.

4:55pm. Ah, no nevermind. He is arguing against simulation. Let me go to the next tutorial. I need to keep going at it. Master the Adobe Illustrator. That should be my goal.

5pm. This is so boring, I can barely stay awake.

5:10pm. Focus me.

https://helpx.adobe.com/illustrator/how-to/shapes-basics.html

Let me go through this. Once I go through these tutorials, I'll be able to start my tracing adventure. First I learn to trace, then I learn to adjust the trace, and pretty soon I'll be a serious artist.

5:30pm. Next! Combine shapes.

5:40pm. Next is tracing. I think after that I'll call it a day.

6pm. https://helpx.adobe.com/illustrator/how-to/edit-artwork-basics.html

Let me stop here. It is time I get lunch and watch Son of Ogre.

6:05pm. Art design much like UI work and concurrency previously, art design is really one of the aspects in which I've felt inferior in ways that stiffled my development. If I can master this aspect along with sound it will go a long way in enabling me to live with my own power."

---
## [coh-lavender-dev/android_device_xiaomi_lavender](https://github.com/coh-lavender-dev/android_device_xiaomi_lavender)@[0d67351f02...](https://github.com/coh-lavender-dev/android_device_xiaomi_lavender/commit/0d67351f0264a03105ffd25c4fb15c8f6e0a3480)
#### Sunday 2021-10-03 18:35:22 by A2L5E0X1

lavender: don't show 4G icon instead of LTE

* BROKEN FUCK YOU KILL

Change-Id: If78ab314fe451f8f81d0cd32c1ad6f884c7e6368

---
## [kleinerm/Psychtoolbox-3](https://github.com/kleinerm/Psychtoolbox-3)@[4190280bc7...](https://github.com/kleinerm/Psychtoolbox-3/commit/4190280bc7b05b0da96d8b2ec645e50b1a82000c)
#### Sunday 2021-10-03 18:35:48 by Mario Kleiner

PsychHID/Windows: Add basic multitouch input support.

This adds a basic implementation of touch input for MS-Windows
8 and later.

Limitations wrt. Linux/X11 implementation:

It currently exposes exactly one touch input queue, which allows
to receive touch input inside exactly one associated onscreen
window (and a special mode where touch input is taken from the
whole desktop, if a windowHandle of 0 is passed in, blocking any
other user input on the desktop).

-> Iow. only one onscreen window can be touch-enabled/receiving
   in any active Psychtoolbox session.

Touch events are taken as a union of input from all connected
touchscreens.

-> No way to differentiate between separate touch input from
   multiple connected screens at the moment.

Given the "exactly one window per touchqueue and exactly one
touchqueue per window" relationship of touchqueues to windows,
and the fact that this implementation only provides one queue,
this is more limited than the Linux/X11 implementation, which
has at least (n+1) queues for n touch devices, ie. one per
individual touch device and then also "master pointer" queues
which represent the union of all (core pointer) or subsets
(added master pointers) of touchscreens. In this sense, this
Windows implementation exposes its touch queue as the equivalent
of the Linux/X11 "master pointer / X core pointer" queue.

-> Each touch event only reports (x,y) touch position, timestamp,
   optionally width and height of touch bounding box, depending
   on touchscreen device, and an "extraData" value which is
   optional, not supported on my two test touchscreens, and
   undefined in its meaning by Microsoft docs, iow. could be
   anything from pressure to confidence, rotation angle, proximity
   etc. These are limitations of the underlying WM_TOUCH messages,
   iow. a Windows OS limitation as of Windows-10.

Iow. this provides a subset of the functionality and flexibility
available on Linux.

How it works:

Touch input is received and handled via the Windows touch input
api. Our kbqueue processing thread now maintains its own Window
class for touch input handling (or windowing system event handling
in general), with its own associated WinProc() event handler and
message pump driven by/in the thread mainloop.

RegisterTouchWindow() is used to register for touch input events
on a window, so they can get processed by our new WinProc handler
and enqueued in a new dedicated "touch input" keyboard queue with
index "touchQueue".

Ideally we'd RegisterTouchWindow() on the already opened Screen()
onscreen window. Unfortunately that is not possible, as win32 only
allows a thread (=our kbqueue thread) to receive winsys events for
windows that the thread has created itself via CreateWindow[Ex]().
As PTB onscreen windows are created on the runtime main interpreter
thread and not the PsychHID kbqueue thread, this is a no-go. I tried,
it fails with "permission denied" error code, as stated in the
docs for RegisterTouchWindow().

A second option would have been to RegisterTouchWindow() from the
main thread in PsychHIDOSKbQueueStart() on the PTB onscreen window,
ie. on the main thread that created that window (albeit inside
Screen mex instead of PsychHID mex, but win32 doesn't know that),
and then maybe use AttachThreadInput() to redispatch all events
received by the main thread to our kbqueue thread. Problem with that
is that in my understanding (not tested, but deduced from earlier
failed experiments with AttachThreadInput()), the main thread would
still have to drive the message pump to get events from its win32
event queue to the PsychHID kbqueue queue. Iow. Touch input would
not be processed at time of touch event delivery by Windows, but
only as part of general event processing as triggered by Screen('Flip'),
GetMouse, KbWait - iow. a purely synchronous model. While this is
not impossible to do, it would add handshaking headaches or pseudo-
races between OS event delivery, pumping on the main thread driven
by user scripts calling suitable trigger functions at a frequency
and timing in the sole discretion of the user script -- iow. maybe
not often enough or at the right points in time, and async reception
by the kbqueue processing thread. This can create lots of correctness
issues, because it is highly dependent on user scripts doing the
right thing without users understanding what the right thing is and
how to implement it in any given experimental paradigm. So this
option has been discarded as too likely to cause hard to debug bugs.

A third option would have been to register for raw input, as that
can apparently be processed from anywhere in the system on any thread,
or at least that's what i think it does, from a cursory read of the
documentation. Problem with that is that we'd get unparsed HID raw
events, instead of touch events, so we'd have to implement our own
HID driver for touch input, possibly for every variant of touchscreen
out there -- very high recurring costs, need for reverse engineering!

Anyway, so the solution we are going for is yet another hack, which
luckily works, at least atm. as of Windows-10 May 2019 update on one
test machine, and more recent October 2020 20H2 update on another
machine:

- The kbqueue processing thread creates its own window "touchWin"
  for reception of touch input events, ie. RegisterTouchWindow()
  on it. The window is created/destroyed inside the thread main
  loop as needed, ie. whenever TouchQueueStart / TouchQueueStop
  is called.

- The window has special windows property set, these are key to
  this hack working without impairing visual stimulation for the
  associated PTB Screen() onscreen window:

  WS_VISIBLE so it is logically "visible" and can receive input.
  WS_POPUP to remove all its window decorations, borders, title bar
  etc., so only the cient area would be there.

  WS_EX_TOPMOST, so it is located on top of the z-order of the
  window stack, *in front of* the PTB onscreen window, and with
  its client area exactly identical to the associated PTB onscreen
  window, so it "covers" and "occludes" the onscreen window, so any
  input events like touch input will end up in its event queue,
  instead of going to the PTB onscreen window. This is crucial!

  WS_EX_NOACTIVATE, so it doesn't become the active foreground window
  or keyboard input focus  window ever! Not at creation, not if it
  receives actual touch input or mouse clicks! This is crucial to
  retain proper visual stimulus onset timing and timestamping for
  fullscreen onscreen windows! Why? If the touch window would become
  the active window, it would take the active status away from the
  PTB onscreen window. This would disable pageflipping/compositor
  bypass on the onscreen window, it would go through the DWM
  compositor and visual timing would be toast!

  As a mild optimization, on Windows 8 and later, we also apply
  WS_EX_NOREDIRECTIONBITMAP to tell the DWM that no redirection
  surface is needed, as the window will not ever display any
  visual content.

  The net result is a topmost invisible inactive window covering
  the area of the onscreen window, which receives all touch input
  events for touches inside the onscreen windows client area.

I was surprised this hack would work, but at least on the two tested
Windows 10 machines with May 2019 and October 2020 20H2 update and
single-touchscreen and dual-touchscreen config, it worked. Visual
timing was indirectly verified as seen in MultiTouchMinimalDemo
with verbosity flag 2 -- It doesn't report input focus loss for the
onscreen window, one requirement for DWM bypass and good timing.
Also the new Screen('Preference','VisualDebuglevel', 6) debug
setting assigns WS_EX_NOREDIRECTIONBITMAP to PTB onscreen windows,
so if they go through DWM desktop composition, their client area
will turn transparent. This didn't happen during testing, indicating
successfull compositor bypass for PTB controlled pageflipping. PTB's
internal timstamping consistency checks also didn't trigger.

As a countercheck, without WS_EX_NOACTIVATE, DWM bypass was indicated
by transparent onscreen window, input focus was reported as lost, and
most of the time PTB's timestamping checks would trigger an error.

So i'm reasonably convinced this doesn't interfere with timing on
a "single onscreen window per session" setup for the single touch
enabled onscreen window. And multiple onscreen windows are broken
on Windows 8 and later timing-wise anyway, so this won't make it
worse than it already is.

Note we use touch event timestamping, remapping event msecs timestamps
to GetSecs() time. The quality and accuracy of touch input timestamps
on Windows is unclear atm. as our KeyboardLatencyTest() for touch
input was very noisy and inconclusive.

Tested OS versions: Windows 10 May 2019 edition, October 2020
edition, 20H2 edition, and the 21H1 edition which is the most
recent Windows-10 version as of 3rd October 2021.

Tested hardware: Microsoft Surface Pro 6 with internal touchscreen
and also with RaspberryPi touchscreen attached as secondary screen.

PC darlene with dual-display, one regular monitor, and the RPi
touchscreen as second monitor, which needed to be set as primary
monitor / main monitor, both for proper touch input coordinate
mapping and for proper onscreen window visual timing.

One curious limitation was observed on the MS Surface Pro dual
touchscreen setup: Only touches from one screen at a time were
reported. If a touch sequence was initiated on one screen, touch
input from the other was ignored/not reported at all until the
touch sequence was finalized. There seems to be a MS-Windows OS
limitation of "only touch one touchscreen at a time". Weird, and
probably inconvenient for some experimental scenarios, but it is
what it is...

Some of the prep work / infrastructure work for this commit is
already part of Psychtoolbox 3.0.17 in an inert state for a while.
This is just the "enabling commit" which adds the "secret sauce"
which took very long to figure out.

This multitouch touchscreen support for Windows was sponsored by
Mathworks. Thanks!

Signed-off-by: Mario Kleiner <mario.kleiner.de@gmail.com>

---

# [<](2021-10-02.md) 2021-10-03 [>](2021-10-04.md)

