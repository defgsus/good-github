# [<](2021-07-10.md) 2021-07-11 [>](2021-07-12.md)

1,893,514 events, 1,089,509 push events, 1,595,266 commit messages, 95,623,530 characters


## [DasSkelett/LunaMultiplayer](https://github.com/DasSkelett/LunaMultiplayer)@[06d3f65e8a...](https://github.com/DasSkelett/LunaMultiplayer/commit/06d3f65e8a374bc9d3d98688f475c6a63c01bfef)
#### Sunday 2021-07-11 00:14:35 by DasSkelett

Extend IPv6 support

**Client**
- Initiate single global ClientConnection at startup, don't replace after disconnect
- Make socket IPv4-only if OS doesn't support IPv6
- Implement IPv6->IPv4 fallback logic in ConnectToServer for direct connections
- The manual retries in `ConnectToServer()` have been removed and replaced by Lidgren's builtin retry logic configured via `Config.MaximumHandshakeAttempts` and `Config.ResendHandshakeInterval`
- `SendNetworkMessage()` starts the `NetClient` when sending unconnected messages to the master servers if necessary, usually when retrieving the server list.
- Servers in the server list are now updated when receiving new data (especially useful for debugging, but might benefit other situations as well)
- Communicate IPv6 addresses with master servers when asking for NAT introduction
- `ServerIsInLocalLan()` compares the prefix for IPv6 addresses (thanks to the global uniqueness of GlobalUnicastAddresses this is fairly reliable)
- Add debug option to overwrite the master server list
- Show IPv6 RTT in server list

**Server**
- Communicate IPv6 addresses with master servers
- Add debug setting to overwrite master server list

**Master server**
- Support IPv6 addresses for servers, send to clients
- Send another NAT introduction for IPv6, if both client and server have IPv6 enabled:
  - The first NAT introduction message triggers hole punching for both the public IPv4 addresses and the IPv6 addresses. This is unavoidable, since we need to send the trigger message to the public IPv4 addresses of the client and server.
    This one is likely to succeed in the most common case (as long as both client and server have working IPv6, or the IPv4 NAT in between allows hole punching).
  - The second NAT introduction message triggers hole punching for both the public IPv4 addresses again and the internal IPv4 addresses. It is sent after a delay of 50 ms, to allow some cooldown after the first round (even though my testing showed there's no problem with sending dozens of NAT punch-through messages, the connection setup after a punch-through succeeded is race-free).
  - Since we have this delay of 50ms, the whole operation now happens in a background thread, as to not block receiving and processing other messages in the meantime.
- Fail softly if it can't get its own external IPv4 address, e.g. if networking of the container is broken \*ahem\*
- Show IPv6 address in HTTP interface table
- Add debug option to overwrite the master server list

**Common**
- `CreateAddressFromString()`  now supports parsing IPv6 addresses, however it does still filter out AAAA records of hostnames. This is not a problem, because it is only used to read the master and dedicated server lists, both of which must run on IPv4 (or dual-stack) as of now. At some point it should be refactored to return an array of addresses, including IPv6.
- `CreateEndpointFromString()` returns all addresses for a hostname, instead of the first. This fixes the direct connection feature if a hostname has an AAAA record but the server (or client) are not IPv6-enabled.  This was already broken before #445.
- A new `GetOwnInternalIPv6Address()` can return any available GUA address, it filters out link-locals and ULAs, first of which are non-routable and the second indicating that the machine is behind IPv6 NAT (ULA's are roughly equivalend to IPv4's RFC1918 subnets, 10.0.0.0/8 etc.).

**Build**
- Some of the `PostBuildEvent` statements have been fixed to not run on *nix systems, there's no `xcopy`.

**Future enhancements**
- Look into port opening for IPv6 using [PCP](https://en.wikipedia.org/wiki/Port_Control_Protocol). It's not as heavily needed for the server, as firewall punch-through is much more likely to succeed via IPv6 due to the lack of NAT. And for the master server you should set up manual port forwardings/openings anyway for stability.
- Look into better ways to determine whether a server is on the same network as the client for IPv6 addresses. Maybe by checking whether the route has gateway or is on-link?
- Make servers lsiten on IPv6 by default after thorough testing, so even casual users who don't look too deep into config files experience the benefits of IPv6.
- Support IPv6-only servers, make master servers listen on IPv6 as well. There is probably not much demand for this, and it is a little trickier to do, but maybe it's useful for some people.

---
## [FrancisMurillo/commanded](https://github.com/FrancisMurillo/commanded)@[f39874cfa3...](https://github.com/FrancisMurillo/commanded/commit/f39874cfa3d4f8a29b309d90892d751083ced275)
#### Sunday 2021-07-11 01:29:19 by Miguel Palhas

Ability to globally override include_execution_result and
include_aggregainclude_aggregate_version

We want to enforce consistent return values in our entire app.
`:include_execution_result` looks exactly like what we want, and
currently fixes two problems for us, so we want to enforce it globally.

I did a similar change to what my colleague zamith already did
previously for another option. however, unlike his case, I didn't find
a good way to test this. Would love to get any input on that front

---
## [WagicProject/wagic](https://github.com/WagicProject/wagic)@[d98956a1b8...](https://github.com/WagicProject/wagic/commit/d98956a1b81263dad65607bda0a68fa1a0c7eb5c)
#### Sunday 2021-07-11 02:41:19 by Eduardo

Fixes to primitives

Dwarven Mine, no need to tap for red since it's a mountain
Mystic Sanctuary, no need to tap for blue since it's an island
Earthshaker Giant does not work
Ranger-Captain of Eos puts card into play not into hand
Jorn, God of Winter has wrong stats
Enemy of Enlightenment subtype misspell
Heavenly Qilin subtype misspell
Urza's Saga subtype misspell
Spirit of the Aldergard subtype misspell
dire tactics loses life even with human on board
piercing rays taps 2 creatures
shipwreck moray should grant +2/-2
sorin, vampire lord text is wrong
spontaneous artist grants 2 energy
Spinerock Knoll does nothing

---
## [NateEag/nateeag.com](https://github.com/NateEag/nateeag.com)@[dfe1da83b3...](https://github.com/NateEag/nateeag.com/commit/dfe1da83b304f90510db648044a5cfff22838727)
#### Sunday 2021-07-11 02:53:51 by Nate Eagleson

Add Mossflower to my reading list for the year

Man. I can remember when I read easily a hundred books a year, usually
several hundred.

Life is different when you have kids.

...annnnd, if I'm honest, when you have a smartphone. That thing sucks
away so much of my time.

---
## [Fargowilta/FargowiltasSouls](https://github.com/Fargowilta/FargowiltasSouls)@[123ed3c9da...](https://github.com/Fargowilta/FargowiltasSouls/commit/123ed3c9dad91f773440054f74957467af354a62)
#### Sunday 2021-07-11 04:25:37 by terrynmuse

nerfed cultist life to 60k (was 80k)
cultist lighting adjusted during ritual
cultist ice mist p2 frost waves adjusted
cultist p2 vortexes track player better, improved consistency and made bolts fire successively faster (this is a nerf)
cultist nebula sphere now starts slow and then speeds up instead of other way around
cultist ancient lights have a stop-and-go thingy
cultist ancient doom is bigger (this is a NERF, they're easier to see)
cultist pillar glow lines very briefly
tweaked eri cage delay AGAIN
eri vortex indicates starting angles of lightning
eri p3 nebula speed nerfed
betsy indicates max range of electrospheres better
betsy electrosppheres immune to gutted heart now
renamed gutted heart creepers to gutted creepers
gutted heart now prevents projs from dealing damage after impacting it, preventing ml proj splash damage from hurting player after hitting a gutted creeper
slight tweak so pierce iframes cannot block gutted creeper contact damage on hostile enemies
king slime no more stunned
king slime p2 spike rain start velocity nerfed
removed ks enrage
altered devi's pause between attacks, generally longer now
nerfed wof hungry chain barrages, now 3 between world evil attacks (was 4)
plantera crystal leaf shots no longer have predictive aim, instead it's a spread shot and speed nerfed
adjusted rotting stat decreases, no longer stacks with living wasteland, has more visuals when applied
changed how cooldown on debuffs like webbed, frozen, stoned, etc. works, now youre immune to them applying again for 4 seconds from most sources after it wears off
added cursed from most enemies to above cooldown debuffs
adjusted backgrounds for class seal buff icons to make them more noticeable
jungle ench gives a weak dash
mutant gives healing when he enters p3, but increased damage of p3
lovestruck on nymph/devi causes you to spew hearts that heal them instead of instant healing
adjusted mutant nuke dust AGAIN
tweaked fossil revive internal implementation, nerfed revival iframes to 3sec (was 5) but gives invul on all iframe timers
fossil/abom wand both print you've revived to chat and combat text since i actually did not notice fossil activating
spaz shoots dark stars instead of fireballs when aiding reti ray spin
reti shoots homing dark stars instead of lasers below 50%
buffed hitbox of dark stars
twins no longer shoot rings of dark stars at 1 life, added text when they endure
prime has improved tells on which limbs he's activating in p2
nerfed golem fists, they can only punch once every 1.5sec (prevents them from machine gun punching next to a wall)
buffed golem fists/head, they track golem body better and don't lag behind when he jumps
fixed golem fists enraging and exploding in edge cases where fists clipped through blocks and "left temple" but you were still fighting in it
golem fist explosions are visible now

---
## [JeremyLeland/caves](https://github.com/JeremyLeland/caves)@[e58b865eb3...](https://github.com/JeremyLeland/caves/commit/e58b865eb360b7ee1fe2a845efea5ce5930208c0)
#### Sunday 2021-07-11 04:28:37 by Jeremy Leland

Fuck colorizing. Just fuck colorizing. God damn it. I have wasted so much fucking time trying to fucking colorize these fucking images and they look like shit. Fuck it.

---
## [rust-lang-ci/rust](https://github.com/rust-lang-ci/rust)@[0d76b73745...](https://github.com/rust-lang-ci/rust/commit/0d76b7374589c45e3e9290309781a1ed9a461951)
#### Sunday 2021-07-11 06:31:47 by bors

Auto merge of #83918 - workingjubilee:stable-rangefrom-pat, r=joshtriplett

Stabilize "RangeFrom" patterns in 1.55

Implements a partial stabilization of #67264 and #37854.
Reference PR: https://github.com/rust-lang/reference/pull/900

# Stabilization Report

This stabilizes the `X..` pattern, shown as such, offering an exhaustive match for unsigned integers:
```rust
match x as u32 {
      0 => println!("zero!"),
      1.. => println!("positive number!"),
}
```

Currently if a Rust author wants to write such a match on an integer, they must use `1..={integer}::MAX` . By allowing a "RangeFrom" style pattern, this simplifies the match to not require the MAX path and thus not require specifically repeating the type inside the match, allowing for easier refactoring. This is particularly useful for instances like the above case, where different behavior on "0" vs. "1 or any positive number" is desired, and the actual MAX is unimportant.

Notably, this excepts slice patterns which include half-open ranges from stabilization, as the wisdom of those is still subject to some debate.

## Practical Applications

Instances of this specific usage have appeared in the compiler:
https://github.com/rust-lang/rust/blob/16143d10679537d3fde4247e15334e78ad9d55b9/compiler/rustc_middle/src/ty/inhabitedness/mod.rs#L219
https://github.com/rust-lang/rust/blob/673d0db5e393e9c64897005b470bfeb6d5aec61b/compiler/rustc_ty_utils/src/ty.rs#L524

And I have noticed there are also a handful of "in the wild" users who have deployed it to similar effect, especially in the case of rejecting any value of a certain number or greater. It simply makes it much more ergonomic to write an irrefutable match, as done in Katholieke Universiteit Leuven's [SCALE and MAMBA project](https://github.com/KULeuven-COSIC/SCALE-MAMBA/blob/05e5db00d553573534258585651c525d0da5f83f/WebAssembly/scale_std/src/fixed_point.rs#L685-L695).

## Tests
There were already many tests in [src/test/ui/half-open-range/patterns](https://github.com/rust-lang/rust/tree/90a2e5e3fe59a254d4d707aa291517b3791ea5a6/src/test/ui/half-open-range-patterns), as well as [generic pattern tests that test the `exclusive_range_pattern` feature](https://github.com/rust-lang/rust/blob/673d0db5e393e9c64897005b470bfeb6d5aec61b/src/test/ui/pattern/usefulness/integer-ranges/reachability.rs), many dating back to the feature's introduction and remaining standing to this day. However, this stabilization comes with some additional tests to explore the... sometimes interesting behavior of interactions with other patterns. e.g. There is, at least, a mild diagnostic improvement in some edge cases, because before now, the pattern `0..=(5+1)` encounters the `half_open_range_patterns` feature gate and can thus emit the request to enable the feature flag, while also emitting the "inclusive range with no end" diagnostic. There is no intent to allow an `X..=` pattern that I am aware of, so removing the flag request is a strict improvement. The arrival of the `J | K` "or" pattern also enables some odd formations.

Some of the behavior tested for here is derived from experiments in this [Playground](https://play.rust-lang.org/?version=nightly&mode=debug&edition=2018&gist=58777b3c715c85165ac4a70d93efeefc) example, linked at https://github.com/rust-lang/rust/issues/67264#issuecomment-812770692, which may be useful to reference to observe the current behavior more closely.

In addition tests constituting an explanation of the "slicing range patterns" syntax issue are included in this PR.

## Desiderata

The exclusive range patterns and half-open range patterns are fairly strongly requested by many authors, as they make some patterns much more natural to write, but there is disagreement regarding the "closed" exclusive range pattern or the "RangeTo" pattern, especially where it creates "off by one" gaps in the presence of a "catch-all" wildcard case. Also, there are obviously no range analyses in place that will force diagnostics for e.g. highly overlapping matches. I believe these should be warned on, ideally, and I think it would be reasonable to consider such a blocker to stabilizing this feature, but there is no technical issue with the feature as-is from the purely syntactic perspective as such overlapping or missed matches can already be generated today with such a catch-all case. And part of the "point" of the feature, at least from my view, is to make it easier to omit wildcard matches: a pattern with such an "open" match produces an irrefutable match and does not need the wild card case, making it easier to benefit from exhaustiveness checking.

## History

- Implemented:
  - Partially via exclusive ranges: https://github.com/rust-lang/rust/pull/35712
  - Fully with half-open ranges: https://github.com/rust-lang/rust/pull/67258
- Unresolved Questions:
  - The precedence concerns of https://github.com/rust-lang/rust/pull/48501 were considered as likely requiring adjustment but probably wanting a uniform consistent change across all pattern styles, given https://github.com/rust-lang/rust/issues/67264#issuecomment-720711656, but it is still unknown what changes might be desired
  - How we want to handle slice patterns in ranges seems to be an open question still, as witnessed in the discussion of this PR!

I checked but I couldn't actually find an RFC for this, and given "approved provisionally by lang team without an RFC", I believe this might require an RFC before it can land? Unsure of procedure here, on account of this being stabilizing a subset of a feature of syntax.

r? `@scottmcm`

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[551351f248...](https://github.com/mrakgr/The-Spiral-Language/commit/551351f248a1076039b4d090b960cb890c25c3f2)
#### Sunday 2021-07-11 11:00:18 by Marko Grdinić

"10:40am. Yesterday I went to bed late, but I did not botch my sleep. Let me just get over my grogginess and I will start.

11:10am. Done chilling. It is time to get something done for the day. Today my agenda is to study the `x-transformers` library. After I do that, I will have everything I need to get started with using them.

11:15am. https://github.com/lucidrains/x-transformers#gated-residual

Why are they using the Decoders instead of Encoders here?

Ok, first of all, let me go through the docs top to bottom. There is not much of them, and I mainly need to figure out how the masks work.

11:30am.

```py
import torch
from x_transformers import ContinuousTransformerWrapper, Decoder

model = ContinuousTransformerWrapper(
    dim_in = 32,
    dim_out = 100,
    max_seq_len = 1024,
    attn_layers = Decoder(
        dim = 512,
        depth = 12,
        heads = 8
    )
)

x = torch.randn((1, 1024, 32))
mask = torch.ones(1, 1024).bool()

model(x, mask = mask) # (1, 1024, 100)
```

This is the padding mask right? I am confused which dimension is the batch and which the sequence...no wait. The second dimension is definitely the sequence as it should be. Why would the example have a sequence of 1 here?

```py
class Encoder(AttentionLayers):
    def __init__(self, **kwargs):
        assert 'causal' not in kwargs, 'cannot set causality on encoder'
        super().__init__(causal = False, **kwargs)

class Decoder(AttentionLayers):
    def __init__(self, **kwargs):
        assert 'causal' not in kwargs, 'cannot set causality on decoder'
        super().__init__(causal = True, **kwargs)
```

The only difference between a decoder and an encoder is the causal argument here.

```
(x, return_embeddings=False, mask=None, return_attn=False, mems=None, **kwargs) -> (tuple[Any, list] | Any)
```

This mask is a padding mask, but what about the attention mask. Also what about the source and target inputs?

```
import torch
from x_transformers import XTransformer

model = XTransformer(
    dim = 512,
    enc_num_tokens = 256,
    enc_depth = 6,
    enc_heads = 8,
    enc_max_seq_len = 1024,
    dec_num_tokens = 256,
    dec_depth = 6,
    dec_heads = 8,
    dec_max_seq_len = 1024,
    tie_token_emb = True      # tie embeddings of encoder and decoder
)

src = torch.randint(0, 256, (1, 1024))
src_mask = torch.ones_like(src).bool()
tgt = torch.randint(0, 256, (1, 1024))
tgt_mask = torch.ones_like(tgt).bool()

loss = model(src, tgt, src_mask = src_mask, tgt_mask = tgt_mask) # (1, 1024, 512)
loss.backward()
```

This has the source and the target. Let me study it.

```py
def groupby_prefix_and_trim(prefix, d):
    kwargs_with_prefix, kwargs = group_dict_by_key(partial(string_begins_with, prefix), d)
    kwargs_without_prefix = dict(map(lambda x: (x[0][len(prefix):], x[1]), tuple(kwargs_with_prefix.items())))
    return kwargs_without_prefix, kwargs
```

Whoever wrote this library is quite decent at FP.

```py
class XTransformer(nn.Module):
    def __init__(
        self,
        *,
        dim,
        tie_token_emb = False,
        **kwargs
    ):
        super().__init__()
        enc_kwargs, kwargs = groupby_prefix_and_trim('enc_', kwargs)
        dec_kwargs, kwargs = groupby_prefix_and_trim('dec_', kwargs)

        assert 'dim' not in enc_kwargs and 'dim' not in dec_kwargs, 'dimension of either encoder or decoder must be set with `dim` keyword'
        enc_transformer_kwargs = pick_and_pop(['num_tokens', 'max_seq_len'], enc_kwargs)
        enc_transformer_kwargs['num_memory_tokens'] = enc_kwargs.pop('num_memory_tokens', None)

        dec_transformer_kwargs = pick_and_pop(['num_tokens', 'max_seq_len'], dec_kwargs)

        self.encoder = TransformerWrapper(
            **enc_transformer_kwargs,
            attn_layers = Encoder(dim = dim, **enc_kwargs)
        )

        self.decoder = TransformerWrapper(
            **dec_transformer_kwargs,
            attn_layers = Decoder(dim = dim, cross_attend = True, **dec_kwargs)
        )

        if tie_token_emb:
            self.decoder.token_emb = self.encoder.token_emb

        self.decoder = AutoregressiveWrapper(self.decoder)
```

Ok, so this has the encoder and the decoder. Let me study the forward.

```py
    def forward(self, src, tgt, src_mask = None, tgt_mask = None):
        enc = self.encoder(src, mask = src_mask, return_embeddings = True)
        out = self.decoder(tgt, context = enc, mask = tgt_mask, context_mask = src_mask)
        return out
```

Ah, it has something called the context.

```py
import torch
from x_transformers import ContinuousTransformerWrapper, Decoder, Encoder, XTransformer

model = ContinuousTransformerWrapper(
    max_seq_len=128,
    attn_layers = Decoder(
        dim = 32,
        depth = 2,
        heads = 1,
        gate_residual = True,
        rotary_pos_emb = True
    )
)

q = torch.rand(1,20,32)
w = torch.rand(1,20,32)
model.forward(q) == model.forward(q,context=w)
```

Mhhh, the context is not doing anything here.

```
decoder = TransformerWrapper(
    num_tokens = 20000,
    max_seq_len = 1024,
    attn_layers = Decoder(
        dim = 512,
        depth = 6,
        heads = 8,
        cross_attend = True
    )
)
```

Maybe I need to pass in this `cross_attend = True`. What is it?

12pm.

```py
        if exists(rotary_pos_emb) and not has_context:
            l = rotary_pos_emb.shape[-1]
            (ql, qr), (kl, kr), (vl, vr) = map(lambda t: (t[..., :l], t[..., l:]), (q, k, v))
            ql, kl = map(lambda t: apply_rotary_pos_emb(t, rotary_pos_emb), (ql, kl))
            q, k, v = map(lambda t: torch.cat(t, dim = -1), ((ql, qr), (kl, kr), (vl, vr)))
```

This library is quite well made. Definitely came out better than I would have written it in Python.

```py
        if self.causal:
            i, j = dots.shape[-2:]
            r = torch.arange(i, device = device)
            mask = rearrange(r, 'i -> () () i ()') < rearrange(r, 'j -> () () () j')
            mask = F.pad(mask, (j - i, 0), value = False)
            dots.masked_fill_(mask, mask_value)
            del mask
```

Causal seems to be doing this.

12:15pm. Yes, this makes the attention mask. And from it I can conclude that I definitely need the Encoder. Having the earlier tokens not being able to see the later like in the Decoder is not what I want. The only thing I do not understand where the context is being handled.

```py
        kv_input = default(context, x)

        q_input = x
        k_input = kv_input
        v_input = kv_input
```

Ah, it is pretty simple actually. That default just returns the second argument if the first one is None.

12:25pm.

```py
        input_mask = None
        if any(map(exists, (mask, context_mask))):
            q_mask = default(mask, lambda: torch.ones((b, n), device = device).bool())
            k_mask = q_mask if not exists(context) else context_mask
            k_mask = default(k_mask, lambda: torch.ones((b, k.shape[-2]), device = device).bool())
            q_mask = rearrange(q_mask, 'b i -> b () i ()')
            k_mask = rearrange(k_mask, 'b j -> b () () j')
            input_mask = q_mask * k_mask
```

I can appreciate the coding style here. This kind of helper is something I could have used myself while doing signSGD.

One thing that has me wondering is whether torch.ones here is right? Maybe raising an exception would be better?

```
mask = F.pad(mask, (j - i, 0), value = False)
```

And I see this and am wondering whether an assert to check that j == i would be better.

I am confused what it means to have causal lookahead when there is cross attention.

12:40pm. Well, it would somewhat make sense when the sequences are the same length. But in this case, just how would one prevent it from masking out the context?

Well, in that case you'd just use an Encoder instead. If the targets and the source are different then there is no need for causal masking.

Hmmmm, I am not sure Encoder and Decoder layers in this library and PyTorch have anything to do with each other.

```
    def forward(self, src, tgt, src_mask = None, tgt_mask = None):
        enc = self.encoder(src, mask = src_mask, return_embeddings = True)
        out = self.decoder(tgt, context = enc, mask = tgt_mask, context_mask = src_mask)
        return out
```

Hmmm, here they use the decoder for the target and the context. I am not sure what to think. It would have made more sense for me if it were reversed.

12:50pm.

```py
import torch
from x_transformers import XTransformer

model = XTransformer(
    dim = 512,
    enc_num_tokens = 256,
    enc_depth = 6,
    enc_heads = 8,
    enc_max_seq_len = 1024,
    dec_num_tokens = 256,
    dec_depth = 6,
    dec_heads = 8,
    dec_max_seq_len = 1024,
    tie_token_emb = True      # tie embeddings of encoder and decoder
)

src = torch.randint(0, 256, (1, 1024))
src_mask = torch.ones_like(src).bool()
tgt = torch.randint(0, 256, (1, 1024))
tgt_mask = torch.ones_like(tgt).bool()

loss = model(src, tgt, src_mask = src_mask, tgt_mask = tgt_mask) # (1, 1024, 512)
loss.backward()
```

Maybe I am misinterpreting what is being done here and in the video by Lennart. Here they are doing autoregressive training (like in a char RNN.) So it makes sense to use causality since the input and output will be a part of the same distribution.

Hmmm, what about the src being in an encoder? By the time that goes to the encoder, wouldn't that result in looking into the future?

Hmmm...what are `return_embeddings`?

```py
out = self.to_logits(x) if not return_embeddings else x
```

```py
out = self.project_out(x) if not return_embeddings else x
```

```py
self.to_logits = nn.Linear(dim, num_tokens) if not tie_embedding else lambda t: t @ self.token_emb.weight.t()
```

https://stackoverflow.com/questions/6392739/what-does-the-at-symbol-do-in-python/28997112#28997112

Ah, Python has a matmul operator.

```py
self.project_out = nn.Linear(dim, dim_out) if exists(dim_out) else nn.Identity()
```

Let me take a break here."

---
## [ProjectIgnis/CardScripts](https://github.com/ProjectIgnis/CardScripts)@[bb4b8e7bbf...](https://github.com/ProjectIgnis/CardScripts/commit/bb4b8e7bbfeaf5bdcda2899976889f4cb1dc2439)
#### Sunday 2021-07-11 13:00:01 by ClementLouis

added new cards + fixes

new:
- Gatekeeping Gargoyle
- Road Magic - Resaltar
- Iron Onslaught
- Mismatch Rivalry
- 7 Chance

fixes
- added missing Yes/No (Demonic Hermit Vessel Kachisuzaku, Heavenly Revelation, Mythic Sword Swordsmith)
- vietor the prevailing wind should not be allowed to activate if you can't enter battle phase
- missing check for Harami Kushiro
- Heat Hyena couting max as 3 instead of 1

---
## [tdauth/wowr](https://github.com/tdauth/wowr)@[963d06e7bb...](https://github.com/tdauth/wowr/commit/963d06e7bbb07b1cc3e00408278e54b2fafafb1b)
#### Sunday 2021-07-11 14:06:38 by barade

Improvements

- Reduce gold bonus for Undead and Night Elf AI from 10 to 5.
- Start with full number of lumber workers for AI.
- Add chat commands like "-friends".
- Change icon of the Magical Cutter.
- Add item Magical Creep Summoner to respawn dead creeps.
- Add new profession "Sorcerer".
- Add second profession selection at hero level 25.
- Decrease the cooldown of Blink with every level.
- Fix the number of Avatars in the tooltip of Vengance.
- Fix registering dialog button events for higher player numbers.
- Translate tooltips of Frost Armor back into English.

---
## [JanCraft/teddor](https://github.com/JanCraft/teddor)@[2c0b3158c3...](https://github.com/JanCraft/teddor/commit/2c0b3158c3aa251ed2aa1b5e01ab67ed5be90c54)
#### Sunday 2021-07-11 15:37:22 by JanCraft's Laptop

Added my TODOs

god i hate myself

this is too much work
fr*ck

---
## [Throlli/DIM-Wishlists](https://github.com/Throlli/DIM-Wishlists)@[cdd57e6a9e...](https://github.com/Throlli/DIM-Wishlists/commit/cdd57e6a9eb8d6aa25aa7174ca69d38cbeb9400f)
#### Sunday 2021-07-11 17:12:25 by Throlli

Introduced Moon and Dreaming City Weapons

Added the following weapons: Loud Lullaby, One Small Step, Tranquility, Arc Logic, Dream Breaker, Every Waking Moment, Love and Death, A Fine Memorial, Night Terror, Tigerspite, Twilight Oath, Abide the Return and Compass Rose

---
## [jcblemai/PhDThesis](https://github.com/jcblemai/PhDThesis)@[29c71c7ab3...](https://github.com/jcblemai/PhDThesis/commit/29c71c7ab35c095f0b6722546511d202ffd1cf26)
#### Sunday 2021-07-11 17:31:56 by chadi

omg there's a ebgaramond-math font I'm in love 😍, also I should have other priorities atm

---
## [scanamo/scanamo](https://github.com/scanamo/scanamo)@[791c728ded...](https://github.com/scanamo/scanamo/commit/791c728ded6a335aa86b2f6e5b32008b7bac6c64)
#### Sunday 2021-07-11 17:46:52 by Roberto Tyley

gitignore files that new developers will commonly encounter

Both IntelliJ and Bloop can create a lot of files that aren't meant to be
committed to source control, and for new contributors coming to Scanamo,
the big list of files they'll see when they come to contribute a commit
can be quite intimidating. IntelliJ is a common IDE for Scala developers,
even more so amongst less-experienced devs.

One possible way of handling this is asking all contributors to add entries
to their personal, user-specific, global git settings, which would avoid
lengthening the .gitignore file committed within the repo itself. However,
if that's the route we want to take, the very minimum we should do is
*document this* for new contributors in the `CONTRIBUTING.md` file. At that
point, it feels to me that it must in fact be better to add common
requirements in a machine-readable format in the .gitignore file, rather
than human-friendly instructions in the `CONTRIBUTING.md`!

---
## [makingglitches/GooglePhotoDownload](https://github.com/makingglitches/GooglePhotoDownload)@[674ce04602...](https://github.com/makingglitches/GooglePhotoDownload/commit/674ce046027eafe0b2d946cd97e3e7eeca140316)
#### Sunday 2021-07-11 18:41:17 by John Sohn

fixed some issues related to accounts with the same images and videos
added some statistics gathering information
pointed out what they are up to everytime they steal my code
fuck them.
redid the fucking keytree code since they're playing the 'lets cut the whole world off to protect fucking chomo garbage' bullshit they did to steal half the straight guys fucking life
fucking whores
i fucked alot of your mothers, please die now.

---
## [KingIburu/github-slideshow](https://github.com/KingIburu/github-slideshow)@[a045ac9849...](https://github.com/KingIburu/github-slideshow/commit/a045ac98496ba51b5a084d6f005a4484c8cb9ea0)
#### Sunday 2021-07-11 18:52:19 by KingIburu

Update 0000-01-02-KingIburu.md

fuckking bloody annoying i need sleep.

---
## [Floranid/Sweet-Daddy](https://github.com/Floranid/Sweet-Daddy)@[7efb08aa73...](https://github.com/Floranid/Sweet-Daddy/commit/7efb08aa73ba7080462cf00e54ecb176a3e231db)
#### Sunday 2021-07-11 19:53:49 by Floranid

Add License 

DO WHATEVER THE FUCK YOU WANT LICENSE

---
## [ruuda/musium](https://github.com/ruuda/musium)@[785dcc38b7...](https://github.com/ruuda/musium/commit/785dcc38b78870d3aa01d73fb21484ffd016d7d0)
#### Sunday 2021-07-11 20:40:15 by Ruud van Asseldonk

Add a state variable filter

Some modern music, especially from recent years, is super bass-heavy,
and when I play it on my HS8s, the room quickly feels “saturated”, even
at a fairly low volume. I don’t dare to turn up the volume much further,
because it is unfomfortable to listen to, but also because I don’t want
to disturb my neighbors. At this volume, the mids are too soft to enjoy
all of the details.

So I think the time has come to introduce some form of EQ. When
experimenting, statically applying a parametric EQ to remove some of
the lows around 30 Hz worked nicely. I want to be able to do this
automatically though, similar to loudness normalization. Some albums,
especially those from the 1980s, are fine as-is, but some really need
their low end toned down a bit. I’m experimenting a bit with that, but
I haven’t found a measurable metric that agrees with my subjective
experience. Either way, in the meantime I can already add this filter
here, and play with the parameters a bit.

I went down the filtering rabbit hole yesterday, from multi-tap IIR
filters, to stacked biquads, but I couldn’t get it to work nicely as a
30Hz low-pass filter with fixed point arithmetic. I later discovered the
very helpful site earlevel.com, which explains that indeed, biquadratic
filters are no good fit for low-pass filters at low cutoff frequencies,
they get numerically unstable, but the so-called “digital state variable
filter” is a good fit here. It turned out to be relatively easy to
implement, and it works great.

I prepared this in a different repository yesterday, so I could also run
some experiments, but let’s no move it here so I can embed it into the
decoding pipeline.

I also considered setting up a virtual Alsa device that has a filter
applied, but it seems pretty complex to get that working, and it would
filter everything, I would not be able to make it filter only the
bass-heavy tracks. So I think the Musium decoder is for now the best
place to put this.

---
## [flofriday/tinydeamon](https://github.com/flofriday/tinydeamon)@[cb5c17e275...](https://github.com/flofriday/tinydeamon/commit/cb5c17e275736c5fd653ab5e59aadaa6632865ca)
#### Sunday 2021-07-11 21:20:26 by flofriday

Add basic result ranking (BM_25)

Oh, damn this was a lot of work (and triel and error) to get here
almost the whole index changed, but I now know better than ever that
the index in the current form does not hold up to larger datasets.

So sharding will be definitly necessary to scale to million webpages.
Well, I kinda knew that but even 10_000 is currently impossible which
just sucks.

---
## [Kisoty/guestbook](https://github.com/Kisoty/guestbook)@[83580e4649...](https://github.com/Kisoty/guestbook/commit/83580e4649e61c8655e68ae4b93cd37badaa06e9)
#### Sunday 2021-07-11 21:23:38 by Kisoty

Some insanely stupid shit done with messenger, but it works ^_^

---
## [KrTeSeriesK/Mickle-Madness](https://github.com/KrTeSeriesK/Mickle-Madness)@[56ce2ebbd3...](https://github.com/KrTeSeriesK/Mickle-Madness/commit/56ce2ebbd35dc5d197f3e1aa44f154d6be60cb1c)
#### Sunday 2021-07-11 23:55:05 by Allan

doin' shit but not gonna finish for a while because stupid band shit :pensive:

this'll probably be the last major change from me for a while lads and lassies, sorry.

---

# [<](2021-07-10.md) 2021-07-11 [>](2021-07-12.md)

