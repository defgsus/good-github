# [<](2021-03-21.md) 2021-03-22 [>](2021-03-23.md)

3,251,872 events, 1,599,683 push events, 2,517,161 commit messages, 185,316,799 characters


## [ccodwg/Covid19Canada](https://github.com/ccodwg/Covid19Canada)@[ca2158088f...](https://github.com/ccodwg/Covid19Canada/commit/ca2158088f74681be98b16a3dc9da3eeed7213d1)
#### Monday 2021-03-22 00:53:01 by Jean-Paul R. Soucy

New data: 2021-03-21. See data notes.

Revise historical data: cases (AB, MB, QC); mortality (ON).

Note regarding deaths added in QC today: â€œ5 new deaths, for a total of 10,599 deaths: 3 deaths in the last 24 hours, 2 deaths between March 14 and March 19.â€ We report deaths such that our cumulative regional totals match todayâ€™s values. This sometimes results in extra deaths with todayâ€™s date when older deaths are removed.

Recent changes:

2021-01-27: Due to the limit on file sizes in GitHub, we implemented some changes to the datasets today, mostly impacting individual-level data (cases and mortality). Changes below:

1) Individual-level data (cases.csv and mortality.csv) have been moved to a new directory in the root directory entitled â€œindividual_levelâ€. These files have been split by calendar year and named as follows: cases_2020.csv, cases_2021.csv, mortality_2020.csv, mortality_2021.csv. The directories â€œother/cases_extraâ€ and â€œother/mortality_extraâ€ have been moved into the â€œindividual_levelâ€ directory.
2) Redundant datasets have been removed from the root directory. These files include: recovered_cumulative.csv, testing_cumulative.csv, vaccine_administration_cumulative.csv, vaccine_distribution_cumulative.csv, vaccine_completion_cumulative.csv. All of these datasets are currently available as time series in the directory â€œtimeseries_provâ€.
3) The file codebook.csv has been moved to the directory â€œotherâ€.

We appreciate your patience and hope these changes cause minimal disruption. We do not anticipate making any other breaking changes to the datasets in the near future. If you have any further questions, please open an issue on GitHub or reach out to us by email at ccodwg [at] gmail [dot] com. Thank you for using the COVID-19 Canada Open Data Working Group datasets.

- 2021-01-24: The columns "additional_info" and "additional_source" in cases.csv and mortality.csv have been abbreviated similar to "case_source" and "death_source". See note in README.md from 2021-11-27 and 2021-01-08.

Vaccine datasets:

- 2021-01-19: Fully vaccinated data have been added (vaccine_completion_cumulative.csv, timeseries_prov/vaccine_completion_timeseries_prov.csv, timeseries_canada/vaccine_completion_timeseries_canada.csv). Note that this value is not currently reported by all provinces (some provinces have all 0s).
- 2021-01-11: Our Ontario vaccine dataset has changed. Previously, we used two datasets: the MoH Daily Situation Report (https://www.oha.com/news/updates-on-the-novel-coronavirus), which is released weekdays in the evenings, and the â€œCOVID-19 Vaccine Data in Ontarioâ€ dataset (https://data.ontario.ca/dataset/covid-19-vaccine-data-in-ontario), which is released every day in the mornings. Because the Daily Situation Report is released later in the day, it has more up-to-date numbers. However, since it is not available on weekends, this leads to an artificial â€œdipâ€ in numbers on Saturday and â€œjumpâ€ on Monday due to the transition between data sources. We will now exclusively use the daily â€œCOVID-19 Vaccine Data in Ontarioâ€ dataset. Although our numbers will be slightly less timely, the daily values will be consistent. We have replaced our historical dataset with â€œCOVID-19 Vaccine Data in Ontarioâ€ as far back as they are available.
- 2020-12-17: Vaccination data have been added as time series in timeseries_prov and timeseries_hr.
- 2020-12-15: We have added two vaccine datasets to the repository, vaccine_administration_cumulative.csv and vaccine_distribution_cumulative.csv. These data should be considered preliminary and are subject to change and revision. The format of these new datasets may also change at any time as the data situation evolves.

https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/#c47900

Note about SK data: As of 2020-12-14, we are providing a daily version of the official SK dataset that is compatible with the rest of our dataset in the folder official_datasets/sk. See below for information about our regular updates.

SK transitioned to reporting according to a new, expanded set of health regions on 2020-09-14. Unfortunately, the new health regions do not correspond exactly to the old health regions. Additionally, the provided case time series using the new boundaries do not exist for dates earlier than August 4, making providing a time series using the new boundaries impossible.

For now, we are adding new cases according to the list of new cases given in the â€œhighlightsâ€ section of the SK government website (https://dashboard.saskatchewan.ca/health-wellness/covid-19/cases). These new cases are roughly grouped according to the old boundaries. However, health region totals were redistributed when the new boundaries were instituted on 2020-09-14, so while our daily case numbers match the numbers given in this section, our cumulative totals do not. We have reached out to the SK government to determine how this issue can be resolved. We will rectify our SK health region time series as soon it becomes possible to do so.

---
## [Dylan-DPC/rust](https://github.com/Dylan-DPC/rust)@[ad8aa185df...](https://github.com/Dylan-DPC/rust/commit/ad8aa185dff457cc18dc38c80d31d348af3d3486)
#### Monday 2021-03-22 01:20:27 by Dylan DPC

Rollup merge of #80771 - thomcc:nonnull-refmut, r=dtolnay

Make NonNull::as_ref (and friends) return refs with unbound lifetimes

# Rationale:

1. The documentation for all of these functions claims that this is what the functions already do, as they all come with this comment:

    > You must enforce Rust's aliasing rules, *since the returned lifetime 'a is arbitrarily chosen* and does not necessarily reflect the actual lifetime of the data...

    So I think it's just a bug that they weren't this way already. Note that had it not been for this part, I wouldn't be making this PR, so if we decide we won't take this change, I'll follow it up with a docs PR to fix this.

2. This is how the equivalent raw pointer functions behave.

    They also take `self` and not `&self`/`&mut self`, but that can't be changed compatibly at this point. This is the next best thing.

3. Without this fix, often code that uses these methods will find it has to expand the lifetime of the result.

    (I can't speak for others but even in unsafe-heavy code, needing to do this unexpectedly is a huge red flag -- if Rust thinks something should have a specific lifetime, I assume it's for a reason)

### Can this cause existing code to be unsound?

I'm confident this can't cause new unsoundness since the reference exists for at most its lifetime, but you get a borrow checker error if you do something that would require/allow the reference to exist past its lifetime.

Additionally, the aliasing rules of a reference only applies while the reference exists.

This *must* be the case, as it is required by the rules used by safe code. (That said, the documentation in this file sort of contradicts it, but I think it's just ambiguity between the lifetime `'a` in `&'a T` and lifetime of the `&'a T` reference itself...)

We are increasing the lifetime of these references, but they should already have hard bounds on that lifetime, or they'd have borrow checker errors.

(CC ``@RalfJung`` because I have gone and done the mistake where I say something definitive about aliasing in Rust which is honestly outside the group of things I should make definitive comments about).

# Caveats

1. This is insta-stable (except for on the unstable functions ofc). I don't think there's any other alternative.

2. I don't believe this is a breaking change in practice. In theory someone could be assigning `NonNull::as_ref` to a function pointer of type `fn(&NonNull<T>) -> &T`. Now they'd need to use a slightly different function pointer type which is (probably) incompatible. This seems pathological, but I guess crater could be used if there are concerns.

3. This has no tests. The old version didn't either that I saw. I could add some stuff that fails to compile without it, if that would be useful.

4. Sometimes the NLL borrow checker gives up and decides lifetimes live till the end of the scope, as opposed to the range where they're used. If this change can cause this to happen more, then my soundness rationale is wrong, and it's likely breaking.

    In practice this seems super unlikely.

Anyway. That was a lot of typing.

Fixes https://github.com/rust-lang/rust/issues/80183

---
## [tomashphill/tomashphill.github.io](https://github.com/tomashphill/tomashphill.github.io)@[3f3cd53f1f...](https://github.com/tomashphill/tomashphill.github.io/commit/3f3cd53f1f43fae757c244f95e29cf4993309b97)
#### Monday 2021-03-22 02:22:35 by tomashphill

fixed two typos pointed out by my lovely sister. Should really type things out where there is autocorrect beforehand. Lesson learned.

---
## [maborak/iemaddon-installer](https://github.com/maborak/iemaddon-installer)@[84763e93d6...](https://github.com/maborak/iemaddon-installer/commit/84763e93d6184fed4bff5230851eed7fadf1023f)
#### Monday 2021-03-22 04:00:15 by Wilmer Adalid (Alienware)

Updates for: If you make people think they're thinking, they'll love you; but if you
really make them think they'll hate you.

---
## [xn4k/xn4k](https://github.com/xn4k/xn4k)@[d43814376e...](https://github.com/xn4k/xn4k/commit/d43814376e135fdb0a430011bd097344c996db4f)
#### Monday 2021-03-22 04:17:44 by Mikhail Zhivoderov

new info 

Passionate about cybersecurity, i like to participate in CTF's and playing games. Interested in Web-application testing and coding.
- ðŸ‘¾ Iâ€™m currently bug hunter on hackerone.com 
- ðŸ‘» Iâ€™m good at being confused, interesten in PWN and Reverse Engeneering but i have no clue about it 
- ðŸ§™â€â™‚ï¸ Iâ€™m looking to collab. with other content creators, so reach out to connect!
- ðŸ¤µðŸ¼ Fun fact: I love to make music, midnight hacking, sports and build some mindmapsðŸ˜‚
- ðŸ‘¨ðŸ½â€ðŸ’» 2021 Goals: Studying now for CEH Practical and eJPT 
- [ðŸ³](https://xn4k.github.io/) My Blog

---
## [dreamisbaka/android_kernel_xiaomi_sm8250](https://github.com/dreamisbaka/android_kernel_xiaomi_sm8250)@[0c652b94f8...](https://github.com/dreamisbaka/android_kernel_xiaomi_sm8250/commit/0c652b94f8fc78b533b8e362860292a590f82b80)
#### Monday 2021-03-22 07:30:28 by Peter Zijlstra

sched/core: Fix ttwu() race

Paul reported rcutorture occasionally hitting a NULL deref:

  sched_ttwu_pending()
    ttwu_do_wakeup()
      check_preempt_curr() := check_preempt_wakeup()
        find_matching_se()
          is_same_group()
            if (se->cfs_rq == pse->cfs_rq) <-- *BOOM*

Debugging showed that this only appears to happen when we take the new
code-path from commit:

  2ebb17717550 ("sched/core: Offload wakee task activation if it the wakee is descheduling")

and only when @cpu == smp_processor_id(). Something which should not
be possible, because p->on_cpu can only be true for remote tasks.
Similarly, without the new code-path from commit:

  c6e7bd7afaeb ("sched/core: Optimize ttwu() spinning on p->on_cpu")

this would've unconditionally hit:

  smp_cond_load_acquire(&p->on_cpu, !VAL);

and if: 'cpu == smp_processor_id() && p->on_cpu' is possible, this
would result in an instant live-lock (with IRQs disabled), something
that hasn't been reported.

The NULL deref can be explained however if the task_cpu(p) load at the
beginning of try_to_wake_up() returns an old value, and this old value
happens to be smp_processor_id(). Further assume that the p->on_cpu
load accurately returns 1, it really is still running, just not here.

Then, when we enqueue the task locally, we can crash in exactly the
observed manner because p->se.cfs_rq != rq->cfs_rq, because p's cfs_rq
is from the wrong CPU, therefore we'll iterate into the non-existant
parents and NULL deref.

The closest semi-plausible scenario I've managed to contrive is
somewhat elaborate (then again, actual reproduction takes many CPU
hours of rcutorture, so it can't be anything obvious):

					X->cpu = 1
					rq(1)->curr = X

	CPU0				CPU1				CPU2

					// switch away from X
					LOCK rq(1)->lock
					smp_mb__after_spinlock
					dequeue_task(X)
					  X->on_rq = 9
					switch_to(Z)
					  X->on_cpu = 0
					UNLOCK rq(1)->lock

									// migrate X to cpu 0
									LOCK rq(1)->lock
									dequeue_task(X)
									set_task_cpu(X, 0)
									  X->cpu = 0
									UNLOCK rq(1)->lock

									LOCK rq(0)->lock
									enqueue_task(X)
									  X->on_rq = 1
									UNLOCK rq(0)->lock

	// switch to X
	LOCK rq(0)->lock
	smp_mb__after_spinlock
	switch_to(X)
	  X->on_cpu = 1
	UNLOCK rq(0)->lock

	// X goes sleep
	X->state = TASK_UNINTERRUPTIBLE
	smp_mb();			// wake X
					ttwu()
					  LOCK X->pi_lock
					  smp_mb__after_spinlock

					  if (p->state)

					  cpu = X->cpu; // =? 1

					  smp_rmb()

	// X calls schedule()
	LOCK rq(0)->lock
	smp_mb__after_spinlock
	dequeue_task(X)
	  X->on_rq = 0

					  if (p->on_rq)

					  smp_rmb();

					  if (p->on_cpu && ttwu_queue_wakelist(..)) [*]

					  smp_cond_load_acquire(&p->on_cpu, !VAL)

					  cpu = select_task_rq(X, X->wake_cpu, ...)
					  if (X->cpu != cpu)
	switch_to(Y)
	  X->on_cpu = 0
	UNLOCK rq(0)->lock

However I'm having trouble convincing myself that's actually possible
on x86_64 -- after all, every LOCK implies an smp_mb() there, so if ttwu
observes ->state != RUNNING, it must also observe ->cpu != 1.

(Most of the previous ttwu() races were found on very large PowerPC)

Nevertheless, this fully explains the observed failure case.

Fix it by ordering the task_cpu(p) load after the p->on_cpu load,
which is easy since nothing actually uses @cpu before this.

Fixes: c6e7bd7afaeb ("sched/core: Optimize ttwu() spinning on p->on_cpu")
Reported-by: Paul E. McKenney <paulmck@kernel.org>
Tested-by: Paul E. McKenney <paulmck@kernel.org>
Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Signed-off-by: Ingo Molnar <mingo@kernel.org>
Link: https://lkml.kernel.org/r/20200622125649.GC576871@hirez.programming.kicks-ass.net
Signed-off-by: dreamisbaka <jolinux.g@gmail.com>

---
## [dreamisbaka/android_kernel_xiaomi_sm8250](https://github.com/dreamisbaka/android_kernel_xiaomi_sm8250)@[aac5457671...](https://github.com/dreamisbaka/android_kernel_xiaomi_sm8250/commit/aac545767113c26f2ee645be29265e4c1e86c761)
#### Monday 2021-03-22 07:30:28 by Peter Zijlstra

sched: Fix loadavg accounting race

The recent commit:

  c6e7bd7afaeb ("sched/core: Optimize ttwu() spinning on p->on_cpu")

moved these lines in ttwu():

	p->sched_contributes_to_load = !!task_contributes_to_load(p);
	p->state = TASK_WAKING;

up before:

	smp_cond_load_acquire(&p->on_cpu, !VAL);

into the 'p->on_rq == 0' block, with the thinking that once we hit
schedule() the current task cannot change it's ->state anymore. And
while this is true, it is both incorrect and flawed.

It is incorrect in that we need at least an ACQUIRE on 'p->on_rq == 0'
to avoid weak hardware from re-ordering things for us. This can fairly
easily be achieved by relying on the control-dependency already in
place.

The second problem, which makes the flaw in the original argument, is
that while schedule() will not change prev->state, it will read it a
number of times (arguably too many times since it's marked volatile).
The previous condition 'p->on_cpu == 0' was sufficient because that
indicates schedule() has completed, and will no longer read
prev->state. So now the trick is to make this same true for the (much)
earlier 'prev->on_rq == 0' case.

Furthermore, in order to make the ordering stick, the 'prev->on_rq = 0'
assignment needs to he a RELEASE, but adding additional ordering to
schedule() is an unwelcome proposition at the best of times, doubly so
for mere accounting.

Luckily we can push the prev->state load up before rq->lock, with the
only caveat that we then have to re-read the state after. However, we
know that if it changed, we no longer have to worry about the blocking
path. This gives us the required ordering, if we block, we did the
prev->state load before an (effective) smp_mb() and the p->on_rq store
needs not change.

With this we end up with the effective ordering:

	LOAD p->state           LOAD-ACQUIRE p->on_rq == 0
	MB
	STORE p->on_rq, 0       STORE p->state, TASK_WAKING

which ensures the TASK_WAKING store happens after the prev->state
load, and all is well again.

Fixes: c6e7bd7afaeb ("sched/core: Optimize ttwu() spinning on p->on_cpu")
Reported-by: Dave Jones <davej@codemonkey.org.uk>
Reported-by: Paul Gortmaker <paul.gortmaker@windriver.com>
Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Tested-by: Dave Jones <davej@codemonkey.org.uk>
Tested-by: Paul Gortmaker <paul.gortmaker@windriver.com>
Link: https://lkml.kernel.org/r/20200707102957.GN117543@hirez.programming.kicks-ass.net
Signed-off-by: dreamisbaka <jolinux.g@gmail.com>

---
## [dreamisbaka/android_kernel_xiaomi_sm8250](https://github.com/dreamisbaka/android_kernel_xiaomi_sm8250)@[8734d82d6e...](https://github.com/dreamisbaka/android_kernel_xiaomi_sm8250/commit/8734d82d6ef396716c250f8a0b0452578c0168eb)
#### Monday 2021-03-22 07:30:28 by Peter Zijlstra

sched: Fix data-race in wakeup

Mel reported that on some ARM64 platforms loadavg goes bananas and
Will tracked it down to the following race:

  CPU0					CPU1

  schedule()
    prev->sched_contributes_to_load = X;
    deactivate_task(prev);

					try_to_wake_up()
					  if (p->on_rq &&) // false
					  if (smp_load_acquire(&p->on_cpu) && // true
					      ttwu_queue_wakelist())
					        p->sched_remote_wakeup = Y;

    smp_store_release(prev->on_cpu, 0);

where both p->sched_contributes_to_load and p->sched_remote_wakeup are
in the same word, and thus the stores X and Y race (and can clobber
one another's data).

Whereas prior to commit c6e7bd7afaeb ("sched/core: Optimize ttwu()
spinning on p->on_cpu") the p->on_cpu handoff serialized access to
p->sched_remote_wakeup (just as it still does with
p->sched_contributes_to_load) that commit broke that by calling
ttwu_queue_wakelist() with p->on_cpu != 0.

However, due to

  p->XXX = X			ttwu()
  schedule()			  if (p->on_rq && ...) // false
    smp_mb__after_spinlock()	  if (smp_load_acquire(&p->on_cpu) &&
    deactivate_task()		      ttwu_queue_wakelist())
      p->on_rq = 0;		        p->sched_remote_wakeup = Y;

We can be sure any 'current' store is complete and 'current' is
guaranteed asleep. Therefore we can move p->sched_remote_wakeup into
the current flags word.

Note: while the observed failure was loadavg accounting gone wrong due
to ttwu() cobbering p->sched_contributes_to_load, the reverse problem
is also possible where schedule() clobbers p->sched_remote_wakeup,
this could result in enqueue_entity() wrecking ->vruntime and causing
scheduling artifacts.

Fixes: c6e7bd7afaeb ("sched/core: Optimize ttwu() spinning on p->on_cpu")
Reported-by: Mel Gorman <mgorman@techsingularity.net>
Debugged-by: Will Deacon <will@kernel.org>
Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://lkml.kernel.org/r/20201117083016.GK3121392@hirez.programming.kicks-ass.net
Signed-off-by: dreamisbaka <jolinux.g@gmail.com>

---
## [dreamisbaka/android_kernel_xiaomi_sm8250](https://github.com/dreamisbaka/android_kernel_xiaomi_sm8250)@[1081b84e61...](https://github.com/dreamisbaka/android_kernel_xiaomi_sm8250/commit/1081b84e61d77a213475854c5d7cfddc1717dbcc)
#### Monday 2021-03-22 07:30:28 by Peter Zijlstra

sched: Fix rq->nr_iowait ordering

  schedule()				ttwu()
    deactivate_task();			  if (p->on_rq && ...) // false
					    atomic_dec(&task_rq(p)->nr_iowait);
    if (prev->in_iowait)
      atomic_inc(&rq->nr_iowait);

Allows nr_iowait to be decremented before it gets incremented,
resulting in more dodgy IO-wait numbers than usual.

Note that because we can now do ttwu_queue_wakelist() before
p->on_cpu==0, we lose the natural ordering and have to further delay
the decrement.

Fixes: c6e7bd7afaeb ("sched/core: Optimize ttwu() spinning on p->on_cpu")
Reported-by: Tejun Heo <tj@kernel.org>
Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Acked-by: Mel Gorman <mgorman@techsingularity.net>
Link: https://lkml.kernel.org/r/20201117093829.GD3121429@hirez.programming.kicks-ass.net
Signed-off-by: dreamisbaka <jolinux.g@gmail.com>

---
## [libzenith/postgres](https://github.com/libzenith/postgres)@[891a61e87e...](https://github.com/libzenith/postgres/commit/891a61e87e3cee5367f3fdf39c0d0464d049b932)
#### Monday 2021-03-22 10:35:58 by Heikki Linnakangas

Refactor locking in page cache, and use async I/O for WAL redo

Story on why:

The apply_wal_records() function spawned the special postgres process
to perform WAL redo. That was done in a blocking fashion: it launches
the process, then it writes the command to its stdin, then it reads
the result from its stdout.  I wanted to also read the child process's
stderr, and forward it to the page server's log (which is just the
page server's stderr ATM). That has classic potential for deadlock:
the child process might block trying to write to stderr/stdout, if the
parent isn't reading it. So the parent needs to perform the read/write
with the child's stdin/stdout/stderr in an async fashion.  So I
refactored the code in walredo.c into async style.  But it started to
hang. It took me a while to figure it out; async makes for really ugly
stacktraces, it's hard to figure out what's going on. The call path
goes like this: Page service -> get_page_at_lsn() in page cache ->
apply_wal_records() the page service is written in async style. And I
refactored apply_wal_recorsds() to also be async. BUT,
get_page_at_lsn() acquires a lock, in a blocking fashion.

The lock-up happened like this:

- a GetPage@LSN request arrives. The asynch handler thread calls
  get_page_at_lsn(), which acquires a lock. While holding the lock,
  it calls apply_wal_records().
- apply_wal_records() launches the child process, and waits on it
  using async functions
- more GetPage@LSN requests arrive. They also call get_page_at_lsn().
  But because the lock is already held, they all block

The subsequent GetPage@LSN calls that block waiting on the lock use up
all the async handler threads. All the threads are locked up, so there
is no one left to make progress on the apply_wal_records() call, so it
never releases the lock. Deadlock So my lesson here is that mixing
async and blocking styles is painful. Googling around, this is a well
known problem, there are long philosophical discussions on "what color
is your function".  My plan to fix that is to move the WAL redo into a
separate thread or thread pool, and have the GetPage@LSN handlers
communicate with it using channels.  Having a separate thread pool for
it makes sense anyway in the long run. We'll want to keep the postgres
process around, rather than launch it separately every time we need to
reconstruct a page. Also, when we're not busy reconstructing pages
that are needed right now by GetPage@LSN calls, we want to proactively
apply incoming WAL records from a "backlog".

Solution:

Launch a dedicated thread for WAL redo at startup. It has an event loop,
where it listens on a channel for requests to apply WAL. When a page
server thread needs some WAL to be applied, it sends the request on
the channel, and waits for response. After it's done the WAL redo process
puts the new page image in the page cache, and wakes up the requesting
thread using a condition variable.

This also needed locking changes in the page cache. Each cache entry now
has a reference counter and a dedicated Mutex to protect just the entry.

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[0cae4a4660...](https://github.com/mrakgr/The-Spiral-Language/commit/0cae4a466051aaa24a193f9580d24abb90b74c8f)
#### Monday 2021-03-22 11:01:55 by Marko GrdiniÄ‡

"9:15am. Let me chill a bit and then I will start.

9:25am. Done. Let me focus. Forget chilling. I do not know what I'll do today, but I know in which direction I must go.

9:30am. This latest issue really strikes at Spiral's weakness. My mental model of quite a lot of things is beyond the conception of what regular ML researchers can come up with. I took care of to maximize its strengths.

But now I need to deal with its weaknesses.

Yes, I can improve various aspects of it. I can put in string interpolation, the build and run command. I can take the time to do bindings. But I won't be able to beat Python in what it is strong.

A lot of the capabilities of Python are giving me heartache when I think of emulating them. Just forget it.

I do not want to work on Spiral anymore. I do not want to put in string interpolation or anything else at this moment in time. Solidifying editor support was a special case. Serious bugs that crash the language take precedence over everything else. But absolutely do not want to put in functionality I do not NEED.

Not before I get my first win.

Even if I can get even a single real world win, I could say: 'I beat poker and I can do it again whenever I want. It is my own piggy bank now. Since I do not need the money, let me instead improve the language.'

9:35am. Here is the time to fight.

But since I am always measuring the effectiveness of my moves, I can understand my problem. I am getting crushed by the amateur style.

https://processing.org/tutorials/

By that I mean code like in here - no abstractions whatsover, just plopping the instructions down. It is the same kind of thing like in the Kivy tutorials that I watched.

This is why I've been depressed. I can't mentally score a decisive win - on paper when it comes to UIs, Spiral should be superior than Python, but the circumstances are conspiring against me.

I need to evolve the way I program again.

In the future it will be different, I'll have exactly the libraries and the tools that I need. I will have the time to set everything up properly. Python and all those lesser languages will become the past. But now I can't beat them.

No matter how good my skills and my overall technique is, I can't beat the decades of effort put in by the overall community. I've been able to work around this, thus far, but at the same time this is how far I will go.

I am on the verge of success, but I won't be able to make the last step unless I do this.

9:45am. So what I will be doing today might seem extremely simple from the outside - I'll forget about my skill and program the way an amateur would. This is the style Python is made to support.

I struggled so much to learn good programming. I need to make my peace with the bad, otherwise I won't get anywhere.

9:50am. Let me see if I can get that UI going.

```
import torch
import torch.distributions
import torch.nn
import torch.nn.functional

def small(intro,mid,out): return torch.nn.Sequential(
    torch.nn.Linear(intro,mid),
    torch.nn.LayerNorm(mid),
    torch.nn.Tanh(),
    torch.nn.Linear(mid,mid),
    torch.nn.LayerNorm(mid),
    torch.nn.Tanh(),
    torch.nn.Linear(mid,out)
    )
```

The way to do ML models is also something that is unresolved for me. I did the serialization in Spiral as it is the best tool for the job, but the Python/Spiral interop will always have friction. Pretty much every single one of Python's language features is a huge hack, and it is giving me heartache to even think what it would take to support all of it.

I hate how Cython's types being non composable requires hacks and cludges in the codegen. The sooner the next wave of hardware starts, the sooner I'll be able to get away from Python. But they all seem to want PyTorch interop and are chasing the present hype. So maybe my assumption that local memory would not require resource management in the usual sense is wrong.

I thought there would be inter-core communication that I'd deal directly, but maybe local allocations will still require managing on the host side. In that case, maybe Python will be here to stay until I figure out how to put those chips in my head and break the dependency on the scientific and programming community.

9:55am. That resource management might be necessary even with the next generations of chips seems like a realistic assumption to me now. I'll pivot to it.

This just makes mastering the amateur style more important.

My problem is not that I do not know it. My problem is that I need to accept it.

This is what I need to do. Once I do this, I'll be able to put in regular effort and achieve proper synergy between Spiral and Python. When I have this, I'll deal with UIs, deal with the agents and will be able to become what I set out to be six years ago.

A single win is all that I need.

10am. Now focus me. Let me go back to the Kivy crash course. I'll play with animations. I want to familiarize myself with them and drawing shapes on a canvas.

I need to break the ice with this. I want to draw a stack of chips and be able to transfer them between stacks in an animated fashion.

The challenge here is no to much how to do this, but to find the ideal workflow for implementing all of my GUI ideas. I'll exclude the time I am spending being anxious and not doing work from my evaluation.

```
with self.canvas:
    Color(1., 1., 0)
    Rectangle(size=(50, 50))
```

I really wonder how this works. Hmmm...actually I have an idea. There is probably a global stack which when not empty, the Color and Rectangle push themselves to in their constructors.

https://kivy.org/doc/stable/api-kivy.graphics.instructions.html

What kind of shapes are there. For chips I'll need elipses. For proper chips though, they'd need to be 3d and cell shaded. I'll just go with 2d for now.

I want them to be oval, and I want the number 1 to be in their center correponding to their value.

10:30am. https://kivy.org/doc/stable/api-kivy.graphics.html?highlight=rectangle#kivy.graphics.Line.rectangle

There is a lot of stuff here. Still, I can't figure out where all these instructions are supposed to be.

10:40am.

```
from kivy.uix.gridlayout import GridLayout
from kivy.uix.button import Button
from kivy.uix.label import Label
from kivy.uix.widget import Widget
from kivy.uix.scrollview import ScrollView
from kivy.core.window import Window
from kivy.app import runTouchApp
from kivy.lang import Builder

root = Builder.load_string('''
<MyWidget>:
    canvas:
        Color:
            rgba: 1,0,0,1
        Rectangle:
            pos: 0,0
            size: 100,100
''')

class MyWidget(Widget):
    pass

runTouchApp(root)
```

So I am doing this and nothing is appearing. This is why I've been so wary of doing this in Spiral. I know well enough myself that all I've done is watched a few tutorials. I do not have real familiary with Kivy.

As annoying as this situation is, building familiarity through experimentation until it goes into my procedural memory is exactly the way to go here. This would be painful, rather than annoying if I also had to deal with Spiral while doing this.

```
Builder.load_string('''
<Root>:
    MyWidget:
        pos: 0, 0

<MyWidget>:
    canvas:
        Color:
            rgba: 1,0,0,1
        Rectangle:
            pos: self.pos
            size: 100,100
''')
```

Hmmm, I had not realized that 0,0 is bottom left unstead ot top left until now.

https://kivy.org/doc/stable/api-kivy.uix.widget.html#kivy.uix.widget.Widget.pos_hint

```
<Root>:
    FloatLayout:
        MyWidget:
            pos_hint: {'top': 0.8}
```

This is not working. How do I make this work?

https://kivy.org/doc/stable/api-kivy.uix.floatlayout.html

11:25am. Had to take a break. Let me resume. Right now I am playing with positional hints.

```
<Root>:
    FloatLayout:
        size: self.parent.size
        canvas.before:
            Color:
                rgba: 0,1,0,1
            Rectangle:
                pos: self.pos
                size: self.size
        MyWidget:
            pos_hint: {'center': (0.5, 0.5)}
            size_hint: 0.2,0.2
```

It is possible to set the center like this.

```
pos_hint: {'pos': (0.5, 0.5)}
```

This is also possible. But in this case, why does top not work here?

```
pos_hint: {'top': 0.99, 'right': 0.99}
```

Ah, it does work. I just misunderstood what `top` and `right` are.

Ok.

11:35am. Ok, now focus me. I've played with this enough.

```
root = Builder.load_string('''
FloatLayout:
    canvas:
        Color:
            rgba: 0,0.8,0,1
        Rectangle:
            pos: self.pos
            size: self.size
    MyWidget:
        pos_hint: {'top': 0.99, 'right': 0.99}
        size_hint: 0.2,0.2

<MyWidget>:
    canvas:
        Color:
            rgba: 1,0,0,0.5
        Rectangle:
            pos: self.pos
            size: self.size
''')
```
```
 Traceback (most recent call last):
   File "c:/Users/Marko/Source/Repos/The Spiral Language/Spiral Compilation Tests/cython_experiments/ui_leduc1/asd.py", line 11, in <module>
     root = Builder.load_string('''
   File "C:\Users\Marko\anaconda3\lib\site-packages\kivy\lang\builder.py", line 408, in load_string
     self._apply_rule(
   File "C:\Users\Marko\anaconda3\lib\site-packages\kivy\lang\builder.py", line 621, in _apply_rule
     cls = Factory_get(cname)
   File "C:\Users\Marko\anaconda3\lib\site-packages\kivy\factory.py", line 146, in __getattr__
     raise FactoryException('Unknown class <%s>' % name)
 kivy.factory.FactoryException: Unknown class <MyWidget>
```

Why does this not work for me. Let me check out the crash course.

As an aside, I really like how Python itself has working exceptions rather than the crap I get from Cython. This is a part of the heartache I was talking about. Cython's errors are nasty, and it always forces me to scroll up a few pages to see what it is.

I actually do not know how to deal with this later thing.

```
Builder.load_string('''
<MyWidget>:
    canvas:
        Color:
            rgba: 1,0,0,0.5
        Rectangle:
            pos: self.pos
            size: self.size
''')

root = Builder.load_string('''
FloatLayout:
    canvas:
        Color:
            rgba: 0,0.8,0,1
        Rectangle:
            pos: self.pos
            size: self.size
    MyWidget:
        pos_hint: {'top': 0.99, 'right': 0.99}
        size_hint: 0.2,0.2
''')
```

I am surprised that even separating it out like this does not work.

https://www.youtube.com/watch?v=ZmteLworB4E&list=PLdNh1e1kmiPP4YApJm8ENK2yMlwF1_edq&index=5

In one of the videos he shows how to mix widgets and their definitions. Was it this one?

https://youtu.be/1d709erhpdQ?list=PLdNh1e1kmiPP4YApJm8ENK2yMlwF1_edq&t=204

Ok, so here is the use of an Elipse. I'll also need to display text.

12pm. Agh, I can't find that video. Let me stop here for a bit."

---
## [kleinerm/Psychtoolbox-3](https://github.com/kleinerm/Psychtoolbox-3)@[dfd982c92c...](https://github.com/kleinerm/Psychtoolbox-3/commit/dfd982c92c1f17c9c4d262eb9772e7c5d0967ceb)
#### Monday 2021-03-22 11:39:41 by kleinerm

FlipTimingWithRTBoxPhotoDiodeTest: Add workarounds for macOS Vulkan/Metal.

As one would expect from an Apple product, the Vulkan on Metal implementation
has various flaws. One of them is the inability to flip at every video refresh cycle.
This makes it impossible to flip from the stimulus that triggers the
VideoSwitcher + RtBox timestamping to a black background within one refresh
cycle, and that in turn can cause double-timestamping the same frame.

To deal with that, we add a PsychRtBox('Clear') after each timestamped flip.
While this increases latency, at least it filters out invalid measured timestamps
and makes a VideoSwitcher measurement possible. Also we can't use the more
efficient RtBox async background reads with this approach, so disable them and
lose even more efficiency.

Additionally this "can't flip in 1 refresh" makes it impossible to present anything
in with less than 4 frames delay (at least 2 for onset, and at least 2 for offset),
together with the 'Clear' hack for RtBox event filtering and other overhead
imposed by macOS + Vulkan, we end up with 6 frames as fastest we can do
with some reliability on a 60 Hz panel for this measurement script. Therefore
adjust waitFrames to be always at least 6, otherwise we'd just get tons of
skipped frames and no way to assess present scheduling under Metal in any
meaningful way.

Then also Metal sporadically reports invalid/bogus zero timestamps after
presents, which confuse the hell out of our scheduling and analysis and plots.
Filter these out: Replace by GetSecs for scheduling purposes and NaN's for
data logging so we can ignore them for plotting and analysis and get some
halfway meaningful results.

With all this taken together, the script is now able to get some reasonable
measurements out of macOS 10.15.7 + Vulkan + Metal + VideoSwitcher + RtBox.

Ofc. this is less than great, that we can only measure with external equipment
at all by degrading the already poor performance of macOS Metal further, but
such is life in iToys land...

---
## [Epxitome/RogueShooter](https://github.com/Epxitome/RogueShooter)@[d628996fe0...](https://github.com/Epxitome/RogueShooter/commit/d628996fe020d097ccc10421c99de54ed711a9ec)
#### Monday 2021-03-22 12:47:35 by Epxitome

Add files via upload

First project I've ever uploaded. The tutorial completed to get this code was Games by James on Udemy. His tutorial was the first I've ever completed for Unity/C#. It was damn amazing. I would highly recommend that you take a look at his, or other Udemy courses if you want to learn. All his code is available after purchasing his course however, this is my version of it with my own changes.

---
## [san9-s-dumpster/android_packages_apps_Launcher3](https://github.com/san9-s-dumpster/android_packages_apps_Launcher3)@[e4260adf33...](https://github.com/san9-s-dumpster/android_packages_apps_Launcher3/commit/e4260adf3385f55429ae18d3c818178ebc04657e)
#### Monday 2021-03-22 14:09:08 by Alex Cruz

Restart with change only on exit

This change allow the user to change everything they have to inside the
homescreen activity and only restart on exit. Previously this was a pain
in the fucking ass because you had to go in and set each option one by one
with a restart inbetween. At least now is not that big of a pain.

- Restart on destroy (hitting the back button, actionbar arrow)
- Restart when a chance is made and the home button is pressed

** Thanks "Jack" for code to detect home button
https://stackoverflow.com/a/27956263

- Cleaned up restart code

@eyosen adapted to 10

Change-Id: I4962916ae0bd59d08247b59de585a97a2b9da3a1
Signed-off-by: DennySPb <dennyspb@gmail.com>
Signed-off-by: aswin7469 <aswinas@pixysos.com>

---
## [expnkx/fast_io](https://github.com/expnkx/fast_io)@[6c29bf75c1...](https://github.com/expnkx/fast_io/commit/6c29bf75c1e08d7de45cbcb26b7319a26cd89d11)
#### Monday 2021-03-22 15:22:17 by expnkx

1. fix around conflicts between fast_io's extern "C" with windows.h
It is so damn shit. Now we directly hack around linker to avoid issues.
So we have so many combinations with windows.
gcc 32/64/cygwin/arm/aarch64
clang 32/64/cygwin/arm/aarch64 with libstdc++ or 32/64/arm/aarch64 with msvc stl
msvc 32/64/cygwin/arm/aarch64
I tried my best to deal with the issues now it won't conflict with other symbols.
BTW, now we are using [[gnu::dllimport]] to allow an even faster function calls

2. Optimize I/O performance greatly on windows with libstdc++ since we can exploit sys-v calling conventions instead of using msvc's one. MSVC's calling convention is too slow. For clang, if you are using with libstdc++, it uses sys-v. if you use the "default" one which is msvc stl, we still use the msvc abi to avoid potential crashing.

3. remove struct timespec in posix_file_status. Change that to unix_timestamp.

---
## [throwawaystuff12408/chilibowlruffle](https://github.com/throwawaystuff12408/chilibowlruffle)@[9540117431...](https://github.com/throwawaystuff12408/chilibowlruffle/commit/954011743160a77d0de3480aab0f9da83a27b8ed)
#### Monday 2021-03-22 17:04:40 by throwawaystuff12408

ABOBO

ABOBO HAPPY YOU ADD HIS GAME HE DO NOT CRUSH YOU WITH BIG ARMS NOW 

I love this character

---
## [amunozdesign/web03_amunozdesign](https://github.com/amunozdesign/web03_amunozdesign)@[24edf04958...](https://github.com/amunozdesign/web03_amunozdesign/commit/24edf049582bdd0772bc1baf3047898364d1db22)
#### Monday 2021-03-22 17:20:00 by andresmunozdesign

cant get the homework to work

akdfsjbsdljfbasdljhfbaljshdkn haTING JAVASCRIPT!  (JUST FOR TODAY, WILL LOVE IT LATER)

---
## [nikp123/xava](https://github.com/nikp123/xava)@[00759dd4b9...](https://github.com/nikp123/xava/commit/00759dd4b90cfea51fc1e3bdd87633ffce5fa113)
#### Monday 2021-03-22 18:44:02 by Nikola Pavlica

[removal] function pointers

Fuck no, these are awful. Do NOT use this unless you're forced to make a
non-dynamic executable.

They also make your code pretty unreadable. Let the compiler/linker
handle this one for you instead, please.

---
## [GitInVisualStudio/KnueppelKampf](https://github.com/GitInVisualStudio/KnueppelKampf)@[328aa3f39c...](https://github.com/GitInVisualStudio/KnueppelKampf/commit/328aa3f39cea19bfa436492e890bd88c93a78e20)
#### Monday 2021-03-22 21:19:51 by yami.miriam

GOT THE FUCKING BULLSHIT WORKING YOU CAN M O V E NOW FUCK YEAH

---
## [apollographql/apollo-server](https://github.com/apollographql/apollo-server)@[a3282a2d7d...](https://github.com/apollographql/apollo-server/commit/a3282a2d7df0c20d9e10b058defae835120fa5b1)
#### Monday 2021-03-22 21:50:01 by David Glasser

Add async server.start() function (#4981)

Previously, server startup worked like this:

- `new ApolloServer`
  - If no gateway, calculate schema and schema derived data immediately
  - If gateway, kick off gateway.load from the end of the constructor, and if it
    async-throws, log an error once and make the server kinda broken forever
- At various spots in the framework integration code, call (but don't await)
  the protected `willStart` function, which is an async function that first
  waits for the gateway to load the schema if necessary and then runs
  serverWillStart plugin functions; save the Promise returned by calling this.
- At request time in the framework integration code, await that Promise.
  And also, if there's no schema, fail with an error.

Now server startup works like this:
- ApolloServer represents its state explicitly with a new ServerState
- `new ApolloServer`
  - If no gateway, initialize all the schema-derived state directly like
    before (though the state now lives inside ServerState)
  - If gateway, the constructor DOES NOT KICK OFF `gateway.load()`
- You can now call `await server.start()` yourself, which will first await
  `gateway.load` if necessary, and then await all serverWillStart calls.
- If you're using `apollo-server` rather than an integration, `server.listen()`
  will just transparently do this for you; explicit `start()` is just for
  integrations!
- Serverless frameworks also call it automatically for you in the background
  (kicked off by the constructor) because their startup has to be
  synchronous; if it fails then future requests will all fail (and log) as before.
- The integration places that used to call willStart now call
  `server.ensureStarting()` instead which will kick off server.start in the
  background if you didn't (and log any errors thrown).
- The places that used to await promiseWillStart no longer do so; generally
  right after that code we end up calling `graphqlServerOptions`
- `graphqlServerOptions` now awaits `server.ensureStarted` which will start the
  server if necessary and throw if it threw.

The overall change to user experience:
- If you're using `apollo-server`, startup errors will cause `listen` to reject;
  no code changes are necessary.
- If you're using a serverless integration, the behavior will be relatively similar,
  except that the startup error will be logged on all requests instead of just
  the first one.
- If you're using an integration you are encouraged to call `await
  server.start()` yourself immediately after the constructor, which will let
  you detect startup errors.
- But if you don't do that, the server will call `start` itself eventually. When
  you try to execute your first GraphQL request, `start` will happen if it
  hasn't already. Also an integration call like `server.applyMiddleware` will
  initiate a background `start`. If startup fails, the startup error will be
  logged on *every* failed graphql request, not just the first time like
  happened before.
- If you have your own ApolloServer subclass that calls the protected
  `willStart` method, it will still work (the method isn't deleted) but you
  should rewrite it to either `await this.start()` or `this.ensureStarting()` instead.

This is close enough to backwards-compatible to be appropriate for a v2 minor
release. We are likely to make `start()` required in Apollo Server 3 for
non-serverless integrations.

Also:
- Previously we used the deprecated `ApolloServer.schema` field to determine
  whether to install ApolloServerPluginInlineTrace, which we want to have active
  by default for federated schemas only. If you're using a gateway, this field
  isn't actually set at the time that ensurePluginInstantiation reads it.
  That's basically OK because we don't want to turn on the plugin automatically
  in the gateway, but in the interest of avoiding use of the deprecated field, I
  refactored it so that `ApolloServerPluginInlineTrace` is installed by default
  (ie, if you don't install your own version or install
  `ApolloServerPluginInlineTraceDisabled`) without checking the schema, and
  then (if it's installed automatically) it decides whether or not to be active
  by checking the schema at `serverWillStart` time.
- Similarly, schema reporting now throws in its `serverWillStart` if the schema
  is federated, instead of in `ensurePluginInstantiation`. (This does mean that
  if you're not using the new `start()` or `apollo-server`, that failure won't
  make your app fail as fast as if the `ApolloServer` constructor threw.)
- Fix some fastify tests that used a fixed listen port to not do that.
- I am doing my best to never accidentally run `prettier` on whole files and
  instead to very carefully select specific blocks of the file to format them
  several times per minute. Apparently I screwed up once and ran it once on
  `packages/apollo-server-core/src/ApolloServer.ts`. The ratio of "prettier
  changes" to "actual changes" in that file is low enough that I'd rather just
  leave the changes in this PR rather than spending time carefully reverting
  them. (It's one of the files I work on the most and being able to keep it
  prettier-clean will be helpful anyway.)
- Replace a hacky workaround for the lack of `start` in the op reg tests!
- Replace a use of a `Barrier` class I added recently in tests with the
  `@josephg/resolvable` npm package, which does basically the same thing.
  Use that package in new tests and in the core state machine itself.
- While running tests I found that some test files hung if run separately due to
  lack of cleanup. I ended up refactoring the cache tests to:
  - make who is responsible for calling cache.close more consistent
  - make the Redis client mocks self-contained mocks of the ioredis API instead
    of starting with an actual ioredis implementation and mocking out some
    internals
  - clean up Jest fake timers when a certain test is done
  I'm not super certain exactly which of these changes fixed the hangs but it
  does seem better this way. (Specifically I think the fake timer fix, which I
  did last, is what actually fixed it, but the other changes made it easier for
  me to reason about what was going on.) Can factor out into another PR if
  helpful.

Fixes #4921. Fixes apollographql/federation#335.

Co-authored-by: Stephen Barlow <stephen@apollographql.com>

---
## [gimbo/gimbo-git.zsh](https://github.com/gimbo/gimbo-git.zsh)@[9298d6c76e...](https://github.com/gimbo/gimbo-git.zsh/commit/9298d6c76efb0eb4d532b46d646262826e4bfcc5)
#### Monday 2021-03-22 22:51:51 by Andy Gimblett

Remove -v flag from some 'git commit' alias from oh-my-zsh

I realised I never look at the diffs, and if I want do I can do it more
pleasantly in my graphical git client of choice, so I'm removing the
`-v` flag from oh-my-zsh's `git commit` aliases.

OTOH if you love `-v` and want it everywhere, this next line should set
you up nicely:

    git config --global commit.verbose true

---

# [<](2021-03-21.md) 2021-03-22 [>](2021-03-23.md)

