# [<](2021-01-06.md) 2021-01-07 [>](2021-01-08.md)

2,814,825 events, 1,360,807 push events, 2,130,717 commit messages, 169,444,821 characters


## [Buildstarted/linksfordevs](https://github.com/Buildstarted/linksfordevs)@[29240101e1...](https://github.com/Buildstarted/linksfordevs/commit/29240101e103a62bc357f5f22594ab4345732273)
#### Thursday 2021-01-07 00:05:46 by Ben Dornis

Updating: 1/6/2021 11:00:00 PM

 1. Added: Nick Caldwell, Twitter's VP of Engineering
    (https://player.simplecast.com/7a2fadbe-797f-43b6-b781-18afafe7d95a)
 2. Added: Using the API Gateway Pattern In .NET to Encapsulate Microservices
    (https://code-maze.com/api-gateway-pattern-dotnet-encapsulate-microservices/)
 3. Added: Nick Caldwell, Twitter's VP of Engineering | Equivalent to Magic
    (https://equivalent-to-magic.simplecast.com/episodes/nick-caldwell-twitters-vp-of-engineering-CaU_0PEF)
 4. Added: Code-first gRPC services and clients with .NET
    (https://docs.microsoft.com/en-us/aspnet/core/grpc/code-first?view=aspnetcore-5.0)
 5. Added: Building React Applications in F#
    (https://www.youtube.com/watch?v=a6Ct3CM_lj4)
 6. Added: Porting Projects to .NET 5
    (https://youtu.be/bvmd2F11jpA?hss_channel=tw-2384354214)
 7. Added: Department of Health and Human Services Victoria
    (https://www.dhhs.vic.gov.au/victorian-coronavirus-covid-19-data)
 8. Added: Create a web app and use data to make decisions on the basketball court | Learn with Dr G
    (https://channel9.msdn.com/Shows/Learn-with-Dr-G/Create-a-web-app-and-use-data-to-make-decisions-on-the-basketball-court)
 9. Added: Curious to know what real cyber attacks on IoT and OT solutions look like and how to secure your own solutions with Azure Defender for IoT? Don't miss this #IoTShow episode with @obloch and @rdecker99
    (https://channel9.msdn.com/Shows/Internet-of-Things-Show/Agentless-IoTOT-security-with-Azure-Defender-for-IoT)
10. Added: Weather and Boinc
    (https://etbe.coker.com.au/2021/01/06/weather-boinc/)
11. Added: The GL-MT300N A $20 hackable Linux Router - James Dawson
    (https://blog.jmdawson.co.uk/the-gl-mt300n-a-20-hackable-linux-router/)
12. Added: please please please offer feedback
    (https://solb.io/blog/please-please-please-offer-feedback)
13. Added: WhatsApp gives users an ultimatum: Share data with Facebook or stop using the app
    (https://arstechnica.com/tech-policy/2021/01/whatsapp-users-must-share-their-data-with-facebook-or-stop-using-the-app/)
14. Added: The democratisation of Data Science : andrew-jones.com
    (https://andrew-jones.com/blog/the-democratisation-of-data-science/)
15. Added: Why Goals Don't Work as We Expect — Bohdan Kit
    (https://bohdankit.com/why-goals-dont-work/)
16. Added: Don't worry son, all your friends are weirdos too | Robert Heaton
    (https://robertheaton.com/all-your-friends-are-weirdos-too/)

Generation took: 00:05:23.7939208

---
## [TheUltimateC0der/Listrr](https://github.com/TheUltimateC0der/Listrr)@[ee8a64ab87...](https://github.com/TheUltimateC0der/Listrr/commit/ee8a64ab877f5a548c9089db98d6acb7564c4199)
#### Thursday 2021-01-07 00:09:18 by UltimateC0der

WHYEVER THE FUCK EF CORE WANTS TO DESTROY THE GOD DAMN DATABASE

---
## [TheUltimateC0der/Listrr](https://github.com/TheUltimateC0der/Listrr)@[90dd843c85...](https://github.com/TheUltimateC0der/Listrr/commit/90dd843c85dc570df20a1d32ee5f680bc065aec7)
#### Thursday 2021-01-07 00:12:03 by Ultimate

Merge pull request #114 from TheUltimateC0der/develop

Go fuck yourself ef core ...

---
## [AwokeinanEnigma/Cloudburst](https://github.com/AwokeinanEnigma/Cloudburst)@[b721757f69...](https://github.com/AwokeinanEnigma/Cloudburst/commit/b721757f694198e76ead69fb36287eb319366620)
#### Thursday 2021-01-07 00:45:59 by AwokeinanEnigma

-update wyatt's achievement
-remove shitpost core
-kinda redoing deep clean
-gave wyatt a FAT hitbox

-please sign this or i will get fired jeff buizel will fire me
oh god oh fuck my wife and children are hungry and her big mommy milkies are costing me a ton because her big mommy milkies are breaking every  bra i have bought for her which is kind of hot not gonna lie but my kids cannot even breast feed because her nipples are long like holy shit that makes my dick hard.
Please pull this btw. Has some breaking changes :]]

---
## [bryceco/nethack-cocoa](https://github.com/bryceco/nethack-cocoa)@[6daa6e2de9...](https://github.com/bryceco/nethack-cocoa/commit/6daa6e2de9d26cccc27104f534e3dd44fbcc8636)
#### Thursday 2021-01-07 01:44:56 by PatR

curing deafness

Make healing magic which cures blindness also cure deafness.  So,
drinking non-cursed potion of healing or any extra healing or full
healing; breathing fumes from blessed potion of healing or non-cursed
potion of extra healing or any potion of full healing; prayer reward
to cure blindness as a minor trouble.  (Doesn't affect unicorn horns
which already treat deafness and blindness as two distinct troubles
that are eligible to be cured.)

More of a missing feature than a bug fix, so I listed it in the new
features section of the fixes file.

---
## [Tamaized/Voidscape](https://github.com/Tamaized/Voidscape)@[2fcd5a3a63...](https://github.com/Tamaized/Voidscape/commit/2fcd5a3a63f603d430948614ad7a928cfb8f82ee)
#### Thursday 2021-01-07 02:12:03 by Tamaized

HOLY FUCKING HACKS BATMAN, instance system

Signed-off-by: Tamaized <9671313+Tamaized@users.noreply.github.com>

---
## [Kang-OS-R/android_frameworks_base](https://github.com/Kang-OS-R/android_frameworks_base)@[625089a0ad...](https://github.com/Kang-OS-R/android_frameworks_base/commit/625089a0ad7318ce4edb26f829ea056847845ea6)
#### Thursday 2021-01-07 02:17:25 by ezio84

Fix 2tap2wake after Ambient Pulsing on some devices

like taimen and walleye, instead sunfish (and probably newer pixels)
doesn't need this

To apply, override the config_has_weird_dt_sensor bool in the device tree

----
TL;DR
for some reason, on taimen and walleye, after ambient pulsing
gets triggered by adb with the official "com.android.systemui.doze.pulse"
intent or by our custom "wake to ambient" features, the double tap
sensor dies if you follow this steps:
- screen is OFF
- trigger ambient pulsing with a double tap to wake (if custom wake to
  ambient feature is enabled), or the official intent by adb, or with
  music ticker or any other event
- after ambient display shows up, don't touch anything and wait till the
  screen goes OFF again
- double tap to wake, again
- the double tap sensor doesn't work at all and device doesn't wake up

Now, funny thing, after the steps above, if you cover then uncover the
proximity/brightness sensor with the hand, then double tap to wake
again, the wake gesture works as expected.

When covering/uncovering the proximity/brightness sensor, this happens:
11-10 22:02:00.916   967   998 I ASH     : @ 1993.460: ftm4_disable_sensor: disabling sensor [double-tap]
11-10 22:02:02.013   967   998 I ASH     : @ 1994.556: ftm4_enable_sensor: enabling sensor [double-tap]

When you switch screen ON with power button, the doze screen states do
the same: the sensor gets disabled then enabled again if device goes
to DOZE idle state.

Instead, after Ambient pulsing, when the pulsing finishes, the sensor
is still enabled, so the disable/enable event doesn't happen this
time. And that's why, for some reason, it doesn't respond anymore.
----

So, in a nutshell: i've no idea why this sh#t happens lol,
but with a super lazy hacky tricky dirty bloody nooby line change,
we can force the sensor disable/enable event when the device goes
to DOZE state.

Change-Id: I8ce463a6e435e540e3ca93336c5dba7a95771b56
Signed-off-by: Joey Huab <joey@evolution-x.org>

---
## [naseefbahwan/how-to-join-illuminati-in-Poland-Zambia-kuwait-London-2349032362340](https://github.com/naseefbahwan/how-to-join-illuminati-in-Poland-Zambia-kuwait-London-2349032362340)@[fbfa1e138b...](https://github.com/naseefbahwan/how-to-join-illuminati-in-Poland-Zambia-kuwait-London-2349032362340/commit/fbfa1e138ba2fa03c28900efba0cdbacc42457b1)
#### Thursday 2021-01-07 03:47:04 by naseefbahwan

Create Call king@+27632807647 HOW TO JOIN ILLUMINATI SOCIETY IN SOUTH AFRICA AND UK!FOR MONEY,FAME,WEALTH AND POWER 100%, in Tembisa

IN South Africa, Lesotho, Namibia, Botswana, Zambia, Swaziland, Canada, Guyana, Uk, France, Germany, Spain, Poland, Switzerland, Romania, Bulgaria, Denmark, Finland, Netherlands, Norway, Sweden
, Egypt, Jordan, Sudan, Tunisia, Bahrain, Iraq, Kuwait, Oman, Qatar, Saudi Arabia, UAE, Australia, New Zealand, GHANA, Uganda, Limpopo, JORDAN, Kuwait, Saudi Arabia, Australia, Johannesburg, Lebanon, Bahrain USA, Kenya, California, Dallas, England, Spain, Austria, Vancouver, Denmark, Pretoria, Durban, Wales, France, Norway, Sweden, Capetown, Tanzania, Northern Cape, New York, Limpopo, London, Sweden, Rwanda, Oman, Qatar, Dubai, Poland, Canada, United Kingdom.
For those who are interested in making money, every good thing comes with money, comes with extra effort, All u need do is a Spiritual work and every wicked power delaying your progress wants clear and good things will come to you like, money, favour from people, open doors, business breakthrough, good job. Etc. For more info you can call agent jeffjerry +27632807647 Note: Its not a child’s play, its for those who are desperate and ready to make a change in their life. Above all its $266 dollar to Join SERVICE TO HUMANITY Call agent JEFFJERRY +27632807647 We are seeking that special wisdom and knowledge that would set us free from the bondage to dull and dreary everyday life, while strengthening us in body, mind and spirit, and bringing us the material rewards of wealth, love, and success. The karishika Brotherhood is a true brotherhood of secret knowledge and power. membership into our fraternity is free and normally through a thorough screening. we are here to liberate those who need wealth, riches, power, prosperity, protection and success in all ramification. Agent JEFFJERRY brotherhood offers all initiate members growth, wealth, fame, power, prosperity and success in all areas of heart desires. we do not demand human sacrifice, the use of any human parts or early personal death as a precondition for you to become our member. we are not suppose to be on the internet but because of questions and comments like: I WANT TO JOIN OCCULT IN SOUTH AFRICA. I WANT TO JOIN REAL OCCULT IN BOTSWANA . I WANT TO JOIN OCCULT TO MAKE MONEY. I WANT TO JOIN OCCULT FOR MONEY. I WANT TO JOIN OCCULT FOR MONEY RITUAL. I WANT TO JOIN OCCULT IN AFRICA TO BE RICH. I WANT TO JOIN GOOD OCCULT FRATERNITY IN SOUTH AFRICA /BOTSWANA. I WANT TO JOIN GREAT ILLUMINATI IN SOUTH AFRICA FOR RICHES. I WANT TO JOIN ILLUMINATI OCCULT IN SOUTH AFRICA OR BOTSWANA. I WANT TO JOIN ILLUMINATI BROTHERHOOD IN SOUTH AFRICA OR BOTSWANA. HOW TO JOIN OCCULT IN SOUTHAFRICA. HOW TO JOIN REAL OCCULT IN BOTSWANA. HOW TO JOIN OCCULT TO MAKE MONEY. HOW TO JOIN OCCULT FOR MONEY. HOW TO JOIN OCCULT FOR MONEY RITUAL. HOW TO JOIN OCCULT IN AFRICA TO BE RICH. HOW TO JOIN GOOD OCCULT FRATERNITY IN SOUTH AFRICA. HOW TO JOIN GREAT ILLUMINATI IN BOTSWANA FOR RICHES. HOW TO JOIN ILLUMINATI OCCULT IN SOUTH AFRICA OR BOTSWANA HOW TO JOIN ILLUMINATI BROTHERHOOD IN SOUTH AFRICA OR . HOW TO MAKE MONEY ONLINE. HOW TO MAKE MONEY IN NIGERIA. HOW TO MAKE MONEY IN GHANA. HOW TO MAKE MONEY BY JOINING OCCULT. HOW TO MAKE MONEY BY JOINING ILLUMINATI. FOR THOSE OF YOU WHO:want to join occult in south Africa how can i join secret society or cult to make money how can join occult for riches i want to be rich but i do not know how etc. how do i do money ritual how do i join good occult that will not affect me and my family forever we are now here for you. Kindly contact us on +27632807647 for details on what to do MONEY,POSH CAR,MAGIC RING,MEMBERSHIP ID,GREEN ****,CERTIFICATE AND GOWN.

---
## [shubham-kumar-tripathi/my_stuff](https://github.com/shubham-kumar-tripathi/my_stuff)@[312899f1c2...](https://github.com/shubham-kumar-tripathi/my_stuff/commit/312899f1c2481f1a02399db6f5acd59122a7e80a)
#### Thursday 2021-01-07 06:34:17 by Shubham Kumar Tripathi

Update Purchasing Information and Receipts for Lovely Loveseats.py

Create Purchasing Information and Receipts for Lovely Loveseats
We’ve decided to pursue the dream of small-business ownership and open up a furniture store called Lovely Loveseats for Neat Suites on Fleet Street. With our newfound knowledge of Python programming, we’re going to build a system to help speed up the process of creating receipts for your customers.

In this project, we will be storing the names and prices of a furniture store’s catalog in variables. You will then process the total price and item list of customers, printing them to the output terminal.

Please note: Projects do not run tests against your code. This experience is more open to your interpretation and gives you the freedom to explore. Remember that all variables must be declared before they are referenced in your code.

---
## [Tokikko/donategifts](https://github.com/Tokikko/donategifts)@[f7ef1b3125...](https://github.com/Tokikko/donategifts/commit/f7ef1b31254f7dd2c07f143f4c45256b56400289)
#### Thursday 2021-01-07 10:20:08 by gnorbsl

Login redirect fix (#245)

* Update config.yml

* Update config.yml

* Update config.yml

* update for slack

* Update app.js

* added data to slack notification

* annoying shit

* changed status for donation

* changed enums in donation history

* Update socialLogin.js

Co-authored-by: gnorbsl <supersecret@email.de>

---
## [open-osrs/plugins](https://github.com/open-osrs/plugins)@[fc1d2451d4...](https://github.com/open-osrs/plugins/commit/fc1d2451d45c78a850e7ac0f084290e81a5ae9df)
#### Thursday 2021-01-07 10:43:22 by TheRealNull

plguins: I'll freak the fuck out if I have to troubleshoot this shit one more time

---
## [KDE/releaseme](https://github.com/KDE/releaseme)@[aac315592e...](https://github.com/KDE/releaseme/commit/aac315592eda30c9a6199a0d32e3093b57829ccb)
#### Thursday 2021-01-07 11:19:36 by Harald Sitter

fix ruby 3 compat

there may or may not be a bug with process status duplication preventing
the newly created instance from initializing completely. could well be
intentional though, copying status is a tad silly anyway as a status
object **ought** to be immutable after process execution.

the dup call came from a reentrant fix where previously `@status` was
captured directly and supposedly that caused trouble with the multi
threading of l10n as later in the run() functions we'd refer to `status`
which was then going through the accessor but that may already have been
modified by another thread. so the important change there was capturing
into a local variable `status` instead of `@status` directly.

to be on the safe side let's freeze the status object even though
reentrancy-wise the local variable is the important bit and statuses
should be always frozen anyway

---
## [Rakeela/dragora-notes](https://github.com/Rakeela/dragora-notes)@[3e169b9d85...](https://github.com/Rakeela/dragora-notes/commit/3e169b9d85b579e6a0a0432bfa5c06c734882c68)
#### Thursday 2021-01-07 12:51:13 by Rakeela

Update #2021-1-7-tenth.md

Despite all the discomforting experiences described, I really actually love thinking about this guy.  He's up there with my dad and my hometown pastor as "awesome people I used to know".  Thinking about Mel makes me want to cry more than anyone else ranked highly on that list, but that's okay, too.

---
## [peff/git](https://github.com/peff/git)@[ee2bdc7b92...](https://github.com/peff/git/commit/ee2bdc7b92ac52cd736c82be34f564ce1aa1252d)
#### Thursday 2021-01-07 14:59:36 by Jeff King

git_connect_git(): forbid newlines in host and path

When we connect to a git:// server, we send an initial request that
looks something like:

  002dgit-upload-pack repo.git\0host=example.com

If the repo path contains a newline, then it's included literally, and
we get:

  002egit-upload-pack repo
  .git\0host=example.com

This works fine if you really do have a newline in your repository name;
the server side uses the pktline framing to parse the string, not
newlines. However, there are many _other_ protocols in the wild that do
parse on newlines, such as HTTP. So a carefully constructed git:// URL
can actually turn into a valid HTTP request. For example:

  git://localhost:1234/%0d%0a%0d%0aGET%20/%20HTTP/1.1 %0d%0aHost:localhost%0d%0a%0d%0a

becomes:

  0050git-upload-pack /
  GET / HTTP/1.1
  Host:localhost

  host=localhost:1234

on the wire. Again, this isn't a problem for a real Git server, but it
does mean that feeding a malicious URL to Git (e.g., through a
submodule) can cause it to make unexpected cross-protocol requests.
Since repository names with newlines are presumably quite rare (and
indeed, we already disallow them in git-over-http), let's just disallow
them over this protocol.

Hostnames could likewise inject a newline, but this is unlikely a
problem in practice; we'd try resolving the hostname with a newline in
it, which wouldn't work. Still, it doesn't hurt to err on the side of
caution there, since we would not expect them to work in the first
place.

The ssh and local code paths are unaffected by this patch. In both cases
we're trying to run upload-pack via a shell, and will quote the newline
so that it makes it intact. An attacker can point an ssh url at an
arbitrary port, of course, but unless there's an actual ssh server
there, we'd never get as far as sending our shell command anyway.  We
_could_ similarly restrict newlines in those protocols out of caution,
but there seems little benefit to doing so.

The new test here is run alongside the git-daemon tests, which cover the
same protocol, but it shouldn't actually contact the daemon at all.  In
theory we could make the test more robust by setting up an actual
repository with a newline in it (so that we'd succeed if our new check
didn't kick in). But a repo directory with newline in it is likely not
portable across all filesystems. Likewise, we could check git-daemon's
log that it waas not contacted at all, but we do not currently record
the log (and anyway, it would make the test racy with the daemon's log
write). We'll just check the client-side stderr to make sure we hit the
expected code path.

Reported-by: Harold Kim <h.kim@flatt.tech>

---
## [catalyst-cooperative/pudl](https://github.com/catalyst-cooperative/pudl)@[15dae32444...](https://github.com/catalyst-cooperative/pudl/commit/15dae32444f518bc9cad851fff902a574a7bfaff)
#### Thursday 2021-01-07 17:35:53 by Christina Gosnell

Extractor/metadata for EIA 861.

All of the "pages" of 861 should now be extractable with 
`pudl.extract.eia861.Extractor().extract` for 2010 through 2018. In 
order to deal with the fact that the colum maps/renaming is different 
for 861 (which uses numeric locations instead of strings) I pulled the 
standard renaming into `process_raw` and overwrote that in the 861 
version. I thought about creating a generic rename function and 
overwriting that but seemed like overkill - although now all of the EIA 
extractors have to rename their columns so maybe this method would be 
better. I'm very open to thoughts 
on this! I also pulled up the testing argument into 
`GenericExtractor.extract` 
so it was easier to turn that knob. I also added a way to skip years of 
pages where there is no filename. Right now this is just when the 
file_map.csv has a -1 for that year. I don't love this - I'd love 
feedback here. Working on #590.

Most of the work here was metadata munging....

Also, Close #470. All of the eia metadata is transposed and the 
GenericExtractor knows how to read the transposed metadata.

WIP: The `pudl.extract.excel_filename` was having a hard time finding a 
few of the files pre-2009. I need to figure that out.

WIP: `pudl.extract.load_excel_file` was caching the first page's file 
and returning that. Not sure what the right solution is.

---
## [fossas/spectrometer](https://github.com/fossas/spectrometer)@[1222abe9d8...](https://github.com/fossas/spectrometer/commit/1222abe9d8a2502f11d2361b1a8c1bf757b04acc)
#### Thursday 2021-01-07 18:27:22 by Wesley Van Melle

FUCK YOU GITHUB!!!!

Signed-off-by: Wesley Van Melle <van.melle.wes@gmail.com>

---
## [pytorch/pytorch](https://github.com/pytorch/pytorch)@[b153a325d4...](https://github.com/pytorch/pytorch/commit/b153a325d46b0ab11b931376a1623c73e84c38e0)
#### Thursday 2021-01-07 18:34:13 by Brian Hirsh

Update on "Plumbing TLS keys through the dispatcher"

Table of contents because this description is too long:
- Overview
- High-level changes
- What order to look at things in
- What I don't like about this PR / things I want to change
- Benchmarking results
- Takeaways

### Overview
Benchmarks have shown that reading from TLS (thread-local scope) in the dispatcher is a noticeable source of framework overhead. The TLS read comes from the fact that some dispatch keys are stored using TLS, and these keys must be read from and aggregated to calculate a single dispatch key, which the dispatcher uses to determine which kernel to dispatch to. The logic for that lives [here](https://github.com/pytorch/pytorch/blob/55b431b17aba504ae7b75f6f97b4437101e50f38/aten/src/ATen/core/dispatch/DispatchKeyExtractor.h#L50). The overhead mainly comes from the fact that calling an operator often results in multiple trips through the dispatcher, and the dispatch keys are read and re-aggregated on every trip.


### High-level changes
This PR attempts to reduce that overhead by "plumbing" the set of keys that the dispatcher computed through (opted-in) kernels. The only kernels currently opted in are the codegen'd autograd + tracing kernels. Kernels can opt into this plumbing by:
- Accepting a DispatchKeySet as their first argument, and manually calculating the new dispatch key set to pass back to the dispatcher
- registering themselves to the dispatcher with a slightly different API

This is accomplished by changing the calling convention inside the dispatcher:
- The dispatcher now expects all kernels registered to have a first argument of type DispatchKeySet.
- There are now two parallel registration paths in the dispatcher
- There are two versions of the functor in `make_boxed_from_unboxed_functor.cpp`. Both versions now also take in a DispatchKeySet argument. One does nothing with it, and the other passes it to the registered kernel.


### What order to look at things in
- In `make_boxed_from_unboxed_functor.h`, look at `make_boxed_from_unboxed_functor_withKeys` and `wrap_kernel_functor_unboxed_withKeys`. This is the core part of the updated calling convention in the dispatcher for unboxed kernels - one functor passes the keys through to the kernel and the other does not. I also added static asserts to make sure that you register your kernel with the right API (only use the new API if your kernel has a first argument of type DispatchKeySet)
- The equivalent version of that for boxed kernels is `KernelFunction_impl.h:make_boxed_function_withKeys()`. This isn't actually used anywhere, and won't be unless we write/update a boxed fallback to plumb TLS keys.
- `KernelFunction.h`, `KernelFunction_impl.h`, `KernelFunction.cpp` and `library.h` all contain the alternate registration path, starting with `Library::impl_withKeys()` and ending in `make_boxed_from_unboxed_functor.h`.
- `Dispatcher.h`, `KernelFunction_impl.h` and `boxing.h` also have changes for the new calling convention: versions of `callWithDispatchKey()` and `redispatch()` that take in a DispatchKeySet. they pass it along to `KernelFunction::call()`, which now always takes in a DispatchKeySet.
- `gen_variable_type.py` and `gen_trace_type.py` are where the change is actually used- the tracing and autograd kernels now accept DispatchKeySet as their first argument, remove the autograd keys from it and forward it back to the dispatcher. They register themselves using the new registration path
  - I also modified the autograd kernels to use `redispatch()` rather than `call()` - originally to avoid making another API, but it turned out to also have perf benefits. See the benchmarking section.
- `op_registration.h`, `CppSignature.h`, `Metaprogramming.h` changes are due to some hoops I had to jump through in the new registration path. They generate a version of CppSignature and FunctionSchema that ignore the first argument to the passed-in function pointer. Reasoning:
  - FunctionSchema expects all of its arguments to be convertible to ivalues, which isn't the case for DispatchKeySet (we probably want to totally hide it from jit-land)
  - OperatorEntry expects the CppSignature of all of its kernels to match, which is technically no longer the case. I could break that invariant, but instead I chose to hide the DispatchKeySet argument so they would all match (I'm open to either though).
- `gen_unboxing_wrappers.py`, `generated_unboxing_wrappers.cpp`, `OperatorEntry.h/cpp` required changes because the unboxing wrapper that we generate now has a different calling convention depending on whether or not the corresponding unboxed kernel takes in a DispatchKeySet. This is a hack on top of a hack, and should go away when we're totally c10-full. I manually hardcoded the fact that only autograd/tracing use the new calling convention, inside of `OperatorEntry.cpp`.


### What I don't like about this PR / things I want to change / where further work is needed
There's a bigger question here of "do the benefits of this PR warrant it landing given it's complexity" that I try to address more in the benchmarking section.
Here though I just want to point out some parts of the PR that are incomplete / can hopefully be cleaned up. I wanted more general feedback on the PR as a whole before spending time cleaning it up further.

1) The new registration path is bad; it's implemented as a giant chain of duplicate functions, all ending in `_withKeys`, spread throughout `library.h`, `KernelFunction[_impl].[h|cpp]`, `make_boxed_from_unboxed_functor.h`, `CppSignature.h`, `op_registration.h` and `Metaprogramming.h`. The `_withKeys` suffix is also subject to change, I just left it as a placeholder so I could easily find all the call-sites. I think that I can write this all more cleanly with templated bools, but I ran into some issues trying that- when I tried merging the pairs of structs in `make_boxed_from_unboxed_functor.h`, the compiler looked like it was complaining about the fact that I was passing in different types in different branches of a `guts::if_constexpr`.
- One way I could fix it- maintain two copies of the structs in `make_boxed_from_unboxed_functor.h`, but template everything else on a boolean. The functions that create those structs can use `if_constexpr` to choose which struct to extract the `call` operator from.

2) `callWithDispatchKey`, `redispatch` and `callBoxed` now each have two variants, one taking in a DispatchKey and one taking in a DispatchKeySet (callBoxed's first variant doesn't take in anything). They are functionally similar, and I need the second variant, but I kept the first around to avoid being BC-breaking. Still, that gives us two pretty much repeated functions. I could write the first variant to call the second, I'd just need to benchmark it to ensure it gets inlined properly.

3) Need to confirm whether it's acceptable that autograd kernels no longer sample RecordFunction (see the notes in the benchmarking section). We get a bit of extra perf by not having to do this but I can add it back in if necessary.

4) The logic I added in `Metaprogramming.h` to remove the first argument of a function is pretty hacky. The only alternative that I see is to special-case the error-checks in FunctionSchema and OperatorKernel to ignore a first argument of type DispatchKeySet. Not sure that that's necessarily cleaner though.

5) I updated 3 of the kernels in `VariableTypeManual.cpp` to plumb dispatch keys, and it looks like all 3 of them are failing to compile on windows in phabricator because they aren't matching a BoxedKernelWrapper specialization ([here](https://www.internalfb.com/intern/ci/signal_trampoline/?phabricator_version_fbid=214217710245195&ci_signal_id=c2FuZGNhc3RsZV9pbnN0YW5jZV9hbGlhczpidWlsZC1vdnItc2VydmVy)). I need to dig into it more.

6) Need to re-write the autograd codegen with the new model on top of Jiakai's changes

7) Need to add unit tests


### Benchmarking results

**Update** I have the callgrind results from Taylor's microbenchmark callgrind report, which are more illuminating than my individual benchmarks here: P160166927. `empty()` regressed a little (strange, because I didn't see a regression originally, but I saw one after rebasing on master). But every other benchmark sees improvements (particularly `add`, `view`, `resize_` and `zero_` and indexing).

Recap: This PR adds a lot of complexity to the dispatcher, and probably isn't worth landing unless there's a clear perf improvement.

One noticeable shortcoming of this PR - especially when tracing is disabled, it has a greater effect on "base operators" over "composite operators". Composite ops result in multiple dispatch chains, and all that this PR tries to guarantee is a single TLS read per dispatch chain. I tried printing out the number of times that TLS keys are read from for a number of simple operators before/after this PR, which I dumped [in this quip](https://fb.quip.com/MNBJAbUq0jEW#RSDACAxyNAu).
So for example, I'd expect this PR to improve `a += 1` (tls reads go from 7 -> 6) less than it improves `c = a + b` (tls reads go from 2 -> 1).

One (unpopular) option would be to pick a small number of simple/commonly used composite ops and implement the plumbing for them too. Although that would add even more complexity and doesn't provide a clear win without more measuring (e.g. since that would probably require adding yet another argument to the calling convention).


I tested 5 benchmarks using torch.Timer's C++ snippets:
```
    stmt="t3 = t1 + t2;",
    setup="auto t1 = torch::randn({1}); auto t2 = torch::randn({1}); auto t3 = torch::zeros({1});",

    stmt="t = torch::empty(size);",
    setup="auto t = torch::zeros({1, 2, 3}); auto size = t.sizes();",

    stmt="t = t1.view(-1);",
    setup="auto t = torch::zeros({1, 2, 3}); auto t1 = torch::zeros({1, 2, 3});",

    stmt="t += 1;",
    setup="auto t = torch::zeros({1, 2, 3});",

    stmt="t.resize_(0);",
    setup="auto t = torch::randn({1});",
```


**wall time results (ran each test for 10 minutes)**
| Test | Before | After | Delta |
| ------------- | ------------- | ------------- | ------------- |
| add_out  | 1.67 +- 0.02 us | 1.36 +- 0.01 us | -18.6% |
| empty | 427.50 +- 2.38 ns | 403.01 +- 2.78 us | -5.7% |
| view | 784.70 +- 10.35 ns | 707.76 +- 15.13 ns | -9.8% |
| add_inplace | 4.42 +- 0.02 us | 4.45 +- 0.02 us | +0.7% |
| resize_inplace | 195.12 +- 0.74 ns | 108.44 +- 0.49 ns | -45.4% |

Due to my paranoia I ran the tests again for 60 minutes each overnight on my devfair.


**wall time results (ran each test for 60 minutes)**
| Test | Before | After  | Delta |
| ------------- | ------------- | ------------- | ------------- |
| add_out | 1.70 +- 0.02 us | 1.41 +- 0.02 us | -17.10% |
| empty | 397.17 +- 2.16 ns | 395.37 +-2.19 us | -0.50% |
| view | 774.42 +- 2.41 us | 666.66 +- 7.91 us | -13.90% |
| add_inplace | 4.40 +- 0.04 | 4.22 +- 0.09 us | -4.10% |
| resize_inplace | 188.82 +- 0.96 ns | 107.05 +- 0.22 ns | -43.30% |

resize_inplace, add_out and view all performed much better than empty and add_inplace. That held up with the expectation I put above, since those 3 all halve the number of tls reads (2->1), while empty has the same number of tls reads (3->3) and adds_inplace goes from 7->6. Importantly, empty and add_inplace didn't get noticeably slower.

I couldn't get a matching benchmark from AIBench though. It actually showed large regressions, specifically in the `add_out` and `empty` tests. That's why I explicitly tests those in my benchmarks - I matched the snippet that was run by AIBench in my local tests. I don't have a good explanation for why I couldn't replicate the results in AIBench, although I'd like to think that the 60 minute tests that I ran locally are more representative. Two examples are [here](https://www.internalfb.com/intern/aibench/details/757195478/) and [here](https://www.internalfb.com/intern/aibench/details/3404018999/).


**instruction count results**
| Test | Before (instruction count) | After (instruction count) | diff in instructions | diff in __tls_get_addr_ count | delta |
| ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |
| add_out | 628461 | 610210 | -18251 | -4400 | -2.90% |
| empty | 218216 | 218116 | -100 | 0 | ~0% |
| view | 324816 | 304016 | -20800 | -4400 | -6.40% |
| add_inplace | 1558265 | 1541325 | -16940 | -4400 | -1.10% |
| resize_inplace | 67314 | 47414 | -19900 | -4400 | -29.60% |

And here's an example instruction count delta. This one is for `resize_inplace`. Sorry, I ran `before.delta(after)`, so positive numbers are good :)
```
rows: 41
<torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7fe0f3d54940>
    4400  /build/glibc-OTsEL5/glibc-2.27/elf/../sysdeps/x86_64/tls_get_addr.S:__tls_get_addr
    4200  VariableTypeManual.cpp:torch::autograd::VariableType::()::resize_(at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    3700  Dispatcher.h:at::Tensor& c10::Dispatcher::callWithDispatchKey<at::Tensor&, at::Tensor&, Ar<l ... oryFormat>)> const&, c10::DispatchKey, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>) const'2
    3700  Dispatcher.h:at::Tensor& c10::Dispatcher::callWithDispatchKey<at::Tensor&, at::Tensor&, Ar<l ... emoryFormat>)> const&, c10::DispatchKey, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>) const
    2400  record_function.cpp:at::shouldRunRecordFunction(bool*)
    2400  DispatchKeyExtractor.h:c10::impl::dispatchTypeId(c10::DispatchKeySet, c10::DispatchKeySet)
    2000  TensorMethods.cpp:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const'2
    1600  Dispatcher.h:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const'2
    1400  LocalDispatchKeySet.cpp:c10::impl::tls_local_dispatch_key_set()
    1200  DispatchKeySet.h:c10::impl::dispatchTypeId(c10::DispatchKeySet, c10::DispatchKeySet)
    1000  llvmMathExtras.h:c10::impl::dispatchTypeId(c10::DispatchKeySet, c10::DispatchKeySet)
    1000  KernelFunction_impl.h:at::Tensor& c10::Dispatcher::callWithDispatchKey<at::Tensor&, at::Tens ... oryFormat>)> const&, c10::DispatchKey, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>) const'2
    1000  KernelFunction_impl.h:at::Tensor& c10::Dispatcher::callWithDispatchKey<at::Tensor&, at::Tens ... emoryFormat>)> const&, c10::DispatchKey, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>) const
     500  record_function.cpp:at::()::manager()
     500  WrapFunctionIntoFunctor.h:c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFun ... 0::MemoryFormat>)>::call(c10::OperatorKernel*, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
     500  RegisterCPU.cpp:c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoF ... 0::MemoryFormat>)>::call(c10::OperatorKernel*, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
     300  TensorBody.h:torch::autograd::VariableType::()::resize_(at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
     300  LegacyTypeDispatch.h:torch::autograd::VariableType::()::resize_(at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
     200  stl_vector.h:at::shouldRunRecordFunction(bool*)
     200  make_boxed_from_unboxed_functor.h:c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail: ... 0::MemoryFormat>)>::call(c10::OperatorKernel*, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
     200  OperatorEntry.h:c10::impl::OperatorEntry::lookup(c10::DispatchKey) const
     200  KernelFunction_impl.h:c10::impl::OperatorEntry::lookup(c10::DispatchKey) const
     200  /usr/include/c++/7/array:c10::impl::OperatorEntry::lookup(c10::DispatchKey) const
     100  LocalDispatchKeySet.h:c10::impl::tls_local_dispatch_key_set()
    -100  stl_list.h:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -100  Dispatcher.h:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const
    -200  make_boxed_from_unboxed_functor.h:c10::impl::wrap_kernel_functor_unboxed_withKeys_<c10::impl ... all(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -200  WrapFunctionIntoFunctor.h:c10::impl::wrap_kernel_functor_unboxed_withKeys_<c10::impl::detail ... all(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -200  OperatorEntry.h:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const
    -300  TensorBody.h:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -300  LegacyTypeDispatch.h:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -400  make_boxed_from_unboxed_functor.h:c10::impl::wrap_kernel_functor_unboxed_withKeys_<c10::impl ... all(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -400  RegisterCPU.cpp:c10::impl::wrap_kernel_functor_unboxed_withKeys_<c10::impl::detail::WrapFunc ... all(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
    -700  llvmMathExtras.h:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const
    -700  DispatchKeySet.h:c10::DispatchKeySet c10::DispatchKeyExtractor::getDispatchKeyUnboxed<*, long>(c10::DispatchKeySet, * const&, long const&) const
    -800  TensorMethods.cpp:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const
    -900  llvmMathExtras.h:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
   -1000  DispatchKeyExtractor.h:c10::DispatchKeySet c10::DispatchKeyExtractor::getDispatchKeyUnboxed<*, long>(c10::DispatchKeySet, * const&, long const&) const
   -1100  KernelFunction_impl.h:at::Tensor::resize_(Ar<long>, opt<c10::MemoryFormat>) const
   -1600  KernelFunction_impl.h:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)
   -4300  VariableTypeManual.cpp:torch::autograd::VariableType::()::resize_(c10::DispatchKeySet, at::Tensor&, Ar<long>, opt<c10::MemoryFormat>)

Total: 19900
```

Some observations:
- Aside from empty (no change), the other benchmarks all have a similar drop in total instruction counts (~18k), which seems reasonable since they're all removing one tls read, from the autograd kernel, on every op call.
  - That probably means that this PR will primarily be useful in training and tracing use cases- not for inference (once `torch.no_grad` lands).
- The instruction count deltas are all smaller than the wall-time deltas. That's probably due to __tls_get_addr being an expensive instruction
- In all cases where fewer tls reads occurred, we dropped instructions in more places than just __tls_get_addr. Taking the above as an example:
  - __ttls_get_addr (-4400). No surprises here.
  - dispatchTypeId (-4600). dispatchTypeId does other bitwise calculations in addition to the tls read, which we now only do once (plus the single mask in the autograd kernels)
  - tls_local_dispatch_key_set (-1400). This is a tiny functions that basically just checks a global flag and calls __tls_get_addr. Maybe that flag checking added up to 1400?
  - callWithDispatchKey (-9400). This is because I updated the autograd kernels to use `redispatch()` rather than `call()`. It looks like `callWithDispatchKey` isn't getting inlined, but `redispatch` is (see below)
  - shouldRunRecordFunction (-2200). Now that we call `redispatch` instead of `callWithDispatchKey` from autograd kernels, we don't use RecordFunction during the redispatch. I **think** that's the right behavior, since we've already used RecordFunction in the original `call()`, and it's not clear to me why we'd want to use RecordFunction multiple times in a single dispatch chain in only some cases. Other than that, `redispatch` and `callWithDispatchKey` aren't too different, so I'm not too sure why the delta for `callWithDispatchKey` is so high.
  - resize_ (+2000). My guess is that this is because the autograd kernels now do a bit more work, to manually mask the DispatchKeySet before calling back into the dispatcher. It could also be due to register pressure (?), since the function now takes in an extra argument. Importantly, this increase looks minimal compared to the other improvements.

I'm also particularly confused by `add_out` from AIBench vs. my benchmarks, since locally I see both a wall-time and an instruction count drop, but the two AIBench runs I posted both show a regression. The same goes for `empty`, although I see mostly no change in my local benchmarks, vs. a regression in AIBench 


### Takeaways
For this PR to merit landing, we want to see:
- substantial benchmark wins. i.e. in the majority of benchmarks, we want to see that (gain from plumbing TLS keys) > (loss due to extra register usage)
- Limited code complexity increase. Specifically, that (value of benchmark wins) > (size of code complexity increase)

If my local benchmarks are trustworthy, I think we see some pretty sizable wins in most cases, and more importantly, no major regressions in the cases where this PR doesn't help (`empty`).

I think the PR is pretty unwieldy as is, but there are some steps I can take to make it better (namely, hopefully templating the op registration path so we don't have two sets of functions everywhere).

But open to other suggestions/opinions!


Differential Revision: [D25614042](https://our.internmc.facebook.com/intern/diff/D25614042)

[ghstack-poisoned]

---
## [inertiajs/inertia](https://github.com/inertiajs/inertia)@[51f7560103...](https://github.com/inertiajs/inertia/commit/51f7560103d209760661b4efa9ab6918eaadbb9d)
#### Thursday 2021-01-07 18:45:51 by Claudio Dekker

Disable eslint rule

This rule is biting us, because we actually DO want to wait an arbitrary time, because without it the CI just fails at times.
Would love to have someone 'fix' this properly instead of just disabling the warnings and hacking around it, but there just isn't anyone around that has Cypress experience at this time :(

---
## [EsliStavenga/AdventOfCode](https://github.com/EsliStavenga/AdventOfCode)@[ff567afa6f...](https://github.com/EsliStavenga/AdventOfCode/commit/ff567afa6f00038821561d3804096c658e5835a1)
#### Thursday 2021-01-07 20:13:03 by root

Day 5
I fucking love this code and how I got the correct answer

---
## [Segorova/Mine-codes](https://github.com/Segorova/Mine-codes)@[0b4474d19a...](https://github.com/Segorova/Mine-codes/commit/0b4474d19a06eb14511999a5e41d0283fe8b8c71)
#### Thursday 2021-01-07 22:08:30 by Светлана

using obj.properties 

BAC% = (A × 5.14 / W × r) - .015 × H 
A: Total alcohol consumed, in ounces (oz)
W: Body weight, in pounds (lbs)
r: The alcohol distribution ratio, 0.73 for man, and 0.66 for women
H: Time passed since drinking, in hours
Alcohol consumed will be passed as a drinks object with two properties: ounces (the total volume of beverage consumed in ounces), and abv (the % of alcohol by volume of the beverage as a floating point number--such as 0.05 for 5% abv beer or 0.4 for 40% abv whisky). For simplicity, Bob assures us that he drinks the same kind of beverage each time he drinks.
The gender will be passed as a string, either "male" or "female".
Output must be returned as a number data-type, greater than or equal to 0, with up to 4 decimal places. No error handling will be required.
Using these parameters, create the function that will calculate Bob's and other partier's BAC.

---
## [tgstation/tgstation](https://github.com/tgstation/tgstation)@[5ad6fd883f...](https://github.com/tgstation/tgstation/commit/5ad6fd883fdb1fd59af346cf003b23b57d34fec5)
#### Thursday 2021-01-07 22:31:31 by tralezab

NOTELEPORT errywhere (#55973)

These prevent some cheats or really low effort ways to get to where you really shouldn't be.

Mappers seriously fucking hate jaunting and phasing mechs, as they let you bypass their custom crafted ruins and the like. But it'll also stop more general "you shouldn't be here" stuff.

---
## [mayan5/The-Power-of-Plots](https://github.com/mayan5/The-Power-of-Plots)@[45abdf884b...](https://github.com/mayan5/The-Power-of-Plots/commit/45abdf884bd239cffb0b51a29c1eaa011abae5c8)
#### Thursday 2021-01-07 22:49:04 by mayan5

Create README.md

The Power of Plots

Background
What good is data without a good plot to tell the story?
So, let's take what you've learned about Python Matplotlib and apply it to a real-world situation and dataset:

While your data companions rushed off to jobs in finance and government, you remained adamant that science was the way for you. Staying true to your mission, you've joined Pymaceuticals Inc., a burgeoning pharmaceutical company based out of San Diego. Pymaceuticals specializes in anti-cancer pharmaceuticals. In its most recent efforts, it began screening for potential treatments for squamous cell carcinoma (SCC), a commonly occurring form of skin cancer.
As a senior data analyst at the company, you've been given access to the complete data from their most recent animal study. In this study, 249 mice identified with SCC tumor growth were treated through a variety of drug regimens. Over the course of 45 days, tumor development was observed and measured. The purpose of this study was to compare the performance of Pymaceuticals' drug of interest, Capomulin, versus the other treatment regimens. You have been tasked by the executive team to generate all of the tables and figures needed for the technical report of the study. The executive team also has asked for a top-level summary of the study results.

Instructions
Your tasks are to do the following:


Before beginning the analysis, check the data for any mouse ID with duplicate time points and remove any data associated with that mouse ID.


Use the cleaned data for the remaining steps.


Generate a summary statistics table consisting of the mean, median, variance, standard deviation, and SEM of the tumor volume for each drug regimen.


Generate a bar plot using both Pandas's DataFrame.plot() and Matplotlib's pyplot that shows the total number of measurements taken for each treatment regimen throughout the course of the study.


NOTE: These plots should look identical.



Generate a pie plot using both Pandas's DataFrame.plot() and Matplotlib's pyplot that shows the distribution of female or male mice in the study.


NOTE: These plots should look identical.



Calculate the final tumor volume of each mouse across four of the most promising treatment regimens: Capomulin, Ramicane, Infubinol, and Ceftamin. Calculate the quartiles and IQR and quantitatively determine if there are any potential outliers across all four treatment regimens.


Using Matplotlib, generate a box and whisker plot of the final tumor volume for all four treatment regimens and highlight any potential outliers in the plot by changing their color and style.
Hint: All four box plots should be within the same figure. Use this Matplotlib documentation page for help with changing the style of the outliers.


Select a mouse that was treated with Capomulin and generate a line plot of tumor volume vs. time point for that mouse.


Generate a scatter plot of mouse weight versus average tumor volume for the Capomulin treatment regimen.


Calculate the correlation coefficient and linear regression model between mouse weight and average tumor volume for the Capomulin treatment. Plot the linear regression model on top of the previous scatter plot.


Look across all previously generated figures and tables and write at least three observations or inferences that can be made from the data. Include these observations at the top of notebook.


Here are some final considerations:


You must use proper labeling of your plots, to include properties such as: plot titles, axis labels, legend labels, x-axis and y-axis limits, etc.


See the starter workbook for help on what modules to import and expected format of the notebook.



Hints and Considerations


Be warned: These are very challenging tasks. Be patient with yourself as you trudge through these problems. They will take time and there is no shame in fumbling along the way. Data visualization is equal parts exploration, equal parts resolution.


You have been provided a starter notebook. Use the code comments as a reminder of steps to follow as you complete the assignment.


Don't get bogged down in small details. Always focus on the big picture. If you can't figure out how to get a label to show up correctly, come back to it. Focus on getting the core skeleton of your notebook complete. You can always revisit old problems.


While you are trying to complete this assignment, feel encouraged to constantly refer to Stack Overflow and the Pandas documentation. These are needed tools in every data analyst's tool belt.


Remember, there are many ways to approach a data problem. The key is to break up your task into micro tasks. Try answering questions like:


How does my DataFrame need to be structured for me to have the right x-axis and y-axis?


How do I build a basic scatter plot?


How do I add a label to that scatter plot?


Where would the labels for that scatter plot come from?


Again, don't let the magnitude of a programming task scare you off. Ultimately, every programming problem boils down to a handful of bite-sized tasks.


Get help when you need it! There is never any shame in asking. But, as always, ask a specific question. You'll never get a great answer to "I'm lost."



Copyright
Trilogy Education Services © 2020. All Rights Reserved.

---
## [DOL-Modders/DOL-Modding-Framework](https://github.com/DOL-Modders/DOL-Modding-Framework)@[8aabb7e7a3...](https://github.com/DOL-Modders/DOL-Modding-Framework/commit/8aabb7e7a3ba1ac760a195200cb0e3ee0cae1d09)
#### Thursday 2021-01-07 23:37:35 by Purity

Quality of Life:
- The "Flaunt" option is now hidden to players without a TF
- Cleaned up the "Game Settings" tab by introducing subsection tabs for Human NPC Settings and Beast Settings + Toggles.
- Improved clarity for Game Modes.
- The player will now receive a notification when they are able to choose a second love interest.

Bug fixes:
- Fixed a bug that prevented Robin from mentioning the player cross dressing with them during Halloween (thanks to braymann for finding).
- Fixed a softlock at Robin's hot chocolate stand.

---

# [<](2021-01-06.md) 2021-01-07 [>](2021-01-08.md)

