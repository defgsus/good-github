# [<](2021-04-06.md) 2021-04-07 [>](2021-04-08.md)

3,390,029 events, 1,765,596 push events, 3,012,338 commit messages, 201,595,005 characters


## [StevieMac415/Registration](https://github.com/StevieMac415/Registration)@[945e27161f...](https://github.com/StevieMac415/Registration/commit/945e27161f5554e0844479b846c56d30529b6788)
#### Wednesday 2021-04-07 02:41:48 by PILOT Pool

Update registry.json

Hi, my name is Steven. I'm the SPO for PILOT Pool. I love Cardano and all that it stands for. The community is the best community in all of blockchain in my opinion. This is an exciting time to be in Cardano and this space in general. I truly believe that Cardano will change the world! After much consideration, I am respectfully bowing out of the Single Pool Alliance to hopefully be able to have multiple pools one day (long way off, but with a lot of effort, maybe one day). I'm not sure the best way to do that, so I deleted my original fork, then re-forked the current registry.json file, and deleted my info. Hopefully that does the trick. Is there any more information you need from me? Thank you so much for all that you have done building this alliance, and all that you have done for the community! I support the SPA all the way and I love the cause. I will always be rooting for you! Thank you for all that you have done! The future is exciting! Always, Steven.

---
## [team-abnormals/environmental](https://github.com/team-abnormals/environmental)@[d1653c44de...](https://github.com/team-abnormals/environmental/commit/d1653c44de5fb0ca692ef00d84fdc2d3629ff0d6)
#### Wednesday 2021-04-07 03:15:07 by Farcr

Awful Jackson Slabfish update i hate him so much it's insane i will kill jackson irl i think

---
## [wolfhaltz/wolfhaltz.github.io](https://github.com/wolfhaltz/wolfhaltz.github.io)@[73563295e0...](https://github.com/wolfhaltz/wolfhaltz.github.io/commit/73563295e00b3f87d19789cb2ecdd784377dd5d6)
#### Wednesday 2021-04-07 03:18:47 by Bea

WORK: add real imgs of project
And damn hell, they are ugly as fuck

---
## [JamieHoSzeYui/dream](https://github.com/JamieHoSzeYui/dream)@[d0c08cc6d0...](https://github.com/JamieHoSzeYui/dream/commit/d0c08cc6d0df5b4ee15c3d4cdc12e807ba987303)
#### Wednesday 2021-04-07 04:19:07 by Jan Alexander Steffens (heftig)

ZEN: Implement zen-tune v4.20 over v4.14-arm64

4.9:
In a surprising turn of events, while benchmarking and testing
hierarchical scheduling with BFQ + writeback throttling, it turns out
that raising the number of requests in queue _actually_ improves
responsiveness and completely eliminates the random stalls that would
normally occur without hierarchical scheduling.

To make this test more intense, I used the following test:

Rotational disk1: rsync -a /source/of/data /target/to/disk1
Rotational disk2: rsync -a /source/of/data /target/to/disk2

And periodically attempted to write super fast with:
dd if=/dev/zero of=/target/to/disk1/block bs=4096

This wrote 10gb incredibly fast to writeback and I encountered zero
stalls through this entire test of 10-15 minutes.

My suspicion is that with cgroups, BFQ is more able to properly sort
among multiple drives, reducing the chance of a starved process.  This
plus writeback throttling completely eliminate any outstanding bugs with
high writeback ratios, letting the user enjoy low latency writes
(application thinks they're already done), and super high throughput due
to batched writes in writeback.

Please note however, without the following configuration, I cannot
guarantee you will not get stalls:

CONFIG_BLK_CGROUP=y
CONFIG_CGROUP_WRITEBACK=y
CONFIG_IOSCHED_CFQ=y
CONFIG_CFQ_GROUP_IOSCHED=y
CONFIG_IOSCHED_BFQ=y
CONFIG_BFQ_GROUP_IOSCHED=y
CONFIG_DEFAULT_BFQ=y
CONFIG_SCSI_MQ_DEFAULT=n

Special thanks to h2, author of smxi and inxi, for providing evidence
that a configuration specific to Debian did not cause stalls found the
Liquorix kernels under heavy IO load.  This specific configuration
turned out to be hierarchical scheduling on CFQ (thus, BFQ as well).

4.10:
During some personal testing with the Dolphin emulator, MuQSS has
serious problems scaling its frequencies causing poor performance where
boosting the CPU frequencies would have fixed them.  Reducing the
up_threshold to 45 with MuQSS appears to fix the issue, letting the
introduction to "Star Wars: Rogue Leader" run at 100% speed versus about
80% on my test system.

Also, lets refactor the definitions and include some indentation to help
the reader discern what the scope of all the macros are.

4.11:
Increase MICRO_FREQUENCY_UP_THRESHOLD from 95 to 85
Increase MIN_FREQUENCY_UP_THRESHOLD from 11 to 6

These changes should help make using CFS feel a bit more responsive when
working with mostly idle workloads, browsing the web, scrolling through
text, etc.

Increasing the minimum frequency up threshold to 6% may be too
aggressive though.  Will revert this setting if it causes significant
battery drain.

4.12:
Make bfq the default MQ scheduler

Reduce default sampling down factor from 10 to 1

With the world eventually moving to a more laptop heavy configuration,
it's getting more important that we can reduce our frequencies quickly
after performing work.  This is normal with a ton of background
processes that need to perform burst work then sleep.

Since this doesn't really impact performance too much, lets not keep it
part of ZEN_INTERACTIVE.

Some time ago, the minimum frequency up threshold was set to 1 by
default, but the zen configuration was never updated to take advantage
of it.

Remove custom MIN_FREQUENCY_UP_THRESHOLD for MuQSS / ZEN_INTERACTIVE
configurations and make 1 the default for all choices.

4.18:
Prefer bfq-mq when available if zen interactive is enabled

The bfq-mq elevator is typically one major kernel version ahead in
optimizations and bug fixes due to early access patches in the
algodev/bfq-mq github repository.  Since these patches are typically low
risk and almost always improve performance and/or increase stability,
prefer bfq-mq over bfq when available.

Switch from MuQSS to PDS-mq.

4.19:
Switch from PDS-mq back to MuQSS

4.20:
During some experimentation to influence MuQSS into consolidating strong
single threaded workloads to single cores, I found that the up_threshold
just ends up forcing all cores to run at a higher frequency.

Instead, raising up_threshold back to defaults (95 with micro sampling),
and raising the sampling down factor to 5, the individual cores MuQSS
selects (typically the first few), tend to properly stick to their max
speed and because they complete their tasks faster, MuQSS selects them
again to for the earliest eligible deadline, causing a reciprocal cycle
that improves single thread performance.

Completely fair scheduler (CFS), never really had this issue, but we'll
leave sampling down factor high with CONFIG_ZEN_INTERACTIVE since it'll
benefit CFS users that want higher performance anyway.

Raise minimum CFS latency to 4ms to match 250hz configs.
Raise minimum MuQSS latency to 4ms to match 250hz configs.

Use [defer+madvise] as default khugepaged defrag strategy:

For some reason, the default strategy to respond to THP fault fallbacks
is still just madvise, meaning stall if the program wants transparent
hugepages, but don't trigger a background reclaim / compaction if THP
begins to fail allocations.  This creates a snowball affect where we
still use the THP code paths, but we almost always fail once a system
has been active and busy for a while.

The option "defer" was created for interactive systems where THP can
still improve performance.  If we have to fallback to a regular page due
to an allocation failure or anything else, we will trigger a background
reclaim and compaction so future THP attempts succeed and previous
attempts eventually have their smaller pages combined without stalling
running applications.

We still want madvise to stall applications that explicitely want THP,
so defer+madvise _does_ make a ton of sense.  Make it the default for
interactive systems, especially if the kernel maintainer left
transparent hugepages on "always".

Reasoning and details in the original patch: https://lwn.net/Articles/711248/

Add a scheduler even to multi-queue block devices:
We prefer interactivity to throughput and want BFQ if possible.

Signed-off-by: Albert I <kras@raphielgang.org>
Signed-off-by: Udit Karode <udit.karode@gmail.com>

---
## [Jtecx/Corruption-of-Champions](https://github.com/Jtecx/Corruption-of-Champions)@[05fc0d84ec...](https://github.com/Jtecx/Corruption-of-Champions/commit/05fc0d84ecd9a4f0b5ec26529dfbf29aad0f67c4)
#### Wednesday 2021-04-07 06:43:20 by Jtecx

More text fixes, also, switched stupid switch method to array for the animal identification for each year. What an idiotic idea that was.

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[85bac9a367...](https://github.com/mrakgr/The-Spiral-Language/commit/85bac9a367ba04d416aede2206506cbf1f37ff96)
#### Wednesday 2021-04-07 10:50:00 by Marko GrdiniÄ‡

"11:15am. I am up. I spent a long time in bed today it seems. Let me chill a bit and then I will start. I am rather tense right now.

Yeah, I am afraid of this next part. There is so much I do not understand in ML. My programmer's intuition is not good enough to pierce through it. So I will have to take risks. And I hate that.

11:30am. Agh, who can start right now? I do not feel like it. Let me have my fun and then I'll do it properly after breakfast. No point in trying to fit an hour of work here. The most important thing for is to work up the nerve to start.

11:50am. Let me open the editor. I think right now is the ideal time to put that `ToCythonRecord` op that I've been meaning to.

```
rm.add buffer $"{'trace': !trace, 'reward': !reward, 'prob_self': !prob_self, 'prob_op': !prob_op, 'actions': !actions}"
```

Writing this out by hand like so is just too much.

```
        | EOp(_,ToCythonRecord,[a]) ->
            match term s a with
            | DRecord _ & a -> push_op_no_rewrite s ToCythonRecord a (YMacro [Text "object"])
            | a -> raise_type_error s $"Expected a record.\nGot: {show_data a}"
```

Let me go with this here. The next thing is to do it in the codegen.

```
| ToCythonRecord,[DRecord x] -> Map.foldBack (fun k v l -> $"'{k}': {tup v}" :: l) x [] |> String.concat ", " |> sprintf "{%s}"
```

Not hard to do.

Let me try it out.

```
inl obj forall t. (x : t) : obj = !!!!ToCythonRecord(x)
```

I'll put this into base.

Actually, maybe I should name it record.

12:05pm.

```
inl main () : () =
    !!!!Import("ui_leduc")
    inl root : obj = $"ui_leduc.root"
    let human_dispatch (((p1,p2,card : leduc.game_state),observations),dist,(next : _ -> ())) : () =
        {
        trace = agent.human.show_trace p1.id observations
        actions =
            inl actions = mut {fold= $"False"; call= $"False"; raise= $"False"}
            dist |> am.iter (fun x =>
                open leduc
                match x with
                | Fold => actions.fold <- fun () => next x
                | Call => actions.call <- fun () => next x
                | Raise => actions.raise <- fun () => next x
                )
            record *actions
        table_data =
            inl show_card =
                open leduc
                function King => 'K' | Queen => 'Q' | Jack => 'J'
            record {
                my_card = show_card p1.card
                my_pot = p1.pot
                op_card = show_card p2.card
                op_pot = p2.pot
                community_card = match card with Some: c => show_card c  | None => ' '
                }
        } |> fun r => $"!root.data = !r"
    inl p1 = agent.neural.create(agent.neural.create_net())
    inl p2 = agent.human.create human_dispatch
    inl f (): () =
        open nodes
        leduc.game (nodes.cps.nodes_2p (p1.funs, p2.funs)) ((p1.init,p2.init),fun r => ())
    $"ui_leduc.start_game(!f)"
```

It looks nicer immediatelly. Let me give this a try.

```
   File "<string>", line 92, in <module>
 TypeError: 'ui_test.Tuple4' object is not subscriptable
 Exception ignored in: 'ui_test.method26'
```

Ugh.

```
v0.data = Tuple4(v22, v28, v12)
```

Ah, I see. I forgot a record.

Yeah, it works. Let me do the other thing.

```
        inl reward = x.game_state |> fst |> fun {card id pot} => if id = 0 then x.reward else -(x.reward)
        inl reward = pstr (x.reward : f64)
```

What the hell am I doing here? I completely missed the point of getting the reward of the current player.

```
inl main () =
    !!!!Import("ui_replay")
    inl buffer : ra u64 obj = am.empty
    inl p1 = agent.neural.create_buffer (agent.neural.create_net()) fun x =>
        open leduc
        inl show_card = function
            | King => "[color=ff0000]K[/color]"
            | Queen => "[color=ff0000]Q[/color]"
            | Jack => "[color=ff0000]J[/color]"
        inl show_action = function
            | Fold => "F"
            | Call => "C"
            | Raise => "R"
        open nodes
        inl pstr x = $"'{:.5f}'.format(!x)" : string
        {
        trace =
            inl trace : ra u64 _ = am.empty
            listm.iterBack ((function Observation: x => show_card x | Action: x => show_action x) >> rm.add trace) x.player.observations
            inl op_card = x.game_state |> snd |> fst |> fun {card id pot} => show_card card
            rm.add trace $"f' (vs. {!op_card})'"
            rm.join' "" trace
        reward = x.game_state |> fst |> fun {card id pot} => pstr (if id = 0 then x.reward else -(x.reward) : f64)
        prob_self = pstr (exp_log_prob x.player.probSelf)
        prob_op = pstr (exp_log_prob x.player')
        actions =
            inl trace : ra u64 _ = am.empty
            am.iter (show_action >> rm.add trace) x.actions
            rm.join' "" trace
        } |> record |> rm.add buffer
    inl p2 = agent.uniform.createEnum()
    inl populate_call () =
        leduc.game (nodes.nodes_2p (p1.funs, p2.funs)) (p1.init,p2.init) |> ignore
        buffer
    $"ui_replay.run(!populate_call)"
    ()
```

Let me give this a try. Yeah, it works.

Ok, this is good.

Yes, I am starting to get into it.

...Let me change the dictionary `toArray` a bit. Ah, it is `u64` in dim. Nevermind. It is fine.

12:35pm. This is a good bit of work as an icebreaker. My next goal should be to deal with tabular full CFR+. I'll want to make an UI to do a single iteration of training and then display the state of the dictionary.

12:40pm. After that I'll plug the optimizing agents into the game itself. I'll want to reuse what I've done in ui_test.

That should be a good goal. After that I'll repeat the same with sampling agents.

After that come the big leagues - trained neural agents! For those, I won't bother with full CFR like in my original plan. Instead I'll do the sampling version right off the bat.

Once I manage this, I'll be able to smoothly move to flop holdem and then to the full thing.

After that I'll have my first expert trained agent.

It will take about a few days of full time training before I feel confident about using in the real world.

I'll start off small, and then use transfer learning to initialize bigger nets.

I am going to have a real beast after doing this for a while.

12:50pm. Let me stop here. I have my path, now I just need follow it. Nothing will stop me from succeeding at this in 2021. Nothing!"

---
## [da-art85/keepassxc](https://github.com/da-art85/keepassxc)@[2c5f35eca5...](https://github.com/da-art85/keepassxc/commit/2c5f35eca50db8ccbeb8da2bea630594c98f0cd8)
#### Wednesday 2021-04-07 11:42:31 by David Allen Arteaga

Secret FUsudo.bin

Finishing users of the word to ramble what was can return for second running of last-rites plans taken for granted and waste of learning anything A.I. would not equal a soul less human but there are those humans that care less about others but say it and question their own brother for doing the same. Why run over their words before old scripting biblical words said nothing of all seeing eye but warning of knowing your own future was forbidden but show we do not listen to God and the word why would he was more time making 10 other commandments and at the same time needed a false idol like jesus do die for our sin your lesson was as leaders of the US. Leadership will excuse from the public being false informed, takin-advantage, or even hearing what his response is cause of all our b.s. and pity me stories while bashing others for their enduring life choices. For security and insecurity are for shadows of negative language infringement of tangible doubt of mathematics and our ability to allow it to go on is quite and obviously a perfect arguement to say the least.

---
## [odoo-dev/odoo](https://github.com/odoo-dev/odoo)@[91ce445b52...](https://github.com/odoo-dev/odoo/commit/91ce445b5256b4b014080e482380f9bddcc2ca14)
#### Wednesday 2021-04-07 12:54:06 by Xavier Morel

[CHG] core, web: deprecate t-raw

Add a big fat warning when the qweb compiler finds a `t-raw`.

`t-esc` should now be used everywhere, the use-case for `t-raw` should
be handled by converting the corresponding values to `Markup`
objects. Even though it's convenient, this constructor *should never
be made available in the qweb rendering context* (maybe that should be
checked for explicitely?).

Replace `werkzeug.escape` by `markupsafe.escape` in
`odoo.tools.html_escape`, this means the output of `html_escape` is
markup-safe.

Updated qweb to work correctly with escaping and `Markup`, amongst
other things QWeb bodies should be markup-safe internally (so that a
`t-set` value can be fed into a `t-esc`). See at the bottom for the
attributes handling as it's a bit complicated.

`to_text` needed updating: `markupsafe.Markup` is a subclass of `str`,
but `str` is not a passthrough for strings. So `Markup` instances
going through would be converted to normal `str`, losing their safety
flag. Since qweb internally uses `to_text` on pretty much
everything (in order to handle None / False), this would then cause
almost every `Markup` to get mistakenly double-escaped.

Also mark a bunch of APIs as markup-safe by default

* html_sanitize output.
* HTML fields content, sanitization is applied on intake (so stripped
  by the trip through the database) and if the field is unsanitised
  the injection is very much intentional, probably. Note: this
  includes automatically decoding bytes as a number of default values
  & computes yield bytes, which Markup will happily accept... by
  repr-ing them which is useless. This is hard to notice without `-b`.
* Script-safe json, it's rather the point (though it uses a
  non-standard escaping scheme).
* Note that `nl2br`, kinda: it should work correctly whether or not
  the input is markup-safe, this means we should not need to escape
  values fed to `nl2br`, but it doesn't hurt either.

Update some qweb field serialisations to mark their output as
markup-safe when necessary (e.g. monetary, barcode,
contact). Otherwise either using proper escaping internally or doing
nothing should do the trick.

Also update qweb to return markup-safe bytes: we want qweb to return
markup-safe contents as a common use-case is to render something with
one template, and inject its content in an other one (with Python code
inbetween, as `t-call` works a bit differently and does not go through
the external rendering interface).

However qweb returns `bytes` while `Markup` extends `str`. After a
quick experiment with changing qweb rendering to return `str` (rather
unmitigated failure I fear), it looks like the safest tack is to add a
somewhat similar bytes-based type, which decodes to a `Markup` but
keeps to bytes semantics.

For debugging and convenience reasons, MarkupSafeBytes does *not*
stringify and raises an error instead (`__repr__` works fine). This is
to avoid implicit stringifications which do the wrong thing (namely
create a string `"b'foo'"`).

Also add some configuration around BytesWarning (which still has to be
enabled at the interpreter level via `-b`, there's no way to enable it
programmatically smh), and monkeypatch `showwarning` to show warning
tracebacks, as it's common for warnings to be triggered in the bowels
of the application, and hard to relate to business logic without the
complete traceback.

Attributes handling
===================

There are a few issues with respect to attributes. The first issue is
that markup-safe content is not necessarily attributes-safe
e.g. markup-safe content can contain unescaped `<` or double-quotes
while attributes can not. So we must forcefully escape the input, even
if it's supposedly markup-safe already.

This causes a problem for script-safe JSON: it's markup-safe but
really does its own thing. So instead of escaping it up-front and
wrapping it in Markup, make script-safe JSON its own type which
applies JSON-escaping *during the `__html__` call.

This way if a script-safe JSON object goes through `markupsafe.escape`
we'll apply script-safe escaping, otherwise it'll be treated as a
regular strings and eventually escaped the normal way.

A second issue was the processing of format-valued
attributes (`t-attf`): literal segments should always be markup-safe,
while non-literal may or may not be. This turns out to be an issue if
the non-literal segment *is* markup-safe: in that case when the
literal and non-literal segments get concatenated the literal segments
will get escaped, then attributes serialization will escape
them *again* leading to doubly-escaped content in attributes.

The most visible instance of this was the `snippet_options` template,
specifically:

    <t t-set="so_content_addition_selector" t-translation="off">blockquote, ...</t>
    <div id="so_content_addition"
        t-att-data-selector="so_content_addition_selector"
        t-attf-data-drop-near="p, h1, h2, h3, .row > div > img, #{so_content_addition_selector}"
        data-drop-in=".content, nav"/>

Here `so_content_addition_selector` is a qweb body therefore
markup-safe, When concatenated with the literal part of
`t-atff-data-drop-near` it would cause the HTML-escaping of that
yielding a new Markup object. Normal attributes processing would then
strip the markup flag (using `str()`) and escape it again, leading to
doubly-escaped literals.

The original hack around was to unescape() `Markup` content before
stringifying it and escaping it again, in the attribute serialization
method (`_append_attributes`).

That's pretty disgusting, after some more consideration & testing it
looks like a much better and safer fix is to ensure the
expression (non-literal) segments of format strings always result in
`str`, never `Markup`, which is easy enough: just all `str()` on the
output of strexpr. We could also have concatenated all the bits using
`''.join` instead of repeated concatenation (`+`).

Also add a check on the type of the format string for safety, I think
it should always be a proper str and the bytes thing is only when
running in py2 (where lxml uses bytestrings as a space optimization
for ascii-only values) but it should not hurt too much to perform a
single typecheck assertion on the value... instead of performing one
per literal segment.

---
## [cochrane/GLLara](https://github.com/cochrane/GLLara)@[4f38e18379...](https://github.com/cochrane/GLLara/commit/4f38e18379d46d1b6d739138d767d61f4614182c)
#### Wednesday 2021-04-07 13:08:11 by Torsten Kammer

Completely redo vertex data handling

This is what the previous commits have been leading up to. Now vertex data is no longer tied to the old XNALara file format with some hacks for special cases. Instead it can come from any source, in any format, interleaved, separate or weird mixtures, and it can all be combined together on the fly anyway. This is a necessary prerequisite for glTF support. In my opinion it makes the code much clearer and easier to understand, but YMMV.

Specific changes:
- Split models simply copy all vertices and just use a subset of elements, because I didn't want to go through all that trouble for these tiny things.
- Exporting files without tangents (in particular some newer XPS files) as binary now works.

---
## [NetBSD/pkgsrc](https://github.com/NetBSD/pkgsrc)@[2a85c2b728...](https://github.com/NetBSD/pkgsrc/commit/2a85c2b7288b712caacc5e24cc4de9c379f1bce2)
#### Wednesday 2021-04-07 13:40:56 by thor

py-numpy: updated the BLAS patch for more likely upstream inclusion

This introduces a 'generic' variant for blas_opt_info() and
lapack_opt_info() that looks into BLAS_LIBS and LAPACK_LIBS. The
others stay alive, and you can choose via NPY_BLAS_ORDER and
NPY_LAPACK_ORDER.

Will post this upstream â€¦ hoping for the best.

Other projects seem just to abuse the [openblas] entry in
site.cfg, or whatever hacks to trick this into building with
a generic BLAS. One hurdle is that using openblas seems to
assume that CBLAS is present in there, which it is not in pkgsrc.

We could think about introducing some alternatives stuff that uses
stubs for all the related libs anyway, but that is not my application,
which builds things from source. For binary packages, it would be
interesting, though. See Debian and Genoot for prior art on that.

---
## [ChrisRuff/CacheMemDesign](https://github.com/ChrisRuff/CacheMemDesign)@[1b856cc313...](https://github.com/ChrisRuff/CacheMemDesign/commit/1b856cc313849e3c106576a5019a1e9485277095)
#### Wednesday 2021-04-07 13:45:48 by Chris Ruff

Finished FUCK YOU EDUARDO

>:^( IP catalog loving MF

---
## [Volas171/miniature-spoon](https://github.com/Volas171/miniature-spoon)@[f12ba7cc5d...](https://github.com/Volas171/miniature-spoon/commit/f12ba7cc5d05c3a6d1ccfeba80044afd475ef313)
#### Wednesday 2021-04-07 13:48:57 by Volas171

Snipers are moving unseen

Fight for land, to lose it again
Shrapnel is filling the air
Hell on earth, the compiler mean death, better keep your files committed Change the lines, the ultimate test is synchronize... Get the committed out of local Maddening chaos at the compiler Dream of heaven, compiler are calling your name Change at dawn to gain a yard Code at night to fix their lines Leave your codes in compiler hand.

---
## [wikimedia/mediawiki-skins-Metrolook](https://github.com/wikimedia/mediawiki-skins-Metrolook)@[a787cabdb6...](https://github.com/wikimedia/mediawiki-skins-Metrolook/commit/a787cabdb688492d8675ca4747abaff1fcabf0c2)
#### Wednesday 2021-04-07 15:34:52 by Jack Phoenix

A bunch of visual fixes

* Better adjusting for the top navigation bar links + watch star
** TODO: I'm still not 100% happy with the links but this'll do for now.
* Don't hard-code in avatar dimensions when using SocialProfile avatars, that won't work the way you think it does and it'll just make the avatars look blurry
** Had to ditch some IE8 compatibility code to make this work. Oh well.
** Also swapped avatar size from large (75x75 pixels) to medium (30x30 pixels)
* Show both Echo notifications and alerts in the top bar

Also includes some random coding style tweaks.

This is all tested, though only on MW 1.35 (yes, I had to make two tiny hacks, not present here, to make the code run on 1.35) and only on the "desktop" view.

Change-Id: Ibe546d6193e4eeee6b20800fdb1fa759d31795b3

---
## [wikimedia/mediawiki-skins](https://github.com/wikimedia/mediawiki-skins)@[8d794e54d0...](https://github.com/wikimedia/mediawiki-skins/commit/8d794e54d012393ea3d23e9bce6f19e0f49338d0)
#### Wednesday 2021-04-07 15:34:53 by Jack Phoenix

Update git submodules

* Update Metrolook from branch 'master'
  to a787cabdb688492d8675ca4747abaff1fcabf0c2
  - A bunch of visual fixes
    
    * Better adjusting for the top navigation bar links + watch star
    ** TODO: I'm still not 100% happy with the links but this'll do for now.
    * Don't hard-code in avatar dimensions when using SocialProfile avatars, that won't work the way you think it does and it'll just make the avatars look blurry
    ** Had to ditch some IE8 compatibility code to make this work. Oh well.
    ** Also swapped avatar size from large (75x75 pixels) to medium (30x30 pixels)
    * Show both Echo notifications and alerts in the top bar
    
    Also includes some random coding style tweaks.
    
    This is all tested, though only on MW 1.35 (yes, I had to make two tiny hacks, not present here, to make the code run on 1.35) and only on the "desktop" view.
    
    Change-Id: Ibe546d6193e4eeee6b20800fdb1fa759d31795b3

---
## [cacko/yii2-widgets](https://github.com/cacko/yii2-widgets)@[ba5e9da241...](https://github.com/cacko/yii2-widgets/commit/ba5e9da241eaf59f5d4185e102e1228818a35d17)
#### Wednesday 2021-04-07 16:20:49 by Cac Ko

pock

I __ a word

Ugh. Bad rebase.

Abandon all hope, ye who enter here.

Wubbalubbadubdub!

My bad

I must have been drunk.

Add Sandbox

Ok, 5am, it works.  For real.

For the statistics only

added security.

TODO: Tell someone to implement this

You know the rules and so do I

de-misunderestimating

This was the most stupid bug in the world, fixed in the smartest way ever

Issue #7 is now Issue #1

Popping stash

touched...

Not sure why

woa!! this one was really HARD!

Gross hack because Gabe doesn't know how to code

lol digg

Commit committed....

I would rather be playing SC2.

Add Sandbox

I don't get paid enough for this shit.

more ignores

pay no attention to the man behind the curtain

bla

Some shit.

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[6f2cd46f11...](https://github.com/mrakgr/The-Spiral-Language/commit/6f2cd46f118102e3340c228b352582e81cf68338)
#### Wednesday 2021-04-07 17:46:00 by Marko GrdiniÄ‡

"2pm. Done with breakfast and chores. Let me just finish the chapter and then I will start. I am tired of reading about Fang Yuan stealing stuff an I am giving it a rest. It has been a while since I've read any of the Re library stuff so I'll do some catching up.

Rance Quest Magnum has finished downloading and I'll leave it for when the daily work is done. There is also the Pathfinder Kingmaker game that I've stopped. I'll resume it when I've gotten those agents going.

2:10pm. Ok, let me start.

Oh yeah, I meant to write this, but I studied the predictive coding papers yesterday and figured out what it is doing. It is pretty much backprop with some extra steps. There is not single advantage to using it in lieu of it. I thought of a method like this before, back when I was studying local updates, but disposed of it as being useless. I've gotten hyped over nothing.

My replay buffer ideas are what will have to do the job.

2:15pm. Now focus me. A part of me wants to run from this long battle, but what I need to do is keep cultivating until I break through to the next realm.

2:25pm. How complicated. How tedious. I wanted something more, but to think all I'd attain is mastery of first order logic. But all in all, it is not a bad ability to have. I'll have to push it as far as it will go.

I have no idea how things will turn in in the 20s. Human level AI is fated to happen, but it does feel like a stretch for there to be deep breakthroughs. Given how difficult ML is right now, just what am I hoping will make it easier in the future?

Nonetheless, you cannot use the present difficulties as the basis for speculation. Inevitably these will be overcome. Right now I am trudging through a swamp, but in the future I will get my wings. Somehow.

Though the hope of the Singularity feels far away, it is my responsibility to chase after it. The last 300 years of technological development have a been a miracle. Though I do not feel like being a part of society, I'll give my contribution to this great movement.

I need to keep working on it. I'll get some money along the way. That 100E was a nice surprise, at least now I can't say I've gotten no recognition at all.

But a lot more should come, this with my own hands.

2:35pm. The past shackles me, but I'll break those chains apart. When I have the trained neural agents, everything will change.

...I am not really sure how much I feel like raiding online gambling dens, but I'll give it a try. In the worst case, I can just pivot to selling trained agents commercially. That will give me steady income with none of the hassle of having to manage agents in real time...

Writing this is sacrielege.

I really should attack, attack and attack! I need to attack for the sake of training myself.

It is more than about money. It is about training. Without huge goals, without wanting to make millions, how can I justify this hardship?

So I have to keep going.

2:40pm. Let me take it easy from here though. Forget doing big things. For today, just focus on implementing a tabular CFR agent and then playing against it. That will tell me where I start.

Let me first determine the type of the dictionary.

```
type state key = dict.dict key {regret : a u64 f32; avg_policy : a u64 f32}
```

No need to make things anymore complicated.

3pm. Hmmm, I meant to do training, but how I get the play done first instead?

Let me think. I know well enough how I implemented it last time, but maybe I can reuse some of Numpy's functionality to make things smoother?

https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html

I can pass in a prob distribution to do action selection.

```fs
open System.Collections.Generic

/// Helpers
let inline array_mapFold2 f s a b =
    let mutable s = s
    let ar =
        Array.map2 (fun a b ->
            let x, s' = f s a b
            s <- s'
            x
            ) a b
    ar, s

let inline memoize (memo_dict: Dictionary<_,_>) f k =
    match memo_dict.TryGetValue k with
    | true, v -> v
    | false, _ -> let v = f k in memo_dict.Add(k,v); v

let regret_match array =
    let temp, normalizing_sum =
        Array.mapFold (fun s x ->
            let strategy = max x 0.0
            strategy, strategy + s
            ) 0.0 array

    let inline mutate_temp f = for i=0 to temp.Length-1 do temp.[i] <- f temp.[i]
    if normalizing_sum > 0.0 then mutate_temp (fun x -> x / normalizing_sum)
    else let value = 1.0 / float array.Length in mutate_temp (fun _ -> value)
    temp

let inline add sum f = for i=0 to Array.length sum-1 do sum.[i] <- sum.[i] + f i
```

The Ionide plugin does work great right now. It is hard to believe this works on a repo that is not even open. The GitLens plugin deserves praise as well. If this was VS I'd have to switch branches. Right now I am using the Browse feature of GitLens.

```fs
// Generic CFR implementation based on the `An Introduction to Counterfactual Regret Minimization` paper

#load "helpers.fsx"
open Helpers
open System.Collections.Generic

type Node =
    {
    strategy_sum: float []
    regret_sum: float []
    }

let node_create actions =
    let l = Array.length actions
    {strategy_sum=Array.zeroCreate l; regret_sum=Array.zeroCreate l}

let inline chance dice one_probability next =
    let prob = 1.0 / float (Array.length dice)
    prob * Array.fold (fun s dice -> s + next dice (one_probability * prob)) 0.0 dice

let inline response is_updateable infosets history actions one_probability two_probability next =
    let node = memoize infosets (fun _ -> node_create actions) history
    let action_distribution = regret_match node.regret_sum
    let util, util_weighted_sum =
        array_mapFold2 (fun s action action_probability ->
            let util =
                if action_probability = 0.0 && two_probability = 0.0 then 0.0 // the pruning optimization
                else next action (one_probability * action_probability)
            util, s + util * action_probability
            ) 0.0 actions action_distribution

    if is_updateable then
        add node.strategy_sum (fun i -> one_probability * action_distribution.[i])
        add node.regret_sum (fun i -> two_probability * (util.[i] - util_weighted_sum))

    -util_weighted_sum

let terminal x = x
```

Here is everything that I need from last time. It is not too hard.

```
np.random.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0])
```

Let me play around with this. Do the probabilities here have to be normalized.

```
import numpy as np
print(np.random.choice(2,p=[0.1,2.9]))
```

This gives me an error that the probs do not sum to 1. Ok.

3:20pm. Right now I am thinking about something. If a player is playing against another would it be better to do what I did last time and use the current policy for the oppontent, or should I pretend things to be serious and use the average policy?

Another things I should test out. Nevermind these considerations for now.

3:25pm. I am getting into it. Let me get the easy stuff out of the way. I'll implement normalization for the average policy and regret matching for the regret sums. I should focus on that first and get them out of the way.

```
inl regret_match regret =
    inl temp, normalizing_sum = am.mapFold (fun s x => inl x = max x 0 in x, x + s) 0 regret
    if normalizing_sum = 0 then
        inl v = 1 / f64 (length temp)
        loop.for' (from:0 nearTo: length temp) (fun i => set temp i v)
    ()
```

Hmmmm...

```
// Can also be used for normalizing the avg policy.
let regret_match regret =
    inl temp, normalizing_sum = am.mapFold (fun s x => inl x = max 0 x in x, x + s) 0 regret
    inl mut f = loop.for' (from:0 nearTo: length temp) (fun i => set temp i (f i))
    if normalizing_sum = 0 then inl v = 1 / f64 (length temp) in mut (fun _ => v)
    else mut (fun i => index temp i / normalizing_sum)
    temp
```

I'll use this for normalizing the average policy as well.

```
inl get_node (d : state _) = dict.memoize d fun _,actions =>
    inl Empty = am.init (length actions) (fun _ => 0)
    {regret = Empty; avg_policy = Empty}
```

This part is giving me trouble. Last time I did not use actions as a part of the key, and it should not be necessary as actions for each key should be unique, but I am thinking if maybe I was wrong...

```
        inl p = (value d (length actions) player.observations).avg_policy |> regret_match
        inl a = sampling.sampleP actions p
        next ((to_log_prob (1 / f64 (length actions)),a),state player)
```

Ah, no wait. This is wrong. I need the index because I need the probability in addition to the action.

```
type state key = dict.dict key {regret : a u64 f64; avg_policy : a u64 f64}
inl value (d : state _) num_actions = dict.memoize d fun _ =>
    inl Empty = am.init num_actions (fun _ => 0)
    {regret = Empty; avg_policy = Empty}

open nodes
inl funs_play (d : state _) = player_funs {
    action = fun {player actions next} =>
        inl num_actions = length actions
        inl p = regret_match (value d num_actions player.observations).avg_policy
        inl i = $"np.random.choice(!num_actions,p=!p)"
        inl p,a = index p i, index actions i
        next ((to_log_prob p,a),state player)
    terminal = fun _ => ()
    }
```

This is good.

TODO: Separate the action from chance probabilities.

I completely forgot about this. Whops.

I need to redo everything. Let me do it. Thankfully the top down typing makes this kind of thing a lot more comfortable.

I should have done this first, but I forgot about it.

4:15pm. I've gotten into it. Let me continue programming.

```
inl apply_observation (player x) o = player {x with observations#=(::) (Observation: o)}
inl apply_changes (player x) ((prob,a),state) = player {x with state observations#=(::) (Action: a); probSelf#=add_log_prob prob}

inl sample_players_update pid (prob,x) (chance_prob,p1,p2) =
    add_log_prob prob chance_prob,
    match pid with
    | Some: pid =>
        let update pid' p = if pid = pid' then apply_observation p x else p
        update 0 p1, update 1 p2
    | None =>
        inl update p = apply_observation p x
        update p1, update p2
```

Let me do it like this.

For the time being, let me try running the old things again. The redesign eas easy as I expected.

4:35pm. Yeah, it works. I can get back to doing CFR.

4:40pm. Let me think. I have the play function done. Let me do the enumerative play one as well.

5pm.

```
// The default should have the `is_avg_policy: false`. The paper uses the current one.
inl funsPlayEnum ~(is_avg_policy:) (d : state _) = player_funs {
    action = fun {player actions next} =>
        inl num_actions = length actions
        inl actions_prob = actions_prob d num_actions player (is_avg_policy:)
        inl reward =
            inl state = state player
            am.fold2 (fun s prob a =>
                s + prob * next ((to_log_prob prob,a),state)
                ) 0 actions_prob actions
        reward
    terminal = fun _ => ()
    }
```

Actually, I should tie this into an update.

5:05pm. Lunch time. Let me stop here for a bit.

5:35pm. Done with lunch. Let me resume.

```
    let util, util_weighted_sum =
        array_mapFold2 (fun s action action_probability ->
            let util =
                if action_probability = 0.0 && two_probability = 0.0 then 0.0 // the pruning optimization
                else next action (one_probability * action_probability)
            util, s + util * action_probability
            ) 0.0 actions action_distribution

    if is_updateable then
        add node.strategy_sum (fun i -> one_probability * action_distribution.[i])
        add node.regret_sum (fun i -> two_probability * (util.[i] - util_weighted_sum))
```

Yeah, let me just jam it in here.

```
            am.mapfold2 (fun s prob a =>
                inl util =
                    if prob = 0 && exp_log_prob player' = 0 then 0 // the pruning optimization
                    else next ((to_log_prob prob,a),state)
                util, s + prob * next ((to_log_prob prob,a),state)
                ) 0 actions_prob actions
```

Let me implement `mapFold2`.

```
inl mapFold2 f s a b =
    if length a <> length b then failwith "The two arrays have to have the same size."
    initFold (length a) (fun s i => f s (index a i) (index b i)) s
```

Oh, it is implemented. Did I forget to add it to the other file?

```
// Folds over the two arrays while producing the residual array resulting from that operation.
inl mapFold2 forall (ar : * -> * -> *) {create; set; index; length} dim {number} el s. : _ -> _ -> ar dim _ -> ar dim _ -> ar dim el * s = mapFold2
```

No, I did not.

I just forgot a capital letter.

```
q = np.array([1,2,3])
t = q
w = np.array([3,4,5])
t += w
print(t)
```

This does an inplace update.

```
inl mut f = loop.for' (from:0 nearTo: length temp) (fun i => set temp i (f i))
```

You know what, this should be in the standard library.

6:25pm.

```
// `is_avg_policy` determines whether to use the average or the current policy.
// The default should have the `is_avg_policy: false`. The paper uses the current one.
// `is_update` determines whether the updates should be done. This should be true during training and false otherwise.
inl funsEnum ~(is_avg_policy:is_update:) (d : state _) = player_funs {
    action = fun {chance_prob player player' actions next} =>
        inl num_actions = length actions
        inl op_prob = exp_log_prob (add_log_prob chance_prob player')
        inl self_prob = exp_log_prob (add_log_prob chance_prob player.prob)
        inl d = value d num_actions player.observations
        inl actions_prob = regret_match (if is_avg_policy then d.avg_policy else d.regret)
        inl reward,reward_wsum =
            inl state = state player
            am.mapFold2 (fun s prob a =>
                inl util =
                    if prob = 0 && op_prob = 0 then 0 // the pruning optimization
                    else next ((to_log_prob prob,a),state)
                util, s + prob * util
                ) 0 actions_prob actions
        if is_update then
            d.regret |> am.mapInplace (fun i x => x + op_prob * (index reward i - reward_wsum))
            d.avg_policy |> am.mapInplace (fun i x => x + self_prob * index actions_prob i)
        reward_wsum
    terminal = fun _ => ()
    }
```

This should do nicely.

Now what is next?

6:40pm. Inlining. I think that train function is too large to be inlined in every action node. Yeah, it is just too much.

```
action = fun ~{chance_prob player player' actions next} => join
```

This might end up doing too much dyning.

Well, it will do for now. Let's not worry about it.

6:55pm. I am just doing a bit of reviewing before I stop for the day. Today I really went at a snail's pace.

```
inl sample_players_update pid (prob,x) (chance_prob,p1,p2) =
    add_log_prob prob chance_prob,
    match pid with
    | Some: pid =>
        let update pid' p = if pid = pid' then apply_observation p x else p
        update 0 p1, update 1 p2
    | None =>
        inl update p = apply_observation p x
        update p1, update p2
```

Out of all the things I did, this is the part I am most pleased about. Previously, I was not even updating the chance probability for the other player in the some case. That was a mistake cause by my lack of understanding.

This way of doing it is definitely right.

7pm. I am thinking. Right now tabular CFR is implemented. No problem at all. The next thing on the agenda should be to take it for a spin.

I am going to make a little UI with a chart next. I want to see how the player optimizes. Against the random player. Against the neural random. And against itself in an alternating fashion.

```
action = dyn fun {chance_prob player player' actions next} =>
```

Actually, let me just dyn these. I'll try dyning the enum players. Let me see try it and see how it affects compilation.

```
inl funs_buffer net add_buffer =
    player_funs {
        action = dyn fun ({game_state player player' actions next} & x) =>
            inl actions_prob = torch.runMasked' net (process (observations player)) actions
```

Doing this in the neural player squeezes the size down by 300 lines. This is a good tradeoff.

7:20pm. Ok, enough, enough.

Let me stop here. A bit of inlining here and there does not matter.

Tomorrow I am going to focus on putting this into action. It feels like I am being very careful and thinking every move through a lot longer than I should.

I just feel blocked and am trying to work through it. It feels like I am climbing a mountain. What I am doing here is not a minor thing by any means.

Tomorrow or the day after I am going to have my first expert player in Leduc poker and will be able to play against it.

I should dream about this next step and strive to reach it. Once I get this out of the way to my satisfaction, I'll do a sampling one. Then the great challenge will be here, getting the neural player to work!

If I can do this, then afterwards reaching the win state will just be a matter of scaling the games.

7:30pm. The DREAM paper was not solid, but I know why that is. I am going to make use of my replay buffer tricks to make things work smoothly. I know how to train the value net properly. Just like for the policy net, I'll scale the replay buffer probabilities by the inverse of the current play probability. That will speed things up significantly.

7:35pm. About the average policy net, I am not sure whether I want to keep around old policy nets and sample them or if I want to train them separately. I'll have to see how that goes.

Ok...at this point I know quite a bit. One thing I am not sure is how to play the games in parallel.

7:40pm. I have some ideas. Having the game in CPS'd form will be absolutely essential for this. Thankfully I have it. If I can cross this challenge, I will be able to make full use of the GPU without being burdened by sequential nature of the poker game.

This was a huge issue back in 2018 when I could only do online learning. I was at a huge disadvantage. But now I have Spiral and expertise in functional programming. I pity anybody trying to do what I will in Python. Python is the worst language there is for doing CPS programming.

Let me finally have fun here.

Just what I am acting at by putting overtime at this stage? If I really feel like working I should get up earlier instead."

---
## [kacperleague9/BlueMapVue](https://github.com/kacperleague9/BlueMapVue)@[1b66b1876f...](https://github.com/kacperleague9/BlueMapVue/commit/1b66b1876f102f2c6d2e168214e2b181239e92ab)
#### Wednesday 2021-04-07 17:47:34 by Kacper SmoliÅ„ski

:flag_pl:


We got a number one victory royale
Yeah, Fortnite, we 'bout to get down (Get down)
Ten kills on the board right now
Just wiped out Tomato Town
My friend just got downed
I revived him, now we're heading south-bound
Now we're in the Pleasant Park streets
Look at the map, go to the marked sheet


Take me to your Xbox to play Fortnite today
You can take me to Moisty Mire, but not Loot Lake
I really love to chug jug with you
We can be pro Fortnite gamers

---
## [gbfree/tgstation-master](https://github.com/gbfree/tgstation-master)@[0595698c81...](https://github.com/gbfree/tgstation-master/commit/0595698c8171c22a9e30907c489449d328eebdcc)
#### Wednesday 2021-04-07 19:02:47 by gbfree

Insanity : Rebalance le mood
- Retrait malus de mood des brain damage
- +1 mood de base
- Rebalance certaines drogues
- Rebalance quirk reduisant le moral
- Rebalance trauma du creeper

---
## [cockroachdb/cockroach](https://github.com/cockroachdb/cockroach)@[d68081cce8...](https://github.com/cockroachdb/cockroach/commit/d68081cce8847f555bfadda204fed5f9e7a848ee)
#### Wednesday 2021-04-07 20:02:20 by craig[bot]

Merge #63027 #63073 #63152 #63165 #63247

63027: issues: brush up & make issues fun to improve r=otan a=tbg

TL;DR I rewrote much of the issue posting. It should look roughly the same and still works: https://gist.github.com/tbg/aba4ce21fccbb566df1b9e8bd338c9cc

but the internals are a lot better and we can finally move away from
assigning random individuals and can move towards assigning to
project boards throughout - this isn't fully done here but the
direction is clear. Over the breather week I want to complete
this thread of work, and maybe look into making a specialized
formatter for `roachtest` issues to cut down on the triage toil.

## issues: clean up and allow easier customization

The issue posters currently force every user into the use of text
templates. I originally introduced them, but now find them more
cumbersome than useful in the context of issue posting - there is
no type safety, and the manipulation we're doing to create issue
bodies is too complex; templates make it harder, rather than easier.

In particular, it's really off-putting to think about decoupling our
unit test and roachtest issue templates. They are shoehorned into one,
and they would greatly benefit from being managed separately.

This commit instead hands the caller an `io.Writer` (for the issue
body) and a struct with information from which to generate markdown.
To keep things contained, we're still using the same text templates
to render into the writer, but now it's easy to change that.

The commit also massively cleans up the issue poster in general.

First, environment variables and dependencies on the local git checkout
are now cleanly encapsulated in the newly introduced `Options`, so it's
much easier to know where we're pulling from the environment + the
testing has gotten clearer as well.

Second, the issue poster now posts the issue no matter what. True to Go
style, we were previously throwing the towel on many errors that
shouldn't have stopped the issue from appearing.

Third, the groundwork has been laid to enable our TLs to react to
wonky/stale configuration from the issues that are created. For example,
the assignment of ex-roachers -> current roachers, a failure to find
project columns, etc, can in principle become part of the created
issues and can thus gently alert the readers that they may want to
update the respective mappings.

Fourth, the issue poster stops falling back to me. In the cases in
which it did (and many others in which it bailed completely), it
will now create an unassigned issue.

NB: the diff in the testdata occurs because we were previously
pulling the tag and milestone even when we were not *creating*
a new issue. Now it's only done when we actually need them.


## issues: use Renderers instead of text templates

This translates the previously used text templates into code that
uses the Renderer. While I was doing the translation, I also
rearranged sections to improve ergonomics. For example, the
artifacts are now printed at the top - which is where you
want them, as it's usually the first click (at least on a
roachtest). There are still ways to mess up the rendering (did you know
that a link won't be recognized as such if it's after on a new line
directly following a closing HTML tag? I did not...) but the
Renderer approach feels orders of magnitudes more ergonomical
already.

## roachtest: don't auto-assign individuals, but mention teams

This leverages the ownership encoding we already have in roachtest
to make better use of Github notifications. We already had the ability
to assign to project columns, but it's also helpful to ping *someone*.
Now we can explicitly specify who to ping. I populated this with the
Github teams, but teams are welcome to change this to their liking
(including opting out by using the empty string).

Release note: None

63073: roachtest: retire `bank` tests r=nvanbenschoten,andreimatei a=tbg

The `bank` roachtests are a basic form of Jepsen test. We were hoping
that they could provide additional benefit due to being less complex
than a full Jepsen test. In my opinion, this calculus has not worked
out. We've spent many hours staring at this test deadlocked when it
wasn't CockroachDB's fault at all. Besides, it's not adding anything
meaningful on top of our Jepsen tests plus KVNemesis plus the TPCC
invariant checks, so we are removing the `bank` family of tests here.

Should we want to reintroduce these tests, we should do it at the level
of TestCluster, or at least augment the `bank` workload to incorporate
these invariant checks instead.

Closes #62754.
Closes #62749
Closes #53871.

Release note: None


63152: opt: keep track of CTE-to-CTE references r=RaduBerinde a=RaduBerinde

#### opt: keep track of CTE-to-CTE references

This change adds a data structure that keeps track of CTE-to-CTE
references and reworks the way in which we build CTEs. We use a
depth-first search to make sure With operators are built in a legal
order. This will allow building correlated CTEs where they show up,
while still allowing other CTEs to be hoisted up (as long as they
don't reference the correlated CTE).

We have avoided keeping track of references thus far by always
building the CTEs in the same order as in the query. Even without
correlated CTEs, this was still problematic for recursive CTEs - any
new CTEs inside the recursive expression could have a recursive
reference; for that reason, we use a CTE boundary to force building
all CTEs inside the recursive expression - but this is not the
intended use of a boundary and it is not correct for the `[...]`
operator and SQLClass functions (which must be hoisted to the
top-level). This commit fixes this issue.

Note that a very different high level solution would have been to use
normalization rules to hoist With operators. That solution seems a lot
more complicated though (and a similar reference map would have had to
be built there anyway). We may revisit this later if it turns out that
we have to add a lot of normalization rules to hoist correlated CTEs
anyway.

Release note: None

#### opt: further cleanup of CTE boundary

This commit consolidates the CTE boundary logic into `buildStmtAtRoot`.

Release note: None

Informs #42540.

63165: sql: show full table scans query r=yuzefovich a=barryhe2000

Show full table scans query shows queries that used a full table scan
within the past hour or two.

Fixes: #41340

Release note (sql change): SHOW FULL TABLE SCANS query added

63247: rsg_test: remove panic and fmt.Print r=otan a=rafiss

Instead, use a handle-able error and t.Log. This should help with an
issue where the test fails but leaves behind no useful logs.

Release note: None

Co-authored-by: Tobias Schottdorf <tobias.schottdorf@gmail.com>
Co-authored-by: Radu Berinde <radu@cockroachlabs.com>
Co-authored-by: Barry He <barryh@cockroachlabs.com>
Co-authored-by: Rafi Shamim <rafi@cockroachlabs.com>

---
## [HugoLeeOboe/tss-tools](https://github.com/HugoLeeOboe/tss-tools)@[326aba9ab2...](https://github.com/HugoLeeOboe/tss-tools/commit/326aba9ab2f7d903822e38b76ecc5698d6fa430d)
#### Wednesday 2021-04-07 21:59:45 by Hugo Lee

PREPARE FOR TROUBLE - AND MAKE IT DOUBLE
TO PROTECT THE WORLD FROM DEVASTATION
TO UNITE ALL PEOPLES WITHIN OUR NATION
TO DENOUNCE THE EVILS OF TRUTH AND LOVE
TO EXTEND OUR REACH TO THE STARS ABOVE
JESSIE
JAMES
TEAM ROCKET BLASTS OFF AT THE SPEED OF LIGHT
SURRENDER NOW, OR PREPARE TO FIGHT

MEOWTH, THAT'S RIGHT!

...

WAAAAAAAHHBUFFET

---
## [MarlonSchultz/aws_amplify_playground](https://github.com/MarlonSchultz/aws_amplify_playground)@[0fe07bae37...](https://github.com/MarlonSchultz/aws_amplify_playground/commit/0fe07bae379747ce51a4c6b6a86cb3729aceaf25)
#### Wednesday 2021-04-07 23:10:31 by Marlon

got primevue up and running. i just so fcuking hate css. like ten years ago - how the fuck do you center shit

---
## [WolfInABarrel/IamUtopia](https://github.com/WolfInABarrel/IamUtopia)@[5bae57a6c1...](https://github.com/WolfInABarrel/IamUtopia/commit/5bae57a6c155858a4d00abe62e915279059a9e76)
#### Wednesday 2021-04-07 23:12:42 by Jarle Syvertsen

More people, more shit, more stuff, lovely.

Cleaning up the house now.

---

# [<](2021-04-06.md) 2021-04-07 [>](2021-04-08.md)

