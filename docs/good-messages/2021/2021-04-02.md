# [<](2021-04-01.md) 2021-04-02 [>](2021-04-03.md)

2,612,160 events, 1,357,414 push events, 2,052,064 commit messages, 152,720,084 characters


## [TTSWarhammer40k/Battleforged-Workshop-Mod-Compilation@e4b69cb9d9...](https://github.com/TTSWarhammer40k/Battleforged-Workshop-Mod-Compilation/commit/e4b69cb9d91e77873d78ccb71234acd011b48b57)
##### 2021-04-02 04:00:34 by Mothman-Zack

4/2//21 Massive Moth AoS Update

AGE OF SIGMAR

MODELS: ORDER

Lumineth Realm-lords
- Vanari Bannerblade
- Scinari Calligrave
- Hurakan Spirit of the Wind
- Sevireth, Lord of the Seventh Wind
- Hurakan Windchargers
- Hurakan Windmage
- Vanari Starshard Ballista
- Scinari Loreseeker
- Lyrior Uthralle, Warden of Ymetrica
- Vanari Bladelords
- Ellania and Ellathor, Eclipsian Warsages
- Vanari Lord Regent
- Myari Lightcaller
- Myari's Purifiers (3x models)
- Shrine Luminor

Seraphon
- Substantial update with new units, improved models and additional weapon option loadouts.

Kharadron Overlords
- Improved Arkanaut Frigate
- Improved Arkanaut Ironclad

Daughters of Khaine
- Updated All Warscrolls
- Improved Morathi-Khaine
- Improved Shadow Queen
- Slaughter Queen
- Slaughter Queen on Cauldron of Blood
- Hag Queen
- Hag Queen on Cauldron of Blood
- Avatar of Khaine
- Bloodwrack Shrine
- 2x Witch Aelf w/ Paired Sacrificial Knives
- Witch Aelf Standard Bearer
- Sister of Slaughter
- Sister of Slaughter Handmaiden
- Sister of Slaughter Banner Bearer
- Doomfire Master of Warlocks
- Doomfire Warlock
- Khinerai Lifetaker Harridynn
- 2x Khinerai Lifetaker
- Khinerai Heartrenders Shryke
- 2x Khinerai Heartrenders
- Melusai Blood Stalker Krone
- 2x Melusai Blood Stalker
- Melusai Blood Sister Gorgai
- Melusai Blood Sister
- Khainite Shadowstalker - Shroud Queen
- Khainite Shadowstalker - Shroudblade w/ Cursed Sword
- Morgwaeth's Blade-coven - Morgwaeth The Bloodied
- Morgwaeth's Blade-coven - Kyrae
- Morgwaeth's Blade-coven - Khamyss
- Morgwaeth's Blade-coven - Kyrssa (- Proxy)
- Morgwaeth's Blade-coven - Lethyr
- Endless Spell - Heart of Fury
- Endless Spell - Bloodwrack Viper
- Endless Spell - Bladewind

MODELS: CHAOS

Maggotkin of Nurgle
- Exalted Greater Daemon of Nurgle
- Great Unclean One w/ Doomsday Bell
- Orghotts Daemonspew
- Morbidex Twiceborn
- Bloab Rotspawned
- Harbinger Of Decay
- Putrid Blightking
- Putrid Blightking w/ Sonorous Tocsin
- Lord Of Plagues
- Gutrot Spume
- Lord of Blights
- Rotbringers Sorcerer
- Festus the Leechlord
- Pusgoyle Blightlord
- Pusgoyle Blightlord w/ Dolorous Tocsin
- Plaguebearer - Plagueridden
- Plaguebearer - Piper
- Plaguebearer

Blades of Khorne
- Bloodthirster of Unfettered Fury
- Bloodreaver Icon Bearer
- Bloodreaver w/ Meatripper Axe
- Skullreaper
- Skullreaper Icon Bearer
- Blood Warrior w/ Goreglaive
- Blood Warrior Chaos Champion
- Skarr Bloodwrath
- Improved Valkia The Bloody
- Wrathmonger
- Exalted Deathbringer w/ Impaling Spear
- Exalted Deathbringer w/ Bloodbite Axe
- Bloodstoker
- Aspiring Deathbringer w/ Bloodaxe + Wrath-hammer

Beasts of Chaos
- Ghorgon
- Cygor
- Dragon Ogor w/ Paired Ancient Weapons
- Doombull
- Doomblast Dirgehorn
- All models updated with proper labels

MODELS: DEATH

Nighthaunt
- Tomb Banshee

Legions of Nagash
- Tomb Banshee
- Coven Throne
- Bloodseeker Palanquin
- Mourngul

---
## [Koi-3088/ForkBot.NET@2a0cc31c85...](https://github.com/Koi-3088/ForkBot.NET/commit/2a0cc31c853c6cb3faddf2ed5ffa44f3018d6608)
##### 2021-04-02 06:38:25 by Koi-3088

Minor clean.
Revise TradeCord "traded" check, remove potential user path straggler entries because paranoia, some minor fixes.
TradeCord fixes (shocker, I know).
Extract Json serializer.
Minor clean and fixes.
Minor fixes.
Fix Milcery when an Alcremie variant is a parent.
Update to latest Core and ALM dependencies.
Handle non-shiny events in a better way.
Work around a race condition?
Simplify and de-bugify trade completion check.
Fix indexing, improve chance for Melmetal-Gmax because it's nigh impossible to get.
Rework TradeCord internals, add new functionality:
-Migrate user data from ".txt" files to a serialized Json (migration for a large amount of users will take a few minutes, be patient).
-Make TradeCord configurable, add its own settings category.
-Add some template events with an optional end timer (YYYY/MM/DD 8PM as an example, though any local time format should work).
-Add barebones Pokedex (counter, flavor text).
-Can check dex completion by typing `$dex`, check missing entries by typing `$dex missing`.
-Completing the Pokedex will slightly improve shiny rate.
-Can now mass release cherish event Pokemon and shinies ($massrelease shiny/cherish).
-Various tweaks, improvements, and bugfixes.

Slightly change FixOT's behavior:
-If a shown Pokemon is illegal and an event, attempt to find a match within the MGDB first.
-Try to force users to trade away the shown Pokemon, log attempt to change shown Pokemon.
Add consideration for easter eggs being enabled in settings, fix Suicune
Change species rng for TradeCord, some bugfixes (I really need to rewrite this mess)
Add check if we're using ListUtil for Giveaway instead of TradeCord.
Amend commit since I'm squashing and force-pushing while bringing the fork in line with the main branch
Add Giveaway module to Discord bot (#22)

Thanks, rigrassm.
Co-authored-by: Koi-3088 <61223145+Koi-3088@users.noreply.github.com>
Specify USB port instead of adding the first result (can be found via Device Manager).
Re-add boolean check because we don't want to fix everything
FixOT will attempt to regenerate illegal Pokémon.
Apply trash bytes for reasons.
Minor TradeCord fixes and adjustments.
Minor clean for C#9
Use "GetValidPreEvolutions()" instead of "GetPreEvolutions()".
Index forms correctly.
Fix the fixed and re-introduced empty daycare index error.
*an* Ultra Ball.
Add EvoTree breeding for TradeCord.
Remove unnecessary value declarations for pinging on encounter match.
Mildly beautify EncounterBot mark output.
Integrate Anubis' system update prevention into Soft Reset and Regigigas Encounter Modes.
Rename "Regi" Encounter Mode to "Soft Reset".
Speed up "A" clicks for Regigigas and Soft Reset modes.
Add Mark logging output for EncounterBot.
Fix oops (re-order logic, remove unnecessary lines).
Add optional species and form specification for $massrelease
Use an obscure string splitter because people like symbols in their names.
Fix things that broke after rebasing to the latest main repo commit.
Use a less unfortunate field name and value splitter...again.
Fix Marowak-Alola always generating as an NPC trade.
Add filters for "$list <species>" to narrow down results.
Fix Cherish Pichu and Octillery
Stop making dumb mistakes, me (implying the rest of it isn't a dumb mistake).
Can't breed antiques.
Use a less unfortunate embed name and value splitter
Add Melmetal-Gmax to TradeCord.
Add ability to search by caught ball.
Have MassRelease ignore events.
Add specific regional form breeding.
Revise egg rate and egg shiny chance.
Have trade evolutions hold an Everstone.
Add an extra right click when navigating to settings for AutoRoll.
Add reworked encounter/egg/fossil logs.
Minor clean.
Minor clean.
Get rid of EncounterBot, FossilBot, EggFetch text logs until I properly rework them.
Break on an empty page due to aggressive rounding
Add multi-page lists for Tradecord.
More random bugfixes.
Fix some bugs before major clean
Add Language parameter for TradeCord.
Change trainer info input format for TradeCord.
Move focus on Showdown set instead of randomizing a pkm file.
Allow user to enter whatever they want for $list, handle edge cases like Kommo-o
Add "$list all" to show non-duplicate caught species.
Automatically remove from favorites if trading or gifting (small QOL thing).
Change how favorites are removed from user file.
Revert base egg shiny chance nerf.
Fix daycare
Add favorites command to TradeCord.
Slightly nerf eggs.
Fix TradeCord list for shinies
Add TradeCord (my dumbest and messiest project so far, Archit pls don't hate the mess).
Add Showdown output for Star/Square shinies and OTGender.
Add optional link code input for FixOT.
Change how OTName, TID, SID is displayed.
Add Regigigas SR bot.
Add SoJ Camp SR bot.
Ribbons now work with EggTrade (remove ribbons if egg).
Remove EggRoll.
Add another filter for FixOT
Fix.. FixOT
Update offsets for EncounterBot catching.
Slightly change StrongSpawn to work with Regi SR and make it its own mode.
Make SpinTrade only available for USB-Botbase
Update valid eggs for CT
winforms: resize icon.ico to fix crash at startup on unix using mono
Rework Spin, read initial in-game coordinates in order to correct drift
Add TID, SID, Language output for Showdown
Remove obsolete OT and Language parsing
Very minor clean until I have time for a proper one.
Detach controller when stopping USB bot.
Actually set LastUsedBall for EncounterBot (missed when bringing in line with main repo)
Move extra RaidBot timings following the official commit
Remove PKHeX Discord invite from Readme.md

Maybe fewer people will pester devs now about my unofficial fork?
Update for latest main repo EncounterBot commits.
Update README.md
Add back best commit: Red's SpinTrade.
Add egg trades, foreign Dittos and OT for Twitch.
If ItemMule is enabled, also display the item a user is receiving.
Add periodic time sync toggle for all methods of hosting (except for non-soft locked AutoRoll) to (hopefully) prevent den rollover during extended hosts.

Add routine to exit a lobby for SoftLock if no players are ready in time (to preserve soft lock).

Add a routine to recover from disbanded lobbies (when someone disconnects unexpectedly) for SoftLock.

Add a routine to restart game if all else fails and we're stuck in a raid.

Add a routine for adding and deleting friends if we're soft locked and raids go empty.

Slightly reorganize settings, extract methods, minor clean.
Don't use such a generic file name for stream assets.
Check USB port index for running bots. Should fix adding additional USB bots when no config is saved.
Add fixed met date for FixOT.
How do I boolean
Change airplane mode logic, tweak timings and routine for soft lock lobby exit
Rework EggRoll cooldown (static list in favor of a txt file).
Start clean up and refactor
Add setting to increase delay after pressing "Home" after a date skip.
Use USB port index for blocking and sprite pngs if connection type is USB
Add option for airplane host (usb-botbase required)
Add option to softlock on selected species for AutoRoll
Add automatic compatibility for all console languages when date skipping (have to set ConsoleLanguage under ScreenDetection)
Attempt to fix multiple USB device add and connect...again
Minor clean
Fix oops?
Handle add/remove of bots
Distinguish between multiple USB devices, tweak BotRemoteControl for USB, other various fixes
Add SpA modifier for foreign Dittos
Add alpha USB-Botbase support
Fix DateTime parsing for European format for EggRoll
Set fixed EggMetDate and MetDate for EggRoll
More FixOT filters
Remove Beheeyem. Oops.
Split EggRoll into its own routine and trade type, only output "Receiving: Mysterious Egg" if routine is EggRoll, other minor tweaks and fixes
Make FixOT its own queue with roles and counts
Add a couple more OTs to $fix
Parsing for EggRaffle auto-clear and $clearcooldown
Adjust timings and split Watt collecting clicks for AutoRoll
Fix oops with file attachments for Ditto
Further improvements for OT, memes for invalid pokemon (disable EasterEggs)
Add spaces, digits for OT
Randomize memes, cut down bloat
Fix miscellaneous bots after Anubis' recent QOL additions
-Ignore events for OT because headache.
-Add overlooked "$convert <generation>" input for OT.
-Move $clearcooldown to SudoModule
-Clear timer automatically if NoTrainerFound
-More reliable Dittos
-Foreign Dittos for $convert
-Command to clear cooldown for EggRaffle in case trade gets disconnected
-Fix "Trade finished" line to keep result secret
-EggRaffle as a toggle, option to specify channels
-Seed Check output to both DMs and Channel (apparently some want it)
-Randomly generated egg raffle via a "$roll" command with a configurable cooldown
-FixAdOT reworked, has its own command "$fix" and no longer overrides $clone
-Ball: <value> output for Showdown sets
-Fix oversight
-Option to output Seed Check results to Discord channel with a User mention
-Showdown set output for OT name and eggs
-Basic "OT: <name>" option without Showdown set output
-Initial $convert support for EggTrade
-Egg moves for EggTrade test attempt
-Minor update
-EggTrade (by nicknaming a Pokémon "Egg" using $trade)
-Failsafe for memes if enabled but field left blank or incomplete
-Niche breedable Ditto trade mode.
Add minimize button
EggFetch text logs
StrongSpawn mode for EncounterBot
Re-add EncounterBot Master Ball catching
More parsing for FixAdOTs
Park Ball as held item instead of string
Actually remove the offset instead of saying I did
Initial DLC commit
Faster code entry
Removed catching for EncounterBot (need a new offset)
CloneBot mode to fix Nickname and OT if adverts detected

---
## [Galentina/CodeWars@9bbb638eeb...](https://github.com/Galentina/CodeWars/commit/9bbb638eeb4dbeff4564547ecf7ee1d0c1880279)
##### 2021-04-02 10:29:42 by Galina Malareva

Create  Blood-Alcohol Content

Bob drinks too much, and he gets in trouble for it a lot. He drinks so much, in fact, that he has broken the local law enforcement's breathalizer with his alcoholic breath! Bob feels simply aweful, so he wants to make up for it by creating a function that will calculate his blood-alcohol level for them. Unfortunately, Bob has gotten too inebriated to do any programming today, so he needs your help!
He did manage to research the formula for blood-alcohol content before getting too drunk, which he describes below.
BAC calculator Formula:
BAC% = (A × 5.14 / W × r) - .015 × H 

A: Total alcohol consumed, in ounces (oz)
W: Body weight, in pounds (lbs)
r: The alcohol distribution ratio, 0.73 for man, and 0.66 for women
H: Time passed since drinking, in hours
Source:
http://www.endmemo.com/medical/bac.php
Alcohol consumed will be passed as a drinks object with two properties: ounces (the total volume of beverage consumed in ounces), and abv (the % of alcohol by volume of the beverage as a floating point number--such as 0.05 for 5% abv beer or 0.4 for 40% abv whisky). For simplicity, Bob assures us that he drinks the same kind of beverage each time he drinks.
The gender will be passed as a string, either "male" or "female".
Output must be returned as a number data-type, greater than or equal to 0, with up to 4 decimal places. No error handling will be required.
Using these parameters, create the function that will calculate Bob's and other partier's BAC.

---
## [BroodLord/TeamProject@dae1606106...](https://github.com/BroodLord/TeamProject/commit/dae16061069e023a8172373e846003218db00355)
##### 2021-04-02 13:25:16 by Dereyabi

yo danny stop changing the god damned version of unity

love you really bby i also added a return to the axe script

---
## [Noob-214/Logan_Ysl@cd9021e25a...](https://github.com/Noob-214/Logan_Ysl/commit/cd9021e25a0c8d4c8a9532cbb3a35d825830def7)
##### 2021-04-02 16:33:42 by George Spelvin

lib/sort: make swap functions more generic

Patch series "lib/sort & lib/list_sort: faster and smaller", v2.

Because CONFIG_RETPOLINE has made indirect calls much more expensive, I
thought I'd try to reduce the number made by the library sort functions.

The first three patches apply to lib/sort.c.

Patch #1 is a simple optimization.  The built-in swap has special cases
for aligned 4- and 8-byte objects.  But those are almost never used;
most calls to sort() work on larger structures, which fall back to the
byte-at-a-time loop.  This generalizes them to aligned *multiples* of 4
and 8 bytes.  (If nothing else, it saves an awful lot of energy by not
thrashing the store buffers as much.)

Patch #2 grabs a juicy piece of low-hanging fruit.  I agree that nice
simple solid heapsort is preferable to more complex algorithms (sorry,
Andrey), but it's possible to implement heapsort with far fewer
comparisons (50% asymptotically, 25-40% reduction for realistic sizes)
than the way it's been done up to now.  And with some care, the code
ends up smaller, as well.  This is the "big win" patch.

Patch #3 adds the same sort of indirect call bypass that has been added
to the net code of late.  The great majority of the callers use the
builtin swap functions, so replace the indirect call to sort_func with a
(highly preditable) series of if() statements.  Rather surprisingly,
this decreased code size, as the swap functions were inlined and their
prologue & epilogue code eliminated.

lib/list_sort.c is a bit trickier, as merge sort is already close to
optimal, and we don't want to introduce triumphs of theory over
practicality like the Ford-Johnson merge-insertion sort.

Patch #4, without changing the algorithm, chops 32% off the code size
and removes the part[MAX_LIST_LENGTH+1] pointer array (and the
corresponding upper limit on efficiently sortable input size).

Patch #5 improves the algorithm.  The previous code is already optimal
for power-of-two (or slightly smaller) size inputs, but when the input
size is just over a power of 2, there's a very unbalanced final merge.

There are, in the literature, several algorithms which solve this, but
they all depend on the "breadth-first" merge order which was replaced by
commit 835cc0c8477f with a more cache-friendly "depth-first" order.
Some hard thinking came up with a depth-first algorithm which defers
merges as little as possible while avoiding bad merges.  This saves
0.2*n compares, averaged over all sizes.

The code size increase is minimal (64 bytes on x86-64, reducing the net
savings to 26%), but the comments expanded significantly to document the
clever algorithm.

TESTING NOTES: I have some ugly user-space benchmarking code which I
used for testing before moving this code into the kernel.  Shout if you
want a copy.

I'm running this code right now, with CONFIG_TEST_SORT and
CONFIG_TEST_LIST_SORT, but I confess I haven't rebooted since the last
round of minor edits to quell checkpatch.  I figure there will be at
least one round of comments and final testing.

This patch (of 5):

Rather than having special-case swap functions for 4- and 8-byte
objects, special-case aligned multiples of 4 or 8 bytes.  This speeds up
most users of sort() by avoiding fallback to the byte copy loop.

Despite what ca96ab859ab4 ("lib/sort: Add 64 bit swap function") claims,
very few users of sort() sort pointers (or pointer-sized objects); most
sort structures containing at least two words.  (E.g.
drivers/acpi/fan.c:acpi_fan_get_fps() sorts an array of 40-byte struct
acpi_fan_fps.)

The functions also got renamed to reflect the fact that they support
multiple words.  In the great tradition of bikeshedding, the names were
by far the most contentious issue during review of this patch series.

x86-64 code size 872 -> 886 bytes (+14)

With feedback from Andy Shevchenko, Rasmus Villemoes and Geert
Uytterhoeven.

Link: http://lkml.kernel.org/r/f24f932df3a7fa1973c1084154f1cea596bcf341.1552704200.git.lkml@sdf.org
Signed-off-by: George Spelvin <lkml@sdf.org>
Acked-by: Andrey Abramov <st5pub@yandex.ru>
Acked-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Cc: Geert Uytterhoeven <geert@linux-m68k.org>
Cc: Daniel Wagner <daniel.wagner@siemens.com>
Cc: Don Mullis <don.mullis@gmail.com>
Cc: Dave Chinner <dchinner@redhat.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

---
## [mrakgr/The-Spiral-Language@7f60a9e655...](https://github.com/mrakgr/The-Spiral-Language/commit/7f60a9e655ce7324031970b274bf0abda0fa10cd)
##### 2021-04-02 16:44:52 by Marko Grdinić

"11:10am. Let me chill a bit and then I will start. I got up too late again today.

11:45am. Let me start for the day. What I want to do right now, before anything else, is study the Deep CFR and the DREAM papers.

It is time to get this shit going. Before I start work on dictionaries or PG or whatever else, it is time to famiarize myself with deep learning version of CFR.

Let me close that issue from yesterday. No way do I feel like checking out the master of Kivy. Why is the author goading me into wasting my time?

...Let me start with the DREAM paper.

Though I do nto understand CFR, what I do not understand will not prevent me from using it effectively.

...For fuck's sake. Let me reset the router.

I should have the paper on my hard drive so let me go for that in the meantime.

12:05pm. 4/14. The paper has been rather clear so far. Let me get the variance reduction parts.

12:10pm. The equations in VR OC part is something I do not understand. What is that p(h',T...) thing. Over what is the Sum h' summing over, don't tell me all possible histories.

> Single Deep CFR (SD-CFR) is a modification of Deep CFR that instead stores all value networks from each CFR iteration to disk and mimics the average policy exactly during play by sampling one of them and using its policy for the entire game. This is mathematically equivalent to sampling actions from the average policy. SD-CFR eliminates the approximation error in Deep CFR resulting from training a network to predict the average policy, at the minor cost of using extra disk space to store the models from each CFR iteration (or a random sample of CFR iterations).

This is interesting.

6/14. These equations are actually easy to understand.

12:35pm. 6/14. I get this stuff almost completely.

12:40pm. Hmmm, no, actually I don't how do it make sense to divide v - Q by the policy probability.

`Q - (v - Q) / e`. And I know that e is a probability.

Is it trying to emulate uniform exploration's values while sampling from the policy? That has to be it.

12:50pm. Ah, right. Eq 7 is the policy update. The multiplication by the opponent's probability is implicit, but it has to correct for its own probability. I've been imagining how I would do this, and it is eactly as in the paper.

If the paper is innovative in something, that would be that it propagated v back...ah, no wait. The values gets corrected in eq 8. So the range of the value will be properly scoped. It makes sense.

12:55pm. Damn it, if only I could understand why ommiting out the self probability during updates makes sense, I could understand CFR.

3/14. I've been hung up on trying to understand the average policy update. Why does it multiply only by self, but not by the opponent probability?

But according to eq 2, the average policy is literally just the average policy. I can consider the thing in the actual algorithm a hack.

Maybe tabular CFR that I implemented would make more sense if I made it a separate pass.

Wait wait...

Maybe I am thinking about this wrong. If the goal is to get the average policy...

Consider the policy update. The oppontent probability is implicit. And the self probability is reversed.

If the goal is to get the average policy, then the reason why it is not necessary to multiply by the opponent probability in the average policy update, because that is already the case.

The policy update has already been multed by the opponent probability! Doing that in the average as well would just double count it.

And the reason why the average policy update multiplies by own probability is to reverse what has been done in the policy update itself!

I see.

2:20pm. Done with lunch.

https://www.reddit.com/r/reinforcementlearning/comments/miac4q/back_to_square_one_superhuman_performance_in/

This made me lol, but no way do I feel like reading all of it.

2:40pm. Let me resume. Focus me. I've gotten a lot from the paper. I can visualize in its entirety. I won't have trouble implementing the sampling CFR when the time comes.

2:45pm. Let me finish the paper. I'll move to the deep CFR one after that.

I really gained a lot from reading the DREAM paper. I finally understand the average policy updates. And I understand the policy update as well.

3pm. Hmmm, it is expecting me to train D. I thought that values can be calculated just from Qs. This is confusing. I am not sure what D is. I really should try all of this in the tabular case first.

> Moreover, DREAM’s Q network requires the input of both player’s private cards and thus has a slightly adjusted input layer

This was in the appendix as the very last sentence. What the hell?

Why cheat like this?

3:20pm. Nevermind this. Let me take a look at the other CFR papers.

Let me go for the Deep CFR paper. Then I'll go for the tabular VR-MCFR paper.

3:30pm. My will to read it is low. it seems a lot of my energy went into that first one, and now I am exhausted mentally. Let me just skim it.

> Model-free policy gradient algorithms have been shown to minimize regret when parameters are tuned appropriately [26] but the performance of these algorithms is comparable to NFSP.

Hmmm...

3:40pm. Focus me. Focus on the paper. Slacking can come later.

4:05pm. Had to take a break after all. Let me resume.

> The neural network model begins with separate branches for the cards and bets, with three and two layers respectively. Features from the two branches are combined and three additional fully connected layers are applied. Each fully-connected layer consists of xi+1 = ReLU(Ax[+x]). The optional skip connection [+x] is applied only on layers that have equal input and output dimension. Normalization (to zero mean and unit variance) is applied to the last-layer features of each position. The network architecture was not highly tuned, but normalization and skip connections were used because they were found to be important to encourage fast convergence when running preliminary experiments on pre-computed equilibrium strategies in FHP.

This is what I was planning to do, so it is nice to see confirmation that it helps.

4:15pm. Let me go for the tabular MCCFR paper. After that I should decide what I want to do. I am leaning towards doing whatever is necessary to get tabular CFR to work on these toy games. After that I will plug in NNs.

4:30pm. No wait, what I thought was the division by the current probability can't possibly have been the case in the previous paper.

Ah, in eq 4 this is the division by the current policy. But if we are doing sampling where does the divison by the current player probability come in?

4:35pm. No nevermind. I do not get it once again.

4:45pm. I get it again.

The value propagation makes perfect sense. So does the strategy averaging, if you ignore that CFR itself does not exactly do it. The average strategy update rule is more of a hack than anything else. I can't reduce the rule to doing explicit averaging.

In order to get that, I'd have to modify CFR so it buffers the policy updates until the end of the traversal (similarly to how gradients are accumulated) and then apply them all at once. The update the average strategy without that self prob multiplication hack.

Anyway, this will be good as it will prevent the strategies from oscilating so much.

No, my reasoning about average strategy being multied by the strategy path probability is bogus.

4:55pm. But damn it, I understand exactly how the average strategy update rule came about.

Imagine you are doing regular CFR on Rock Paper Scissors.

If you are player 1, that is one update for the average strategy.

If you are player 2, that comes down to three updates for the average strategy.

That causes an imbalance. Then to resolve, you can add the rule to multiply the average strategy update by the path prob of ... no wait.

The self update in that case would be 1 in both cases.

But suppose you have a chance node instead of player two. Then it would make sense.

5:05pm. Yeah, if the goal is strategy averaging, the current CFR formulation is bogus. It is missing a regret accumulation step. It is not at all compatible with sampling old strategies.

5:40pm. There is also one more troublesome consideration.

I am wracking my brain over it right now.

I know the strategy/policy update is `prob_op * (v_cur - v_all)`. But is it the right choice to simply leave up the `prob_self`. Might it not be better to importance sample it.

In the tabular case (and depending on the game) it might now matter since all the states are sparse, but in the dense base whether I simply ommit the prob_self or importance sample the uniform distribution will affect the shape of the replay buffer.

But ways can't possibly be right!

The average strategy rule is definitely wrong, but could this rule be wrong as well.

5:55pm. I am wracking my brains over this, but there is no point in thinking about it.

I should just test it out and confirm my suspicions with my own hands.

6pm. There is also another point of suspicion. I've been folding the chance node probabilities into both of the players. This would work when it is just for updating the strategy regularly, but in a sampling scheme, if I divide by the self probability to correct the sampling bias, it won't match the update. It will correct for both players chance node path probs.

I should redesign the games so that chance node probs are separate from action probs.

This is something the papers did not talk about it at all, but it is important.

6:05pm. No. The uniform distribution is correct.

Imagine I was sampling using self uniform probs and op policy probs.

In that case would I adjust the buffer so that self probs are all one?

Hmmmm...I am imagining adding some fake player nodes.

6:10pm. Surprisngly, the CFR rules are right. Adding fake 0.5 change nodes that lead to terminal states with 0 rewards would wreck things with uniform sampling. But with hard sampling like CFR does, the results would be proper.

6:15pm. I need to think about the shape of the data in the replay buffer, both for the policy and the value nets carefully.

I think I gained quite a bit from today's session - I am definitely going to separate chance probabilities from action probabilities. Otherwise the replay buffer will be broken by the time I try NN training.

6:20pm. Hard sampling that CFR does is quite profound now that I think about it. At first it does not make sense to just switch the target distribution to whatever has been picked - it seems like it would make more sense to just pick a distribution and stick to that, but that approach would be too inefficient. If the target distribution is 1 at one category and 0 everywhere else, then the program would just be burning clock cycles.

But looking at it most broadly, if one iterates through all the combinations of hard distributions and filters out the 0 probability nodes, one would get exactly the same result as if one did importance sampling with switching to the target hard distribution.

This is the right approach. The CFR paper is right in this.

6:30pm. I did quite a bit of thinking today, enough to get a headache. The question right now that I should be asking myself is - what is next?

Hrmmmm...I am strongly leaning towards implementing the tabular version of various CFR algorithms.

Unless I do this, I won't have a baseline to compare the neural ones against.

The problem with neural algos is that if I implement them, they will work. But I won't be able to know whether they are truly strong or weak.

Not unless I want to spent my own time playing against the agents.

Leduc poker is one thing, but I should do what the paper does and implement Flop Holdem. That will still be viable as a game, but it has a much larger number of states than Leduc does.

That game should be the ultimate test for tabular algorithms. It is what I should be pitting the NN agents against.

After I do that, I'll be ready for HU NL Holdem with large stacks.

6:40pm. I'll stop here for the day. Time for lunch.

Tomorrow, I'll get the drudge work out of the way and implement that dictionary.

TODO: Separate the action from chance probabilities.

Let me also not forget about this."

---

# [<](2021-04-01.md) 2021-04-02 [>](2021-04-03.md)

