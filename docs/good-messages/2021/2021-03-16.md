# [<](2021-03-15.md) 2021-03-16 [>](2021-03-17.md)

3,185,210 events, 1,608,968 push events, 2,492,013 commit messages, 181,636,128 characters


## [ya-sach1/ya-sach1](https://github.com/ya-sach1/ya-sach1)@[69b545150e...](https://github.com/ya-sach1/ya-sach1/commit/69b545150e4bccdda4300843e139f2672aee72d1)
#### Tuesday 2021-03-16 00:13:09 by sach1

holy shit I hate mark fucking down so fucking much

---
## [ap00rv/aws-cdk](https://github.com/ap00rv/aws-cdk)@[f5ab374eaf...](https://github.com/ap00rv/aws-cdk/commit/f5ab374eafeafff02f386be445d10863717b51ed)
#### Tuesday 2021-03-16 00:17:29 by Rico Huijbers

fix(bootstrap): same-account modern bootstrapping still requires policy ARNs (#9867)

The current bootstrapping experience has sharp edges. It requires you
to pass `--cloudformation-execution-policies` in all cases, even if
you just want a "simple", same-account bootstrap stack. If you bootstrap
your own accounts, you probably don't have a centralized SecOps
team that is limiting you, and you're probably intending to deploy
everything using the CDK, which means you're looking for AdministratorAccess.

In effect, you are forced to constantly Google and copy/paste the ARN
for `AdministratorAccess` (because who can remember that)
and it's a bad experience.

In the case of bootstrapping an account just for use "by itself",
however (which is the 90% use case for bootstrapping),
the trust boundary is very clear and there's no risk of privilege
escalation between accounts.

Add an optimization where in the case of a "simple", non-cross account
bootstrap, we'll default to the AdministratorAccess ARN for you.

Once you establish `--trust` with another account, we'll still
force you to spell out the execution policy you'll want to use though.

Fixes #8571.

----

*By submitting this pull request, I confirm that my contribution is made under the terms of the Apache-2.0 license*

---
## [lindafittante/keyschoolsummercamp](https://github.com/lindafittante/keyschoolsummercamp)@[3b91faf43b...](https://github.com/lindafittante/keyschoolsummercamp/commit/3b91faf43beaf55f5c029a5906d30e888868e0b6)
#### Tuesday 2021-03-16 00:32:59 by lindafittante

Update language

Here's what we cut: 
<br><h3>High School SSL/CIT:</h3> High school campers have an opportunity to earn their SSL hours while honing their Counselor skills. Students will help facilitate art projects, take a lead on sports teams and organize LEGO teams while developing critical leadership and counselor skills. The cost is $99/week. There is an early registration discount so the cost is $50/week before February 28 and $75/week prior to May 15. Each camper will receive three hours of community service hours (or SSL) each day (15/week) and will be a CIT for two hours each day. Snack is provided for this program. <br>
		<br><h3>CIT:</h3> We have an application form for Counselors in Training (CITs). A CIT must be enrolled in Grades 6-8. Each CIT will be mailed a responsibilities form to fill out and return before the first day of camp. We love our CITs and look forward to having our former and incoming CITs join us! <br>
		<br><h3>Pizza Lunch:</h3> New in 2020: You can sign up your camper for a daily lunch that includes two slices of pizza, carrots or apples and a bottle of water.<br>
		<br><h3>Payment and Early Registration Discounts:</h3> Full payment must be made by credit card at time of registration. We only accept Visa and MasterCard. There is an early registration discount of $50 discount prior to February 28th and $25 discount prior to May 15th. Discounted prices are reflected on website until May 15, 2020. Cash will not be accepted for camp or aftercare fees.<br>
		<br><h3>Refunds:</h3> Any camper who has voluntarily withdrawn from Key School Summer Camp on or before Friday, May 15, 2020 will receive a full refund. Key School Summer Camp must be notified in writing of the withdrawal by May 15, 2020 in order for the camper to receive a refund. Refunds will not be given after the May 15, 2020 deadline. There are no refunds for absences. <br>
		<br><h3>Additional Terms:</h3> There is no prorating of fees. We reserve the right to dismiss, without refund, any child who does not comply with the expectations of Key School Summer Camp. <br>

---
## [lindafittante/keyschoolsummercamp](https://github.com/lindafittante/keyschoolsummercamp)@[e482d66aad...](https://github.com/lindafittante/keyschoolsummercamp/commit/e482d66aad58badb8d39f2c50ff2549e4c3803f8)
#### Tuesday 2021-03-16 00:43:45 by lindafittante

New introductory paragraph

Cut:
<p>Key School Summer Camp is celebrating its 18th year! Come join us as we pass the summer days playing sports, creating amazing artwork and building Lego structures in a fun, familiar and happy setting. Picnic lunches, popsicle parties, our ever-popular talent show and our much loved counselors (once campers themselves) are just a few of the exciting Key Camp traditions that bring our campers back every year. This year we are introducing pizza lunch and a program for high school students to earn their SSL volunteer hours.
		</p>

---
## [cechiu2/mbti-board](https://github.com/cechiu2/mbti-board)@[b2c57e19e7...](https://github.com/cechiu2/mbti-board/commit/b2c57e19e718b21918ccb38bb446c3152b3957fb)
#### Tuesday 2021-03-16 01:09:34 by cechiu2

hi friends i've added myself!

<3 love y'all hope i didn't mess up that'd be embarrassing

---
## [smxi/inxi](https://github.com/smxi/inxi)@[75433a383a...](https://github.com/smxi/inxi/commit/75433a383afce30c07ab67ea1f2138212cc174a2)
#### Tuesday 2021-03-16 01:44:28 by Harald Hope

Huge upgrade!! Bug Fixes!! Refactors!!! BSDs!!! More BSDs!!!
raspberry pi!! New Features!!! Enhanced old features!!! Did I
mention bluetooth?! USB? Audio? No? well, all hugely upgraded!

------------------------------------------------------------------------
BUGS:

1. Sadly, 3.3.01 went out with a bug, forgot to remove a debugger,
resulted in hardcoded kernel compiler version always showing.

Note that there is a new inxi-perl/docs/inxi-bugs.txt file to
track such bugs, and matched to specific tagged releases so you
know the line number and items to update to fix it.

2. Typo in manjaro system base match resulted in failing to report
system base as expected.

------------------------------------------------------------------------
KNOWN ISSUES BUT CAN'T OR WON'T BE FIXED:

1. OpenBSD made fvwm -version output an error along with the
version, and not in the normal format for standard fvwm, this
is just too complicated to work around for now, though it could
be in theory by creating a dedicated fvwm-oBSD item in
program_values. But that kind of granularity gets too hard to track,
and they are likely to change or fix this in the future anyway.
Best is they just restore default -version output to what it is
elsewhere, not nested in error outputs.

2. Discovered an oddity, don't know how widespread this
is, but Intel SSDs take about 200 milliseconds to get the sys
hwmon based drive temps, when it should take under a
millisecond, this may be a similar cause as those drives having
a noticeable SMART report delay, not sure. This is quite
noticeable since 200 ms is about 15% of the total execution
time on my test system.

------------------------------------------------------------------------
FIXES:

1. For --recommends, added different rpm SUSE xdpyinfo package name.

2. Distro Data: added double term filter for lsb-release due to sometimes
generating repeated names in distro.

3. Packages: fix for appimage package counts.

4. Desktop: fixed ID for some wm when no xprop installed, fallback to
using @ps_cmd detections, which usually work fine.

5a. When swap used was 0, showed N/A, fixed to correctly show 0 KiB.

5b. If no swap devices found, BSDs were not correctly showing
no swap data found message. Corrected.

6a. Bluetooth: Removed hcidump from debugger, in some cases, that will
just hang endlessly. Also wrapped bluetoothctl and bt-adapter debugger
data collection with @ps_cmd bluetooth running test. Only run if
bluetooth service is running.

6b. Bluetooth: running detections have to be very strict, only
bluetoothd, not bluetooth, the latter can show true when bluetoothd
is not running, and did in my tests.

7. USB: with Code Change 1, found a few places where fallback usb type
detections were creating false matches, which resulted in say,
bluetooth devices showing up as network devices due to the presence
of the word 'wireless' in the device description. These matches are
all updated and revised to be more accurate and less error prone.

8. Battery: an oversight, had forgotten to have percent used of
available capacity, which made Battery data hard to decipher, now
it shows the percent of available total, as well as the condition
percent, so it's easier to understand the data now, and hopefully
more clear.

9a. OpenBSD changed usbdevs output format sometime in the latest
releases, which made the delicate matching patterns fail. Updated
to handle both variants. They also changed pcidump -v formatting
at some point, now inxi will try to handle either. Note that
usbdevs updates also work fine on NetBSD.

9b. FreeBSD also changed their pciconf output in beta 13.0, which
also broke the detections completely, now checks for old and new
formats. Sigh. It should not take this much work to parse tools
whose output should be consistent and reliable. Luckily I ran
the beta prior to this release, or all pci device detections
would simply have failed, without fallback.

9c. Dragonfly BSD also changed an output format, in vmstat, that
made the RAM used report fail. Since it's clearly not predictable
which BSD will change support for which vmstat options, now just
running vmstat without options, and then using processing logic
to determine what to do with the results.

10. It turns out NetBSD is using /proc/meminfo, who would have
thought? for memory data, but they use it in a weird way that
could result in either negative or near 0 ram used. Added in
some filters to not allow such values to print, now it tries
to make an educated guess about how much ram the system is
really using based on some tests.

11. Something you'd only notice if testing a lot, uptime failed
when the uptime was < 1 minute, it had failed to handle the seconds
only option, now it does, seconds, minutes, hours:minutes,
days hours:minutes, all work.

12. Missed linsysfs type to exclude in partitons, that was a partner
to linprocfs type, both are BSD types.

13. Added -ww to ps arguments, that stops the cutting width to terminal
size default behavior in BSDs, an easy fix, wish I'd known about
that a long time ago.

15. gpart seems to show sizes in bytes, not the expected KiB, so
that's now handled internally. Hopefully that odd behavior won't
randomly change in the future, sigh.

16. Fixed slim dm detection, saw instance where it's got slim.pid
like normal dms, not the slim.lock which inxi was looking for, so
now inxi looks for both, and we're all happy!

------------------------------------------------------------------------
ENHANCEMENTS:

1. Added in something that should have been there all along, now inxi
validates the man page download as well as the self, this avoids
corrupted downloads breaking the man.

2. Init: added support for shepherd init system.

3. Distro Data: added support for guix distro ID; added support for
NomadBSD, GhostBSD, HardenedBSD system base. GhostBSD also shows the main
package version for the distro version ID, which isn't quite the
same as the version you download, but it's close. Also added os-release
support for BSDs, using similar tests as for linux distros, that
results in nicer outputs for example for Dragonfly BSD.

4. Package Data: added guix/scratch [venom]/kiss/nix package managers.
Update for slackware 15 package manager data directory relocation,
now handles either legacy current or future one.

5. Repos: added scratch/kiss/nix-channels; Added GhostBSD, HardenedBSD
pkg repos.

6. USB Data: added usbconfig. That's FreeBSD's, and related systems.

7. Device Data: Added pcictl support, that's NetBSD's, I thought
inxi had supported that, but then I remembered last time I tried to
run netBSD in a vm, I couldn't get it figured out. Now debugged and
working reasonably well.

8. Raspberry Pi 3, 4: ethernet nic now detected; wifi device,
which is on a special mmcnr type, now works, that stopped working in
pi 3, due to the change, now it's handled cleanly. Also added support
for pi bluetooth, which lives on a special serial bus, not usb.
For Raspberry Pi OS, added system base detections, which are tricky.
Also matched mmcnr devices to IF data, which was trickyy as well.
Note that as far as I could discover, only pi puts wifi on mmcnr.

9. Bluetooth: due to deprecated nature of the fine hciconfig
utility, added in support for bt-adapter, which also allows matching
of bluetooth data to device data, but is very sparse in info
supplied compared to hciconfig. bluetoothctl does not have enough
data to show the hci device, so it's not used, since inxi can't
match the bluetooth data to the device (no hci[x]). This should help
the distros that are moving away from hciconfig, in particular,
AUR is only way arch users can get hciconfig, which isn't ideal.

10. New tool and feature, ServiceData, this does two things,
as cross platform as practical, show status of bluetooth service,
this should help a lot in support people debugging bluetooth problems,
since you have bluetooth enabled but down, or up, disabled, and you
can also have the device itself down or up, so now it shows all that
data together for when it's down, but when the device is up, it just
shows the device status since the other stuff is redundant then.

In -Sa, it now shows the OS service manager that inxi detected
using a bunch of fallback tests, that's useful to admins who
are on a machine they don't know, then you can see the service
manager to use, like rc-service, systemctl, service, sv, etc.

11. Big update for -A: Sound Servers: had always been really
just only ALSA, now it shows all detected sound servers, and whether
they are running or not. Includes: ALSA, OSS, PipeWire, PulseAudio,
sndio, JACK. Note that OSS version is a guess, might be wrong source
for the version info.

12. Added USB device 'power:' item, that's in mA, not a terrible
thing to have listed, -xxx. This new feature was launched cross
platform, which is nice. Whether the BSD detections will break
in the future of course depends on whether they change the output
formats again or not. Also added in USB more chip IDs, which can
be useful. For BSDs, also added in a synthetic USB rev, taken
from the device/hub speeds. Yes, I know, USB 2 can have low speed,
full speed, or high speed, and 1.1 can have low and full speeds,
so you actually can't tell the USB revision version from the speeds,
but it's close enough.

13. Made all USB/Device data the same syntax and order, more
predictable, bus, chip, class IDs all the same now.

14. Added in support for hammer and null/nullfs file system types,
which trigger 'logical:' type device in partitions, that's also
more correct than the source: Err-102 that used to show, which
was really just a flag to alert me visibly that the partition
type detection had simply failed internally. Now for detected
types, like zfs tank/name or null/nullfs, it knows they are
logical structures.

15. Expanded BSD CPU data, where available, now can show L1/L2/
L3 cache, cpu arch, stepping, family/model ids, etc, which is
kind of nifty, although, again, delicate fragile rules that
will probably break in the future, but easier to fix now.

16. By an old request, added full native BSD doas support.
That's a nice little tool, and it plugged in fairly seamlessly
to existing sudo support. Both the internal doas/sudo stuff
should work the same, and the detection of sudo/doas start
should work the same too.

17a. Shell/Parent Data: Big refactor of the shell start/parent logic,
into ShellData which helped resolve some issues with running-in
showing shell name, not vt terminal or program name. Cause of that
is lots of levels of parents before inxi could reach the actual
program that was running inxi. Solution was to change to a longer
loop, and let it iterate 8 times, until it finds something that is
not a shell or sudo/doas/su type parent, this seems to work quite
well, you can only make it fail now if you actually try to do it on
purpose, which is fine.

This was very old logic, and carried some mistakes and
redundancies that made it very hard to understand, that's cleaned
up now. Also restored the old (login) value, which shows
when you use your normal login account on console, some system
will also now show (sudo,login) if the login user sudos inxi,
but that varies system to system.

17b. BSD running-in: Some of the BSDs now support the -f flag
for ps, which made the parent logic for running-in possible for
BSDs, which was nice. Some still don't support it, like OpenBSD
and NetBSD, but that's fine, inxi tests, and if no support detected,
just shows tty number. Adding in more robust support here cleaned
up some redundant logic internally as well.

17c. Updated terminal and shell ID detections, there's quite a few
new terminals this year, and a new shell or two. Those are needed
for more reliable detections of when the parent is NOT a shell,
which is how we find what it is.

18. Added ctwm wm support, that's the new default for NetBSD,
based on twm, has version numbers.

19. Upgraded BSD support for gpart and glabel data, now should
catch more more often.

20. For things like zfs raid, added component size, that doesn't
always work due to how zfs refers to its components, but it often
does, which is better than never before.

21. To make BSD support smoother, got rid of some OpenBSD only
rules, which in fact often apply to NetBSD as well. That may
lead to some glitches, but overall it's better to totally stay
away from OpenBSD only tests, and all BSD variant tests, and
just do dynamic testing that will work when it applies, and
not when it doesn't. In this case, added ftp downloader support
for netBSD by removing the openBSD only flag for that item.

There's a bit of a risk there in a sense since if different ftp
programs with different options were to be the fallback for something
else, it might get used, but that's fine, it's a corner case, better
to have them all work now than to worry about weird future things.
But limiting it to only BSDs should get rid of most of the problem.

vmstat and optical drive still use net/openbsd specifics because
it is too tricky to figure out it out in any more dynamic way.

22. For -Sxxx, added if systemd, display, virtual terminal number.
Could be useful to debug subtle issues, if the user is for example
not running their desktop in vt 7, the default for most systems.

------------------------------------------------------------------------
CHANGES:

1. Moved battery voltage to -Bx output, the voltage is quite
important to know since that is the key indicator of battery state.
If voltage is within .5 volts of specified minimum, shows voltage
for -B since that's a prefail condition, it's getting close to
death.

2. In partitions and raid, when the device was linear raid logical
type layout, it said, no-raid, when it should be 'linear', that's
now cleaner and more correct.

3. When running-in is a tty value, it will now show the entire
tty ID, minus the '/dev/tty', this will be more precise, and also
may resolve cases where tty was fully alpha, no numbers, previously
inxi filtered out everything that was not a number, but that can
in some tty types remove critical tty data, so now it will show:

running-in:
tty 2 [not changed]; tty pts/2 [adds pts/]; tty E2 [adds the E];
tty rx [would have not shown at ll before]

------------------------------------------------------------------------
CODE CHANGES:

NOTE: unlike the previous refactors, a lot of these changes were
done to make inxi more maintainable, which means, slightly less
optimized, which has been my preference in the past, but if the
stuff can't be maintained, it doesn't matter how fast it runs!

These changes have really enhanced the quality of the code and
made it a lot easier to work with. It's also now a lot easier to
add debuggers, force/fake data switches, etc, so it gets done,
unlike before, when it was a pain, so it got skipped, and then
caused bugs because of stray debuggers left in place, and so on.

The bright side is while reading up on this, I learned that using
very large subs is much more efficient than many small ones,
which I've always felt was the case, and it is, so the style
used internally in inxi proves to be the best one for optimizations.

These refactors, ongoing, have now touched at least 1/3, almost
1/2, of the entire inxi codebase, so the stuff is getting more
and more consistent and up to date, but given how old the logic
is in places, there will be more refactors in the future, and
maybe once the code is easier to maintain, some renewed
optimizations!, if we can find anything that makes sense, like
passing array/hash references back to the caller, already the
first half is done, passing references to the sub/method always.

The second part is started, using the Benchmark Perl module,
which really speeds up testing and helps avoid pointless tweaks
that do little re speed improvements.

I could see with some care some areas where working on data
directly via references could really speed things up, but it's
hard to write and read that type of code, but it's already being
done in the recursive data and output logics, and a few other
places.

1. Large refactor of USBData, that was done in part to help make
it work for BSDs better, but also to get it better organized.

This refactor also made all the device items, like -A,-G,-N,-E
use the same methods for creating USB output, previously they
had used a hodgepodge of methods, some super old, it was not
possible to add USB support more extensively for BSDs without
this change.

Also added in some fallback usb type detection tools using
several large online collections of that info to see what possible
matching patterns could catch more devices and correctly match
them to their type, which is the primary way now that usb output
per type is created. This really helps with BSDs, though BSD
usb utilities suffer from less data than lsusb so they don't always
get device name strings in a form where they can be readily ID'ed,
but it's way better than it was before, so that's fine!

Moved all previous methods of detecting if a card/device was USB
into USBData itself so it would all be in one place, and easier
to maintain.

All USB tools now use bus_id_alpha for sorting, and all now
sort as well, that was an oversight, previously the BSD usb
tools were not sorted, but those have been enhanced a lot, so
sorting on alpha synthetic bus ids became possible.

Removed lsusb as a BSD option, it's really unreliable, and the data
is different, and also varies a lot, it didn't really work at all
in Dragonfly, or had strange output, so lsusb is now a linux only
item.

2. Moved various booleans that were global to %force, %loaded, and
some to the already present, but lightly used, %use hashes. It was
getting too hard to add tests etc, which was causing bugs to happen.
Yes, using hashes is slower than hardcoding in the boolean scalars,
but this change was done to improve maintainability, which is starting
to matter more.

3. Moved several sets of subs to new packages, again, to help with
debugging and maintainability. MemoryData, redone in part to
handle the oddities with NetBSD reporting of free, cached, and
buffers, but really just to make it easier to work with overall.
Also moved kernel parameter logic to KernelParameters, gpart logic
to GpartData, glabel logic to GlabelData, ip data IpData, check_tools
to CheckTools, which was also enhanced largely, and simplified,
making it much easier to work with.

4. Wrapped more debugger logic in $fake{data} logic, that makes
it harder to leave a debugger uncommented, now to run it, you have
to trigger it with $fake{item} so the test runs, that way even if
I forget to comment it out, it won't run for regular user.

5. Big update to docs in branch inxi-perl/docs, those are now
much more usable for development. Updated in particular
inxi-values.txt to be primary reference doc for $fake, $dbg,
%force, %use, etc types and values. Also updated inxi-optimization.txt
and inxi-resources.txt to bring them closer to the present.

Created inxi-bugs.txt as well, which will help to know which known
bugs belonged to which frozen pools. These bugs will only refer
to bugs known to exist in tagged releases in frozen pool distros.

6. For sizes, moved most of the sizing to use main::translate_size,
this is more predictable, though as noted, these types of
changes make inxi a bit slower since it moved stuff out of inline
to using quick expensive sub calls, but it's a lot easier to
maintain, and that's getting to be more important to me now.

7. In order to catch live events, added in dmesg to dmesg.boot data
in BSDs, that's the only way I could find to readily detect
usb flash drives that were plugged in after boot. Another hack,
these will all come back to bite me, but that's fine, the base
is easier to work on and debug now, so if I want to spend time
revisiting the next major version BSD releases, it will be easier
to resolve the next sets of failures.

8. A big change, I learned about the non greedy operator for
regex patterns, ?, as in, .*?(next match rule), it will now
go up only to the next match rule. Not knowing this simple
little thing made inxi use some really convoluted regex to
avoid such greedy patterns. Still some gotchas with ?, like
it ignores following rules that are zero or 1, ? type, and
just treats it as zero instances. But that's easy to work with.

9. Not totally done, but now moved more to having set data
tools set their $loaded{item} value in get data, not externally,
that makes it easier to track the stuff. Only where it makes
sense, but there's a lot of those set/get items, they should
probably all become package/classes, with set/get I think.

10. Optimized reader() and grabber() and set_ps_aux_data(), all
switched from using grep/map to using for loops, that means
inxi doesn't have to go through each array 2x anymore, actually
4x in  the case of set_ps_aux_data(). This saved a visible
amount of execution time, I noticed this lag when running
pinxi through NYTProf optimizer, there was a quite visible
time difference between grabber/reader and  the subshell
time, these optimizations almost removed that difference,
meaning only the subshell now really takes any time to run.

Optimized url_cleaner and data_cleaner in RepoData, those
now just work directy on the array references, no returns.

Ran some more optimization tests, but will probably hold off
on some of them, for example, using cleaner() by reference is
about 50% faster than by copy, but redoing that requires
adding in many copies from read only things like $1, so
the change would lead to slightly less clean code, but may
revisit this in the future, we'll see.

But in theory, basically all the core internal tools that
take a value and modify it should do that by reference
purely since it's way faster, up to 10x.

---
## [ccodwg/Covid19Canada](https://github.com/ccodwg/Covid19Canada)@[660357e7a4...](https://github.com/ccodwg/Covid19Canada/commit/660357e7a4442dd95ba2f8014513756aea74692e)
#### Tuesday 2021-03-16 01:54:09 by Jean-Paul R. Soucy

New data: 2021-03-15: See data notes.

Revise historical data: cases (AB, BC, MB, ON, QC); mortality (QC).

Note regarding deaths added in QC today: “10 new deaths, for a total of 10,550 deaths: 2 deaths in the last 24 hours, 6 deaths between March 8 and March 13, 2 deaths before March 8.” We report deaths such that our cumulative regional totals match today’s values. This sometimes results in extra deaths with today’s date when older deaths are removed.

Recent changes:

2021-01-27: Due to the limit on file sizes in GitHub, we implemented some changes to the datasets today, mostly impacting individual-level data (cases and mortality). Changes below:

1) Individual-level data (cases.csv and mortality.csv) have been moved to a new directory in the root directory entitled “individual_level”. These files have been split by calendar year and named as follows: cases_2020.csv, cases_2021.csv, mortality_2020.csv, mortality_2021.csv. The directories “other/cases_extra” and “other/mortality_extra” have been moved into the “individual_level” directory.
2) Redundant datasets have been removed from the root directory. These files include: recovered_cumulative.csv, testing_cumulative.csv, vaccine_administration_cumulative.csv, vaccine_distribution_cumulative.csv, vaccine_completion_cumulative.csv. All of these datasets are currently available as time series in the directory “timeseries_prov”.
3) The file codebook.csv has been moved to the directory “other”.

We appreciate your patience and hope these changes cause minimal disruption. We do not anticipate making any other breaking changes to the datasets in the near future. If you have any further questions, please open an issue on GitHub or reach out to us by email at ccodwg [at] gmail [dot] com. Thank you for using the COVID-19 Canada Open Data Working Group datasets.

- 2021-01-24: The columns "additional_info" and "additional_source" in cases.csv and mortality.csv have been abbreviated similar to "case_source" and "death_source". See note in README.md from 2021-11-27 and 2021-01-08.

Vaccine datasets:

- 2021-01-19: Fully vaccinated data have been added (vaccine_completion_cumulative.csv, timeseries_prov/vaccine_completion_timeseries_prov.csv, timeseries_canada/vaccine_completion_timeseries_canada.csv). Note that this value is not currently reported by all provinces (some provinces have all 0s).
- 2021-01-11: Our Ontario vaccine dataset has changed. Previously, we used two datasets: the MoH Daily Situation Report (https://www.oha.com/news/updates-on-the-novel-coronavirus), which is released weekdays in the evenings, and the “COVID-19 Vaccine Data in Ontario” dataset (https://data.ontario.ca/dataset/covid-19-vaccine-data-in-ontario), which is released every day in the mornings. Because the Daily Situation Report is released later in the day, it has more up-to-date numbers. However, since it is not available on weekends, this leads to an artificial “dip” in numbers on Saturday and “jump” on Monday due to the transition between data sources. We will now exclusively use the daily “COVID-19 Vaccine Data in Ontario” dataset. Although our numbers will be slightly less timely, the daily values will be consistent. We have replaced our historical dataset with “COVID-19 Vaccine Data in Ontario” as far back as they are available.
- 2020-12-17: Vaccination data have been added as time series in timeseries_prov and timeseries_hr.
- 2020-12-15: We have added two vaccine datasets to the repository, vaccine_administration_cumulative.csv and vaccine_distribution_cumulative.csv. These data should be considered preliminary and are subject to change and revision. The format of these new datasets may also change at any time as the data situation evolves.

https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/#c47900

Note about SK data: As of 2020-12-14, we are providing a daily version of the official SK dataset that is compatible with the rest of our dataset in the folder official_datasets/sk. See below for information about our regular updates.

SK transitioned to reporting according to a new, expanded set of health regions on 2020-09-14. Unfortunately, the new health regions do not correspond exactly to the old health regions. Additionally, the provided case time series using the new boundaries do not exist for dates earlier than August 4, making providing a time series using the new boundaries impossible.

For now, we are adding new cases according to the list of new cases given in the “highlights” section of the SK government website (https://dashboard.saskatchewan.ca/health-wellness/covid-19/cases). These new cases are roughly grouped according to the old boundaries. However, health region totals were redistributed when the new boundaries were instituted on 2020-09-14, so while our daily case numbers match the numbers given in this section, our cumulative totals do not. We have reached out to the SK government to determine how this issue can be resolved. We will rectify our SK health region time series as soon it becomes possible to do so.

---
## [kairikeymaster/LifeUp-Translation](https://github.com/kairikeymaster/LifeUp-Translation)@[2b7ec5a8f8...](https://github.com/kairikeymaster/LifeUp-Translation/commit/2b7ec5a8f8a8a791925c2ebffde6a0f7a34dfabe)
#### Tuesday 2021-03-16 02:20:19 by kairikeymaster

Update strings.xml

Specific questions or remarks:


line 20: I don't know what you mean to say here: "Share your daily or your colorful life online." Why do you say "or"? "Daily life" is a compound noun, so "daily" can't be contrasted with "colorful" as if they are two alternative adjectives you could choose to describe "life." You could have a "colorful life" or a "colorful daily life," but those mean different things: the first means that you've had a lot of interesting and unusual experiences *throughout* your life; the second means that you have a lot of interesting experiences on any given day.

line 181: This explanation is a little unclear: "You can set a future task by changing its start time." I would recommend explaining it slightly differently. For instance, you might say something like, "If you want this task to appear on your daily list before the day it is due, set an earlier start time." However, I did not make this change because I don't understand how the "Auto" start time is computed, and that information would affect how you should describe the custom start time (see my comments for line 606).

line 329: I wasn't sure what you meant by "Most function support using with network except world~\n" so please check that my translation makes sense.

line 352: I think there is something wrong with the variable %2$d because my header card says I've completed 2 out of 3 when I have actually completed 2 out of 4. When I click on the Day section, it shows that I still have 2 remaining.

line 601: I recommend including a link to this github file after you say that help is welcome :)

line 606: "Auto (According to Repeat Frequency)" does not make it clear when the start time will be. It would be helpful to describe somewhere how the start time is determined automatically -- for instance, in the description on line 181. 

line 675: I wasn't sure what you meant by "Only item that is still not used will be put in here," so please double-check my translation. 
   
lines 843-849; 863-869; 897-901: Starter -> Scholar -> Bachelor -> Master is not a natural hierarchy in English (at least not American English). There isn't one specific hierarchy that you have to use, but "Scholar" and "Bachelor" are not terms we would use to identify a person with a certain level of expertise. "Scholar" just means someone with an academic career, and "Bachelor" is really only used to refer to unmarried men. I replaced them with Novice, Journeyman, Expert, Master, but you could also say "Intermediate" instead of Journeyman or "Proficient" instead of Expert; I just don't think those sound good as nouns. 

lines 875-881: I wasn't sure what "mega" or "nia" meant, and I couldn't find anything about them in English sources that could be connected to the traits of intelligence/knowledge and endurance. I thought "scholar" made sense for intelligence and "marathoner" for endurance. I also thought "leader" was too broad for vitality: I think "dynamo" fits better. I wasn't sure what "travel artist" was supposed to mean, but the best thing I could come up with for charm/charisma was "celebrity."

line 1096: I don't know what "It induces vote" means.

lines 1303-1307: I replaced several periods with exclamation points because the periods would have been interpreted by many English speakers as dour, disheartening, or even sarcastic. "Let's get this done." gives the impression that the task is necessary, but will be difficult and unpleasant. "Let's get this done!" would be interpreted as encouraging and enthusiastic, which is something most English speakers want in a productivity app. And many younger Americans in particular would read "Congrats, work timer is over." as insincere, because "congrats"/"congratulations" is almost universally followed by an exclamation point.

line 1353: I don't know where "sell out" is meant to appear, but just in case, I should mention that "sell out" specifically means "sell all available inventory." If I were to "sell out" of tomatoes, I would have no tomatoes left: if I had five, I would sell five; if I had 100, I would sell 100. If you just mean "sell," remove the word "out."

lines 1556-1557: I'm not sure what "Synthesis Cost Item" or "Synthesis Got Item" mean.

line 1576; lines 1688-1689: I'm not sure what context a lot of these phrases are used in, so it's difficult for me to assess whether they are translated properly.

line 1696: I don't know what this means: "Out step count is calculated by the difference of the total step count."

line 1716: I don't know what this means: "Don\'t prompt temporarily"

line 1781: I don't know what you mean by "it\'s using the simple way to implement so that it may be not working well with some actions"

Other:
- It's not clear that "Normal" means that a task will not repeat. For repeat frequency, you should change "Normal" to "No repeat" or "None"
- I can't find an explanation for what "Ebbinghaus" means under the repeat section: does it mean repeats will become less frequent over time? How quickly? When will they stop?
- Keep in mind that the word "weekday" refers to Monday, Tuesday, Wednesday, Thursday, and Friday. "Day of the week" includes all of the previous as well as Saturday and Sunday. (I know, it's stupid, but the days of the weekend don't count as "weekdays" because they don't occur "during the (work) week.")
- In case I missed any, the button to acknowledge or dismiss a popup/hint should say "OK" instead of "YES"
- I didn't have the time to go through and change every instance of these, but "Attention:" would be better translated as "Warning:"
- You use the word "entrance" several times, but I don't know what this means in the context of software.

---
## [chronicallyunfunny/NodeSniper](https://github.com/chronicallyunfunny/NodeSniper)@[1bb5c4bbe7...](https://github.com/chronicallyunfunny/NodeSniper/commit/1bb5c4bbe78b091fab5f00f76a23211fdc5f19a0)
#### Tuesday 2021-03-16 03:02:00 by chronicallyunfunny

Fix sending skin with a bloated method just to send multipart data, fuck you Java

---
## [STRIX-Project/STRIX_kernel_xiaomi-sdm660](https://github.com/STRIX-Project/STRIX_kernel_xiaomi-sdm660)@[4e60dc95e6...](https://github.com/STRIX-Project/STRIX_kernel_xiaomi-sdm660/commit/4e60dc95e6826f0cc0f383bc7afe442a33442d7b)
#### Tuesday 2021-03-16 04:05:34 by Michal Hocko

oom: make oom_reaper freezable

After "oom: clear TIF_MEMDIE after oom_reaper managed to unmap the
address space" oom_reaper will call exit_oom_victim on the target task
after it is done.  This might however race with the PM freezer:

CPU0				CPU1				CPU2
freeze_processes
  try_to_freeze_tasks
  				# Allocation request
				out_of_memory
  oom_killer_disable
				  wake_oom_reaper(P1)
				  				__oom_reap_task
								  exit_oom_victim(P1)
    wait_event(oom_victims==0)
[...]
    				do_exit(P1)
				  perform IO/interfere with the freezer

which breaks the oom_killer_disable semantic.  We no longer have a
guarantee that the oom victim won't interfere with the freezer because
it might be anywhere on the way to do_exit while the freezer thinks the
task has already terminated.  It might trigger IO or touch devices which
are frozen already.

In order to close this race, make the oom_reaper thread freezable.  This
will work because
	a) already running oom_reaper will block freezer to enter the
	   quiescent state
	b) wake_oom_reaper will not wake up the reaper after it has been
	   frozen
	c) the only way to call exit_oom_victim after try_to_freeze_tasks
	   is from the oom victim's context when we know the further
	   interference shouldn't be possible

Signed-off-by: Michal Hocko <mhocko@suse.com>
Cc: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Cc: David Rientjes <rientjes@google.com>
Cc: Mel Gorman <mgorman@techsingularity.net>
Cc: Oleg Nesterov <oleg@redhat.com>
Cc: Hugh Dickins <hughd@google.com>
Cc: Rik van Riel <riel@redhat.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Reinazhard <muh.alfarozy@gmail.com>
Signed-off-by: Fiqri Ardyansyah <fiqri15072019@gmail.com>

---
## [STRIX-Project/STRIX_kernel_xiaomi-sdm660](https://github.com/STRIX-Project/STRIX_kernel_xiaomi-sdm660)@[d2de488f6a...](https://github.com/STRIX-Project/STRIX_kernel_xiaomi-sdm660/commit/d2de488f6a6890965a07045f332bfad6bbee3bdf)
#### Tuesday 2021-03-16 04:05:34 by Michal Hocko

mm, oom: introduce oom reaper

This patch (of 5):

This is based on the idea from Mel Gorman discussed during LSFMM 2015
and independently brought up by Oleg Nesterov.

The OOM killer currently allows to kill only a single task in a good
hope that the task will terminate in a reasonable time and frees up its
memory.  Such a task (oom victim) will get an access to memory reserves
via mark_oom_victim to allow a forward progress should there be a need
for additional memory during exit path.

It has been shown (e.g.  by Tetsuo Handa) that it is not that hard to
construct workloads which break the core assumption mentioned above and
the OOM victim might take unbounded amount of time to exit because it
might be blocked in the uninterruptible state waiting for an event (e.g.
lock) which is blocked by another task looping in the page allocator.

This patch reduces the probability of such a lockup by introducing a
specialized kernel thread (oom_reaper) which tries to reclaim additional
memory by preemptively reaping the anonymous or swapped out memory owned
by the oom victim under an assumption that such a memory won't be needed
when its owner is killed and kicked from the userspace anyway.  There is
one notable exception to this, though, if the OOM victim was in the
process of coredumping the result would be incomplete.  This is
considered a reasonable constrain because the overall system health is
more important than debugability of a particular application.

A kernel thread has been chosen because we need a reliable way of
invocation so workqueue context is not appropriate because all the
workers might be busy (e.g.  allocating memory).  Kswapd which sounds
like another good fit is not appropriate as well because it might get
blocked on locks during reclaim as well.

oom_reaper has to take mmap_sem on the target task for reading so the
solution is not 100% because the semaphore might be held or blocked for
write but the probability is reduced considerably wrt.  basically any
lock blocking forward progress as described above.  In order to prevent
from blocking on the lock without any forward progress we are using only
a trylock and retry 10 times with a short sleep in between.  Users of
mmap_sem which need it for write should be carefully reviewed to use
_killable waiting as much as possible and reduce allocations requests
done with the lock held to absolute minimum to reduce the risk even
further.

The API between oom killer and oom reaper is quite trivial.
wake_oom_reaper updates mm_to_reap with cmpxchg to guarantee only
NULL->mm transition and oom_reaper clear this atomically once it is done
with the work.  This means that only a single mm_struct can be reaped at
the time.  As the operation is potentially disruptive we are trying to
limit it to the ncessary minimum and the reaper blocks any updates while
it operates on an mm.  mm_struct is pinned by mm_count to allow parallel
exit_mmap and a race is detected by atomic_inc_not_zero(mm_users).

Signed-off-by: Michal Hocko <mhocko@suse.com>
Suggested-by: Oleg Nesterov <oleg@redhat.com>
Suggested-by: Mel Gorman <mgorman@suse.de>
Acked-by: Mel Gorman <mgorman@suse.de>
Acked-by: David Rientjes <rientjes@google.com>
Cc: Mel Gorman <mgorman@suse.de>
Cc: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Cc: Oleg Nesterov <oleg@redhat.com>
Cc: Hugh Dickins <hughd@google.com>
Cc: Andrea Argangeli <andrea@kernel.org>
Cc: Rik van Riel <riel@redhat.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Reinazhard <muh.alfarozy@gmail.com>
Signed-off-by: Fiqri Ardyansyah <fiqri15072019@gmail.com>

---
## [Ndymario/PvsP-Engine](https://github.com/Ndymario/PvsP-Engine)@[51ef51b310...](https://github.com/Ndymario/PvsP-Engine/commit/51ef51b310fd1a92063d96132756eba88ee0e543)
#### Tuesday 2021-03-16 04:10:15 by bbomb64

please for the love of god i hate this code someone do something with it im tired

---
## [austation/austation](https://github.com/austation/austation)@[84c4b89d1e...](https://github.com/austation/austation/commit/84c4b89d1e922e106e969b6fa0d8543d90030fb2)
#### Tuesday 2021-03-16 05:26:39 by AuStation Bot

[MIRROR] Ports PRs suggested by Archanial (#3201)

* Ports PRs suggested by Archanial (#3830)

* Fixes GC for observers and new players, and tons of loose references to stuff that shouldnt be (tgstation/tgstation#55563)

I've done this on a signal because atom_hud is applied very loosely in some contexes, and the objects themselves dont have an easy way to track back into what huds they're affected by, so this seemed the best. Properly cleans up next_time_allowed, which was missing.

Update: I discovered this is also an issue for a lot of simple mobs, such as slimes and bots and such. So fixing this is huge

* Removes a source of ian harddels, keeps mcgruffs bed discription from getting overwritten at roundstart, moves the bed claiming feature to just the dogbed typepath, none of the subtypes, this applies to buckling too (tgstation/tgstation#55158)

Removes a source of ian harddels, keeps mcgruff's bed description from getting overwritten at roundstart, moves the bed claiming feature to just the dogbed typepath, blacklisting subtypes. This applies to buckling too.

This means that a dogbed can only ever belong to one dog. Fuck you.
Remake of #54892, github doesn't like force pushes, not sure why

* Some changes suggested by lummox

* Fixes an edgecase where an area can be deleted, but still be stored inside GLOB.sortedAreas, which can cause a runtime on player related Initialize(), which can cause mobs to improperly init. No I don't know why this would happen, but it happen to me. This is an ided commit (tgstation/tgstation#56954)

Fixes an edgecase where an area can be deleted, but still be stored inside GLOB.sortedAreas, which can cause a runtime on player related Initialize(), which can cause mobs to improperly init. No I don't know why this would happen, but it happen to me.

Co-authored-by: Azarak <azarak10@gmail.com>
Co-authored-by: LemonInTheDark <58055496+LemonInTheDark@users.noreply.github.com>
Co-authored-by: oranges <email@oranges.net.nz>

* Ports PRs suggested by Archanial

Co-authored-by: Xenomedes <park246824@gmail.com>
Co-authored-by: Azarak <azarak10@gmail.com>
Co-authored-by: LemonInTheDark <58055496+LemonInTheDark@users.noreply.github.com>
Co-authored-by: oranges <email@oranges.net.nz>

---
## [No767/Digitial-Changelog](https://github.com/No767/Digitial-Changelog)@[34f88b7431...](https://github.com/No767/Digitial-Changelog/commit/34f88b7431a96152a67f629c231310ed10fbc6dc)
#### Tuesday 2021-03-16 06:07:54 by No767

Added License [DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE]

---
## [cryptee/web-client](https://github.com/cryptee/web-client)@[79de5c963a...](https://github.com/cryptee/web-client/commit/79de5c963a2886a393179be0bd92a86357f8033e)
#### Tuesday 2021-03-16 07:58:00 by John Ozbay

worker speedup, better large file delivery, fixes

+ quicker service worker bypass.
+ fixes un-closable uploader fail popups
+ fallback for large file downloads

older versions of Cryptee allowed uploading files larger than 50mb, but the file delivery mechanism was different. Servers could json parse stuff even if users could manage to upload massive files like (i.e. 150mb) V3 servers can’t parse JSON files larger than a certain amount as an added security measure.

but there are some legacy users who have >50mb files on Cryptee from V1 / V2.

This update adds a fallback stream-downloader to server, and a way for the client to request a streaming download instead.

this way, if the client tries to download a file that’s too large, server will return a specific error code (422) indicating that the file is too large for the v3 servers to json parse.

Once the client receives a 422, it’ll make a new download request, this time with the “streamingDownload = 1” to instruct the server not to json parse the file, and once the streaming downlad is completed, client will json parse the file instead.

This means, with this update, we’re shifting the json parse responsibility from server to client for large legacy files. This means for large legacy files, clients may experience some frozen UI etc, but at least files will still be accessible.

+ should fix viewing mode button bug
+ fixes CRYPTEE-54R – [BUG REPORT] AF7E1128
+ fixes locked doc toggle button – thx steffen!
+ fixes locked doc toggle button – thx steffen!
+ fixes panel buttons in safari. thx steffen!
+ fixes localized PDF viewer ui issues. thx Steffen!
+ fixes long filenames bug on Safari! thx Steffen!

Also holy shit apparently Safari doesn’t support “overflow-wrap : anywhere” because … why not … 🤦🏻‍♂️

https://developer.mozilla.org/en-US/docs/Web/CSS/overflow-wrap

+ tiny seo tweaks
+ better lazy loading for landing page

---
## [XilogOfficial/xilog](https://github.com/XilogOfficial/xilog)@[4c353fde5a...](https://github.com/XilogOfficial/xilog/commit/4c353fde5a6096a759271fbb6d14d4df2346b8f4)
#### Tuesday 2021-03-16 08:37:02 by Alan

Removed a lot of jquery dependence, jquery free version coming soon (?)

fuck jquery slow ass shit

---
## [TheXPerienceProject/android_device_xiaomi_sm6250-common](https://github.com/TheXPerienceProject/android_device_xiaomi_sm6250-common)@[7e9f7817bc...](https://github.com/TheXPerienceProject/android_device_xiaomi_sm6250-common/commit/7e9f7817bcfea89ea9b120737a4d3a9289371806)
#### Tuesday 2021-03-16 13:21:32 by klozz

Atoll: Moar sepolicy
Holly shit!!! i hate this

Signed-off-by: klozz <klozz@TheXPerienceProject.org>

---
## [Kitsunemitsu/KirieStation](https://github.com/Kitsunemitsu/KirieStation)@[70e8f31362...](https://github.com/Kitsunemitsu/KirieStation/commit/70e8f313628cb5e25075dbf1ab6d10b6c45346f6)
#### Tuesday 2021-03-16 17:27:50 by Kirie Saito

Fuck you Dumbass Dreammaker

Centcom wasn't loading because a checkbox wasn't checked

---
## [SilentEnforcer/tgwr-mod](https://github.com/SilentEnforcer/tgwr-mod)@[599fe10d8e...](https://github.com/SilentEnforcer/tgwr-mod/commit/599fe10d8e59283157de3a4291ef0f425f608c08)
#### Tuesday 2021-03-16 20:54:10 by Ahmet-Samet

niggers going to bu planes

Based? Based on what? In your dick? Please shut the fuck up and use words properly you fuckin troglodyte, do you think God gave us a freedom of speech just to spew random words that have no meaning that doesn't even correllate to the topic of the conversation? Like please you always complain about why no one talks to you or no one expresses their opinions on you because you're always spewing random shit like poggers based cringe and when you try to explain what it is and you just say that it's funny like what? What the fuck is funny about that do you think you'll just become a stand-up comedian that will get a standing ovation just because you said "cum" in the stage? HELL NO YOU FUCKIN IDIOT, so please shut the fuck up and use words properly you dumb bitch.

---
## [SMF9/oasis](https://github.com/SMF9/oasis)@[400ddaeb8c...](https://github.com/SMF9/oasis/commit/400ddaeb8cc52ec6c752c045adebc7700bf2dd5e)
#### Tuesday 2021-03-16 22:36:28 by SMF9

AGAIN.

sorry just that sometimes my brain is like "yeah lol it's good like that" but no it's not so please understand

---
## [kwangilkimkenny/Story_Analysis](https://github.com/kwangilkimkenny/Story_Analysis)@[773f33afd5...](https://github.com/kwangilkimkenny/Story_Analysis/commit/773f33afd51819b3135c3d9e0070e4b9af528e4d)
#### Tuesday 2021-03-16 23:29:45 by kwangilKyle

개발완료

###### Run ######
# ++++++   값 입력방법   ++++++
# input_text : 입력에세이
# promt_no : 선택질문  >> ex) 'prompt_1'...
# intended_character : mostly me >> 'me' = 1, me & some others : 'meAndOtehrs' = 2, other characters: 'others' = 3
# intended_character의 입력은 'me', 'meAndOtehrs', 'others'


input_text = """Bloomington Normal is almost laughably cliché for a midwestern city. Vast swathes of corn envelop winding roads and the heady smell of BBQ smoke pervades the countryside every summer. Yet, underlying the trite norms of Normal is the prescriptive force of tradition—the expectation to fulfill my role as a female Filipino by playing Debussy in the yearly piano festival and enrolling in multivariable calculus instead of political philosophy.So when I discovered the technical demand of bebop, the triplet groove, and the intricacies of chordal harmony after ten years of grueling classical piano, I was fascinated by the music's novelty. Jazz guitar was not only evocative and creative, but also strangely liberating. I began to explore different pedagogical methods, transcribe solos from the greats, and experiment with various approaches until my own unique sound began to develop. And, although I did not know what would be the 'best' route for me to follow as a musician, the freedom to forge whatever path I felt was right seemed to be exactly what I needed; there were no expectations for me to continue in any particular way—only the way that suited my own desires.While journeying this trail, I found myself at Interlochen Arts Camp the summer before my junior year. Never before had I been immersed in an environment so conducive to musical growth: I was surrounded by people intensely passionate about pursuing all kinds of art with no regard for ideas of what art 'should' be. I knew immediately that this would be a perfect opportunity to cultivate my sound, unbounded by the limits of confining tradition. On the first day of camp, I found that my peer guitarist in big band was another Filipino girl from Illinois. Until that moment, my endeavors in jazz guitar had been a solitary effort; I had no one with whom to collaborate and no one against whom I could compare myself, much less someone from a background mirroring my own. I was eager to play with her, but while I quickly recognized a slew of differences between us—different heights, guitars, and even playing styles—others seemed to have trouble making that distinction during performances. Some even went as far as calling me 'other-Francesca.' Thus, amidst the glittering lakes and musky pine needles of Interlochen, I once again confronted Bloomington's frustrating expectations.After being mistaken for her several times, I could not help but view Francesca as a standard of what the 'female Filipino jazz guitarist' should embody. Her improvisatory language, comping style and even personal qualities loomed above me as something I had to live up to. Nevertheless, as Francesca and I continued to play together, it was not long before we connected through our creative pursuit. In time, I learned to draw inspiration from her instead of feeling pressured to follow whatever precedent I thought she set. I found that I grew because of, rather than in spite of, her presence; I could find solace in our similarities and even a sense of comfort in an unfamiliar environment without being trapped by expectation. Though the pressure to conform was still present—and will likely remain present in my life no matter what genre I'm playing or what pursuits I engage in—I learned to eschew its corrosive influence and enjoy the rewards that it brings. While my encounter with Francesca at first sparked a feeling of pressure to conform in a setting where I never thought I would feel its presence, it also carried the warmth of finding someone with whom I could connect. Like the admittedly trite conditions of my hometown, the resemblances between us provided comfort to me through their familiarity. I ultimately found that I can embrace this warmth while still rejecting the pressure to succumb to expectations, and that, in the careful balance between these elements, I can grow in a way that feels both like discove"""
promt_no = "promt_2"
intended_character = "meAndOtehrs"

result = focusOnCharacters(input_text, promt_no, intended_character)

print(result)

# 결과해석

# admitted_student_for : 문장완성을 위한 값 'Focus on Character(s) by Admitted Students for _선택한 Prompt # 문항_'
# intended_character :  1~3의 결과가 나옴 1: Mostly Me , 2: Me & some others, 3: Other characters
# result:  'Detected characters from essay' 1~3의 결과가 나옴 1: Mostly Me , 2: Me & some others, 3: Other characters
# sentence1 ~5 : 이것은 문장생성 결과

## << Chart 표현 부분 >> ##
# total_character_descriptors_personal:  개인 에세이에서 분석 추출한 총 캐릭터 표현 수
# descriptors_about_yourself : 개인 에세이 추출 표현 about i
# total_character_descriptors_group: 1000명의 에세이에서 공통적으로 추출계산한 캐릭터 총 평균값(임의로 정함, 계산후 넣어야 함)
# descriptors_about_others_group: 1000명의 에세이 추출 others 캐릭터 평균값(임의로 정했음, 계산후 넣어야 함)

## << Emphasis on You vs. Others >> 그래프 표현 부분 ##
# admitted_case_avg : ex) [35. 65] 
# your_essay_you_vs_others : ex) [49, 13] 개인 에세이 계산 결과

# emp_sentence1~4 : Emphasis on You vs. Others의 비교분석값 Sentece 4 커멘트 부분임

---

# [<](2021-03-15.md) 2021-03-16 [>](2021-03-17.md)

