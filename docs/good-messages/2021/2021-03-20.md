# [<](2021-03-19.md) 2021-03-20 [>](2021-03-21.md)

2,470,880 events, 1,227,868 push events, 1,734,699 commit messages, 138,592,266 characters


## [johnmart19/redline_qs_ginkgo@05d672cd1a...](https://github.com/johnmart19/redline_qs_ginkgo/commit/05d672cd1ab1dcc4cc10246135c2fd7130ec2c89)
##### 2021-03-20 03:47:32 by George Spelvin

lib/sort: make swap functions more generic

Patch series "lib/sort & lib/list_sort: faster and smaller", v2.

Because CONFIG_RETPOLINE has made indirect calls much more expensive, I
thought I'd try to reduce the number made by the library sort functions.

The first three patches apply to lib/sort.c.

Patch #1 is a simple optimization.  The built-in swap has special cases
for aligned 4- and 8-byte objects.  But those are almost never used;
most calls to sort() work on larger structures, which fall back to the
byte-at-a-time loop.  This generalizes them to aligned *multiples* of 4
and 8 bytes.  (If nothing else, it saves an awful lot of energy by not
thrashing the store buffers as much.)

Patch #2 grabs a juicy piece of low-hanging fruit.  I agree that nice
simple solid heapsort is preferable to more complex algorithms (sorry,
Andrey), but it's possible to implement heapsort with far fewer
comparisons (50% asymptotically, 25-40% reduction for realistic sizes)
than the way it's been done up to now.  And with some care, the code
ends up smaller, as well.  This is the "big win" patch.

Patch #3 adds the same sort of indirect call bypass that has been added
to the net code of late.  The great majority of the callers use the
builtin swap functions, so replace the indirect call to sort_func with a
(highly preditable) series of if() statements.  Rather surprisingly,
this decreased code size, as the swap functions were inlined and their
prologue & epilogue code eliminated.

lib/list_sort.c is a bit trickier, as merge sort is already close to
optimal, and we don't want to introduce triumphs of theory over
practicality like the Ford-Johnson merge-insertion sort.

Patch #4, without changing the algorithm, chops 32% off the code size
and removes the part[MAX_LIST_LENGTH+1] pointer array (and the
corresponding upper limit on efficiently sortable input size).

Patch #5 improves the algorithm.  The previous code is already optimal
for power-of-two (or slightly smaller) size inputs, but when the input
size is just over a power of 2, there's a very unbalanced final merge.

There are, in the literature, several algorithms which solve this, but
they all depend on the "breadth-first" merge order which was replaced by
commit 835cc0c8477f with a more cache-friendly "depth-first" order.
Some hard thinking came up with a depth-first algorithm which defers
merges as little as possible while avoiding bad merges.  This saves
0.2*n compares, averaged over all sizes.

The code size increase is minimal (64 bytes on x86-64, reducing the net
savings to 26%), but the comments expanded significantly to document the
clever algorithm.

TESTING NOTES: I have some ugly user-space benchmarking code which I
used for testing before moving this code into the kernel.  Shout if you
want a copy.

I'm running this code right now, with CONFIG_TEST_SORT and
CONFIG_TEST_LIST_SORT, but I confess I haven't rebooted since the last
round of minor edits to quell checkpatch.  I figure there will be at
least one round of comments and final testing.

This patch (of 5):

Rather than having special-case swap functions for 4- and 8-byte
objects, special-case aligned multiples of 4 or 8 bytes.  This speeds up
most users of sort() by avoiding fallback to the byte copy loop.

Despite what ca96ab859ab4 ("lib/sort: Add 64 bit swap function") claims,
very few users of sort() sort pointers (or pointer-sized objects); most
sort structures containing at least two words.  (E.g.
drivers/acpi/fan.c:acpi_fan_get_fps() sorts an array of 40-byte struct
acpi_fan_fps.)

The functions also got renamed to reflect the fact that they support
multiple words.  In the great tradition of bikeshedding, the names were
by far the most contentious issue during review of this patch series.

x86-64 code size 872 -> 886 bytes (+14)

With feedback from Andy Shevchenko, Rasmus Villemoes and Geert
Uytterhoeven.

Link: http://lkml.kernel.org/r/f24f932df3a7fa1973c1084154f1cea596bcf341.1552704200.git.lkml@sdf.org
Signed-off-by: George Spelvin <lkml@sdf.org>
Acked-by: Andrey Abramov <st5pub@yandex.ru>
Acked-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Cc: Geert Uytterhoeven <geert@linux-m68k.org>
Cc: Daniel Wagner <daniel.wagner@siemens.com>
Cc: Don Mullis <don.mullis@gmail.com>
Cc: Dave Chinner <dchinner@redhat.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

---
## [Proxyer/NewRatkin@06b075dd40...](https://github.com/Proxyer/NewRatkin/commit/06b075dd40aa35afcce346b3b2fcfa3b3dbad03d)
##### 2021-03-20 10:17:46 by Proxyer

Japanese translation update: 20 Mar, 2021

 - Add "Ratkin shepherd boy" has "girl" female backstory.
 - Add "Ratkin heir" has "heiress" female backstory
 - Add new young girl only backstory "Apprentice seamstress".
 - Add new backstory "Farmhand".
 - Add new backstory type B "Guardener leader".
 - Add new female only backstory "Seamstress".

---
## [mrakgr/The-Spiral-Language@29bbee1e97...](https://github.com/mrakgr/The-Spiral-Language/commit/29bbee1e979934d90f2179684cbea567bc7c9c35)
##### 2021-03-20 11:16:09 by Marko GrdiniÄ‡

"9:25am. I am up.

Let me chill a bit and then I will start. What I will do in the morning session is go through the Kivy crash course. After taking hours just to do a scroll view label, my motivation to actually sit down and learn has gone up significantly.

9:55am. Let me start. It is time for that crash course.

During the night I've realized something - rather than applying for job, if I am really serious I should start a company and pretend to be multiple people. People would balk at paying 200k per year to one person, but 50k for 4 people would be quite palatable.

I rarely see this kind of power move being encouraged, but this is something I would do.

Right now, in Python I am good as 0.5 people so no way could I sustain that. .NET would be fine, but Python is another ballgame and I am missing too many things at the moment.

As for Spiral, it will be the last time I will do something in anticipation of the future. If I had started work on 2005 and finished it in a few years, I'd have time to build up my prestige. Then I could conquer the AI chip market. But right now, that is just a delusion.

Ultimately, this is an arms race and I should not be obligated to speed up the pace at which my adversaries can reach the Singularity. I do not have an obligation to make a library only for the company to go belly up and waste my time.

I'll do things at my own pace.

10:05am. https://www.youtube.com/playlist?list=PLdNh1e1kmiPP4YApJm8ENK2yMlwF1_edq

Let me start going through this list. Once I build up some proficiency in making UIs with Kivy, my work will get a lot easier.

The ramp up phase will take a while. I still do not know much about Python concurrency either. But .NET is not really a viable platform for ML due to lack of ref counting. It is superior in every other aspect compared to this one, but this one is the one that really matters.

10:10am. I really want to get familiar with the ways of doing concurrency in Python. I do not have Hopac unfortunately, but I want to get my proficiency up as much as possible regardless.

All this will take a while. Let me get to it. At some point I will be good enough.

10:20am. https://youtu.be/ZmteLworB4E?list=PLdNh1e1kmiPP4YApJm8ENK2yMlwF1_edq&t=368

Hmmm, this is not so bad. It feels fairly expressive.

10:45am. https://youtu.be/2Gc8iYJQ_qk?list=PLdNh1e1kmiPP4YApJm8ENK2yMlwF1_edq&t=256

This is worth watching. I am learning a lot about how Kivy works.

11:10am. https://www.youtube.com/watch?v=ChmfVOu9aIc&list=PLdNh1e1kmiPP4YApJm8ENK2yMlwF1_edq&index=11

I should just about have time to finish this before breakfast. It has been worth it so far.

11:50am. https://youtu.be/xx-NLOg6x8o?list=PLdNh1e1kmiPP4YApJm8ENK2yMlwF1_edq&t=574

Hmmm, maybe it would be worth it to use the screen manager to switch between the menu and the current ongoing game.

One thing I've been unsure is how during the duration of the game I could deal with managing the replay buffer.

Like in poker apps, you can look at hand histories while the game is ongoing. I've been feeling that my current way of thinking lacks flexibility. I thought aobut using tabs, but maybe this thing would be better.

https://www.youtube.com/watch?v=oXlwWbU8l2o
OpenCV Course

I just noticed this on the sidebar.

Yeah, OpenCV is on my TODO list. When I do the reverse UIs, I can't afford to hardcode all the positions. Instead, the agent will require some ability to understand the desktop. But actually training a CNN to interpret my own moves would be way too expensive. Though classical computer vision is getting obsoleted by CNNs, this might be one area where it could shine.

I won't do study this right now, but a few months down the road. Right now I need to improve my UI and ML skills. That will be my focus.

12:10pm. Time for breakfast. I am thinking about random things. I think I am going to consider the case where an UI component is dedicated to a single game. I'll make a view just for that. And then move towards towards implementing it.

That should be my goal for today. A fancy control center can wait until I've build up enough experience. I'll do things step by step without rushing. That is the way to establish a proper foundation.

One language feature I am sorely missing right now are interpolated strings. It is really killing me to use macros for that right now. Along with standard library structures, this is really a hole that needs filling at some point

12:15pm. Let me stop. Time to chill.

My anime backlog keeps growing because I keep reading RI. At this point, maybe I will catch up completely in a few weeks."

---
## [Amorymeltzer/dotfiles@0d2f32d155...](https://github.com/Amorymeltzer/dotfiles/commit/0d2f32d155b0f838ece921f4fcfefea4d025df13)
##### 2021-03-20 16:00:46 by Amory Meltzer

.bashrc: Remove beloved cask alias, more fallout from unification

"Funny, sir, how you always seem to find yourself in an Alliance-friendly bar, come U-Day, lookin' for a quiet drink."

---
## [ignasoler/Coursera_Capstone@d56d9509be...](https://github.com/ignasoler/Coursera_Capstone/commit/d56d9509be44bd0bd954b654623123a274175ce2)
##### 2021-03-20 16:01:38 by ignasoler

Business Proposal

The Battle of Neighborhoods | Business Proposal | Introduction
Introduction:
The purpose of this Project is to help people in exploring better facilities around their neighborhood. It will help people making smart and efficient decision on selecting great neighborhood out of numbers of other neighborhoods in Scarborough, Toranto.

Lots of people are migrating to various states of Canada and needed lots of research for good housing prices and reputated schools for their children. This project is for those people who are looking for better neighborhoods. For ease of accessing to Cafe, School, Super market, medical shops, grocery shops, mall, theatre, hospital, like minded people, etc.

This Project aim to create an analysis of features for a people migrating to Scarborough to search a best neighborhood as a comparative analysis between neighborhoods. The features include median housing price and better school according to ratings, crime rates of that particular area, road connectivity, weather conditions, good management for emergency, water resources both freash and waste water and excrement conveyed in sewers and recreational facilities.

It will help people to get awareness of the area and neighborhood before moving to a new city, state, country or place for their work or to start a new fresh life.

Problem Which Tried to Solve:
The major purpose of this project, is to suggest a better neighborhood in a new city for the person who are shiffting there. Social presence in society in terms of like minded people. Connectivity to the airport, bus stand, city center, markets and other daily needs things nearby.

Sorted list of house in terms of housing prices in a ascending or descending order
Sorted list of schools in terms of location, fees, rating and reviews
The Location:
Scarborough is a popular destination for new immigrants in Canada to reside. As a result, it is one of the most diverse and multicultural areas in the Greater Toronto Area, being home to various religious groups and places of worship. Although immigration has become a hot topic over the past few years with more governments seeking more restrictions on immigrants and refugees, the general trend of immigration into Canada has been one of on the rise.

Foursquare API:
This project would use Four-square API as its prime data gathering source as it has a database of millions of places, especially their places API which provides the ability to perform location search, location sharing and details about a business.

Work Flow:
Using credentials of Foursquare API features of near-by places of the neighborhoods would be mined. Due to http request limitations the number of places per neighborhood parameter would reasonably be set to 100 and the radius parameter would be set to 500.

Clustering Approach:
To compare the similarities of two cities, we decided to explore neighborhoods, segment them, and group them into clusters to find similar neighborhoods in a big city like New York and Toronto. To be able to do that, we need to cluster data which is a form of unsupervised machine learning: k-means clustering algorithm

Libraries Which are Used to Develope the Project:
Pandas: For creating and manipulating dataframes.

Folium: Python visualization library would be used to visualize the neighborhoods cluster distribution of using interactive leaflet map.

Scikit Learn: For importing k-means clustering.

JSON: Library to handle JSON files.

XML: To separate data from presentation and XML stores data in plain text format.

Geocoder: To retrieve Location Data.

Beautiful Soup and Requests: To scrap and library to handle http requests.

Matplotlib: Python Plotting Module.

---
## [mrakgr/The-Spiral-Language@2746700b74...](https://github.com/mrakgr/The-Spiral-Language/commit/2746700b74e40a34577b9f94e60113bc56464437)
##### 2021-03-20 18:40:56 by Marko GrdiniÄ‡

"1:25pm. Done with breakfast. Just a bit more chilling and I'll move to the chores. After that I'll get the human player going.

2:35pm. The chores really took a while. Phew.

2:40pm. Let me start my daily dose of programming.

2:45pm.

```
open kivy
open lithe

union msg =
    | Clicked

type state (a : * -> * -> *) (b : * -> * -> *) = {
    p1 : nodes.player_funs a leduc.card leduc.action f64
    p2 : nodes.player_funs b leduc.card leduc.action f64
    text : string
    }

inl model (s : state _ _) = function
    | Clicked =>
        open nodes
        inl Empty = player {probSelf=to_log_prob 1; observations=Nil; state=agent.stateless()} |> dyn
        inl r = leduc.game (nodes.cps.nodes_2p (s.p1, s.p2)) ((Empty,Empty),dyn id)
        inl ts = $"f\"Reward for player one is {!r}.\\n\"" : string
        {s with text#=fun t => $"!t + !ts"}

inl view dispatch (state : rx.observable (state _ _)) =
    inl (~+) x = +state x
    boxlayout [
        -orientation Vertical
        children [
            scrollview [
                -do_scroll_x false
                -do_scroll_y true
                children [
                    label [
                        -size_hint_y None
                        @on_texture_size (fun (l,(_,v)) => $"!l.height = !v")
                        +text fun {text} => text
                        ]
                    ]
                ]
            boxlayout [
                -orientation Horizontal
                -size_hint_y (Some: 0.2)
                children [
                    button [
                        -text "Start Game."
                        @on_press (fun _ => dispatch Clicked)
                        ]
                    ]
                ]
            ]
        ]

inl main () =
    inl app = appm.create()
    inl p1 = agent.neural_random.create()
    inl p2 = agent.uniform_random.create()
    inl text = ""
    inl _ = rx.subscribe (loop {p1 p2 text} model view) (appm.root app)
    appm.run app
```

I touched this up a bit, but let me leave it as so. Let me turn off the router otherwise I will not pry myself off /a/.

2:50pm. What is the next step?

I had a bit of inspiration during the break. Maybe it is because of my 2016 experience, but I am not thinking of UIs in modular enough fashion.

Because if that I keep dithering between various choices. I am trying to go forward, but I am encountering too much friction.

2:55pm. It is a difficult thing to make a single step.

The reason why I've managed to come this far is because I know that even a single step, no matter how insignificant it seems in isolation bring me closer to my ultimate goal.

But with UIs, I am carrying a mentality of it being one big object. I think I never shook off the mentality with the NetMQ examples that I did either.

I spent too much time on those in hindsight.

But it is just like with Spiral's editor support. My first attempt was a failure, my second was a partial success and my most recent was a complete success.

This whole thing of making a RL agent + am UI depends mostly on my UI skills. UIs are the big bottleneck. It does not matter if this next part takes me a few months. I could make huge gains if I can master this.

Right now I am strugling, but the future me could sit down and knock it all out in a day or two.

What will take me weeks, the future me will need only a day.

3:05pm. I am thinking about string interpolation right now. I can't really use the generic design F# and Python have.

I can't really just plug in vars of arbitrary types into it. Instead as a compromise, I should just type them as strings. That would be a decent compromise. I could always build on that solution later. Nevermind this for now.

I went through the docs, I went through the course. I have basic skills in Kivy. I need to keep going forward. Eventually I'll cover all the widgets and internalize them.

Let me just dwell on this next part for a bit. What exactly do I want? I know what I want, but not exactly.

4:15pm. Let me go take a bath. I am still thinking about it.

5:55pm. Done with lunch. Today I did not do much after all.

Rather than a glorious pursuit it feels more like the first half of 2020. Back then I spent an enormous amount of time just getting myself to the starting line of even being able to work on Spiral.

Today I could have done that human player UI. I could have done string interpolation. Instead I am just swaying in this chair or on the bed, gathering my thoughts.

6:05pm. This is a sign that I am too pressured right now.

Yeah, a deadline of 3 months is not enough. I am just not feeling it. I should give myself as much time as needed to cultivate my Python UI and concurrency skills properly.

I am going into this with a combative mindset, but the kind of work I need to be doing is more like art.

To explain what my problem is, I am pulled in two different directions. The first vector is pulling me in the direction of 2018. That is - finish Spiral, then with into RL as soon as possible. I've been intending to go on this trajectory.

But the second impulse is to cultivate UIs and concurrency skills.

6:10pm. Today my goal was to do the human UI.

That is fine. I'll be able to use it as a component in a bigger UI that will allow me to manage players and replay buffers.

But what should the human UI component be like?

It can just be a label with the trace printed out on it and a few button for action selection.

6:10pm. Today when I watched one of the videos, there was a neat demo showing Kivy animations.

My emotion at that time was interest.

In fact, if I had to implement the human UI, instead of a text printout of the trace, why not diplay the stack size and the card like on a real poker table.

Animations for cards, proper graphics. I could even add a little back button to wind back the last move.

6:15pm. That would be good to have and yet here I am trying to push the fast forward button on my development. I barely want to make time to do string interpolation.

I want to go forward, but these thoughts are at the back of my mind pressuring me.

6:20pm. In order to develop skills it is not enough to just run forward. You need to be like a little kid and play.

Kids become adults, and adults supposedly get things done, but that is not true. Those who play around are much stronger long term than those who just do what they must.

Thought most of that time was wasted, what I did in 2020 was a show of strength. Strained as it were, I did the right thing by overcoming my past inhibitions. I did the right thing by taking the time to do that.

6:25pm. Right now I am strained again. My failure to apply to AI chip companies is just one of the symptoms of me being in a delusional state.

I spent six years programming to get to this point, Spiral v2 is done. I want to want to keep shouting and show the world how great my skills are. But somehow the world is not cooperating and giving me the chance that I want.

Instead the message I am getting back is that it does not really matter whether I am good or not. Note that this is distinct of it saying that I am bad.

6:30pm. The old me would have approved of my current skills and my never ending effort. But I am not sure that he would have approved of my obsession to make money. Society beat this into me, and I need to beat it out.

Society knows jack shit about skill development. Culture the way it is now is a turd on the side of the road. It is 2000 year old Christian values, perverted and degenerated. Beggars are kings, degeneracy is virtue, rebellion is stability, druggies and drunkards are the pillars of society and technology is just some tool. Life is a cycle. Happiness is true meaning. Everything can be forgiven. Schools are useless. Proofs certainly aren't simple to understand explanations that can be traced.

6:40pm. My desire to make money is partly with how distasteful I find science to be. The current science caste does not deserve its position of prestige. If somebody stumbles on a breakthrough AI discovery in the 20s, it will be by accident rather than clear thinking.

Playing around is not just for the sake of playing around. The kids aren't the ones wasting time.

6:45pm. I should just play. It is the height of idiocy to make career plans in the present age. What is the point of investing in the stock market when it might not even be around in a decade?

I know that it is going to happen, but I am not acting like I 100% believe in it. Maybe I believe 90% in it. I like my hedging bets. This is better than the maybe 0-10% belief of the people on the ML sub.

Forget money. Focus on absolute power.

6:50pm. Forget my current age and circumstances. Living on the edge means giving up opportunities.

I am going to abandom my plans of doing the RL agents as soon as possible. Forget that goal. Forget the AI chips. Forget making money through Spiral or gathering donations.

Instead I should focus on making my UI experience as great as possible.

Nevermind that I am doing it for Leduc poker. It does not matter if I do art or music along the way or spent an inordinate amount of time on the design. It does not matter if I take the time to put in language feature like string interpolation.

6:55pm. I am sick of ML. I am sick of language development. I am sick of racing towards success.

I want my programming to be art from here on out. I want things to be easy and for it to come to me naturally. I want to properly abstract ML into proper components. I do not want to be rushed.

I want to consolidate all of my skills.

7pm. Ultimately, I'll still be going where I want. I'll still do the human UI next.

But I need to accept - I cannot do what I want if my goal is to make that DREAM agent as soon as possible.

If my goal is to get back into ML as soon as possible, I should not be working on the UIs in the first place.

If my goal is to get into ML as soon as possible - my 2018 experience was the ideal undertaking! I fired up my brain, pushed myself to the limit and got nowhere for it. I failed!

So why I am I trying to keep that failed ideal alive?

Isn't my new belief that user experience is worth exercising for its own sake?

If cultivating UX skills is my primary goal, then why am I pressuring myself to start RL as soon as possble?

I have time. Maybe somebody else will cause the Singularity in the 20s. Maybe I will need 20-30 more years myself at this rate. Maybe a few Simulacrum readers will be disappointed that my 2022 prediction did not pan out. Screw them. They aren't my power. Neither is anybody reading this journal.

7:10pm. The UX skills are what will evetually make ML easy enough to be tractable.

So I am going to go wild with them. It does not matter how long it takes. Let me make a proper Leduc poker game. Graphics, animations, sounds, keyboard input, time rewinding, charts, replay buffer analysis.

```
inl ts = $"f\"Reward for player one is {!r}.\\n\"" : string
```

As a matter of principle I will stop using Python's string interpolation macros. Until Spiral has its own native string interpolation, I'll at least put them in a list and then join them. This here is just nasty.

7:15pm. In 2016 I only spent a month working on that poker app before giving up. Maybe if I'd put in more effort, I'd realized how good Rx is in the end.

Just how many months of grinding the VS Code API took me to arrive at those epiphanies?

The amount of effort I put into Spiral v2 for the sake improving the user experience is astonishing. I should show this same dedication when making the games for my agents.

If there exists a God, I'd bet it took him more effort to create the universe than to evolve humans. Once the universe was there, intelligent life sprung up on its own. I should learn from that.

7:20pm. Besides the above, I want to resume going through Processing tutorials tomorrow. That is how I should split my time.

Though I did those players and have set everything up, I somehow really dislike the observation traces.

Instead of doing the human UI, I should do the plain UI.

I should display the cards, the stacks and the actions. That is what the state should be. Not some trace. Forget the agents. The UI is what should be central to my consideration.

7:25pm. I am wrong with my current approach. Right now I am still trying to pare things down and abstract things. Instead like with Spiral's editor support, I should keep information around. Or I should make up my mind and make an interpreter for the traces, since I do not want to put game state directly in the nodes.

Right now I am still missing something. I need to be aggressive, but I need to aim in the right direction as well.

I should forget the Leduc game itself and try doing the UI in isolation.

7:30pm. In addition to Processing, I really should check out more Python concurrency. I keep yearning for that Hopac feeling.

7:35pm. Let me just stop here.

Tomorrow, I will do the smallest possible moves until I get the feeling that I want. At some point I will overcome the weaknesses that Python imposes on me and will be able to benefit from its strengths. I won't be arrogant about this work. Yesterday I spent the entire day trying to get the scroll view to work. I should do more of that. That was the way to go."

---
## [ajkalinin/based.cooking@99da8d68a2...](https://github.com/ajkalinin/based.cooking/commit/99da8d68a24cf9b6c635d41ee8b3f8af3896e0df)
##### 2021-03-20 19:31:53 by ajkalinin

Create Toum (garlic paste).md

# Classic Mediterranean restaurant grade garlic paste

- â²ï¸ Prep time: 15m
- ðŸ³Process time: 5-10 minutes

## Ingredients

- 1 cup of peeled and rinsed garlic cloves.  Hardneck garlic tastes better if you can obtain it.
- 1/2 cup of lemon juice
- 1 1/2 to 2 teaspoons of salt depending on taste
- 2 to 3 cups of a bland vegetable oil (corn, canola) or very light olive oil.  I notice heavier oils yield a thicker product.

## Directions

Order is important here, as you are forming a water-in-oil emulsion.  The finished product will have a sheen and the consistency of mayonnaise. 

1. In a good size food processor, grind your garlic and salt together until fairly smooth.
2. Stop your processor and add lemon juice.  Restart processor and grind until well mixed.
3. Now the important part - while the processor is running, start to slowly (but steadily) drip your oil into the rotating mass.
4. You won't start to see results until about 1 1/2 cups are in, but keep going.
4. When the emulsion forms, you will notice a significant volumetric increase of the contents of the food processor.
5. At the point that the mixture attains the consistency of mayonnaise, hardly moves and you have added most or all the oil, you are done.
6. Stop the processor.  If you overheat the mixture, the emulsion will break and all you'll be left with is a big gooey mess.

Goes excellent of a variety of pita, naan and other breads, main dishes or whatever you intend to use it for.  

Will keep for about a week in the refrigerator if your friends and family don't polish it off. 

## Contribution
akalinin@wowway.com

;tags: garlic, Mediterranean, basic garlic sauce

---
## [kraj/binutils-gdb@08c428aff4...](https://github.com/kraj/binutils-gdb/commit/08c428aff4a793b63c7dd2229ae172879623e3a2)
##### 2021-03-20 22:27:14 by Nick Alcock

libctf: eliminate dtd_u, part 5: structs / unions

Eliminate the dynamic member storage for structs and unions as we have
for other dynamic types.  This is much like the previous enum
elimination, except that structs and unions are the only types for which
a full-sized ctf_type_t might be needed.  Up to now, this decision has
been made in the individual ctf_add_{struct,union}_sized functions and
duplicated in ctf_add_member_offset.  The vlen machinery lets us
simplify this, always allocating a ctf_lmember_t and setting the
dtd_data's ctt_size to CTF_LSIZE_SENT: we figure out whether this is
really justified and (almost always) repack things down into a
ctf_stype_t at ctf_serialize time.

This allows us to eliminate the dynamic member paths from the iterators and
query functions in ctf-types.c in favour of always using the large-structure
vlen stuff for dynamic types (the diff is ugly but that's just because of the
volume of reindentation this calls for).  This also means the large-structure
vlen stuff gets more heavily tested, which is nice because it was an almost
totally unused code path before now (it only kicked in for structures of size
>4GiB, and how often do you see those?)

The only extra complexity here is ctf_add_type.  Back in the days of the
nondeduplicating linker this was called a ridiculous number of times for
countless identical copies of structures: eschewing the repeated lookups of the
dtd in ctf_add_member_offset and adding the members directly saved an amazing
amount of time.  Now the nondeduplicating linker is gone, this is extreme
overoptimization: we can rip out the direct addition and use ctf_member_next and
ctf_add_member_offset, just like ctf_dedup_emit does.

We augment a ctf_add_type test to try adding a self-referential struct, the only
thing the ctf_add_type part of this change really perturbs.

This completes the elimination of dtd_u.

libctf/ChangeLog
2021-03-18  Nick Alcock  <nick.alcock@oracle.com>

	* ctf-impl.h (ctf_dtdef_t) <dtu_members>: Remove.
	<dtd_u>: Likewise.
	(ctf_dmdef_t): Remove.
	(struct ctf_next) <u.ctn_dmd>: Remove.
	* ctf-create.c (INITIAL_VLEN): New, more-or-less arbitrary initial
	vlen size.
	(ctf_add_enum): Use it.
	(ctf_dtd_delete): Do not free the (removed) dmd; remove string
	refs from the vlen on struct deletion.
	(ctf_add_struct_sized): Populate the vlen: do it by hand if
	promoting forwards.  Always populate the full-size
	lsizehi/lsizelo members.
	(ctf_add_union_sized): Likewise.
	(ctf_add_member_offset): Set up the vlen rather than the dmd.
	Expand it as needed, repointing string refs via
	ctf_str_move_pending. Add the member names as pending strings.
	Always populate the full-size lsizehi/lsizelo members.
	(membadd): Remove, folding back into...
	(ctf_add_type_internal): ... here, adding via an ordinary
	ctf_add_struct_sized and _next iteration rather than doing
	everything by hand.
	* ctf-serialize.c (ctf_copy_smembers): Remove this...
	(ctf_copy_lmembers): ... and this...
	(ctf_emit_type_sect): ... folding into here. Figure out if a
	ctf_stype_t is needed here, not in ctf_add_*_sized.
	(ctf_type_sect_size): Figure out the ctf_stype_t stuff the same
	way here.
	* ctf-types.c (ctf_member_next): Remove the dmd path and always
	use the vlen.  Force large-structure usage for dynamic types.
	(ctf_type_align): Likewise.
	(ctf_member_info): Likewise.
	(ctf_type_rvisit): Likewise.
	* testsuite/libctf-regression/type-add-unnamed-struct-ctf.c: Add a
	self-referential type to this test.
	* testsuite/libctf-regression/type-add-unnamed-struct.c: Adjusted
	accordingly.
	* testsuite/libctf-regression/type-add-unnamed-struct.lk: Likewise.

---

# [<](2021-03-19.md) 2021-03-20 [>](2021-03-21.md)

