# [<](2021-12-19.md) 2021-12-20 [>](2021-12-21.md)

1,789,957 events recorded by [gharchive.org](https://www.gharchive.org/) of which 1,789,957 were push events containing 2,604,370 commit messages that amount to 207,940,340 characters filtered with [words.py@e23d022007...](https://github.com/defgsus/good-github/blob/e23d022007992279f9bcb3a9fd40126629d787e2/src/words.py) to these 33 messages:


## [jgomez002/Final-Project](https://github.com/jgomez002/Final-Project)@[041015a550...](https://github.com/jgomez002/Final-Project/commit/041015a550e113fc1e2af00c4bdaedb70ebaaa66)
#### Monday 2021-12-20 01:52:09 by jgomez002

hugeee push

so during my process i was really caught up in trying to make the code work out I forgot to push regularly so this is a huge update.

Despite how it seem, this game isn't interactive all all but it almost like the charcter interacts with the player. Using txt files, audio, video, and console tease had allowed me to make this creppy meta/4th wall type of narrtive which I really enjoy.

I was able to impletment txt string dialouge, save files, and sound to add to the atmostphere

I really struggled on trying to make a typewriter animation for the text. Sadly I never got it to work and spend hours on these effect for nothing :(

I did divate from orginal plans which I think turned out well.

In my process i utilzied txt files to make onscreen and off screen dialouge

Using the console to directly speak to the user if definelty my proud effects. Its so invasive yet distant.

in open processing at least one of my sound files crash the whole browers thing but also makes it disorted when it was supposed to be cute

this was a plus and a loss as i wanted to introduce creepy vibes later in my game.

Enjoy this huge push, and see my easter eggs in the open processing files :))

---
## [fighterslam/Shiptest](https://github.com/fighterslam/Shiptest)@[2c3e36df75...](https://github.com/fighterslam/Shiptest/commit/2c3e36df75d18f0970a199d0780f04215033232c)
#### Monday 2021-12-20 02:33:27 by Omppusolttu

Scrapper-b Update (#417)

* Discovery Update

* Fuck you. *unfucks your scrapper-b

* Add files via upload

---
## [fighterslam/Shiptest](https://github.com/fighterslam/Shiptest)@[bccb2d32d3...](https://github.com/fighterslam/Shiptest/commit/bccb2d32d3f82bfa5ea3e24543f08590c45b618e)
#### Monday 2021-12-20 02:33:27 by Omppusolttu

Scrapper Update (#416)

* scrapper update

* fix

* Fuck you. *unfucks your scrapper-A*

* Add files via upload

---
## [weizhengte/incubator-doris](https://github.com/weizhengte/incubator-doris)@[ef2ea1806e...](https://github.com/weizhengte/incubator-doris/commit/ef2ea1806e4fb77369ab17a02d20fc8a286be43e)
#### Monday 2021-12-20 02:44:53 by HB

[docs] Improve the chapter on debugging FE in doc.  (#7309)

At present, there are defects in the chapter on debugging FE in doc. My colleagues and I stepped on the pit when 
building the debugging environment, so I want to improve this chapter in combination with my own stepping on the pit 
experience.

The following is my explanation of the changes: 

1. mkdir -p ./thirdparty/installed/bin
explain: When I downloaded versions 0.14 and 0.15, there were no files under thirdparty, so I didn't know whether to 
create it myself or what to do. Finally, I decided to create it myself. I think it's necessary to add instructions here.

2. Add installation thrift@0.13.0 Failed handling method. 
explain: My colleagues and I failed to find the installation package when executing the installation command, and finally 
found a solution on GitHub. Therefore, I added the handling method of the problem to avoid other Mac users from 
getting stuck in this place.

3. Fixed an error in the generated code description.
explain: Before I finished building the code, I debugged FE, and I failed all the time. Idea hints that no files can be found. 
Later, after consulting with morningman in wechat group, it was understood that `mvn install -DskipTests` does not 
need to execute `mvn generate-sources` after execution. This is inconsistent with the description in the document and 
needs to be corrected.

---
## [Azarak/Skyrat-tg](https://github.com/Azarak/Skyrat-tg)@[90a7aaff28...](https://github.com/Azarak/Skyrat-tg/commit/90a7aaff286b5bde4e93b9cb8e4675f3e9be5893)
#### Monday 2021-12-20 03:53:28 by SkyratBot

[MIRROR] Reduces the move delay buffer to 1 tick, fixes "Flash stepping" (Is that what the kids are calling it?) [MDB IGNORE] (#10013)

* Reduces the move delay buffer to 1 tick (#63332)

We've got this delay buffer behavior
Idea is basically, if we're just holding down the key, just keep adding to the old delay
This way, fractional move delays make sense

Was added in this commit 491bdac

When it was added, movement was triggered by verbs sent by the client
So we needed a big grace window to account for networking delay

Don't need that anymore cause we use keyLoop, so let's just cut it all the way down

Why?
Because right now if you somehow manage to input a move afer move_delay is up
but before the window runs out, you will be elidgable for a new move before you visually reach the tile

Got a dm from mothblocks about this last night, something about flash stepping? IDK I don't play here
Seems silly though, let's sweep this up

Oh and mothblocks owes me a pizza, please add this to the commit history so it can be certified as a part of the blockchain

* Reduces the move delay buffer to 1 tick, fixes "Flash stepping" (Is that what the kids are calling it?)

Co-authored-by: LemonInTheDark <58055496+LemonInTheDark@users.noreply.github.com>

---
## [madolson/redis](https://github.com/madolson/redis)@[0e5b813ef9...](https://github.com/madolson/redis/commit/0e5b813ef94b373f82bc75efcf3405f2c81af3dc)
#### Monday 2021-12-20 05:44:55 by yoav-steinberg

Multiparam config set (#9748)

We can now do: `config set maxmemory 10m repl-backlog-size 5m`

## Basic algorithm to support "transaction like" config sets:

1. Backup all relevant current values (via get).
2. Run "verify" and "set" on everything, if we fail run "restore".
3. Run "apply" on everything (optional optimization: skip functions already run). If we fail run "restore".
4. Return success.

### restore
1. Run set on everything in backup. If we fail log it and continue (this puts us in an undefined
   state but we decided it's better than the alternative of panicking). This indicates either a bug
   or some unsupported external state.
2. Run apply on everything in backup (optimization: skip functions already run). If we fail log
   it (see comment above).
3. Return error.

## Implementation/design changes:
* Apply function are idempotent (have no effect if they are run more than once for the same config).
* No indication in set functions if we're reading the config or running from the `CONFIG SET` command
   (removed `update` argument).
* Set function should set some config variable and assume an (optional) apply function will use that
   later to apply. If we know this setting can be safely applied immediately and can always be reverted
   and doesn't depend on any other configuration we can apply immediately from within the set function
   (and not store the setting anywhere). This is the case of this `dir` config, for example, which has no
   apply function. No apply function is need also in the case that setting the variable in the `server` struct
   is all that needs to be done to make the configuration take effect. Note that the original concept of `update_fn`,
   which received the old and new values was removed and replaced by the optional apply function.
* Apply functions use settings written to the `server` struct and don't receive any inputs.
* I take care that for the generic (non-special) configs if there's no change I avoid calling the setter (possible
   optimization: avoid calling the apply function as well).
* Passing the same config parameter more than once to `config set` will fail. You can't do `config set my-setting
   value1 my-setting value2`.

Note that getting `save` in the context of the conf file parsing to work here as before was a pain.
The conf file supports an aggregate `save` definition, where each `save` line is added to the server's
save params. This is unlike any other line in the config file where each line overwrites any previous
configuration. Since we now support passing multiple save params in a single line (see top comments
about `save` in https://github.com/redis/redis/pull/9644) we should deprecate the aggregate nature of
this config line and perhaps reduce this ugly code in the future.

---
## [outreachy/website](https://github.com/outreachy/website)@[8f83b8090c...](https://github.com/outreachy/website/commit/8f83b8090cda15c08ea9e14e28a525141609db4f)
#### Monday 2021-12-20 06:45:09 by Sage Sharp

Week 3 chat: change topic back to everyone struggles

For the May 2021 cohort, we tried changing the week 3 chat topic to be
about confusing open source vocabulary. While the chat was lively, we
noticed that we had a higher than normal amount of interns who were
struggling and not talking to their mentor, or who were shy about asking
questions of their mentor.

We think the week 3 chat really normalizes that it's okay to struggle,
and it's important that interns reach out for help when they're stuck.

We have received feedback that interns are uncomfortable sharing how
they're struggling if their mentors are participating in the chat. So we
are moving the chat into the interns & alums private channel.

There might be some mentors who are past Outreachy interns in that
channel, but I don't want to create a new channel every cohort for just
this chat. It's also a pain to add people to a stream outside of when
they're initial subscribed. You have to add people individually.

Interns also told us in the past that they were uncomfortable writing
about what they were struggling with. So we'll keep the blog post about
confusing open source vocabulary instead. I still shared the rubber duck
debugging article, because I like it a lot, but it may be less relevant.

---
## [fredKonan/books](https://github.com/fredKonan/books)@[6a1c373bbf...](https://github.com/fredKonan/books/commit/6a1c373bbfaca3d19fe88ce7dea86fd6063ef738)
#### Monday 2021-12-20 07:45:16 by Fred.K

Update README.md

8th Light Application - Kristina Jaggard
This is a command line application that allows you to search the Google Books API and create a reading list.

🏁 Getting started
These instructions assume that you have already downloaded Git and Node and that you have a basic understanding of the command line. 🕺

Open up your terminal and clone this repository in a location of your choosing.
git clone https://github.com/teenie-quaggard/google-books-api.git

Navigate into the folder google-books-api folder.
cd google-books-api

Install the project dependencies by running npm i from within the google-books-api folder.
For more information about the project dependencies, please see the "Dependencies" section below.

🤷 How to
After installing the project dependencies, you will be able to open the command line programme by typing the command books-cli into your terminal. You'll need to start your command with books-cli every time you want to access the programme.

From within the programme, there are a number of main commands:

Search command
books-cli search --keyword yourKeywordHere

Use this command followed by a space, the --keyword flag and a search phrase to return five books related to your query.

If your seach term is one word you can use it as is; if your search is made up of multiple words, wrap your phrase in quotation marks.

For example: books-cli search --keyword dogs

or

books-cli search --keyword 'dog diets'

Your results will contain five books, including a title, author and publisher, as well as a unique ID.

If you would like to save a book to your reading list, you will need to use that ID.

Save command
books-cli save --id

After you've made a search, select and copy the ID of the book you'd like to save to your reading list.

On a Mac, you can highlight the ID and copy it using the command Command-C. On a PC, use the command Ctrl C.

Use the save command followed by a space and the ID of the book you'd like to save to your reading list.

For example: books-cli save --id PLcNhqWr7VcC

This example command will save a book called Dinner for Dogs by Henrietta Morrison to your reading list.
List command
books-cli list

This command will print any books saved to your reading list to your console.

Help command
books-cli help or book-cli -h

This command displays a menu which lists available commands.

Version command
books-cli version or books-cli -v

This command displays the current verion of the programme.

🤖 Run some test
To run tests, write the following command in your terminal:

npm test

🙋🏻‍Things I learned
The bin file
This process taught me how to use a bin file to run my programme when using the command books-cli.

Always read the docs carefully
I started the project by getting an API key from Google Books and by installing and configuring the dependency dotenv. What I noticed a few days later, was that given that I was only making get requests, I didn't need to use a key. The lesson here is to not make assumptions and check out the documentation first!

Local storage
My initial thoughts were to use local storage to save the user's reading list. In this process, I learned that local storage is only available the the browser side! Instead, I familiarized myself with the fs Node Module.

Mocking external modules - Axios
This was the first time that I learned how to mock modules with Jest. I've only really scratched the surface here.

Testing
I am ashamed to say that in the past I've really shied away from writing tests. Largely, this has been due to a lack of understanding the underpinning methodologies. I have always seen the benefits of creating well tested code bases, but I wasn't really sure how to implement tests within my code.

From this project, I learned two main things:

Dependency injection: what is it and how it help us test
Error handling: how tests can drive error handling and how there are two types of errors (operational and programmer)
Dependency Injection
To me, learning to inject dependencies meant that I could:

Further modularise my code so that I could reduce the responsibility of each function
Test that my functions were being passed the correct parameters (and error handle where necessary)
Reuse parts of my code in places that I hadn't before.
Error handling
Although I had been introduced to error handling while on the Founders and Coders boot camp, this was something that I hadn't really implemented in any of my recent projects. In this project, I learned how to throw and catch errors, as well as how to create my own custom errors. Largely, I used the throw error class to test against. What I mean by this is that I would run my functions with incorrect parameters in my test suites and check that returned with the errors that I had created.

---
## [roxell/linux](https://github.com/roxell/linux)@[992df15b52...](https://github.com/roxell/linux/commit/992df15b5253e096264354d178cb0e75e3b1cf3d)
#### Monday 2021-12-20 08:09:03 by Mauricio Faria de Oliveira

mm: fix race between MADV_FREE reclaim and blkdev direct IO read

Problem:
=======

Userspace might read the zero-page instead of actual data from a direct IO
read on a block device if the buffers have been called madvise(MADV_FREE)
on earlier (this is discussed below) due to a race between page reclaim on
MADV_FREE and blkdev direct IO read.

Race condition:
==============

During page reclaim, the MADV_FREE page check in try_to_unmap_one() checks
if the page is not dirty, then discards its PTE (vs remap it back if the
page is dirty).

However, after try_to_unmap_one() returns to shrink_page_list(), it might
keep the page _anyway_ if page_ref_freeze() fails (it expects a single
page ref from the isolation).

Well, blkdev_direct_IO() gets references for all pages, and on READ
operations it sets them dirty later.

So, if MADV_FREE pages (i.e., not dirty) are used as buffers (more later)
for direct IO read from block devices and page reclaim runs during
__blkdev_direct_IO[_simple]() AFTER bio_iov_iter_get_pages() but BEFORE it
sets pages dirty, that situation happens.

The direct IO read eventually completes.  Now, when userspace reads the
buffers, the PTE is no longer there and the page fault handler
do_anonymous_page() services that with the zero-page, NOT the data!

A synthetic reproducer is provided.

Page faults:
===========

The data read from the block device probably won't generate faults due to
DMA (no MMU) but even in the case it wouldn't use DMA, that happens on
different virtual addresses (not user-mapped addresses) because `struct
bio_vec` stores `struct page` to figure addresses out (which are different
from/unrelated to user-mapped addresses) for the data read.

Thus userspace reads (to user-mapped addresses) still fault, then
do_anonymous_page() gets another `struct page` that would address/ map to
other memory than the `struct page` used by `struct bio_vec` for the read
(which runs correctly as the page wasn't freed due to page_ref_freeze(),
and is reclaimed later) -- but even if the page addresses matched, that
handler maps the zero-page in the PTE, not that page's memory (on read
faults.)

If page reclaim happens BEFORE bio_iov_iter_get_pages() the issue doesn't
happen, because that faults-in all pages as writeable, so
do_anonymous_page() sets up a new page/rmap/PTE, and that is used by
direct IO.  The userspace reads don't fault as the PTE is there (thus
zero-page is not used.)

Solution:
========

One solution is to check for the expected page reference count in
try_to_unmap_one() too, which should be exactly two: one from the
isolation (checked by shrink_page_list()), and the other from the rmap
(dropped by the discard: label).  If that doesn't match, then remap the
PTE back, just like page dirty does.

The new check in try_to_unmap_one() should be safe in races with
bio_iov_iter_get_pages() in get_user_pages() fast and slow paths, as it's
done under the PTE lock.  The fast path doesn't take that lock but it
checks the PTE has changed, then drops the reference and leaves the page
for the slow path (which does take that lock).

- try_to_unmap_one()
  - page_vma_mapped_walk()
    - map_pte() # see pte_offset_map_lock():
        pte_offset_map()
        spin_lock()
  - page_ref_count() # new check
  - page_vma_mapped_walk_done() # see pte_unmap_unlock():
      pte_unmap()
      spin_unlock()

- bio_iov_iter_get_pages()
  - __bio_iov_iter_get_pages()
    - iov_iter_get_pages()
      - get_user_pages_fast()
        - internal_get_user_pages_fast()

          # fast path
          - lockless_pages_from_mm()
            - gup_{pgd,p4d,pud,pmd,pte}_range()
                ptep = pte_offset_map() # not _lock()
                pte = ptep_get_lockless(ptep)
                page = pte_page(pte)
                try_grab_compound_head(page) # get ref
                if (pte_val(pte) != pte_val(*ptep))
                        put_compound_head(page) # put ref
                        # leave page for slow path
          # slow path
          - __gup_longterm_unlocked()
            - get_user_pages_unlocked()
              - __get_user_pages_locked()
                - __get_user_pages()
                  - follow_{page,p4d,pud,pmd}_mask()
                    - follow_page_pte()
                        ptep = pte_offset_map_lock()
                        pte = *ptep
                        page = vm_normal_page(pte)
                        try_grab_page(page) # get ref
                        pte_unmap_unlock()

Regarding transparent hugepages, that number shouldn't change, as
MADV_FREE (aka lazyfree) pages are PageAnon() && !PageSwapBacked()
(madvise_free_pte_range() -> mark_page_lazyfree() -> lru_lazyfree_fn())
thus should reach shrink_page_list() -> split_huge_page_to_list() before
try_to_unmap[_one](), so it deals with normal pages only.

(And in case unlikely/TTU_SPLIT_HUGE_PMD/split_huge_pmd_address() happens,
which it should not or be rare, the page refcount is not two, as the head
page counts tail pages, and tail pages have zero.  That also prevents
checking the head `page` then incorrectly call page_remove_rmap(subpage)
for a tail page, that isn't even in the shrink_page_list()'s page_list (an
effect of split huge pmd/pmvw), as it might happen today in this unlikely
scenario.)

MADV_FREE'd buffers:
===================

So, back to the "if MADV_FREE pages are used as buffers" note.  The case
is arguable, and subject to multiple interpretations.

The madvise(2) manual page on the MADV_FREE advice value says:
- 'After a successful MADV_FREE ... data will be lost when
   the kernel frees the pages.'
- 'the free operation will be canceled if the caller writes
   into the page' / 'subsequent writes ... will succeed and
   then [the] kernel cannot free those dirtied pages'
- 'If there is no subsequent write, the kernel can free the
   pages at any time.'

Thoughts, questions, considerations...
- Since the kernel didn't actually free the page (page_ref_freeze()
  failed), should the data not have been lost? (on userspace read.)
- Should writes performed by the direct IO read be able to cancel
  the free operation?
  - Should the direct IO read be considered as 'the caller' too,
    as it's been requested by 'the caller'?
  - Should the bio technique to dirty pages on return to userspace
    (bio_check_pages_dirty() is called/used by __blkdev_direct_IO())
    be considered in another/special way here?
- Should an upcoming write from a previously requested direct IO
  read be considered as a subsequent write, so the kernel should
  not free the pages? (as it's known at the time of page reclaim.)

Technically, the last point would seem a reasonable consideration and
balance, as the madvise(2) manual page apparently (and fairly) seem to
assume that 'writes' are memory access from the userspace process (not
explicitly considering writes from the kernel or its corner cases; again,
fairly)..  plus the kernel fix implementation for the corner case of the
largely 'non-atomic write' encompassed by a direct IO read operation, is
relatively simple; and it helps.

Reproducer:
==========

@ test.c (simplified, but works)

	#define _GNU_SOURCE
	#include <fcntl.h>
	#include <stdio.h>
	#include <unistd.h>
	#include <sys/mman.h>

	int main() {
		int fd, i;
		char *buf;

		fd = open(DEV, O_RDONLY | O_DIRECT);

		buf = mmap(NULL, BUF_SIZE, PROT_READ | PROT_WRITE,
                	   MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);

		for (i = 0; i < BUF_SIZE; i += PAGE_SIZE)
			buf[i] = 1; // init to non-zero

		madvise(buf, BUF_SIZE, MADV_FREE);

		read(fd, buf, BUF_SIZE);

		for (i = 0; i < BUF_SIZE; i += PAGE_SIZE)
			printf("%p: 0x%x
", &buf[i], buf[i]);

		return 0;
	}

@ block/fops.c (formerly fs/block_dev.c)

	+#include <linux/swap.h>
	...
	... __blkdev_direct_IO[_simple](...)
	{
	...
	+	if (!strcmp(current->comm, "good"))
	+		shrink_all_memory(ULONG_MAX);
	+
         	ret = bio_iov_iter_get_pages(...);
	+
	+	if (!strcmp(current->comm, "bad"))
	+		shrink_all_memory(ULONG_MAX);
	...
	}

@ shell

	# yes | dd of=test.img bs=1k count=16
	# DEV=$(losetup -f --show test.img)
	# gcc -DDEV=\"$DEV\" -DBUF_SIZE=16384 -DPAGE_SIZE=4096 test.c -o test

	# od -tx1 $DEV
	0000000 79 0a 79 0a 79 0a 79 0a 79 0a 79 0a 79 0a 79 0a
	*
	0040000

	# mv test good
	# ./good
	0x7f1509206000: 0x79
	0x7f1509207000: 0x79
	0x7f1509208000: 0x79
	0x7f1509209000: 0x79

	# mv good bad
	# ./bad
	0x7fd87272f000: 0x0
	0x7fd872730000: 0x0
	0x7fd872731000: 0x0
	0x7fd872732000: 0x0

Ceph/TCMalloc:
=============

For documentation purposes, the use case driving the analysis/fix is Ceph
on Ubuntu 18.04, as the TCMalloc library there still uses MADV_FREE to
release unused memory to the system from the mmap'ed page heap (might be
committed back/used again; it's not munmap'ed.)
- PageHeap::DecommitSpan() -> TCMalloc_SystemRelease() -> madvise()
- PageHeap::CommitSpan() -> TCMalloc_SystemCommit() -> do nothing.

Note: TCMalloc switched back to MADV_DONTNEED a few commits after the
release in Ubuntu 18.04 (google-perftools/gperftools 2.5), so the issue
just 'disappeared' on Ceph on later Ubuntu releases but is still present
in the kernel, and can be hit by other use cases.

The observed issue seems to be the old Ceph bug #22464 [1], where checksum
mismatches are observed (and instrumentation with buffer dumps shows
zero-pages read from mmap'ed/MADV_FREE'd page ranges).

The issue in Ceph was reasonably deemed a kernel bug (comment #50) and
mostly worked around with a retry mechanism, but other parts of Ceph could
still hit that (rocksdb).  Anyway, it's less likely to be hit again as
TCMalloc switched out of MADV_FREE by default.

(Some kernel versions/reports from the Ceph bug, and relation with
the MADV_FREE introduction/changes; TCMalloc versions not checked.)
- 4.4 good
- 4.5 (madv_free: introduction)
- 4.9 bad
- 4.10 good? maybe a swapless system
- 4.12 (madv_free: no longer free instantly on swapless systems)
- 4.13 bad

[1] https://tracker.ceph.com/issues/22464

Thanks:
======

Several people contributed to analysis/discussions/tests/reproducers
in the first stages when drilling down on ceph/tcmalloc/linux kernel:

- Dan Hill
- Dan Streetman
- Dongdong Tao
- Gavin Guo
- Gerald Yang
- Heitor Alves de Siqueira
- Ioanna Alifieraki
- Jay Vosburgh
- Matthew Ruffell
- Ponnuvel Palaniyappan

Link: https://lkml.kernel.org/r/20211211022115.1547617-1-mfo@canonical.com
Signed-off-by: Mauricio Faria de Oliveira <mfo@canonical.com>
Cc: Dan Hill <daniel.hill@canonical.com>
Cc: Dan Streetman <dan.streetman@canonical.com>
Cc: Dongdong Tao <dongdong.tao@canonical.com>
Cc: Gavin Guo <gavin.guo@canonical.com>
Cc: Gerald Yang <gerald.yang@canonical.com>
Cc: Heitor Alves de Siqueira <halves@canonical.com>
Cc: Ioanna Alifieraki <ioanna-maria.alifieraki@canonical.com>
Cc: Jay Vosburgh <jay.vosburgh@canonical.com>
Cc: Matthew Ruffell <matthew.ruffell@canonical.com>
Cc: Ponnuvel Palaniyappan <ponnuvel.palaniyappan@canonical.com>
Cc: Minchan Kim <minchan@kernel.org>
Cc: Huang Ying <ying.huang@intel.com>
Cc: Miaohe Lin <linmiaohe@huawei.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Stephen Rothwell <sfr@canb.auug.org.au>

---
## [Jprimero15/lolz_rebase](https://github.com/Jprimero15/lolz_rebase)@[3a8d4867b8...](https://github.com/Jprimero15/lolz_rebase/commit/3a8d4867b80f7fff67388ed6a5e85c7bed6bad78)
#### Monday 2021-12-20 08:46:39 by Park Ju Hyung

drivers: cpufreq: Support Lazyplug

Other hotplugging methods including mpdecision and intelli_plug focuses
on how should we turn off CPU cores. They hotplugs the individual CPU
cores based on the current load divided by thread capacity.
Lazyplug takes a whole new approach on how we should do hotplugging
based on the foundation of the other side of the coin;
“Linux’s hotplugging is very inefficient.”

Current hotplugging code on Linux is a total waste of CPU cycles and
delays, so rather than hotplugging and hurt performance & battery life,
just leaving the CPU cores on might be a better choice. This kind of
approach is spreading out more and more.
Samsung has been using this method for a very long time with big.LITTLE
devices and recent Nexus 6 firmware also does the similar thing.

Lazyplug just leaves them on, most of the time. It also tries to solve
some problems with the “Always on” approach. On situations such as video
playback, turning on all CPU cores is not battery friendly. So Lazyplug
*does* actually turns off CPU cores, but only when idle state is long
enough(to reduce the number of CPU core switchings) and when the device
has its screen off(determination is done via earlysuspend or
powersuspend because framebuffer API causes troubles on hotplugging CPU
cores).

Basic methodology :
Lazyplug uses majority of the codes from intelli_plug by faux123 to
determine when to turn off CPU cores. If the system has been idle for
(DEF_SAMPLING_MS * DEF_IDLE_COUNT)ms, it turns off the CPU cores. And if
the next poll determines 1 core isn’t enough, it fires up all CPU cores
(instead of selective CPU cores; which is the traditional intelli_plug’s
method).
Lazyplug also takes touch-screen input events to fire up CPU cores to
minimize noticeable performance degradation.
There’s also a “lazy mode” for *not* aggressively turning on CPU cores
on scenario such as video playback. For example, if you hook up
lazyplug_enter_lazy() to the video session open function, Lazyplug won’t
aggressively turn on CPU cores and tries to handle it with 1 CPU core.

* TODO :
* Dual-core mode : YouTube video playback is mostly single-threaded.
* It usually hovers around 10% ~ 30% of total CPU usage on quad-core
* device. That means 1 CPU core might not be enough to handle it, but
* also turning on all CPU cores is unnecessarily wasting power.

Signed-off-by: Park Ju Hyung <qkrwngud825@gmail.com>
Signed-off-by: Jprimero15 <jprimero155@gmail.com>

---
## [turex/android_kernel_huawei_hi6250](https://github.com/turex/android_kernel_huawei_hi6250)@[db258fd3a6...](https://github.com/turex/android_kernel_huawei_hi6250/commit/db258fd3a626b90f8cefc752e2a2fced8adc04a6)
#### Monday 2021-12-20 08:55:39 by Christian Brauner

BACKPORT: signal: add pidfd_send_signal() syscall

The kill() syscall operates on process identifiers (pid). After a process
has exited its pid can be reused by another process. If a caller sends a
signal to a reused pid it will end up signaling the wrong process. This
issue has often surfaced and there has been a push to address this problem [1].

This patch uses file descriptors (fd) from proc/<pid> as stable handles on
struct pid. Even if a pid is recycled the handle will not change. The fd
can be used to send signals to the process it refers to.
Thus, the new syscall pidfd_send_signal() is introduced to solve this
problem. Instead of pids it operates on process fds (pidfd).

/* prototype and argument /*
long pidfd_send_signal(int pidfd, int sig, siginfo_t *info, unsigned int flags);

/* syscall number 424 */
The syscall number was chosen to be 424 to align with Arnd's rework in his
y2038 to minimize merge conflicts (cf. [25]).

In addition to the pidfd and signal argument it takes an additional
siginfo_t and flags argument. If the siginfo_t argument is NULL then
pidfd_send_signal() is equivalent to kill(<positive-pid>, <signal>). If it
is not NULL pidfd_send_signal() is equivalent to rt_sigqueueinfo().
The flags argument is added to allow for future extensions of this syscall.
It currently needs to be passed as 0. Failing to do so will cause EINVAL.

/* pidfd_send_signal() replaces multiple pid-based syscalls */
The pidfd_send_signal() syscall currently takes on the job of
rt_sigqueueinfo(2) and parts of the functionality of kill(2), Namely, when a
positive pid is passed to kill(2). It will however be possible to also
replace tgkill(2) and rt_tgsigqueueinfo(2) if this syscall is extended.

/* sending signals to threads (tid) and process groups (pgid) */
Specifically, the pidfd_send_signal() syscall does currently not operate on
process groups or threads. This is left for future extensions.
In order to extend the syscall to allow sending signal to threads and
process groups appropriately named flags (e.g. PIDFD_TYPE_PGID, and
PIDFD_TYPE_TID) should be added. This implies that the flags argument will
determine what is signaled and not the file descriptor itself. Put in other
words, grouping in this api is a property of the flags argument not a
property of the file descriptor (cf. [13]). Clarification for this has been
requested by Eric (cf. [19]).
When appropriate extensions through the flags argument are added then
pidfd_send_signal() can additionally replace the part of kill(2) which
operates on process groups as well as the tgkill(2) and
rt_tgsigqueueinfo(2) syscalls.
How such an extension could be implemented has been very roughly sketched
in [14], [15], and [16]. However, this should not be taken as a commitment
to a particular implementation. There might be better ways to do it.
Right now this is intentionally left out to keep this patchset as simple as
possible (cf. [4]).

/* naming */
The syscall had various names throughout iterations of this patchset:
- procfd_signal()
- procfd_send_signal()
- taskfd_send_signal()
In the last round of reviews it was pointed out that given that if the
flags argument decides the scope of the signal instead of different types
of fds it might make sense to either settle for "procfd_" or "pidfd_" as
prefix. The community was willing to accept either (cf. [17] and [18]).
Given that one developer expressed strong preference for the "pidfd_"
prefix (cf. [13]) and with other developers less opinionated about the name
we should settle for "pidfd_" to avoid further bikeshedding.

The  "_send_signal" suffix was chosen to reflect the fact that the syscall
takes on the job of multiple syscalls. It is therefore intentional that the
name is not reminiscent of neither kill(2) nor rt_sigqueueinfo(2). Not the
fomer because it might imply that pidfd_send_signal() is a replacement for
kill(2), and not the latter because it is a hassle to remember the correct
spelling - especially for non-native speakers - and because it is not
descriptive enough of what the syscall actually does. The name
"pidfd_send_signal" makes it very clear that its job is to send signals.

/* zombies */
Zombies can be signaled just as any other process. No special error will be
reported since a zombie state is an unreliable state (cf. [3]). However,
this can be added as an extension through the @flags argument if the need
ever arises.

/* cross-namespace signals */
The patch currently enforces that the signaler and signalee either are in
the same pid namespace or that the signaler's pid namespace is an ancestor
of the signalee's pid namespace. This is done for the sake of simplicity
and because it is unclear to what values certain members of struct
siginfo_t would need to be set to (cf. [5], [6]).

/* compat syscalls */
It became clear that we would like to avoid adding compat syscalls
(cf. [7]).  The compat syscall handling is now done in kernel/signal.c
itself by adding __copy_siginfo_from_user_generic() which lets us avoid
compat syscalls (cf. [8]). It should be noted that the addition of
__copy_siginfo_from_user_any() is caused by a bug in the original
implementation of rt_sigqueueinfo(2) (cf. 12).
With upcoming rework for syscall handling things might improve
significantly (cf. [11]) and __copy_siginfo_from_user_any() will not gain
any additional callers.

/* testing */
This patch was tested on x64 and x86.

/* userspace usage */
An asciinema recording for the basic functionality can be found under [9].
With this patch a process can be killed via:

 #define _GNU_SOURCE
 #include <errno.h>
 #include <fcntl.h>
 #include <signal.h>
 #include <stdio.h>
 #include <stdlib.h>
 #include <string.h>
 #include <sys/stat.h>
 #include <sys/syscall.h>
 #include <sys/types.h>
 #include <unistd.h>

 static inline int do_pidfd_send_signal(int pidfd, int sig, siginfo_t *info,
                                         unsigned int flags)
 {
 #ifdef __NR_pidfd_send_signal
         return syscall(__NR_pidfd_send_signal, pidfd, sig, info, flags);
 #else
         return -ENOSYS;
 #endif
 }

 int main(int argc, char *argv[])
 {
         int fd, ret, saved_errno, sig;

         if (argc < 3)
                 exit(EXIT_FAILURE);

         fd = open(argv[1], O_DIRECTORY | O_CLOEXEC);
         if (fd < 0) {
                 printf("%s - Failed to open \"%s\"\n", strerror(errno), argv[1]);
                 exit(EXIT_FAILURE);
         }

         sig = atoi(argv[2]);

         printf("Sending signal %d to process %s\n", sig, argv[1]);
         ret = do_pidfd_send_signal(fd, sig, NULL, 0);

         saved_errno = errno;
         close(fd);
         errno = saved_errno;

         if (ret < 0) {
                 printf("%s - Failed to send signal %d to process %s\n",
                        strerror(errno), sig, argv[1]);
                 exit(EXIT_FAILURE);
         }

         exit(EXIT_SUCCESS);
 }

/* Q&A
 * Given that it seems the same questions get asked again by people who are
 * late to the party it makes sense to add a Q&A section to the commit
 * message so it's hopefully easier to avoid duplicate threads.
 *
 * For the sake of progress please consider these arguments settled unless
 * there is a new point that desperately needs to be addressed. Please make
 * sure to check the links to the threads in this commit message whether
 * this has not already been covered.
 */
Q-01: (Florian Weimer [20], Andrew Morton [21])
      What happens when the target process has exited?
A-01: Sending the signal will fail with ESRCH (cf. [22]).

Q-02:  (Andrew Morton [21])
       Is the task_struct pinned by the fd?
A-02:  No. A reference to struct pid is kept. struct pid - as far as I
       understand - was created exactly for the reason to not require to
       pin struct task_struct (cf. [22]).

Q-03: (Andrew Morton [21])
      Does the entire procfs directory remain visible? Just one entry
      within it?
A-03: The same thing that happens right now when you hold a file descriptor
      to /proc/<pid> open (cf. [22]).

Q-04: (Andrew Morton [21])
      Does the pid remain reserved?
A-04: No. This patchset guarantees a stable handle not that pids are not
      recycled (cf. [22]).

Q-05: (Andrew Morton [21])
      Do attempts to signal that fd return errors?
A-05: See {Q,A}-01.

Q-06: (Andrew Morton [22])
      Is there a cleaner way of obtaining the fd? Another syscall perhaps.
A-06: Userspace can already trivially retrieve file descriptors from procfs
      so this is something that we will need to support anyway. Hence,
      there's no immediate need to add another syscalls just to make
      pidfd_send_signal() not dependent on the presence of procfs. However,
      adding a syscalls to get such file descriptors is planned for a
      future patchset (cf. [22]).

Q-07: (Andrew Morton [21] and others)
      This fd-for-a-process sounds like a handy thing and people may well
      think up other uses for it in the future, probably unrelated to
      signals. Are the code and the interface designed to permit such
      future applications?
A-07: Yes (cf. [22]).

Q-08: (Andrew Morton [21] and others)
      Now I think about it, why a new syscall? This thing is looking
      rather like an ioctl?
A-08: This has been extensively discussed. It was agreed that a syscall is
      preferred for a variety or reasons. Here are just a few taken from
      prior threads. Syscalls are safer than ioctl()s especially when
      signaling to fds. Processes are a core kernel concept so a syscall
      seems more appropriate. The layout of the syscall with its four
      arguments would require the addition of a custom struct for the
      ioctl() thereby causing at least the same amount or even more
      complexity for userspace than a simple syscall. The new syscall will
      replace multiple other pid-based syscalls (see description above).
      The file-descriptors-for-processes concept introduced with this
      syscall will be extended with other syscalls in the future. See also
      [22], [23] and various other threads already linked in here.

Q-09: (Florian Weimer [24])
      What happens if you use the new interface with an O_PATH descriptor?
A-09:
      pidfds opened as O_PATH fds cannot be used to send signals to a
      process (cf. [2]). Signaling processes through pidfds is the
      equivalent of writing to a file. Thus, this is not an operation that
      operates "purely at the file descriptor level" as required by the
      open(2) manpage. See also [4].

/* References */
[1]:  https://lore.kernel.org/lkml/20181029221037.87724-1-dancol@google.com/
[2]:  https://lore.kernel.org/lkml/874lbtjvtd.fsf@oldenburg2.str.redhat.com/
[3]:  https://lore.kernel.org/lkml/20181204132604.aspfupwjgjx6fhva@brauner.io/
[4]:  https://lore.kernel.org/lkml/20181203180224.fkvw4kajtbvru2ku@brauner.io/
[5]:  https://lore.kernel.org/lkml/20181121213946.GA10795@mail.hallyn.com/
[6]:  https://lore.kernel.org/lkml/20181120103111.etlqp7zop34v6nv4@brauner.io/
[7]:  https://lore.kernel.org/lkml/36323361-90BD-41AF-AB5B-EE0D7BA02C21@amacapital.net/
[8]:  https://lore.kernel.org/lkml/87tvjxp8pc.fsf@xmission.com/
[9]:  https://asciinema.org/a/IQjuCHew6bnq1cr78yuMv16cy
[11]: https://lore.kernel.org/lkml/F53D6D38-3521-4C20-9034-5AF447DF62FF@amacapital.net/
[12]: https://lore.kernel.org/lkml/87zhtjn8ck.fsf@xmission.com/
[13]: https://lore.kernel.org/lkml/871s6u9z6u.fsf@xmission.com/
[14]: https://lore.kernel.org/lkml/20181206231742.xxi4ghn24z4h2qki@brauner.io/
[15]: https://lore.kernel.org/lkml/20181207003124.GA11160@mail.hallyn.com/
[16]: https://lore.kernel.org/lkml/20181207015423.4miorx43l3qhppfz@brauner.io/
[17]: https://lore.kernel.org/lkml/CAGXu5jL8PciZAXvOvCeCU3wKUEB_dU-O3q0tDw4uB_ojMvDEew@mail.gmail.com/
[18]: https://lore.kernel.org/lkml/20181206222746.GB9224@mail.hallyn.com/
[19]: https://lore.kernel.org/lkml/20181208054059.19813-1-christian@brauner.io/
[20]: https://lore.kernel.org/lkml/8736rebl9s.fsf@oldenburg.str.redhat.com/
[21]: https://lore.kernel.org/lkml/20181228152012.dbf0508c2508138efc5f2bbe@linux-foundation.org/
[22]: https://lore.kernel.org/lkml/20181228233725.722tdfgijxcssg76@brauner.io/
[23]: https://lwn.net/Articles/773459/
[24]: https://lore.kernel.org/lkml/8736rebl9s.fsf@oldenburg.str.redhat.com/
[25]: https://lore.kernel.org/lkml/CAK8P3a0ej9NcJM8wXNPbcGUyOUZYX+VLoDFdbenW3s3114oQZw@mail.gmail.com/

Cc: "Eric W. Biederman" <ebiederm@xmission.com>
Cc: Jann Horn <jannh@google.com>
Cc: Andy Lutomirsky <luto@kernel.org>
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Oleg Nesterov <oleg@redhat.com>
Cc: Al Viro <viro@zeniv.linux.org.uk>
Cc: Florian Weimer <fweimer@redhat.com>
Signed-off-by: Christian Brauner <christian@brauner.io>
Reviewed-by: Tycho Andersen <tycho@tycho.ws>
Reviewed-by: Kees Cook <keescook@chromium.org>
Reviewed-by: David Howells <dhowells@redhat.com>
Acked-by: Arnd Bergmann <arnd@arndb.de>
Acked-by: Thomas Gleixner <tglx@linutronix.de>
Acked-by: Serge Hallyn <serge@hallyn.com>
Acked-by: Aleksa Sarai <cyphar@cyphar.com>

(cherry picked from commit 3eb39f47934f9d5a3027fe00d906a45fe3a15fad)

Conflicts:
        arch/x86/entry/syscalls/syscall_32.tbl - trivial manual merge
        arch/x86/entry/syscalls/syscall_64.tbl - trivial manual merge
        include/linux/proc_fs.h - trivial manual merge
        include/linux/syscalls.h - trivial manual merge
        include/uapi/asm-generic/unistd.h - trivial manual merge
        kernel/signal.c - struct kernel_siginfo does not exist in 4.9
        kernel/sys_ni.c - cond_syscall is used instead of COND_SYSCALL
        arch/x86/entry/syscalls/syscall_32.tbl
        arch/x86/entry/syscalls/syscall_64.tbl

(1. manual merges because of 4.9 differences
 2. change prepare_kill_siginfo() to use struct siginfo instead of
kernel_siginfo
 3. exclude kill() changes to avoid struct kernel_siginfo usage
 4. exclude copy_siginfo_from_user_any() to avoid struct kernel_siginfo usage
 5. use copy_from_user() instead of copy_siginfo_from_user() in copy_siginfo_from_user_any()
 6. replaced COND_SYSCALL with cond_syscall
 7. Removed __ia32_sys_pidfd_send_signal in arch/x86/entry/syscalls/syscall_32.tbl.
 8. Replaced __x64_sys_pidfd_send_signal with sys_pidfd_send_signal in arch/x86/entry/syscalls/syscall_64.tbl.)

Bug: 135608568
Test: test program using syscall(__NR_pidfd_send_signal,..) to send SIGKILL
Change-Id: I00f1c618b2e9dbafae4d4113ad4d8a1a44b6957c
Signed-off-by: Suren Baghdasaryan <surenb@google.com>

---
## [xdustinface/chia-blockchain](https://github.com/xdustinface/chia-blockchain)@[a3e929b836...](https://github.com/xdustinface/chia-blockchain/commit/a3e929b83615807de1b8fee8f7ab9f59ff5424bd)
#### Monday 2021-12-20 10:09:00 by xdustinface

tests: Use `temp_dir` as `tmp2_dir`, drop `temp_dir` if canceled

If you currently cancel the test during the plot setup phase it just
removes the whole directoy and with it all the test plots for no good
reason. At least in my opinion its just annoying. Sure, you can clone
the `test-cache` repo and copy them over if this happens but i still
think its better to just merge this PR :)

---
## [Claymore1297/android_kernel_htc_msm8994](https://github.com/Claymore1297/android_kernel_htc_msm8994)@[37b324728b...](https://github.com/Claymore1297/android_kernel_htc_msm8994/commit/37b324728b2c629629221ae51d31dab6c2d1db67)
#### Monday 2021-12-20 12:55:40 by Masahiro Yamada

modpost: file2alias: go back to simple devtable lookup

commit ec91e78d378cc5d4b43805a1227d8e04e5dfa17d upstream.

Commit e49ce14150c6 ("modpost: use linker section to generate table.")
was not so cool as we had expected first; it ended up with ugly section
hacks when commit dd2a3acaecd7 ("mod/file2alias: make modpost compile
on darwin again") came in.

Given a certain degree of unknowledge about the link stage of host
programs, I really want to see simple, stupid table lookup so that
this works in the same way regardless of the underlying executable
format.

Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
Acked-by: Mathieu Malaterre <malat@debian.org>
[nc: Omit rpmsg, sdw, fslmc, tbsvc, and typec as they don't exist here
     Add of to avoid backporting two larger patches]
Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
Signed-off-by: Sasha Levin <sashal@kernel.org>
Signed-off-by: Kevin F. Haggerty <haggertk@lineageos.org>
Change-Id: Ic632eaa7777338109f80c76535e67917f5b9761c

---
## [peff/git](https://github.com/peff/git)@[c46d75b57c...](https://github.com/peff/git/commit/c46d75b57c5c97044b399f8b2c8a9abe36b5dea9)
#### Monday 2021-12-20 13:37:04 by Jeff King

commit: give a hint when a commit message has been abandoned

If we launch an editor for the user to create a commit
message, they may put significant work into doing so.
Typically we try to check common mistakes that could cause
the commit to fail early, so that we die before the user
goes to the trouble.

We may still experience some errors afterwards, though; in
this case, the user is given no hint that their commit
message has been saved. Let's tell them where it is.

Signed-off-by: Jeff King <peff@peff.net>

---
## [peff/git](https://github.com/peff/git)@[9b66a95eb3...](https://github.com/peff/git/commit/9b66a95eb3c7d2b82f8a1f1c5440ba6ee6bc7a81)
#### Monday 2021-12-20 13:37:40 by Jeff King

ahead-behind: do not die when we see no INTERESTING pending object

We currently die if we are fed an ahead/behind with zero
objects (`foo..foo` in the most basic case, but in practice
something like `foo@{upstream}..foo`, when `foo` has just
been merged).  The problem is that we let
`handle_revision_arg` parse it, and then pick the pieces out
of the pending object list. So "^foo" looks no different to
us there than "foo".

This patch hacks around it by picking up the UNINTERESTING
object in that case. However, this isn't great because:

  1. Now we won't notice some types of bogus input.

  2. We end up reporting the name of the UNINTERESTING object.

We probably should pick apart the ".." ourselves, or even
just change it to ":" or whitespace.

Signed-off-by: Jeff King <peff@peff.net>

---
## [ElementsProject/secp256k1-zkp](https://github.com/ElementsProject/secp256k1-zkp)@[b2206619e6...](https://github.com/ElementsProject/secp256k1-zkp/commit/b2206619e69d6d57304e7b4bb0ea5d92ca3b7821)
#### Monday 2021-12-20 14:14:57 by Tim Ruffing

Merge ElementsProject/secp256k1-zkp#131: Replace MuSig(1) module with MuSig2

ac1e36769dda3964f7294319ecb06fb5c414938d musig: turn off multiexponentiation for now (Jonas Nick)
3c79d97bd92ec22cc204ff5a08c9b0e5adda12e6 ci: increase timeout for macOS tasks (Jonas Nick)
22c88815c76e6edb23baf9401f820e1a944c3ecf musig: replace MuSig(1) with MuSig2 (Jonas Nick)

Pull request description:

  The main commit comprises `905 insertions(+), 1253 deletions(-)`. The diff isn't as small as I had hoped, but that's mostly because it was possible to simplify the API quite substantially which required rewriting large parts. Sorry, almost all of the changes are in one big commit which makes the diff very hard to read. Perhaps best to re-review most parts from scratch.

  A few key changes:

  - Obviously no commitment round. No big session struct and no `verifier` sessions. No `signer` struct.
  - There's a new `secnonce` struct that is the output of musig_nonce_gen and derived from a uniformly random session_id32. The derivation can be strengthened by adding whatever session parameters (combined_pk, msg) are available. The nonce function is my ad-hoc construction that allows for these optional inputs. Please have a look at that.
  - The secnonce is made invalid after being used in partial_sign.
  - Adaptor signatures basically work as before, according to https://github.com/ElementsProject/scriptless-scripts/pull/24 (with the exception that they operate on aggregate instead of partial sigs)
  - To avoid making this PR overly complex I did not consider how this implementation interacts with nested-MuSig, sign-to-contract, and antiklepto.
  - Testing should be close to complete. There's no reachable line or branch that isn't exercised by the tests.
  - [x] ~In the current implementation when a signer sends an invalid nonce (i.e. some garbage that can't be mapped to a group element), it is ignored when combining nonces. Only after receiving the signers partial signature and running `partial_sig_verify` will we notice that the signer misbehaved. The reason for this is that 1) this makes the API simpler and 2) malicious peers don't gain any additional powers because they can always interrupt the protocol by refusing to sign. However, this is up for discussion.~ EDIT: this is not the case anymore since invalid nonces are rejected when they're parsed.
  - [x] ~For every partial signature we verify we have to parse the pubnonce (two compressed points), despite having parsed it in `process_nonces` already. This is not great. `process_nonces` could optionally output the array of parsed pubnonces.~ EDIT: fixed by having a dedicated type for nonces.
  - [x] ~I left `src/modules/musig/musig.md` unchanged for now. Perhaps we should merge it with the `musig-spec`~ EDIT: musig.md is updated
  - [x] partial verification should use multiexp to compute `R1 + b*R2 + c*P`, but this can be done in a separate PR
  - [x] renaming wishlist
      - pre_session -> keyagg_cache (because there is no session anymore)
      - pubkey_combine, nonce_combine, partial_sig_combine -> pubkey_agg, nonce_agg, partial_sig_agg (shorter, matches terminology in musig2)
      - musig_session_init -> musig_start (shorter, simpler) or [musig_generate_nonce](https://github.com/ElementsProject/secp256k1-zkp/pull/131#discussion_r654190890) or musig_prepare
      - musig_partial_signature to musig_partial_sig (shorter)
  - [x] perhaps remove pubnonces and n_pubnonces argument from process_nonces (and then also add a opaque type for the combined nonce?)
  - [x] write the `combined_pubkey` into the `pre_session` struct (as suggested [below](https://github.com/ElementsProject/secp256k1-zkp/pull/131#issuecomment-866904975): then 1) session_init and process_nonces don't need a combined_pk argument (and there can't be mix up between tweaked and untweaked keys) and 2) pubkey_tweak doesn't need an input_pubkey and the output_pubkey can be written directly into the pre_session (reducing frustration such as Replace MuSig(1) module with MuSig2 #131 (comment))
  - [x] perhaps allow adapting both partial sigs (`partial_sig` struct) and aggregate partial sigs (64 raw bytes) as suggested [below](https://github.com/ElementsProject/secp256k1-zkp/pull/131#issuecomment-867281531).

  Based on #120.

ACKs for top commit:
  robot-dreams:
    ACK ac1e36769dda3964f7294319ecb06fb5c414938d
  real-or-random:
    ACK ac1e36769dda3964f7294319ecb06fb5c414938d

Tree-SHA512: 916b42811aa5c00649cfb923d2002422c338106a6936a01253ba693015a242f21f7f7b4cce60d5ab5764a129926c6fd6676977c69c9e6e0aedc51b308ac6578d

---
## [entrez/NetHack](https://github.com/entrez/NetHack)@[420d121f93...](https://github.com/entrez/NetHack/commit/420d121f939686f2bdc734038119b9cf932e1f3a)
#### Monday 2021-12-20 14:24:20 by PatR

'urgent' messages

Follow up on some old groundwork.  For tty, if the core has designated
a message as 'urgent', override any message suppression taking place
because of ESC typed at the --More-- prompt.  Right now, "You die"
messages, feedback about having something stolen, feedback for
"amorous demon" interaction (mainly in case of armor removal), and
exploding a bag of holding are treated as urgent.

The "You die" case is already handled by a hack in top-line handling;
I left that in place so the conversion of 3 or 4 pline("You die.*")
to custompline(URGENT_MESSAGE, "You die.*") was redundant.  There
are probably various non-You_die messages which precede done() which
should be marked urgent too.

Other interfaces might want to do something similar.  And we ought to
implement MSGTYPE=force or MSGTYPE=urgent to allow players to indicate
other messages that they want have to override suppression.  But I'm
not intending to work on either of those.  I mainly wanted to force
the magic bag explosion message to be shown since a sequence of "You
put <foo> into <bag>." messages is a likely candidate for --More--ESC.

---
## [DaVikingMan/FalconXOS](https://github.com/DaVikingMan/FalconXOS)@[cc244ca7b1...](https://github.com/DaVikingMan/FalconXOS/commit/cc244ca7b1a2ab4268d1a71ce10c72106209645e)
#### Monday 2021-12-20 14:30:27 by DaVikingMan

Create new license

Now, I know what you are asking, why relicense this project which hasn't been updated for so long?
Well, there's a long reason to it

As you may have noticed this program hasn't gotten any updates since the last month(or maybe it hasn't been that long) and it has diverted from its goals many times, and by many, I mean many.

First, FalconXOS(which was then known as TerminalXOS) was a TerminalOs, or that was its aim
Then, after it was renamed to FalconXOS it's goal was changed to be a Operating Shell, a new tech for which I have not released the docs for(you might have already noticed but I don't like to write docs)

After, its goal was changed for it to be a set of different programs, including UFT, Operating Shell and many others.
And, currently its aim is to become a set  of cli tools, which include the UFT, Operating Shell, more refined cli commands and thus creating a set of tools, like gen to create projects, icat which is a more smarter cat command and, the recently announced Yuki component which I haven't released the source code for(Yuki was supposed to be a renderer for FalconXOS, which will allow FalconXOS to graphically render stuff).

So, as you can see there have been changes to the projects's goal and currently it has become a mess.
The Operating Shell developement hasn't started.
I haven't updated the Yuki component and haven't been working on it and the code for UFT is a mess, with no clear goal of what it aims to be.

I'm relicensing this project as I wanted this project to be more open and free(as in freedom), so yeah here is the license which I think is quite open and free(If anyone wants to use this license for their project, they can do so).

Now, onto the main topic or the TL;DR of this commit:

For now, I will not be updating this project.
I might do it afterwards in the near future, but currently I don't plan to continue this project as it has just become a complete mess, upto the point where I'm thinking that I should recreate this entire project but with a more clearer goal.
So yeah, if I continue this project's developement I will either recreate this project or fix this entire project and probably release a cleanup update.

I will still create other projects on this account like I was thinking of creating a open-source game or game engine, so that may happen in the future but it will not be coded in c#(it will be coded in c++). But don't worry, all of my main projects will always be open-source.

I will also release the Yuki component's source code(although I haven't done any developement to it, all I had done was link the libraries that I was about to use).

Signed-off by : DaVikingMan

---
## [tdauth/wowr](https://github.com/tdauth/wowr)@[89320ab211...](https://github.com/tdauth/wowr/commit/89320ab2115acd1175ba19881c5be89f23e3f5c4)
#### Monday 2021-12-20 14:46:17 by barade

1.8.7

- Fix some Battle.net ID for a VIP member.
- Fix setting race to None in the beginning which allowed to purchase the Human race items for Freelancers.
- Fix allowing VIPs to enter the Bonus Hero chamber even with VIPs turned off.
- Disable permanently summoned units from Archimonde's Dark Portal.
- Fix tooltips of profession books and race scepters.
- Remove research Evolution from Guardian's Citadel.
- Reduce Evasion of Drunken Brawler.
- Reduce number of summoned Demons from Demon Master by 1 per level.
- Reduce chances of stunning for both Bash abilities from Mountain King and Eredar Warlock.
- Replace healing ability of Stonemaul Arena Master Belt with Roar ability.
- Add upgrade Improved Power Generator to all AI scripts.
- Check for a second hero in "-secondherorepick".
- Make some Draenei units weaker.
- Correct tooltip text of Reward Freelancer.
- Translate tooltip of Blood Elf Arcane Sanctum back into English.
- Fix the text in the tooltip of Blood Elf Barracks.
- Change Unit Inventory (Undead) ability for Blood Elf Lieutenant's to Unit Inventory (Human).
- Give  Blood Elf Swordsmen and Blood Elf Archers Unit Inventory (Human).
- Change Spirit Wolf and Reincarnation from Akama hero to adapt the tooltips for the hero.
- Fix tooltip of Draenei Shop.
- Fix tooltip of Tiny Boulder Tower.
- Fix train tooltip of Draenei Laborer (Blizzard's mistake!).
- Remove Unit Inventory from Young Furbolg.
- Furbolg Marketplace sells custom Talisman of the Wild now which summons a Furbolg who benefits from Furbolg upgrades.
- Remove Hide ability from Lumber Camp.
- Increase maximum hitpoints of Furbolg Barrack to 1200.
- Fix Battle Stations of Furbolg.
- Remove old Young Furbolg version from the World Editor.
- Give Furbolg Dire Wolves Unit Inventory.
- Make Draenei and Furbolg units not neutral hostile anymore to hide their creep level.
- Give Outland base with Illidan much more space (required for the AI).
- Give Sorceress custom Invisibility ability which won't affect herself and has the correct icon position
- Do not research the Scorceress Adept Training upgrade for all players from start.
- Invisibility for heroes does not require Sorceress Adept Training anymore.
- Move icons of Gryphon Rider and Storm Hammer to the left.
- Remove Spellbreaker info from the tooltip of Arcane Sanctum.
- Add floating texts to portals in bonus hero chamber and VIP room.

---
## [gys619/jd](https://github.com/gys619/jd)@[f4deb86968...](https://github.com/gys619/jd/commit/f4deb869685db7ddd40484ad16f79064babbea5c)
#### Monday 2021-12-20 15:54:49 by gys619

新增：[ CK_WxPusherUid.json, JDJRValidator_Pure.js, JD_extra_cookie.js, JS1_USER_AGENTS.js, Loon/LoonTask.conf, Loon/lxk0301_LoonTask.conf, ModScript/jd_dreamFactory_Mod.js, ModScript/jd_fanli_Mod.js, ModScript/jd_fruit_Mod.js, ModScript/jd_health_Mod.js, ModScript/jd_jdfactory_Mod.js, ModScript/jd_joy_reward_Mod.js, ModScript/jd_medal_Mod.js, ModScript/jd_pet_Mod.js, ModScript/jd_plantBean_Mod.js, ModScript/jd_sgmh_Mod.js, ModScript/jd_speed_sign_Mod.js, NoUsed/NoUsed_jd_priceProtect_Mod.js, NoUsed/NoUsed_jd_speed_sign_Part1.js, NoUsed/NoUsed_jd_speed_sign_Part2.js, NoUsed/NoUsed_jd_speed_sign_Part3.js, NoUsed/NoUsed_jd_syj_Mod.js, Orz-3.conf, QuantumultX/cookies.conf, QuantumultX/gallery.json, QuantumultX/lxk0301_cookies.conf, QuantumultX/lxk0301_gallery.json, QuantumultX_Profiles.conf, Surge/Task.sgmodule, Surge/lxk0301_Task.sgmodule.sgmodule, TS_USER_AGENTS.ts, ZooFaker_Necklace.js, activity/desktop.ini, activity/jdCookie.js, activity/jd_5g.js, activity/jd_818.js, activity/jd_FLP.js, activity/jd_UnknownTask4.js, activity/jd_angryBean.js, activity/jd_angryKoi.js, activity/jd_apple_live.js, activity/jd_appliances.js, activity/jd_blueCoin.py, activity/jd_bookshop.js, activity/jd_car_exchange.js, activity/jd_carnivalcity.js, activity/jd_carnivalcity_help.js, activity/jd_cfd_fresh_exchange.js, activity/jd_cfdtx.js, activity/jd_city_exchange.js, activity/jd_city_lottery.js, activity/jd_coupon.js, activity/jd_crazy_joy.js, activity/jd_crazy_joy_bonus.js, activity/jd_crazy_joy_coin.js, activity/jd_daily_egg.js, activity/jd_ddwj.js, activity/jd_ddwj_help.js, activity/jd_decompression.js, activity/jd_digital_floor.js, activity/jd_dlpj.js, activity/jd_dqmh.js, activity/jd_ds.js, activity/jd_family.js, activity/jd_fanli.py, activity/jd_fcwb.js, activity/jd_fcwb_auto.js, activity/jd_festival.js, activity/jd_film_museum.js, activity/jd_finance.js, activity/jd_firecrackers.js, activity/jd_firecrackers2.js, activity/jd_focus.js, activity/jd_ftzy_help.js, activity/jd_global.js, activity/jd_global_mh.js, activity/jd_golden_machine.js, activity/jd_haier.js, activity/jd_health.js, activity/jd_honour.js, activity/jd_hotNeight.js, activity/jd_hotnight.js, activity/jd_hyj.js, activity/jd_immortal.js, activity/jd_immortal_answer.js, activity/jd_industrial_task.js, activity/jd_industryLottery.js, activity/jd_jddt.js, activity/jd_jdh.js, activity/jd_jika.js, activity/jd_jingsubang.js, activity/jd_joy_park_newtask.js, activity/jd_joy_tx.js, activity/jd_jr_draw.js, activity/jd_jxd.js, activity/jd_jxhlk.js, activity/jd_jxhlk.py, activity/jd_jxlhb.js, activity/jd_jxnc.js, activity/jd_jxstory.js, activity/jd_kxcdz.js, activity/jd_ldhwj.js, activity/jd_live_redrain.js, activity/jd_live_redrain2.js, activity/jd_ljd.js, activity/jd_lol.js, activity/jd_lotteryMachine.js, activity/jd_lsj.js, activity/jd_lxLottery.js, activity/jd_market_lottery.js, activity/jd_mcxhd.js, activity/jd_mh.js, activity/jd_mofang_exchange.js, activity/jd_ms_redrain.js, activity/jd_mx_shop.js, activity/jd_newTreasure.py, activity/jd_newYearMoney.js, activity/jd_newYearMoney_lottery.js, activity/jd_nh.js, activity/jd_nian.js, activity/jd_nian_ar.js, activity/jd_nian_sign.js, activity/jd_nian_wechat.js, activity/jd_party_night.js, activity/jd_petTreasureBox.js, activity/jd_price.js, activity/jd_pubg.js, activity/jd_qcshj.js, activity/jd_qjd.py, activity/jd_qqxing.js, activity/jd_qycl.js, activity/jd_redPacket.js, activity/jd_ryhxj.js, activity/jd_selectionOffice.js, activity/jd_sjjc.js, activity/jd_small_home.js, activity/jd_speed.js, activity/jd_split.js, activity/jd_summer_movement.js, activity/jd_superBrand.js, activity/jd_super_box.js, activity/jd_superbox.js, activity/jd_sxLottery.js, activity/jd_syj.js, activity/jd_tcl.js, activity/jd_teamFLP.js, activity/jd_tewu.js, activity/jd_travel_shop.js, activity/jd_tyt_w.js, activity/jd_unbind.js, activity/jd_unknownTask1.js, activity/jd_vivo.js, activity/jd_watch.js, activity/jd_wxFans.js, activity/jd_xg.js, activity/jd_xgyl.js, activity/jd_xiaolong.js, activity/jd_xiaomi.js, activity/jd_xinxiangyin.js, activity/jd_xtg.js, activity/jd_xtg_help.js, activity/jd_yijiajiu.js, activity/jd_ylyn.js, activity/jd_ys.js, activity/jd_zoo.js, activity/jd_zooCollect.js, activity/jd_zooElecsport.js, activity/jd_zzt.js, activity/jr_sign.js, activity/jx_mc_coin.js, activity/jx_sign.js, aiqicha.js, backUp/AlipayManor.js, backUp/ZooFaker_Necklace.js, backUp/gitSync.md, backUp/gua_MMdou.js, backUp/gua_UnknownTask1.js, backUp/gua_UnknownTask3.js, backUp/gua_UnknownTask4.js, backUp/gua_UnknownTask5.js, backUp/gua_carnivalcity.js, backUp/gua_ddgame.js, backUp/gua_doge.js, backUp/gua_olympic_opencard.js, backUp/gua_olympic_opencard2.js, backUp/gua_opencard10.js, backUp/gua_opencard12.js, backUp/gua_opencard13.js, backUp/gua_opencard14.js, backUp/gua_opencard17.js, backUp/gua_opencard21.js, backUp/gua_opencard22.js, backUp/gua_opencard23.js, backUp/gua_opencard24.js, backUp/gua_opencard25.js, backUp/gua_opencard26.js, backUp/gua_opencard27.js, backUp/gua_opencard28.js, backUp/gua_opencard30.js, backUp/gua_opencard31.js, backUp/gua_opencard38.js, backUp/gua_opencard4.js, backUp/gua_opencard43.js, backUp/gua_opencard5.js, backUp/gua_opencard6.js, backUp/gua_opencard7.js, backUp/gua_opencard8.js, backUp/gua_opencard9.js, backUp/gua_wealth_island.js, backUp/gua_wealth_island_help.js, backUp/gua_xiaolong.js, backUp/iCloud.md, backUp/iOS_Weather_AQI_Standard.js, backUp/jd_15.py, backUp/jd_HongBao.js, backUp/jd_OpenCard.py, backUp/jd_all_bean_change.js, backUp/jd_angryBean.js, backUp/jd_angryCash.js, backUp/jd_angryKoi.js, backUp/jd_appliances.js, backUp/jd_beauty_twelfth.js, backUp/jd_big_winner.js, backUp/jd_blueCoin.py, backUp/jd_bs.py, backUp/jd_car.js, backUp/jd_car_exchange_xh.js, backUp/jd_cart_remove.js, backUp/jd_cashHelp.py, backUp/jd_cfd.js, backUp/jd_cfd_SlotMachine.js, backUp/jd_cfd_loop.js, backUp/jd_cfd_mooncake.js, backUp/jd_cfdtx.js, backUp/jd_ddPlayer.js, backUp/jd_ddwj.js, backUp/jd_decompression.js, backUp/jd_delete.py, backUp/jd_deletenotify.py, backUp/jd_djyyj.js, backUp/jd_dyj_help.js, backUp/jd_fansa.js, backUp/jd_fc.js, backUp/jd_fcdyj.js, backUp/jd_fcffl.js, backUp/jd_film_museum.js, backUp/jd_flpa.js, backUp/jd_foodRunning.js, backUp/jd_goddess.js, backUp/jd_golden_machine.js, backUp/jd_gq.js, backUp/jd_hyj.js, backUp/jd_hyj_help.py, backUp/jd_industryLottery.js, backUp/jd_iqoo_run.js, backUp/jd_jika.js, backUp/jd_joy_help.js, backUp/jd_joy_reward_Mod.js, backUp/jd_joy_score.js, backUp/jd_jx_sign.js, backUp/jd_jxgc.js, backUp/jd_jxgc_tuan.py, backUp/jd_kanjia.js, backUp/jd_kanjia2.js, backUp/jd_kanjia3.js, backUp/jd_ldhwj.js, backUp/jd_lol.js, backUp/jd_lzdz2_fashion.js, backUp/jd_lzdz2_fashion1.js, backUp/jd_mb.js, backUp/jd_mid.js, backUp/jd_mid2.js, backUp/jd_mofang.js, backUp/jd_necklace_new.js, backUp/jd_olympicgames.js, backUp/jd_phone.js, backUp/jd_ppdz.js, backUp/jd_price.js, backUp/jd_priceProtect_Mod.js, backUp/jd_productZ4Brand.js, backUp/jd_qjd.py, backUp/jd_qqxing.js, backUp/jd_redPacket.js, backUp/jd_redPacket_help.js, backUp/jd_ryhxj.js, backUp/jd_speed_signfaker.js, backUp/jd_summer_movement.js, backUp/jd_summer_movement_bet.js, backUp/jd_summer_movement_card.js, backUp/jd_summer_movement_help.js, backUp/jd_summer_movement_map.js, backUp/jd_superBrand.js, backUp/jd_superBrand2.js, backUp/jd_superMarket_xh.js, backUp/jd_teamAnJia.js, backUp/jd_teamFLP.js, backUp/jd_travel_shop.js, backUp/jd_try.js, backUp/jd_twlove.js, backUp/jd_vivo_add.js, backUp/jd_wxFans.js, backUp/jd_xiaomi.js, backUp/jd_xxy.js, backUp/jd_young.js, backUp/jd_yqyl.js, backUp/jd_ys.js, backUp/jd_zjd.py, backUp/jd_zy_ddwj_help.js, backUp/jddj_fruit.js, backUp/mySelf.boxjs.json, backUp/webhook.js, backUp/xmSports.js, boxjs.json, cleancart_activity.js, creat.sh, docker/Dockerfile, docker/Readme.md, docker/auto_help.sh, docker/bot/jd.png, docker/bot/jd_bot, docker/bot/requirements.txt, docker/bot/setup.py, docker/crontab_list.sh, docker/default_task.sh, docker/docker_entrypoint.sh, docker/example/custom-append.yml, docker/example/custom-overwrite.yml, docker/example/default.yml, docker/example/docker\345\244\232\350\264\246\346\210\267\344\275\277\347\224\250\347\213\254\347\253\213\345\256\271\345\231\250\344\275\277\347\224\250\350\257\264\346\230\216.md, docker/example/jd_scripts.custom-append.syno.json, docker/example/jd_scripts.custom-overwrite.syno.json, docker/example/jd_scripts.syno.json, docker/example/multi.yml, docker/notify_docker_user.js, docker/proc_file.sh, function/.DS_Store, function/common.js, function/config.js, function/eval.js, function/jdValidate.js, function/jdcookie.js, function/jxAlgo.js, function/ql.js, function/sendNotify.js, gdbhapp.js, getJDCookie.js, gua_MMdou.js, gua_UnknownTask7.js, gua_UnknownTask9.js, gua_ddworld.js, gua_opencard81.js, gua_opencard82.js, gua_opencard83.js, gua_opencard84.js, gua_opencard85.js, gua_opencard86.js, gua_wealth_island.js, gua_wealth_island_help.js, jdEnv.py, jdJxncShareCodes.js, jdJxncTokens.js, jd_7dayClockin.py, jd_CkSeq.js, jd_DailyBonus_Mod.js, jd_DrawEntrance.js, jd_EsportsManager.js, jd_Evaluation.py, jd_aid_factory.js, jd_angryBean.js, jd_angryKoi.js, jd_bean_change_new.js, jd_beauty_ex.js, jd_blueCoin.py, jd_bookshop.js, jd_card_collecting_common_enc.js, jd_cart_remove.js, jd_cash_exchange.js, jd_cfd_fresh.js, jd_cfd_mooncake_help.js, jd_cfd_pearl.js, jd_daily_lottery.js, jd_ddnc_farmpark.js, jd_delCoupon.js, jd_dlpj.js, jd_dqmh.js, jd_dreamFactory_tuan.js, jd_duobao.js, jd_dyj_help.js, jd_evaluation.js, jd_exchangejxbeans.js, jd_exjxbeans.js, jd_family.js, jd_fan.js, jd_fanli.py, jd_fc.js, jd_fcwb.js, jd_fission.js, jd_flp.js, jd_foodRunning.js, jd_fruit_friend.js, jd_fruit_help.js, jd_fruit_task.js, jd_fxhh.js, jd_game_common_enc.js, jd_getFollowGift.py, jd_goodMorning.js, jd_gyp.js, jd_half_redrain.js, jd_hbCount.py, jd_health_collect.js, jd_health_exchange.py, jd_help_sendBean.js, jd_jchsign.js, jd_jddt.js, jd_jieMo.js, jd_joy-park.js, jd_joy_feedPets.js, jd_joy_park_help.js, jd_joy_reward_Mod.js, jd_joy_tx.js, jd_joyjd_open.js, jd_joypark_open.js, jd_jx_factory_automation.js, jd_jxg.js, jd_jxlhb.js, jd_jxmc_hb.js, jd_jxnc.js, jd_jxnn.js, jd_jxqd_new.js, jd_kanjia.js, jd_koiHelp.js, jd_koi_Help.js, jd_live_redrain.js, jd_look_video_common_enc.js, jd_lotteryMachine.js, jd_lucky_egg.js, jd_lzdz_unify.js, jd_mall.js, jd_mall_active.js, jd_market_lottery.js, jd_medal.js, jd_mofang.js, jd_mofang_exchange.js, jd_morningSc.js, jd_mx_jddt.js, jd_nnfl.js, jd_openCard.py, jd_prodev_dailyTask.js, jd_productZ4Brand.js, jd_qjd.js, jd_qjd.py, jd_rankingList.js, jd_redPacket.js, jd_refreshInvokeKey.js, jd_reward.ts, jd_rush_lzclient.js, jd_sendBeans.js, jd_share_common_enc.js, jd_shop_sign.js, jd_sign_graphics1.js, jd_sign_graphics_validate.js, jd_small_home.js, jd_speed.js, jd_speed_sign_Mod.js, jd_speed_sign_Part1.js, jd_speed_sign_Part2.js, jd_speed_sign_Part3.js, jd_speed_sign_Part4.js, jd_speed_sign_Part5.js, jd_speed_signfaker.js, jd_speed_signfree.js, jd_split.js, jd_star_wind_zzt.js, jd_super_mh.js, jd_super_redrain.js, jd_sxLottery.js, jd_syj.js, jd_task_checkCookie.js, jd_task_farm.js, jd_task_hby.js, jd_task_invokeKey.js, jd_task_jd2xd.js, jd_task_lottery.js, jd_task_noahHaveFunLottery.js, jd_task_price.js, jd_task_shopBean.js, jd_task_unfollowShop.js, jd_task_validate.js, jd_try_MyTrials.js, jd_unsubscriLive.js, jd_update.js, jd_upgrade.js, jd_vivo.js, jd_week.js, jd_wish2.js, jd_wish3.js, jd_work_price.js, jd_work_validate.js, jd_wxCollectionActivity.js, jd_wxFans.js, jd_wyw.js, jd_xiaolong.js, jd_xmf.js, jd_xmf_exchange.js, jd_xqscjd.js, jd_ylyn.js, jd_yqyl.js, jd_ys.js, jd_zbjmh.js, jd_zdjr.js, jd_zqfl.py, jddjCookie.js, jddj_bean.js, jddj_bean.json, jddj_fruit.js, jddj_fruit.json, jddj_fruit_collectWater.js, jddj_fruit_collectWater.json, jddj_getPoints.js, jddj_getPoints.json, jddj_getck.js, jddj_plantBeans.js, jddj_plantBeans.json, jkdapp.js, joy_run_token.json, jr_task_pig.js, jw_task_jdzz.js, jw_task_signRedpacket.js, jx_aid_cashback.js, jx_help_cashback.js, lxk0301.boxjs.json, lzdz1_jx.json, m_fanli.js, m_jd_car_sign.js, m_jd_delete_coupon.js, m_jd_duobao.js, m_jd_jd2xd.js, m_jd_sign.js, m_jd_yfcoupon.js, m_jx_cfd_card.js, m_jx_cfd_pearl_exchange.js, m_jx_factory_automation.js, m_jx_factory_commodity.js, m_jx_mc_zn_exchange.js, magic.js, package-lock.json, productZ4Brand11.js, ql.js, rush_jinggengjcq_dapainew.js, rush_lzclient.js, rush_lzdz1_dapai.js, rush_wxCollectionActivity.js, sendNotify.py, shell_script_mod.sh, starShop.json, tools/a.py, tools/empty.json, tools/jd_dreamFactory_product.js, utils/JDCookie.py, utils/JDJRValidator.js, utils/JDJRValidator_Pure.js, utils/JDJRValidator_Pure1.js, utils/JDSignValidator.js, utils/JD_DailyBonus.js, utils/MoveMentFaker.js, utils/MovementFaker.js, utils/USER_AGENTS.js, utils/ZooFaker_Necklace.js, utils/common.js, utils/config.js, utils/eval.js, utils/jdCookie.js, utils/jdShareCodes.js, utils/jdValidate.js, utils/jd_jxmcToken.js, utils/jd_sign_validate.js, utils/jdcookie.js, utils/jxAlgo.js, utils/magic.js, utils/ql.js, utils/sendNotify.js, utils/share_code.js, utils/sign_graphics_validate.js, utils/sign_graphics_validate1.js, zcodes.json]
修改内容：[ LICENSE, README.md, backUp/getJDCookie.js, backUp/jd_bean_change.js, backUp/jd_carnivalcity.js, backUp/jd_carnivalcity_help.js, backUp/jd_cfd_fresh_exchange.js, backUp/jd_crazy_joy.js, backUp/jd_crazy_joy_bonus.js, backUp/jd_crazy_joy_coin.js, backUp/jd_fan.js, backUp/jd_industrial_task.js, backUp/jd_jxlhb.js, backUp/jd_jxnc.js, backUp/jd_kxcdz.js, backUp/jd_kyd.js, backUp/jd_live_redrain.js, backUp/jd_lotteryMachine.js, backUp/jd_lsj.js, backUp/jd_qcshj.js, backUp/jd_qixi.js, backUp/jd_small_home.js, backUp/jd_vivo.js, backUp/jd_xtg.js, backUp/tencentscf.md, githubAction.md, index.js, jdCookie.js, jdDreamFactoryShareCodes.js, jdFactoryShareCodes.js, jdFruitShareCodes.js, jdPetShareCodes.js, jdPlantBeanShareCodes.js, jd_bean_change.js, jd_bean_home.js, jd_bean_sign.js, jd_big_winner.js, jd_car.js, jd_car_exchange.js, jd_cash.js, jd_cfd.js, jd_cfd_mooncake.js, jd_cfd_pearl_ex.js, jd_club_lottery.js, jd_daily_egg.js, jd_ddly.js, jd_ddworld.js, jd_dreamFactory.js, jd_dwapp.js, jd_fanli.js, jd_fcdyj.js, jd_fruit.js, jd_genz.js, jd_health.js, jd_jdfactory.js, jd_jdzz.js, jd_jfcz.js, jd_jin_tie.js, jd_joy.js, jd_joy_park.js, jd_joy_park_task.js, jd_joy_reward.js, jd_joy_run.js, jd_joy_steal.js, jd_jump.js, jd_jxgckc.js, jd_jxmc.js, jd_kd.js, jd_lxLottery.js, jd_mofang_ex.js, jd_mohe.js, jd_moneyTree.js, jd_moneyTree_help.js, jd_ms.js, jd_nnfls.js, jd_nzmh.js, jd_pet.js, jd_pigPet.js, jd_plantBean.js, jd_price.js, jd_qqxing.js, jd_redrain.js, jd_redrain_half.js, jd_sgmh.js, jd_shop.js, jd_signFree.js, jd_sign_graphics.js, jd_speed_sign.js, jd_superBrand.js, jd_superMarket.js, jd_try.js, jd_wish.js, jd_wsdlb.js, jd_zjb.js, jx_sign.js, jx_sign_xd.js, package.json, sendNotify.js, serverless.yml]

---
## [simonsj/git](https://github.com/simonsj/git)@[1763334caf...](https://github.com/simonsj/git/commit/1763334caf6c060f38b3310960b38cd3b1d54687)
#### Monday 2021-12-20 15:56:23 by Jeff King

ref-filter: stop setting FILTER_REFS_INCLUDE_BROKEN

Of the ref-filter callers, for-each-ref and git-branch both set the
INCLUDE_BROKEN flag (but git-tag does not, which is a weird
inconsistency).  But now that GIT_REF_PARANOIA is on by default, that
produces almost the same outcome for all three.

The one exception is that GIT_REF_PARANOIA will omit dangling symrefs.
That's a better behavior for these tools, as they would never include
such a symref in the main output anyway (they can't, as it doesn't point
to an object). Instead they issue a warning to stderr. But that warning
is somewhat useless; a dangling symref is a perfectly reasonable thing
to have in your repository, and is not a sign of corruption. It's much
friendlier to just quietly ignore it.

And in terms of robustness, the warning gains us little. It does not
impact the exit code of either tool. So while the warning _might_ clue
in a user that they have an unexpected broken symref, it would not help
any kind of scripted use.

This patch converts for-each-ref and git-branch to stop using the
INCLUDE_BROKEN flag. That gives them more reasonable behavior, and
harmonizes them with git-tag.

We have to change one test to adapt to the situation. t1430 tries to
trigger all of the REF_ISBROKEN behaviors from the underlying ref code.
It uses for-each-ref to do so (because there isn't any other mechanism).
That will no longer issue a warning about the symref which points to an
invalid name, as it's considered dangling (and we can instead be sure
that it's _not_ mentioned on stderr). Note that we do still complain
about the illegally named "broken..symref"; its problem is not that it's
dangling, but the name of the symref itself is illegal.

Signed-off-by: Jeff King <peff@peff.net>
Reviewed-by: Jonathan Tan <jonathantanmy@google.com>
Signed-off-by: Junio C Hamano <gitster@pobox.com>

---
## [M0-san/webserv](https://github.com/M0-san/webserv)@[a211d8c5a8...](https://github.com/M0-san/webserv/commit/a211d8c5a842d1cfa1ad332d2040ae52cb9794d2)
#### Monday 2021-12-20 16:41:43 by M0-san

handle uploading binary data && pass created fds through select fuck you|

---
## [loftyGiraffe/prime-ape-last](https://github.com/loftyGiraffe/prime-ape-last)@[5e865fa891...](https://github.com/loftyGiraffe/prime-ape-last/commit/5e865fa891a90b6b96d2e373974c3263fa82c4b4)
#### Monday 2021-12-20 17:44:29 by loftyGiraffe

Delete stop-stealing-my-ideas-you-fcking-piece-of-shit.Dumb-fucker.png

---
## [flofriday/Lox](https://github.com/flofriday/Lox)@[00d73f7bc3...](https://github.com/flofriday/Lox/commit/00d73f7bc3158e9191d9925717de541c41d0f3ca)
#### Monday 2021-12-20 17:51:21 by flofriday

Implement the jLox interpreter till chapter 8
Damn this is exciting 😊
It runs, it actually runs. Sure they are only mathematical expressions
and not yet a full programming language but hey it runs.
I am so hyped to continue, but I can already feel my concentration
dropping so I will take a little break an probably only continue
tomorrow.

Amazing book 😍

---
## [notmynamex/RefinedBot](https://github.com/notmynamex/RefinedBot)@[11a2c768c0...](https://github.com/notmynamex/RefinedBot/commit/11a2c768c0221932ae0515f608364146dec7d88d)
#### Monday 2021-12-20 19:11:50 by notmyname

finally osu command works holy fucking shit

also patched a little something in purge command

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[9218178cd9...](https://github.com/mrakgr/The-Spiral-Language/commit/9218178cd90f4f18ba587bcc37a06c2ec774c752)
#### Monday 2021-12-20 19:37:18 by Marko Grdinić

":50pm. I got a book on GP off Libgen. Here is a section from it.

Exploring Genetic Programming Systems with MAP-Elites

///

Test Problems

All problems except the logic problem were defined by a set of test cases in which programs were given specified input data and were scored on how close their output was to the correct output. For MAP-Elites and tournament selection, we calculated fitness as the sum of scores on these test cases.

• Logic: Programs receive two integers in binary form and must output the results of doing bitwise logic operations on them. We reward 10 2-input (with the exception of ECHO, which is 1-input) logic operations: ECHO, NOT, NAND, OR-NOT, AND, OR, AND-NOT, NOR, XOR, and EQUALS. To facilitate the evolution of these computations, we added a Nand instruction to the instruction set, which converts inputs to integers and then performs a bitwise not-and operation, structured in the same way as the Add instruction. Every unique logic operation that a program outputs the solution to over the course of its execution increases that program’s score by 1. Once a program has solved all of the logic problems, it gets bonus points for the speed with which it solved them. Specifically, the bonus is equal to the total number of allowed instruction executions minus the number of instructions the program actually executed before performing all 10 logic tasks. For lexicase selection, each logic operation was treated as a different test case.
• Squares: Programs receive an integer as input and must output its square. Because this problem is known to be easy, we evaluated programs on just 11 test cases.
• Sum: Programs receive a list of five integers as input that they must add together and output their total. Programs were evaluated on a set of 200 test cases.
• Smallest: Programs receive a list of four integers as input and must output the smallest one (from [7]). Programs were evaluated on a set of 200 test cases.

///

Sigh, it is going to be a slog to make use of genetic programming. This is the scale they are operating on right now. It is like the 80s are alive for these guys.

Still, this is the only way. I either find a way to make use of the power of machines to make them learn to learn, or my quest will die there.

10pm. I'll skip LoboCorp for today. Let me read Demon Sword Maiden and then I am going to bed early.

10:40pm. https://youtu.be/naed4C4hfAg
David Patterson: Computer Architecture and Data Storage | Lex Fridman Podcast

He makes an interesting point on how AI companies go belly up becase they neglect software.

12/20/2021

11:30am. https://www.biorxiv.org/content/10.1101/2021.12.02.471005v2.full
In vitro neurons learn and exhibit sentience when embodied in a simulated game-world

My sleep is good so I'll excuse my late wakeups. Right now, let me read the above and then I will finally make the Groq and Graphcore posts.

11:45am.

///

An example of this can be seen in the contrasting results between different cell sources. Active cortical cultures, from both human and mouse cell sources, both displayed synchronous activity patterns, in line with previous research. Yet importantly, significant differences between cell sources were observed as human cortical cells always outperformed mouse cortical cells with nuances in gameplay characteristics. Although further work is required, this is the first work finding empirical evidence supporting the hypothesis that human neurons have superior information-processing capacity over rodent neurons.

///

This research line is really interesting.

11:55am. https://www.youtube.com/watch?v=upljocX5mrk
Reinventing Compilers for AI :: GroqDay December 2021

Let me watch this. Then I'll make the Groq post.

https://groq.com/products/

It semes they have chips on PCie. Only 230mb per chip though. This is quite low.

https://cambrian-ai.com/interview-with-ceo-jonathan-ross-of-groq/

12:10pm. https://youtu.be/Bvl5VIlVyG0?t=505

He says the Groq-chip is single core. That means I can't really practice my concurrency skills on it. Together with it low memory, the product is not attractive from a programming point of view.

Hmmm...I do not think that Groq-chip has a C backend. Instead it seems it goes straight to assembler. It being single core renders it less attractive than TensTorrent, but whatever. If I can get it for free, plus a monthly stipend, I won't mind doing a backend in return.

https://youtu.be/ya9swcdrBQg
Natural Language Processing :: GroqDay December 2021

Let me watch this and then I'll compose the post.

https://youtu.be/ya9swcdrBQg?t=99

Honestly, being 7x faster is not that big of a deal. Especially considering that Groq chip has 200mb and the NVidia card 40gb.

12:25pm. Whatever, let me make the post.

///

As the 20s proceed, novel AI hardware to replace GPUs will arrive at the scene, but by the looks of things Python + C++ seems like it will be a dominant combination for programming them. This is a huge pity as we could do better than languages created in the 80s and 70s for programming hardware created in the 2020s. I am trying to change this destiny with [Spiral](https://github.com/mrakgr/The-Spiral-Language).

Apart from some special features to control inlining and specialization which make it suitable for hardware with no dynamic memory allocation capability like the GPUs, Spiral is quite similar to languages like F# and OCaml. It has static typing, global type inference, first class functions, records, tuples, unions and more as any competent functional language would. Unlike toy languages, it has a well done language server - if you want to try out the language, it is as simple as installing its plugin in the VS Code marketplace. About 3 years of full time work went into it.

If you have ambitions of your chips being used for more than just deep learning and more than just accelerators for existing frameworks, you should consider supporting an effort to make programming your hardware directly easier. I want to create a [ref counted](https://en.wikipedia.org/wiki/Reference_counting) Spiral backend for your AI chip. I want to make the new generation of AI hardware easier to use and am offering a modern, highly expressive functional language as an interface for them. Please consider this offer and if you approve, [grant](https://opencollective.com/spiral-collective) me a monthly stipend and access to your hardware. Your customers are sure to find it useful.

I myself am interested in using the hardware for my own research and game dev work. I am interested in finding out what kind of speedups are possible when the CPU is cut off from the training loop and RL algorithms are used on games running directly on the chip itself. I also want to try evolving novel learning algorithms using genetic programming. This kind of work should serve as a demo on how to use Spiral on your chip.

Background: See my [resume](https://docs.google.com/document/d/e/2PACX-1vSe88lhaoSZaF-YHKeiA_RlpkPwzLetrIAoY2v6ckbaLn59QQ95nvMC-Cc13hxDsLzVJ-KGE824S1bF/pub).

Would you be interested in supporting language development for your hardware?

///

This is a nice generic message. Let me post it on the Groq page.

12:50pm. https://www.reddit.com/r/GroqInc/comments/rklj2y/seeking_a_sponsor_for_a_functional_programming/

Mhhh, this will have to do. Now Graphcore.

https://www.graphcore.ai/products

Graphcore does not have an single chip products unfortunately.

https://sambanova.ai/wp-content/uploads/2021/04/SambaNova_Accelerated-Computing-with-a-Reconfigurable-Dataflow-Architecture_Whitepaper_English.pdf

This is the SambaNova.

12:55pm. I am going to skip SambaNova. It bothers me how they don't even try to market their AI chip and instead shuffle it off to the side. They aren't a hardware, but a services company. Let me get this out of the way. There is no need to hesitate.

https://semianalysis.substack.com/p/graphcore-looks-like-a-complete-failure

https://brainchipinc.com/products/

Forget Graphcore. I want to only do backends for companies that sell PCIe chips I could put in my desktop rig.

https://brainchipinc.com/akida-neural-processor-soc/

Does this support training?

https://www.youtube.com/watch?v=DFMyCWmyAAY
BrainChip Demonstrates how the Akida Neural Processor Solves Problems At the Edge

I hadn't heard about this company before.

1:10pm. Once you put things into perspective you realize how sparse the offerings are. Out of 50 companies only 2 will be selling things I can use to train NNs in my desktop rig. Lame.

Why am I obsessed about the possibilities of this yet? This is so far away from the market.

https://www.reddit.com/r/hardware/comments/ocbarb/sth_graphcore_celebrates_a_stunning_loss_at/
https://www.servethehome.com/graphcore-celebrates-a-stunning-loss-at-mlperf-training-v1-0/

> Personally, I found the Graphcore MLPerf Training v1.0 submission to be borderline heartbreaking. I have wanted to see a legitimate challenger to NVIDIA to increase competition in the industry and frankly hoped that Graphcore would be it.

> Instead, Graphcore showed that it has an IPU-POD16 solution that is roughly equivalent to the NVIDIA HGX A100-based servers in terms of list price and power consumption. Graphcore’s performance, given the price/ power context, was significantly worse than NVIDIA’s. Even allowing for customization by comparing an “Open” result to the standard “Closed” result, it was far behind in terms of performance.

https://www.servethehome.com/category/ai-deep-learning/

There is a lot of interesting stuff here. Let me get breakfast while I read this.

2pm. Done with breakfast. Let me read some of these articles and I will go do the chores. After that I am done. Groq and TensTorrent will have to do.

2:25pm. Ok, done.

https://www.servethehome.com/

This site is a really good resource for AI hardware news.

So far, I think I've been way too excited. If I got Groq chips, it would just be a single core accelerator with little memory. The TensTorrent one is the only one with the right pieces in place. Making post on their social media pages is the right strategy, but it just serves to underscore how nascent the field is that I only have like two different companies to choose from.

With this I Am done with applications for the next six months. I honestly don't think I'll get a bite anytime soon, so I have a lot of free time to level up my art skills. Let me do the chores here.

I know that I've been essentially wasting time reading news, but I wanted to make sure that there aren't any interesting new developments. It seems there aren't.

3:15pm. Dnoe with chores. Let me just see what the Cerberas CEO says about bringing in the Cuda devs and then I will put this aside.

https://www.servethehome.com/our-interview-with-andrew-feldman-ceo-of-cerebras-systems/

///

Are you seeing any pipeline challenge? A college student is likely developing on their NVIDIA GPU so they grow up with CUDA-based platforms. Is there a plan to focus on expanding developers?

AF: Sure those programs are impressive. But I think in this we were very much helped by Google and Facebook. They sat back and they said, for the first part of our lives, we were limited to a single chip vendor, Intel x86 world. AMD really wasn’t a competitor there. Lisa’s doing great work. And we’re huge fans of hers. But this was the thinking over the past 10 years. And now we’re moving to GPUs. There’s no way we’re going to be in a single source environment again. There is no way that that’s going to happen.

So they invented TensorFlow and they invented PyTorch to gut CUDA of its ability to create lock-in. If you’re doing ML work right now, you’re writing TensorFlow or PyTorch. In Japan, maybe you are writing in Chainer. At Baidu, you may write for Paddle Paddle. They are all as different as, I don’t know, chocolate and rocky road. I mean, they are Python-based library languages and frameworks. They were designed specifically so that you could take your model across any hardware. I mean, that was Google stated objective with TensorFlow. They could take it to a CPU, they could take to a GPU, they could take it to the TPU, and they can take it anywhere else. That created an opportunity for those of us who will build dedicated hardware to bolt on to an open-source framework designed to support multiple hardware platforms. That really weakened NVIDIA’s story around lock-in. We want kids to play games. We want more girls in particular to play games and to get fired up about the power of compute when it’s fun. Then to take that passion forward and to know that you can write software that works on many different types of hardware. That you should think about what the right hardware is when you write your software.

///

A bunch of typical CEO non answers. Neither are they interested in benchmarking against their competitors. What bullshit.

Right now, only TensTorrent has any kind of interest to me as a programmer. But who knows when I'll get my hands on it. A few years down the road there will be something else.

3:25pm. Now focus me. What is on the menu for today.

https://www.youtube.com/watch?v=D6a6eA1hE8s
How to Create Fog using Blender's Mist Pass (Tutorial)

https://www.youtube.com/watch?v=rtPzXrZ23k0
Glass Plasma Orb in Blender (Blender Tutorial)

https://www.youtube.com/results?search_query=blender+water

https://youtu.be/NWqCb5O6MLg
Blender Volume Modifier Inception: Mesh to volume - volume to mesh - mesh to volume

https://youtu.be/pYa5q0a7INM
How To Make Volumetric Clouds (Blender Tutorial)

https://youtu.be/w_mYYy4-5PU
Common Mistakes When Making Glass / How To Make A Glass In Blender (Beginner Tutorial)

https://www.youtube.com/results?search_query=blender+pool

Let me start with the mist pass. I am not really comfortable with the compositor. Blender really has so much stuff in it that it is overwhelming.

3:30pm. Focus me, focus.

https://youtu.be/D6a6eA1hE8s?t=150

So the mist pass is a feature of the camera. That is good.

https://youtu.be/D6a6eA1hE8s?t=220

Does it not show up in render view? I guess the compositor is necessary after all.

3:50pm. Let me move to the next thing. That is the Glass Plasma Orb.

> Having volume within an object is a Cycles only feature for the time being.

https://youtu.be/rtPzXrZ23k0?t=114

Principled volume seems like something I should watch a tutorial on.

https://youtu.be/rtPzXrZ23k0?t=174

This is something new. It really looks like plasma now.

4:10pm. https://youtu.be/rtPzXrZ23k0?t=176

I am trying to immitate this and nothing is showing up for me.

https://youtu.be/rtPzXrZ23k0?t=103

Wait, it needs to be transmisive. I just removed the surface myself.

4:30pm. I figured out how to do it. I have no idea how he though to combine the noise and the muskgrave textures like he did. I tip my hat to him.

4:35pm. Beofre I move on, let me go back and watch that HDRI vid that I forgot about. I should have watched it yesterday. It was a beach HDRI that had a floor.

https://youtu.be/RsAUfQlZH_w
HDRIs Just Got Better

This is the one. Let me watch it.

5:15pm. Had to take a break. Let me resume. I am really slow today. For the past few days, I've been running a track in my mind where I think about my past and future path.

It is finally time to play the metalearning card. Having the machine itself give me the algorithm that blows away the state of the art in poker for example, then studying it, thne applying the lessons to a bigger and better game would be a strong path.

In contrast, trying to learn from other humans is a particularly weak path. I feel like my future is taken hostage by them.

It is ironic. It is really ironic that out of all the areas of ML, genetic programming has the closest ties to language work. I think out of all the ML researchers that exist, I have the strongest foundation to begin doing this kind of research.

It depends zero on any existing work, I only need the right hardware for it. I'd have been more than happy to use the algorithms by other people had they done a good job, but that is not the case. So this is a challenge I need to surmount.

5:20pm. Focus me, the next vid. I want to finish this today so I can do actual art tomorrow.

https://youtu.be/NWqCb5O6MLg
Blender Volume Modifier Inception: Mesh to volume - volume to mesh - mesh to volume

Let me watch this.

This guy has such a thick accent that he is hard to understand. This confuses me. Why is putting a modifier on an empty affecting the other object? I'll have to play with this.

Lunch.

5:45pm. Let me resume.

I did not understand the last video, but nevermind that. I guess I'll figure it out when it comes to doing clouds. What is the next vid?

https://youtu.be/pYa5q0a7INM
How To Make Volumetric Clouds (Blender Tutorial)

https://youtu.be/w_mYYy4-5PU
Common Mistakes When Making Glass / How To Make A Glass In Blender (Beginner Tutorial)

Clouds.

https://youtu.be/pYa5q0a7INM?t=125

Setting up the initial part is quite simple it seems.

https://youtu.be/pYa5q0a7INM?t=338

This cloud is really nice, but my own looks like crap.

6:15pm. I need to play around with this. Let me try making my own cloud. Also I am not sure that I really need the volume object. It might be possible to do this same thing with shaders directly.

6:35pm. This is nice, but damn do these clouds require an insane amount of compute. They take forever to render.

https://youtu.be/DVmzic-cF4E?t=4
Making a 100% procedural Cloud in Blender, hell yeah!

I'll leave this for later. Let me watch the glass tutorial.

Let me move to the next thing.

https://youtu.be/w_mYYy4-5PU?t=17

He says he will show how to make the liquids inside as well. Then that is what I need to study.

https://youtu.be/w_mYYy4-5PU?t=777

This is a really good explanation of what volume absorbtion is doing and how it differs from surface color. The rendered volume absorbtion color is affected by the thickness of the glass.

https://youtu.be/w_mYYy4-5PU?t=922

The liquid needs to be inside the walls a tad. I wonder hhy?

7:10pm. Done with the video. What was that black outline for the water.

https://youtu.be/w_mYYy4-5PU?t=943

I mean this. Why did this happen?

7:15pm. I have no idea. Maybe because it is an Ngon. At any rate, the way to make a glass with liquid is surprisingly involved. Let me move to the next thing.

https://www.youtube.com/results?search_query=blender+water

Let me check out water and pools.

https://youtu.be/e3mhJXuveFo
Learn Blender's NEW Water Physics in 6 minutes! (Blender 2.9+)

7:25pm. Let me move to the next thing. Pools.

https://youtu.be/A-R07GaruK0
WATER POOL CAUSTICS WITH CYCLES? | BLENDER FOR ARCHVIZ

https://youtu.be/A-R07GaruK0?t=289

Just what the hell is he doing?

I see the dynamic paint and displace aqua modifiers. I'll keep them in mind, but I'll definitely have to watch another tutorial after this.

7:40pm. Ok, enough of this. This video is shit. It is just hack after hack.

https://youtu.be/QKIRrXcTThA
Make STUNNING Blender Concept Art (For Beginners!)

Let me give this a try.

He says he will recreate the scenery in Blender and paint over it in Photoshop. That is exactly the art style I am trying to master.

https://youtu.be/QKIRrXcTThA?t=455

This looks pretty nice.

7:55pm. https://youtu.be/QKIRrXcTThA?t=792

He mentions his course, 3d for artists. It might be worth checking out. So far the way to do water here has been solid. I'll want to know how to do ripples as well.

https://youtu.be/QKIRrXcTThA?t=872

The way he did the rock is interesting. A brush with a rock texture is what did the trick.

https://youtu.be/QKIRrXcTThA?t=996

I really like this. This has a lot of potential.

https://youtu.be/QKIRrXcTThA?t=1165

Ohh, so that is how you measure. I forgot to look into that tool for like forever.

https://youtu.be/QKIRrXcTThA?t=1250

I am not sure what setting the max steps here is supposed to be doing.

8:20pm. That was informative.

https://youtu.be/mmk09JJNKJU
UNDERWATER GODRAYS AND CAUSTICS IN BLENDER- FAST! - TUTORIAL

Let me watch this. I think I'll be done after that for today.

https://youtu.be/I2B-x3J0W4I
Underwater Scenes In Blender

I have in mind a scene looking up from the stars from the bottom of the pool and am wondering how that would look.

https://arxiv.org/abs/2003.03384
AutoML-Zero: Evolving Machine Learning Algorithms From Scratch

> Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.

I'll finish the day with this. Let me close here though. It is time to rest. Tomorrow, I will deal with water, and look up stars and aurora borealis. After that I should be ready to do my own work in Blender. Bit by bit, I'll knock my skills into shape."

---
## [polygoblyn/MonkeStation](https://github.com/polygoblyn/MonkeStation)@[d011e51dcf...](https://github.com/polygoblyn/MonkeStation/commit/d011e51dcf956ceebd29b54c8594cde48a740e6d)
#### Monday 2021-12-20 20:49:20 by nednaZ

Adds a newline to this file

I know a commit to master is bad, but oh my god it's one newline because this was made BEFORE the new linter requirements and this wasn't caught after the upstream merge.
I'm literally typing a hundred times the edit amount to justify adding the enter key.

How are you though? I hope things are going well for you, keep your mind fresh and don't stress over the small stuff because it's not worth it.
And always remember, grab moths.

---
## [Stephen-M-Anderson/Olaf-the-Unhuggable](https://github.com/Stephen-M-Anderson/Olaf-the-Unhuggable)@[9754e445d8...](https://github.com/Stephen-M-Anderson/Olaf-the-Unhuggable/commit/9754e445d8ebae937a5447e5e568529460fd7cd5)
#### Monday 2021-12-20 21:06:12 by Christian Morales

Changes Made During the Meeting

Good lord I am a fucking moron for not documenting shit better I'm sorry frends I am a hack fraud. We fixed some shit with these changes but I don't recall everything we fixed. For sure we fixed the glitch of the crazy goddamn bullshit that would happen when you tried to wrap around a circular object.

---
## [SanctusAnimus/Angel-Arena-Reborn](https://github.com/SanctusAnimus/Angel-Arena-Reborn)@[94662ab559...](https://github.com/SanctusAnimus/Angel-Arena-Reborn/commit/94662ab559e4e3256f0a865db8af92904cc1c31b)
#### Monday 2021-12-20 21:27:32 by Akke

Nerf the Soul Collector

I think that the soul collector has a very good place in the current meta of the game, and it has honestly always been great. The problem (in my opinion) is that it is capable of decreasing the value of someones networth based on the fact that it stops all current regeneration, and on top of this it also slows for a huge amount.

This nerf would target the healing reduction primarily, but also slightly touch the slow amount to make it feel a bit more balanced without impacting the game too much.
 
Specifically for the healing reduction, I've decided to decrease it to 75%, because if you're playing as a tank hero it's capable of turning your high networth spent on tanky regen items into basically nothing. On top of this, it's also a very powerful nuke item, and when cast on enemies in their fountain you prevent the fountain from actually protecting them, and I still feel like that should never be the case. 

Decreasing it from 100% to 75% is justified, in my opinion, because the 25% will still let you keep some of that regen, while also making it possible to kill you — it would just take a second or two longer.

---
## [Sage1000100/study.med.student.kit.demo](https://github.com/Sage1000100/study.med.student.kit.demo)@[a8d19ebdbe...](https://github.com/Sage1000100/study.med.student.kit.demo/commit/a8d19ebdbe9016b38b3f23852d9030ea59c14ebd)
#### Monday 2021-12-20 22:43:05 by Sage1000100

sure

I'm not  burnout I'm ex top anon and I got kicked out of brown university a few times. I attend @stanford I never cheated a day in my life my speciality was outsmarting robotics. machines. not humans. they kicked me out of server temporarily when I fried people who were the dark web day and night and alternative sequences.... I still believe this will always be a trend but im out the game for at least 50 years. im aware of my interstellar time. Vedic sciences and the way.

---
## [tdauth/wowr](https://github.com/tdauth/wowr)@[abff3169b1...](https://github.com/tdauth/wowr/commit/abff3169b16f95e84e9c173fbb0dee7134f3b78c)
#### Monday 2021-12-20 22:44:04 by barade

1.8.8

- Reveal the initial town hall location to all players in the beginning.
- Unpause Harpy Queen when starting Orc Quest 2.
- Pan camera to hero after leaving the portal.
- Add chat command "-pinggoldmines".
- Add VIP flags for Undead, Night Elf and Orc as well.
- Move creeps fruther away from Northrend West start base.
- Setup alliances for bosses during the map initialization instead of after 0 seconds which might prevent the creeps attacking one boss bug.
- Add VIP marker item with the players name and some text.
- Move VIP room portal to the left.
- Restrict constructing buildings at hidden bases to hero level 35.
- Add second hidden base in the Ocean.
- Fix colors of crafted items of Dragon Breeder and Sorcerer.
- Add Hero Glow to bonus hero Gul'dan.
- Add custom Siphon Mana and Life Drain abilities with correct icon positions and tooltips to bonus hero Gul'dan.
- Move VIP portal to the Outland portal area, so you can enter it more often.
- Add Fountain of Blood to Orc Warlords.
- Do not allow dropping regular items in the VIP room.

---
## [jamesjarvis/monzo-users](https://github.com/jamesjarvis/monzo-users)@[3e5fe6f07d...](https://github.com/jamesjarvis/monzo-users/commit/3e5fe6f07d0a36141a34a19510cebc5076f41119)
#### Monday 2021-12-20 22:47:50 by James Jarvis

replace charts (#53)

* yeah nah this shit sucks imma try something else

* use apex charts as they are just better

---
## [StePyl/name-not-found](https://github.com/StePyl/name-not-found)@[ab3fd493a3...](https://github.com/StePyl/name-not-found/commit/ab3fd493a3592e8db82e86cb83f93d2164949461)
#### Monday 2021-12-20 23:07:30 by JasoonX

Merge branch 'master' of github.com:StePyl/name-not-found into fuck-you

---

# [<](2021-12-19.md) 2021-12-20 [>](2021-12-21.md)

