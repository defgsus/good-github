# [<](2021-04-12.md) 2021-04-13 [>](2021-04-14.md)

3,173,207 events, 1,614,166 push events, 2,505,253 commit messages, 195,046,358 characters


## [gquintard/official-images@e99f5d3915...](https://github.com/gquintard/official-images/commit/e99f5d39157e8fc8ee91af7739ffd86305ca7415)
##### 2021-04-13 00:04:48 by Guillaume Quintard

[varnish] overload the binaries with scripts

This is a follow-up of #9914. The now current approach works well EXCEPT
when people exec into the container with `bash` or whatever since the
entrypoint can't work it magic.

So, the blunt approach is to create a series of trampoline scripts that
will just add `-n /var/lib/varnish` before all arguments. It's not super
elegant, and I'm not a fan of overloading `PATH` but:
- it works transparently
- you can easily bypass the trampoline by using the binary's absolute
  path
- the logic is pretty obvious with `/varnish_cmds/` sitting proudly at
  the root level of the file-system.

I decided against generating the scripts from the `Dockerfile`s to avoid
escape hell, but I can be convinced otherwise if it makes reviews
easier.

---
## [JJawesomeJJ/jjawesome-3d@dbd051ad82...](https://github.com/JJawesomeJJ/jjawesome-3d/commit/dbd051ad82a32649d78e6af3575273ce88c4f562)
##### 2021-04-13 09:06:01 by zhaolijie

-water----normal life --
--single life how long will continue
--No mater how sadness of the life remember you are petty unique boy
--fight young man the futher may be darkness but don't be fear,remember the beauty will always wait for you in the some which is not far away --2020-12-15

---
## [mrakgr/The-Spiral-Language@abbc2802b5...](https://github.com/mrakgr/The-Spiral-Language/commit/abbc2802b519d606ceb4d9ecd5aca00bbffc058d)
##### 2021-04-13 11:05:48 by Marko Grdinić

"11:15am. Am I getting sleep during the night or not? I can't tell anymore. But it definitely was not deep. But I am not completely exhausted.

Well, nevermind this. Let me chill a bit and then I will start. The first order of business is to take care of that compiler bug. After that I'll bring back the old core. I can't be bothered to fix the docs and the test cases.

11:40am. Let me find that bug.

```fs
            let file_build (s : SupervisorState) mid (tc : WDiff.ProjStateTC, prepass : WDiffPrepass.ProjStatePrepass) =
                let _,b = tc.files.uids_file.[mid]
                let x,_ = prepass.files.uids_file.[mid]
                Hopac.start (b >>= fun (has_error,_) ->
                    if has_error then fatal $"File {Path.GetFileNameWithoutExtension file} has a type error somewhere in its path."; Job.unit() else
```

This is the wrong has error. Let me track it down.

```fs
    member _.file(name,state,x) =
        let x = wdiff_file_update_state funs_file_tc x state
        let env =
            typechecker_results_summary x.result >>-* fun (has_error,env) ->
            has_error, match name with None -> env | Some name -> in_module name env
        x,env
```

Hmmm....

11:45am. I know what the error is, but I am not sure how to fix it.

11:55am.

```fs
            let file_build (s : SupervisorState) mid (tc : WDiff.ProjStateTC, prepass : WDiffPrepass.ProjStatePrepass) =
                let a,b = tc.files.uids_file.[mid]
                let x,_ = prepass.files.uids_file.[mid]
                Hopac.start (a.state >>= fun (has_error',_) ->
                    b >>= fun (has_error,_) ->
                    if has_error || has_error' then fatal $"File {Path.GetFileNameWithoutExtension file} has a type error somewhere in its path."; Job.unit() else
```

I've gone over this, and I don't know whether there is a better way. But this should be the `||` of the errors coming in, and the errors in the module.

Let me give it a try.

Yeah, it works. Let me deal with core.

12:10pm. I put the old core back in and modified the array operations so they use the new ops. I have no idea why I haven't done this earlier.

Let me publish the patch. Also let me add a new entry to the readme.

12:15pm. Sigh, the router is acting up again and the package is not going through. This is going to be huge trouble once I have my agents ready. I guess I'll just buy a router out of my own pocket at that time. My father told me he is keeping this one around because it is programmable. Well, it might be programmable, but also belongs in the trash.

12:35pm. Let me reset the damn router.

12:40pm. These Internet connection issues are killing me. I reset the router and the regular browsing seems more responsive now, but the plugin still won't go through. I meant to push the commit here and have breakfast, but I guess I'll leave it until I managed to publish the patch.

12:45pm. It seems I am have more trouble publishing the patch than actually fixing the bug. Let me leave that aside for later.

...The OVSX went through.

```
1) Free up the UI loop while training is being done in the background. Right now the chart is not even updating while the training is going on.

2) Integrate this with the game and play against the CFR agent.

3) Optimize the whole program. Right now the training is way to slow. It will take forever once I move on to flop poker.
```

These will be my goals for the day.

If it was .NET, I'd just implement the training server as an agent and have the UI send messages to it. What about Python? Does it have anything I can use for agent based concurrency? Or channels?

https://stackoverflow.com/questions/19130986/python-equivalent-of-golangs-select-on-channels

Let me read this. Google suggested it to me.

1pm. https://docs.python.org/2/library/multiprocessing.html#multiprocessing.Pipe
https://docs.python.org/2/library/threading.html#threading.Thread

Mhhh, I have to make time to study this.

1:05pm. Oh, it finally went through. Let me commit here and have breakfast. I am going to watch some Python concurrency vids after that and play around with this. I still have no idea how Python can have concurrency given the GIL, but I guess I'll find out."

---
## [williamjcm/m.css@915ffcbed5...](https://github.com/williamjcm/m.css/commit/915ffcbed545b9c38f55fac07f33ef04433863a8)
##### 2021-04-13 13:25:29 by Vladimír Vondruš

package/ci: go back to Pelican 4.2 until I find a fix.

OH GOD, one can't just leave a project alone for 6 months because every
damn thing just breaks, changes or gets removed. Kids these days, FFS.

Imagine if the standard of electrical outlets changed rapidly every two
weeks, you'd just have to constantly buy new fucking adapters and you
would HATE it. So why is it COMPLETELY FINE with software?!

---
## [puddly/home-assistant.io@5ddb6529c1...](https://github.com/puddly/home-assistant.io/commit/5ddb6529c13dd4ba8f5aa364b2560740a77bf178)
##### 2021-04-13 15:27:14 by elyobelyob

I found that a 4pm or other non midnight required buffering. (#16182)

* Update history_stats.markdown

---
title: History Stats
description: Instructions about how to integrate historical statistics into Home Assistant.
ha_category:
  - Utility
  - Sensor
ha_iot_class: Local Polling
ha_release: 0.39
ha_quality_scale: internal
ha_domain: history_stats
---

The `history_stats` sensor platform provides quick statistics about another integration or platforms, using data from the [`history`](/integrations/history/) integration.

It can track how long the integration has been in a specific state, in a custom time period.

Examples of what you can track:

- How long you were at home this week
- How long the lights were ON yesterday
- How long you watched TV today

## Configuration

To enable the history statistics sensor, add the following lines to your `configuration.yaml`:

{% raw %}

```yaml
# Example configuration.yaml entry
sensor:
  - platform: history_stats
    name: Lamp ON today
    entity_id: light.my_lamp
    state: 'on'
    type: time
    start: '{{ now().replace(hour=0, minute=0, second=0) }}'
    end: '{{ now() }}'
```

{% endraw %}

{% configuration %}
entity_id:
  description: The entity you want to track.
  required: true
  type: string
state:
  description: The states you want to track.
  required: true
  type: [list, string]
name:
  description: Name displayed on the frontend. Note that it is used by Home Assistant to generate sensor's `object_id` so it is advisable to choose a unique one and change name for frontend using [customization](/docs/configuration/customizing-devices/#friendly_name) or via [Lovelace](/lovelace/entities/#name).
  required: false
  default: unnamed statistics
  type: string
type:
  description: "The type of sensor: `time`, `ratio`, or `count`."
  required: false
  default: time
  type: string
start:
  description: When to start the measure (timestamp or datetime).
  required: false
  type: template
end:
  description: When to stop the measure (timestamp or datetime).
  required: false
  type: template
duration:
  description: Duration of the measure.
  required: false
  type: time
{% endconfiguration %}

<div class='note'>

  You have to provide **exactly 2** of `start`, `end` and `duration`.
<br/>
  You can use [template extensions](/topics/templating/#home-assistant-template-extensions) such as `now()` or `as_timestamp()` to handle dynamic dates, as shown in the examples below.

</div>

## Sensor type

Depending on the sensor type you choose, the `history_stats` integration can show different values:

- **time**: The default value, which is the tracked time, in hours
- **ratio**: The tracked time divided by the length of your period, as a percentage
- **count**: How many times the integration you track was changed to the state you track

## Time periods

The `history_stats` integration will execute a measure within a precise time period. You should always provide 2 of the following :
- When the period starts (`start` variable)
- When the period ends (`end` variable)
- How long is the period (`duration` variable)

As `start` and `end` variables can be either datetimes or timestamps, you can configure almost any period you want.

### Duration

The duration variable is used when the time period is fixed. Different syntaxes for the duration are supported, as shown below.

```yaml
# 6 hours
duration: 06:00
```

```yaml
# 1 minute, 30 seconds
duration: 00:01:30
```

```yaml
# 2 hours and 30 minutes
duration:
  # supports seconds, minutes, hours, days
  hours: 2
  minutes: 30
```

<div class='note'>

  If the duration exceeds the number of days of history stored by the `recorder` component (`purge_keep_days`), the history statistics sensor will not have all the information it needs to look at the entire duration. For example, if `purge_keep_days` is set to 7, a history statistics sensor with a duration of 30 days will only report a value based on the last 7 days of history.

</div>

### Examples

Here are some examples of periods you could work with, and what to write in your `configuration.yaml`:

**Today**: starts at 00:00 of the current day and ends right now.

{% raw %}

```yaml
    start: '{{ now().replace(hour=0, minute=0, second=0) }}'
    end: '{{ now() }}'
```

{% endraw %}

**Yesterday**: ends today at 00:00, lasts 24 hours.

{% raw %}

```yaml
    end: '{{ now().replace(hour=0, minute=0, second=0) }}'
    duration:
      hours: 24
```

{% endraw %}

**This morning (6AM - 11AM)**: starts today at 6, lasts 5 hours.

{% raw %}

```yaml
    start: '{{ now().replace(hour=6, minute=0, second=0) }}'
    duration:
      hours: 5
```

{% endraw %}

**Current week**: starts last Monday at 00:00, ends right now.

Here, last Monday is _today_ as a timestamp, minus 86400 times the current weekday (86400 is the number of seconds in one day, the weekday is 0 on Monday, 6 on Sunday).

{% raw %}

```yaml
    start: '{{ as_timestamp( now().replace(hour=0, minute=0, second=0) ) - now().weekday() * 86400 }}'
    end: '{{ now() }}'
```

{% endraw %}

**Next 4pm **: ends today at 00:00, lasts 30 days. Easy one.

{% raw %}

```yaml
    end: '{{ now().replace(hour=0, minute=0, second=0) }}'
    duration:
      days: 30
```

{% endraw %}

**Last 30 days**: ends today at 00:00, lasts 30 days. Easy one.

{% raw %}

```yaml
    end: '{{ now().replace(hour=0, minute=0, second=0) }}'
    duration:
      days: 30
```

{% endraw %}


** 4PM always in the future**: ends in the future at 16:00, starts 24 hours before.

{% raw %}

```yaml
    end: '{{ (now().replace(minute=0,second=0) + timedelta(hours=8)).replace(hour=16) }}'
    duration:
      hours: 24
```

{% endraw %}

**All your history** starts at timestamp = 0, and ends right now.

{% raw %}

```yaml
    start: '{{ 0 }}'
    end: '{{ now() }}'
```

{% endraw %}

<div class='note'>

  The `/developer-tools/template` page of your Home Assistant UI can help you check if the values for `start`, `end` or `duration` are correct. If you want to check if your period is right, just click on your component, the `from` and `to` attributes will show the start and end of the period, nicely formatted.

</div>

* $pm - 4pm example implemented

* Tweak

* Update source/_integrations/history_stats.markdown

Very happy with this change ...

Co-authored-by: Franck Nijhof <frenck@frenck.nl>

* Update source/_integrations/history_stats.markdown

Co-authored-by: Franck Nijhof <frenck@frenck.nl>

---
## [mrakgr/The-Spiral-Language@5d3b803a63...](https://github.com/mrakgr/The-Spiral-Language/commit/5d3b803a63e7be9cd3cf90a2b10c54cf9b7a166d)
##### 2021-04-13 17:43:11 by Marko Grdinić

"2:20pm. Let me do the chores here.

2:50pm. Let me start.

https://docs.python.org/3/library/multiprocessing.html

The docs for this are quite good and I can already see that multiprocessing is what I should study. In fact, the doc says at the outset that I should use multiprocessing if I want more than just a single thread.

But still, let me do a bit of research. I'll see whether there is a video on multiprocessing on Youtube.

...No these all seem like simple tutorials. Nevermind them. Let me play around with examples then.

> https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming

Ensure that the arguments to the methods of proxies are picklable.

This is something that has me worried. Don't tell me it is pickling these. If so I am going to have to account for these kinds of transfers.

3:10pm. Focus me, stop surfing /g/ on the side. Read the multiprocessing docs.

https://docs.python.org/3/library/multiprocessing.html#connection-objects
> Return the file descriptor or handle used by the connection.

Damn it, these things literally communicate through files. I suppose in this case the files might be memory mapped, but it is no possible that performance of this would ever be good.

3:55pm. Ugghhhhhhhhh...

I should try it out, but I doubt that Cython cdef objects will be picklable.

What should I do here? I really do not want to use multiprocessing. It is obviously the wrong thing for the job.

https://stackoverflow.com/questions/35275323/python-gui-threading

https://realpython.com/python-pyqt-qthread/

Let me take a look at this last thing.

> Fortunately, there are some techniques you can use to work around this issue. A commonly used solution is to run your long-running task outside of the application’s main thread using a worker thread.

Worker threads? In Python? My current understanding is that Python cannot have multiple concurrent threads and just emulates them using a single one. If I am wrong that will simplify my life a lot.

> In Python’s C implementation, also known as CPython, threads don’t run in parallel. CPython has a global interpreter lock (GIL), which is a lock that basically allows only one Python thread to run at a time.

> This can negatively affect the performance of threaded Python applications because of the overhead that results from the context switching between threads. However, multithreading in Python can help you solve the problem of freezing or unresponsive applications while processing long-running tasks.

4:10pm.

> QThread isn’t a thread itself. It’s a wrapper around an operating system thread. The real thread object is created when you call QThread.start().

https://realpython.com/python-pyqt-qthread/#using-qthread-vs-pythons-threading

I was just wondering about this.

Hmmm, could I use Python's `threading` to offload long running tasks. Maybe it itself can get around the GIL. I don't know.

4:10pm. Ok, so PyQt does have threads pools, which is proof that is possible in Python. This is evidence enough that I won't need to spawn multiple processes just to get responsive GUIs. If PyQt had the advantage of actual true threads and `threading` did not, they would definitely advertize it. This is proof that `threading` can do it as well.

4:30pm. Had to take a break. Forget multiprocessing. Let me check out multithreading.

4:35pm. https://realpython.com/intro-to-python-threading/

Let me read this first and then I will move to Python docs.

> If you are running a standard Python implementation, writing in only Python, and have a CPU-bound problem, you should check out the multiprocessing module instead.

You know what, threading will be fine. Yes, the task is IO bound. But the UI itself is not CPU instensive, at least it should not be. Using multiprocessing will turn into a serialization and a maintenance nightmare. The Cython backend is not structured towards passing Python types effortlessly.

4:50pm. https://docs.python.org/3/library/threading.html

I skimmed the other article let focus on this page here.

It would be doable to make a multiprocessing based solution in Spiral, but the dictionary already took up enough of my time. I can't afford to wrestle with serialization issues. `threading` will do.

> If you want your application to make better use of the computational resources of multi-core machines, you are advised to use multiprocessing or concurrent.futures.ProcessPoolExecutor.

Actually what is this last one? Forget it, it is based on processes.

.NET has a huge advantage over Python in concurrency, almost as much as Python has in ML.

.NET's approach will definitely win long term on CPUs. Maybe once more restricted AI chips than GPUs get here, .NET will become a viable platform for ML. But for now I'll take my hacks. My cuts and bruises.

5pm. What is next? Let me think.

5:10pm. I see it. Communicating with the GUI itself is not a problem.

I need to figure out how to make an agent. Once I do that I am set. Let me take a look at that first SO question.

https://stackoverflow.com/questions/19130986/python-equivalent-of-golangs-select-on-channels
https://docs.python.org/3/library/queue.html

Does using `get` block the thread?

> Queue.get(block=True, timeout=None)
> Remove and return an item from the queue. If optional args block is true and timeout is None (the default), block if necessary until an item is available.

Yes, it is as I expected. Ok.

https://docs.python.org/3/library/queue.html

What is `task_done` supposed to be doing?

///

See also
Class multiprocessing.Queue
    A queue class for use in a multi-processing (rather than multi-threading) context.

collections.deque is an alternative implementation of unbounded queues with fast atomic append() and popleft() operations that do not require locking and also support indexing.

///

https://docs.python.org/3/library/collections.html#collections.deque

> Deques are a generalization of stacks and queues (the name is pronounced “deck” and is short for “double-ended queue”). Deques support thread-safe, memory efficient appends and pops from either side of the deque with approximately the same O(1) performance in either direction.

5:30pm. No, I require blocking gets for when the queue is empty.

https://goless.readthedocs.io/
https://github.com/stackless-dev/stackless/wiki

What is this?

Thought it is doable, I am really leaning towards getting an existing channel or agent library.

https://pypi.org/project/pygolang/

This even supports Cython.

https://stackoverflow.com/questions/26302572/python-kivy-properly-start-a-background-process-that-updates-gui-elements

6:25pm. https://www.youtube.com/watch?v=IEEhzQoKtQU

I am thinking about it. Let me watch this tut. As expected, concurrency quickly turns into a nightmare of complexity.

With the system I have now, even though it freezes the UI, I still have my sequential guarantees. That will fly out the window once I start putting in threads.

https://goless.readthedocs.io/en/latest/#a-references

This is not good, it cannot pool on the channel. I am going to have to do as in the SO question using queues and threads after all.

6:35pm. https://youtu.be/IEEhzQoKtQU?t=1081

This is worth watching. I would not have figured out the thread pool executor on my own.

6:50pm. Let me have lunch here. I am still thinking about it.

7:25pm. Done with lunch.

```
1) Free up the UI loop while training is being done in the background. Right now the chart is not even updating while the training is going on.

2) Integrate this with the game and play against the CFR agent.

3) Optimize the whole program. Right now the training is way too slow. It will take forever once I move on to flop poker.
```

I've planned out how to do the first point. I've had all day to think about it, and threading and queues are the way to go. I am not going to bother with special libraries for this. All sort of issue come up when the move from sequential to concurrent is done and it is a huge problem. I've forgotten how hard it really is.

I'll also give up multiprocessing for the time being. For this to be sound I'd need to deal with inter process serialization and they would be too much work.

Spiral uses its own types everywhere, and it would be hard to do this quickly. Not to mention, all sort of difficulties that I can't anticipate right now would crop up. For example, with multithreading I can call functions in `ui_train.py` module, but what if that was in a different process? I'd need to write extra manual interop code to get around the limitation.

It is simply a poor idea, if I needed this level of concurrency I'd just move to .NET. The UI won't use up the CPU too much, and even when GPU training starts getting done, most of the time will be waiting for the GPU operation to complete after which the thread will block.

In fact, tabular CFR training will be a lot more taxing on the CPU than the neural net one.

7:35pm. Let me stop here for the day. I want to do a good job and think things through, but progress is just so slow. That impacts my motivation to do the work negatively.

But at the very least I will do the UI tomorrow. Then I will move to the other points.

Once I deal with sampling tabular CFR, it will be time to move to the neural version. I will have a true trial of insight and skill at that time. Until then, all I can do is plug along.

Maybe things will get more fun once I have trained agents and can play against them.

I wish that one day I will understand the algorithms that underlie intelligence."

---

# [<](2021-04-12.md) 2021-04-13 [>](2021-04-14.md)

