# [<](2021-05-26.md) 2021-05-27 [>](2021-05-28.md)

3,664,319 events, 1,518,542 push events, 2,481,337 commit messages, 182,866,550 characters


## [nin66/CompGraphics@0b7394023e...](https://github.com/nin66/CompGraphics/commit/0b7394023e11ee0906e1eaab13d5e43aea3ff90f)
##### 2021-05-27 00:42:21 by WichaelMu

Minor Fish Update

"Minor"? this movement thing literally took me 12 hours and i still couldn't figure it out.

for some dumb reason, only BrownFish wants to move towards a coral, nothing else. Even though there's a fishies array that holds every single fish in the scene, it still doesnt want to move. However, 1 in 100 times, everything works properly.

Still, the fishies will still collide into terrain and go through them because three js and javascript are hilariously slow at processing anything and it takes too long to load Reef Exploration.

Three JS and javascript are both the two worst things ive ever worked with, same goes for python. interpreted languages are very stupid and should never be used.

i started working on this at 10am and its now 10pm. i literally wasted my whole day trying to get something to work on an inferior language.

I also love this subject, ive learnt more about how three js and javascript suck ass than actually learning content because no one teaches it anyway.

who even reads this?

---
## [KeefeOverby/Button-to-Second-Screen@fdba23a811...](https://github.com/KeefeOverby/Button-to-Second-Screen/commit/fdba23a811b0493fb296ff8eb109f87f671adb51)
##### 2021-05-27 01:43:24 by KeefeOverby

Button to Second Screen App
v 1.1
Success!!!!!!!!!!
It was way to difficult to find a simple explanation for one button that navigates to a second screen. Developers that have a lot of experience make "basic" lessons way too complicated. It took me three days searching the internet to find little bits and pieces of information just to complete this simple app. It's a shame that experienced developers call their extremely complicated lessons "basic" it's dishonest to say that overly complicated lessons are "basic" when they know deep down that its clearly not basic. This app that I just created is basic, one button to a second screen. That is basic, clear and easy to comprehend. I am honest, but unfortunately some people are not, dishonest people are horrible.

---
## [guzzlehumdrum/GuzzleHumdrum@01965911ac...](https://github.com/guzzlehumdrum/GuzzleHumdrum/commit/01965911ac5e23fd64a48d877cbba34759a1e061)
##### 2021-05-27 07:48:26 by guzzlehumdrum

Create The Pedantic Ones@Resultant Never New.html

Kakhaber(giggle) : "thoughts coming to urge me now.."
Nestani(giggle) : "oh nuzzle why i you how.."
Kakhaber+Nestani(giggle) : "oh swoons to whom/oh witness you loom..
Over and after and forever oh saying to/Random Random Existing/Oh Ocean Checked Real Consisting/Never By Made Up Oh Insistence/Oh Reality checked Existence..
check by or check as self/obviously incidence of made/up if then oh i/Adventure of Can in Try..
Oh Ocean be no all/my boo real your call/checked as then will be made/oh what incidence paid..
to exist no existence/real boo obviously made..
yo..adventure of paths/existing really berth/testaments look circle and/Quill Gunning to be Can..
Living Living Painting/Proven Dual Umpteen/Adventuring of Paths/Reality Chekced two-and-one-Hush.."
Roxanne(giggle) : "eww.. Satu how did they come up with it how i realized this#..Satoshi..Adventures of Path,#,.."
Satoshi(frown) : "Roxie didn't i tell you not to come inside the changeroom at random times#.."
Roxanne(making a face) : "huh as if you could come up with this spontaneously unlike if you were in knowledge of i not me#..Kakhaber+Nestani..The Vertical Ones,#,..Satoshi+Roxanne too un..,#,.."
Nejla(giggle) : "no you if weren't i would've said..
Oh Penchant Penchant Penchant..Locate Oh Aspect Indeed#..Roxanne..Nestled Logic,#,..Nejla too un..,#,.."
Roxanne(making a face) : "huh as if you understand he actual meanings#.."
Nejla(frown) : "relying-s yeah#.."
Satoshi(frown) : "enough#.."
Kesiraju(making a face..) : "enough..this exactly this is why you come up with situations and conclusions never repechage of attention..like,
sect fact pact deal..in-turn pass/next attention gap i discuss discuss..
so rendering to void you see Roxie exactly this fear has stopping Satu for claiming as i#..Satoshi..Case-of-Logic,#,..Roxanne..The Scripted Ones,#,..Kesiraju+Nejla too un..,#,.."
Satoshi(angry) : "hey hey don't mention that lowlife about MY personal life ok#..Discuss Gap,#,.."
Kakhaber+Nestani(returning from set,giggle) : "oh curly curly will mention be/wheel then runs over me/discuss look imputes duality/relationship thus illusion's peity..as image of me/discuss gap will look to duality..but unto murmur murmur oh says consciousness why nuzzle me#..Satoshi+Roxanne..The Drifted Ones,#,..Kakhaber+Nestani too un..,#,.."
Satoshi(angry) : "Roxie did that lowlife Enkhu tell you to turn up here randomly#.."
Roxanne(giggle) : "oh i and imputed..la la la la me or my thee..cue cue/never new so i hihi..Simile.."
Satoshi(angry) : "you..i'm leaving ok you all lowlifes set up yourselves..no aslo i'm leaving with MY move it#.."
Roxanne(giggle) : "aww..that's called thought : the Discussed Gap#.. that's ehat this show is supposed to show too hence no difference between backlogs and presence see#..Satoshi..Convene Skats,#,.."
Poppy(scowl,was only audience) : "it would've been added see the least objective but you deviated from presence to causality#..Roxanne..Incentive Overdose,#,.."
Satoshi(scowl) : "and you claim to be un-singular#.."
Poppy(happy) : "down to desire/i want alas then desire will tire/thus said by trier/oh intelligence why soundness you retire..
oh speaking not/offer ought/if means/oh dually really/what means seems..
oh you're subjective to me not objects of i fair enough i tried to tell how and what to me my#..Satoshi+Roxanne..Incentive Overdose,#,.."
Kakhaber+Nestani&Kesiraju+Nejla(giggle) : "no Satu,Roxie this is the way to ask Poppy flower like,
but then conjunctive is cessation.."
Poppy(scowl) : "you preceptor's orientation's conjecture based perceptual tenacity's b.. it would've said comprehensive of consequent discussion#..Kakhaber+Nestani&Kesiraju+Nejla..The Pedantic Ones,#,.."

---
## [mrakgr/The-Spiral-Language@c63628a932...](https://github.com/mrakgr/The-Spiral-Language/commit/c63628a932fc3f2acf94629a79d32de7755a3661)
##### 2021-05-27 10:05:45 by Marko GrdiniÄ‡

"9:45am. I am up. Let me chill a little.

9:50am. No reply to the issue I've opened. This is going to be harsh. I'll have to get creative with my use of PyTorch.

10:20am. Let me finish the chapter I am reading and then I will start. I have only 15 chapters of Katahane No Riku left, so I am looking for new things.

10:25am. Let me start.

Hmmmm, what am I going to do? Well, for starters let me make the example from yesterday work. I had some time to think about how to make it effective.

```py
class VarianceMatch(Function):
    @staticmethod
    def forward(ctx, x):
        y = f(x)
        y_grad_fn = y.grad_fn
        ctx.save_for_backward(x,y,y_grad_fn)
        return y

    @staticmethod
    def backward(ctx, grad_y):
        x,y,y_grad_fn = ctx.saved_tensors
        y_grad_fn.backward(grad_y)
        x.grad *= torch.sqrt(torch.square(grad_y).sum(1) / torch.square(x.grad).sum(1))
        return None
```

Let me go with this. It is worth a try.

```py
y_grad_fn(ctx,grad_y)
```

Ah, maybe like this.

```py
        print(x)
        y = f(x)
        print(y)
        y_grad_fn = y.grad_fn
```

This is trouble. Doing the foward here does not give me the backward function. No doubt, this is on purpose.

Hmmm...I guess it makes sense. This allows me to easily reuse the forward primitives, if it really did give me the backward in the forward, that would just be overwritten anyway.

10:45am. Can I even implement what I want within the constraints PyTorch is giving me? No, not like this.

I am going to have to get that `y_grad_fn` somehow. Otherwise, I can get to work writing my own library.

Let me ask on the PyTorch forums.

https://discuss.pytorch.org/t/what-are-hooks-used-for/40020

> You could pass a function as the hook to register_hook, which will be called every time the gradient is calculated. This might be useful for debugging purposes, e.g. just printing the gradient or its statistics, or you could of course manipulate the gradient in a custom way, e.g. normalizing it somehow etc.

Oh, this is interesting.

https://pytorch.org/docs/stable/autograd.html#torch.Tensor.register_hook

This is not flexible enough for me. I am not sure how to use it anyway.

```py
import torch
from torch.autograd import Function

# Is meant to be arbitrary.
def f(x):
    return x*2

class VarianceMatch(Function):
    @staticmethod
    def forward(ctx, x):
        y = f(x)
        y_grad_fn = y.grad_fn # Results in None
        ctx.save_for_backward(x,y,y_grad_fn)
        return y

    @staticmethod
    def backward(ctx, grad_y):
        x,y,y_grad_fn = ctx.saved_tensors
        y_grad_fn(ctx,grad_y)
        x.grad *= torch.sqrt(torch.square(grad_y).sum(1) / torch.square(x.grad).sum(1))
        return None

i = torch.scalar_tensor(2,requires_grad=True)
x = VarianceMatch.apply(i)
x.backward(torch.scalar_tensor(1))
print(i.grad)
```

Let me post this on the forum so I can ask how to do this.

11:15am. https://discuss.pytorch.org/t/how-to-implement-a-function-whose-input-and-output-vectors-have-the-same-gradient-variance/122529

11:20am. Ok, what the hell do I do now? Is there anything I can do? I can think of some way using hooks, but that is basically it. I am not sure how to feel about adding hooks on the forward pass. Can I have a hook unregister itself?

11:30am. Now I am reading the isekai thread.

11:35am. Focus me. Let me try the hook idea. Let's not waste the entire day today.

```py
import torch
from torch.autograd import Function

class VarianceMatch(Function):
    @staticmethod
    def forward(ctx, x):
        y = x * 2
        def h(grad):
            print(y.grad)
            print(grad)
            return grad * torch.sqrt(torch.square(y.grad).sum(1) / torch.square(grad).sum(1))
        x.register_hook(h)
        return y

    @staticmethod
    def backward(ctx, grad_y):
        return grad_y * 2

i = torch.scalar_tensor(2,requires_grad=True)
x = VarianceMatch.apply(i)
x.backward(torch.scalar_tensor(1))
print(i.grad)
```

Let me try this.

No, `y.grad` is not present so that idea is out of the question. I give up. I can't implement this on my own.

Actually, maybe since it is not a leaf node, I should enable the grads for it.

https://discuss.pytorch.org/t/how-do-i-calculate-the-gradients-of-a-non-leaf-variable-w-r-t-to-a-loss-function/5112

Let me try using `retain_grad`.

11:55am. Nope. `y.grad` is simply not there no matter what I do.

12pm. I am just wasting my time here. Let me have breakfast while I think about it. Maybe I will do some research on how to write C++ PyTorch extensions. Right now I am at a dead end, but I can't just spend the whole day doing nothing. I might as well get familiar with PyTorch internals. Maybe this will give me a hint on how to deal with the softmax.

This sucks."

---
## [ZeraGmbH/vf-qmllibs@281cf5f8a7...](https://github.com/ZeraGmbH/vf-qmllibs/commit/281cf5f8a7ce0291bf9ad36b816e1177e2bbad35)
##### 2021-05-27 11:52:56 by Andreas MÃ¼ller

Cleanup CMake files

* remove annoying line feeds: Why scrolling more than necessary
* remove leftovers
* remove extra quirks: They are not necessary and from my experience as
  oe-packer: Every non standard option tends to break throughout the lifetime
  of a project
* use CMAKE_BUILD_TYPE correctly without forcing oe-recipe to preset it

Signed-off-by: Andreas MÃ¼ller <schnitzeltony@gmail.com>

---
## [ropensci/osmextract@d182504aad...](https://github.com/ropensci/osmextract/commit/d182504aad41854a7d054339d9600c63f80475c8)
##### 2021-05-27 14:13:40 by Andrea Gilardi

I think immediate. = TRUE for warnings was a stupid idea

@Robinlovelace, thoughts?

---
## [ropensci/osmextract@5d02193946...](https://github.com/ropensci/osmextract/commit/5d021939469a223e5823dae0589a26c9fb57ddb8)
##### 2021-05-27 14:23:34 by Andrea Gilardi

I think immediate. = TRUE in warnings was a stupid idea

@Robinlovelace, thoughts?

---
## [SylvanasIII/Rebirth-Of-The-Night@f358bd448c...](https://github.com/SylvanasIII/Rebirth-Of-The-Night/commit/f358bd448c133eaf7dd404e52afe0cf00758ed82)
##### 2021-05-27 16:53:53 by SylvanasIII

A metric crapton of changes

Beetburger partly unnerfed (16->12->14)
Cantaloupe nerfed
Toast sandwich buffed
Garlic bread buffed, as this divine substance should be
Caesar salad buffed (though I feel like there should be a separate crouton item made from the toast, so salads aren't unreasonably filling)
Stuffed mushroom buffed
Salmon patties buffed
Fried egg buffed (partly why beet burger was buffed, as this is an ingredient)
Pork lettuce wrap buffed
PB&J buffed
PB banana sandwich buffed
Chili chocolate buffed
Hearty breakfast untouched, it would be a waste of ingredients if nerfed
Maple sausage buffed significantly
Honeycomb chocolate bar nerfed
Fairy bread significantly buffed. Consume the fae.
Chocolate bacon nerfed
Pepperoni nerfed
Non-durian milkshakes buffed
Naan buffed
Paneer tikka masala buffed
Hot and sour soup buffed
Peking duck buffed
Char siu nerfed
Apple fritter nerfed
Creeper cookie buffed significantly. Why it doesn't make you explode or resist explosions, I don't know.
Meatloaf sandwich greatly buffed, somewhat against my judgement but the math checks out
Nether wings untouched, blazes are relatively easy to farm once you find a nether fort, and you get 3 powder per rod.
Cookies and milk buffed
Crackers and derivatives untouched for now, I think crackers should be nerfed and you should get multiple from the recipe (e.g., only 1 shank, but the recipe gives 2).
Lastly, chicken dinner buffed.
Kale list parts dealt with: 1, 2 (partly), 7, 12, 14, 15, 21-25, 27-36, 38, 40.

---
## [clayne/mpv@f4e89dde36...](https://github.com/clayne/mpv/commit/f4e89dde36644edec7d09856ac83140317f0b687)
##### 2021-05-27 17:08:01 by Dudemanguy

wayland: simplify render loop

This is actually a very nice simplification that should have been
thought of years ago (sue me). In a nutshell, the story with the
wayland code is that the frame callback and swap buffer behavior doesn't
fit very well with mpv's rendering loop. It's been refactored/changed
quite a few times over the years and works well enough but things could
be better. The current iteration works with an external swapchain to
check if we have frame callback before deciding whether or not to
render. This logic was implemented in both egl and vulkan.

This does have its warts however. There's some hidden state detection
logic which works but is kind of ugly. Since wayland doesn't allow
clients to know if they are actually visible (questionable but
whatever), you can just reasonably assume that if a bunch of callbacks
are missed in a row, you're probably not visible. That's fine, but it is
indeed less than ideal since the threshold is basically entirely
arbitrary and mpv does do a few wasteful renders before it decides that
the window is actually hidden.

The biggest urk in the vo_wayland_wait_frame is the use of
wl_display_roundtrip. Wayland developers would probably be offended by
the way mpv abuses that function, but essentially it was a way to have
semi-blocking behavior needed for display-resample to work. Since the
swap interval must be 0 on wayland (otherwise it will block the entire
player's rendering loop), we need some other way to wait on vsync. The
idea here was to dispatch and poll a bunch of wayland events, wait (with
a timeout) until we get frame callback, and then wait for the compositor
to process it. That pretty much perfectly waits on vsync and lets us
keep all the good timings and all that jazz that we want for mpv. The
problem is that wl_display_roundtrip is conceptually a bad function. It
can internally call wl_display_dispatch which in certain instances,
empty event queue, will block forever. Now strictly speaking, this
probably will never, ever happen (once I was able to to trigger it by
hardcoding an error into a compositor), but ideally
vo_wayland_wait_frame should never infinitely block and stall the
player. Unfortunately, removing that function always lead to problems
with timings and unsteady vsync intervals so it survived many refactors.

Until now, of course. In wayland, the ideal is to never do wasteful
rendering (i.e. don't render if the window isn't visible). Instead of
wrestling around with hidden states and possible missed vblanks, let's
rearrange the wayland rendering logic so we only ever draw a frame when
the frame callback is returned to use (within a reasonable timeout to
avoid blocking forever).

This slight rearrangement of the wait allows for several simplifications
to be made. Namely, wl_display_roundtrip stops being needed. Instead, we
can rely entirely on totally nonblocking calls (dispatch_pending, flush,
and so on). We still need to poll the fd here to actually get the frame
callback event from the compositor, but there's no longer any reason to
do extra waiting. As soon as we get the callback, we immediately draw.
This works quite well and has stable vsync (display-resample and audio).
Additionally, all of the logic about hidden states is no longer needed.
If vo_wayland_wait_frame times out, it's okay to assume immediately that
the window is not visible and skip rendering.

Unfortunately, there's one limitation on this new approach. It will only
work correctly if the compositor implements presentation time. That
means a reduced version of the old way still has to be carried around in
vo_wayland_wait_frame. So if the compositor has no presentation time,
then we are forced to use wl_display_roundtrip and juggle some funny
assumptions about whether or not the window is hidden or not. Plasma is
the only real notable compositor without presentation time at this stage
so perhaps this "legacy" mechanism could be removed in the future.

---
## [hipe/downtownfun@bd648cea34...](https://github.com/hipe/downtownfun/commit/bd648cea34d4069170bcfecb924197dbb3aaaacd)
##### 2021-05-27 20:29:24 by Mark Meves

test(curses-yikes): introduce poly-option (65)

I have no words

(times)
  12-12 00:25  begin editing state machine flowchart for poly-option
        01:00  done, happy with rewrite to state machine (schematic)
        01:08  wanna take a little rest
        10:20  begin writing test for the story of add two
        11:47  finished very rough draft of first stroke of asset code
               with tons of logic missing for emacs
  12-14 10:56  finally done with what we think is entering the value of
               the name/value. now get it to render and lots of catch-up
               refactoring all over the place
  12-15 10:46  ready to be done with this. begin re-green mono
  12-16 01:00  oh my freaking god. visual test ok. unit test ok.
               leaving it all behind now
.

---
## [Kazkin/sojourn-station@0dca421e69...](https://github.com/Kazkin/sojourn-station/commit/0dca421e697851f3701e7be5a087994980cb6bc2)
##### 2021-05-27 22:17:30 by Kazkin

Summary Changes

-Blackshield synths have been added. These synths focus towards combat, with models ranging from melee, ballistic, and non-lethal. They are faster than soteria synths, but not as insulated as AG synths.
-Blackshield synthetic limbs are now available, they come with the same armor as soteria synthetics but a less chance to malfunction. However, unlike sot limbs, you can't obtain them in round.
-Defibs now log and message admins with the rez sickness levels and stat losses for those who get revived so we can keep track.
-Modified the vision range and aggro vision of hell divers, cerberus, and chimeras to make their AI breaking alot less likely until we get a full patch through, making them far more reliable.
-Fixed an issue with the myrmidon rail pistol so it correctly fires kurtz rail rounds, buffing its power.
-All guild rail guns (myr and reductor) have been massively buffed.
--Reductor rail rifle, +20% damage, higher credit value, more recoil, charge cost per shot reduced by 75%. This makes the rail rifle more like a highly modular high impact rifle with somewhat slow fire speed, much better for frontline fighting.
--Myrmidon rail pistol, recoil increased, charged cost per shot reduced by 50%, fire delay reduced by 45%. Damage mildly buffed due fixing a pathing issue with bullet assignment.
-The conselour stun gun now has its fire modes set to the hand menu, making it easier to switch between taster, stunbolt, and stunshot.
-Implanted arm smg buffed to make it on par with a wirbel wind, giving it good 1 handed suppression ability, moderate damage, amazing recoil control, but shit armor penetration.
-Syndicate storm trooper gunslinger damage buffed due to kurtz ammo fix.

---
## [hashicorp/terraform-plugin-framework@9216942ca7...](https://github.com/hashicorp/terraform-plugin-framework/commit/9216942ca7a9f3afafb1b5660c5126e2013ef9b1)
##### 2021-05-27 22:52:12 by Paddy Carver

Always use reflect.Values, fix numbers.

Rather than passing around interface{}s everywhere, convert from
interface{} once and use a reflect.Value. This ensures we don't lose any
information about whether a value can be set or not, because
reflect.ValueOf(pointerToStruct).FieldByName("NonPointerField") can be
set but reflect.ValueOf(pointerToStruct.NonPointerField) cannot be.
Easiest just to use reflect.Values everywhere internally.

Numbers were panicking when trying to set them because *big.Float was a
nil pointer. Special-case numbers, allowing provider devs to use any of
the built-in number types, and manually set them, rather than letting
tftypes.Value.As do it for us. This took a lot of work and I am in a
blood feud with the math/big package and also architecture-specific int
sizes (why is the size of an int accessible through the strconv
package?)

Options gained an AllowRoundingNumbers option so we can decide later
whether we want to round or throw an error when provider devs try to put
a value in a type that it won't fit in. Rounding seems nice until you
remember that Terraform hates rounding with a fiery passion that eats
away at its soul. Errors seem nice until you remember my blood feud with
the math/big package.

Primitives got tests. Well, strings. Same difference, really.

Objects got tests. Started getting tests. Then I got distracted with
numbers.

Into is now into, with Into calling into. Recursion hurts my brain. This
is so we can accept an interface{} but recurse on reflect.Values.

---
## [pytorch/pytorch@3ee1e69e22...](https://github.com/pytorch/pytorch/commit/3ee1e69e22aebae6ed2418953ee6cd5f984cb444)
##### 2021-05-27 23:39:38 by Brian Hirsh

Update base for Update on "add a boxed CPU fallback kernel"

This PR replaces the existing code-generated CPU fallback kernels that XLA uses with a single boxed CPU fallback.

Current state: there are a couple different design ideas that I want to point out, but the logic for the actually kernel is mostly done and passing tests.

### Design

To preface, I'm not 100% tied to the current design and I'm putting the PR up now for opinions and totally open to alternatives, some of which I listed below. Actually after writing this description, I'm leaning toward the following changes:
* Confirm whether or not we can remove all C++ logging info directly in the yaml.


**Current Design**

All of the CPU fallback codegen is deleted. In its place, XLA (and other external backends, later) can choose to opt into a CPU fallback by adding the following code in a C++ file. I have an corresponding [xla-side PR with the xla changes](https://github.com/pytorch/xla/pull/2945/files#diff-1a005c10039f0cb11130a3b740f5de716d2f10acaea121017016025861886798R1).

There's no actual requirement to split up the code into a .h and .cpp file, but that's necessary in the XLA case because they sometimes need to call the fallback directly from their handcrafted kernels.

```
// xla_cpu_fallback.h
#include <ATen/native/CPUFallback.h>
...
void xla_cpu_fallback(const c10::OperatorHandle& op, torch::jit::Stack* stack);
...
```
```
// xla_cpu_fallback.cpp
#include "torch_xla/csrc/aten_cpu_fallback.h"
...
void xla_cpu_fallback(const c10::OperatorHandle& op, torch::jit::Stack* stack) {
  // Do custom logging here
  ...
  // Call the actual boxed CPU fallback.
  at::native::cpu_fallback(op, stack);
}

TORCH_LIBRARY_IMPL(_, XLA, m) {
  m.fallback(torch::CppFunction::makeFromBoxedFunction<&xla_cpu_fallback>());
}
```

Now that the fallback is exposed in the backend, they can call it directly. Doing so requires converting from an unboxed to a boxed context, which we provide a utility function before. E.g.:
```
#include <ATen/native/CPUFallback.h>

at::Tensor addmm(const at::Tensor& self,const at::Tensor& mat1,const at::Tensor& mat2,const at::Scalar& beta,const at::Scalar& alpha) {
  ....
  if (...call_fallback...) {
    return at::native::call_fallback_fn<&xla_cpu_fallback, decltype(at::addmm)>::call("aten::addmm", self, mat1, mat2, beta, alpha);
  }
  ...
}
```

That `decltype(at::addmm)` logic isn't actually used everywhere in the xla-side PR yet, since you hit issues with overloads. I could use it everywhere once #58092 lands.

**Alternatives: The API for calling the CPU fallback directly is ugly, can we make it nicer?**
We could change the api to use `at::redispatch`, which would make it look something like this:
```
at::Tensor addmm(const at::Tensor& self,const at::Tensor& mat1,const at::Tensor& mat2,const at::Scalar& beta,const at::Scalar& alpha) {
  ....
  if (...call_fallback...) {
    return at::redispatch::addmm(c10::DispatchKeySet(c10::DispatchKey::CPUFallback), self, mat1, mat2, beta, alpha);
  }
  ...
}
```
Which definitely feels cleaner, but also requires adding a new DispatchKey just for this use case. Conditionally calling the CPU fallback doesn't sound like a hugely important use case, so I don't know if giving up one of our 64 dispatch key slots is worth the API improvement. Totally open to other opinions though!


Another more mild improvement that would avoid having to pass operator string names (including overloads) around would be to codegen (yet another) namespaced API. Something like this:
```
at::Tensor addmm(const at::Tensor& self,const at::Tensor& mat1,const at::Tensor& mat2,const at::Scalar& beta,const at::Scalar& alpha) {
  ....
  if (...call_fallback...) {
    return at::fallback::addmm<&xla_cpu_fallback>(self, mat1, mat2, beta, alpha);
  }
  ...
}
```

Writing that out actually I actually like it more (I think it'll let us get rid of `decltype(...)`). Maybe that is nice enough to warrant a new codegen API - I haven't tried adding that yet, but if people like it I'm happy to try it out.

**More alternatives**
The current design also involves the backend manually writing and registering the boxed fallback themselves, but an alternative would be for us to do it in codegen too: they would just need to pass in all of the C++ logging that they want done in the fallback, directly through the yaml. The main downsides:
* Backend code that wants to call the fallback needs to abide by whatever convention our codegen uses to name the generated boxed fallback.
* Passing custom C++ logging through yaml is just more fragile: right now xla uses an `iostream` to log each tensor arg in the operator, so we'd have to either force other backends into the same convention or figure something else out later.

To be fair, we actually already do that: XLA has custom per-tensor-arg logging for all of the generated `out` wrappers in the codegen, which we do by passing their C++ logging info through the yaml. This seems unnecessary though, since `out` wrappers just call into a functional kernel, which is hand written with its own custom logging. So my take is: try to remove custom C++ logging from the yaml, and if it turns out to be really necessary, then we may as well take advantage of that to codegen the fallback.

### Performance impact

While ops that fall back to CPU aren't exactly hot path, we probably don't want to use a boxed fallback if it turns out to be an absolute perf killer.

I ran my benchmarks using callgrind, benchmarking both `at::add` and `at::add_out` run on XLA. My callgrind benchmark for `at::add` can be found here (the add_out benchmark looks basically the same): https://www.internalfb.com/phabricator/paste/view/P415418587. I created the benchmark by hacking the existing xla C++ test build scripts and throwing in a reference to callgrind.

I also attached the full callgrind output for each benchmark; the full output is actually pretty noise and hard to parse, but I focused on everything underneath the `at::add()` call in the output, which was much more stable. My guess is that it's due to some heavyweight async startup processing that xla does.

`at::add`:
before: 88,505,130 instructions. Full output: https://www.internalfb.com/phabricator/paste/view/P415421001
after: 102,185,654 instructions. Full output: https://www.internalfb.com/phabricator/paste/view/P415421273
delta: ~15.5% increase

`at::add_out`:
before: 63,897,395 instructions. Full output: https://www.internalfb.com/intern/everpaste/?handle=GBrrKwtAPlix9wUEAOZtrFXpdO5UbsIXAAAz
after: 73,170,346 instructions. Full output: https://www.internalfb.com/phabricator/paste/view/P415423227
delta: ~14.5% increase

High level takeaway: A framework overhead increase of 10-20% doesn't seem too horrible for the CPU fallback use case.

For structured, functional ops that requires a CPU fallback, we're actually in an unfortunate situation: we're doing even more work than necessary. Our codegen automatically creates a `CompositeExplicitAutograd` kernel which calls into the `out` operator. So the extra work that we end up doing is:
* An extra dispatcher hop: (at::add -> CompositeExplicitAutograd -> CPUFallback -> at::native::add) instead of (at::add -> CPUFallback -> at::native::add)
* An unnecessary tensor allocation (the CompositeExplicitAutograd kernel uses at::empty() to create an output tensor, which is immediately overwritten by the CPU fallback)
* An unnecessary meta() call (the CompositeExplicitAutograd kernel calls it to create the output tensor, but we call it again in the CPU kernel).
* unboxing->boxing->unboxing logic (this is the only strictly required piece)

There are definitely ways to avoid the unnecessary work explained above: one would be to give the boxed fallback higher priority than composite keys (there's [an issue for it here](https://github.com/pytorch/pytorch/issues/55104)), and codegen fallthroughs for all composite ops. It'll require more infra to set up, so I see it as more of a perf knob that we can apply if we need it later.

Unfortunately I couldn't dig much deeper into the differences aside from the aggregate change in instructions, since it looks like callgrind fudged some of the instruction attribution (`at::to_cpu` takes up a ton of instructions, but I don't see any attribution for the `at::native::add` kernel anywhere).




[ghstack-poisoned]

---

# [<](2021-05-26.md) 2021-05-27 [>](2021-05-28.md)

