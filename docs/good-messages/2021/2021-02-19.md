# [<](2021-02-18.md) 2021-02-19 [>](2021-02-20.md)

2,889,391 events, 1,451,303 push events, 2,268,895 commit messages, 186,984,111 characters


## [zen-kernel/zen-kernel](https://github.com/zen-kernel/zen-kernel)@[2b541bf1e5...](https://github.com/zen-kernel/zen-kernel/commit/2b541bf1e5e27c51f96326f6c9d6c8abcf682d93)
#### Friday 2021-02-19 01:51:36 by Steven Barrett

ZEN: INTERACTIVE: Set MuQSS' yield_type to 0 (don't yield)

Turns out when I investigated performance issues with RPCS3 on Linux
with MuQSS, my choice to set yield_type to 2 was flawed since I didn't
benchmark or any other applications that cared about it.

Phoronix wrote an article measure performance of Liquorix against a
stock 5.4 configuration here: https://www.phoronix.com/vr.php?view=28750

All the benchmarks measured framerate and Liquorix for the most part got
up to 20% less FPS than stock CFS, depending on the game.  Turns out
some of it had to do with yield_type, and always yielding when requested
dropped minimum frame times quite a bit.  Disabling yield entirely
raised the average frame rate a bit and the minimum frametimes on Deus
Ex: Mankind Divided by nearly 10%.

Also, Linus Torvalds wrote in a forum about sched_yield.  He indicated
that yield used to make sense on uniprocessor configurations, but now
with multi-core being the norm, yield almost always causes performance
issues due to cache thrashing and thread/process migration on multicore
systems: https://www.realworldtech.com/forum/?threadid=189711&curpostid=189752

And finally, even if we don't yield, MuQSS will reschedule the thread
that's spinning anyway.  All setting yield_type to 2 did was reschedule
the thread sooner.  Lets let MuQSS decide when a thread needs to be
rescheduled, not the program.

Previous commit messages:

muqss, zen: Set yield_type to 2

  In my previous attempt in making games and emulators behave better, I
  found that making sched_yield a no-op by setting yield_type to 0 caused
  emulators like RPCS3 to perform far better without frame drops.
  Unfortunately, on my next boot I noticed the whole system felt less
  responsive in general.

  Fortunately, _always_ expiring the timeslice of the yielding process and
  calculating the next deadline also fixes this weird performance anomaly.
  Setting yield_type to 2 with a reduced rr_interval (2ms), should help
  offset the disadvantages of rescheduling a process that has yielded.

muqss, zen: Disable sched_yield by default

  While experimenting with audio stutter and frame drops through the RPCS3
  emulator, I found that yet again, sched_yield is the source of
  unpredictable performance drops.  Reading the original post[1] by Con
  where he outlined his last (final?) change to sched_yield, he changed
  the behavior of sched_yield in MuQSS to only yield to better priority or
  deadline tasks.

  It seems then on my system, emulators and games are yielding to some
  number of higher priority / next deadline tasks and performing much
  worse.  If you look at the comments on the blog post, however, many
  people found that setting yield_type to 0 improve performance on their
  games.

  Lets just turn sched_yield into a noop for now and see how that fairs.
  Worst case we'll receive a report about an application behaving badly,
  and best case everyone will get a net benefit in gaming and emulators.

  [1] http://ck-hack.blogspot.com/2016/12/linux-49-ck1-muqss-version-0150.html

Revert "muqss, zen: Disable sched_yield by default"

  This reverts commit 8ec985bcd0ded1bcdd8bb999c90c094dc9536a0b.

  This change, as expected, has strange side-effects with system
  responsiveness when many applications are launching at boot.  Also at
  random times, the mouse becomes unresponsive while over saturating CPU
  bandwidth.

---
## [00Beetzncheez00/Infosec_Reference](https://github.com/00Beetzncheez00/Infosec_Reference)@[cef2bd6f6c...](https://github.com/00Beetzncheez00/Infosec_Reference/commit/cef2bd6f6c2cbf3476f4b212b7c3c94adefc138e)
#### Friday 2021-02-19 01:59:40 by rmusser01

If you're reading this, I hope you're having at least a decent 3rd weekend of December. Hopefully next year won't be such a trashfire. #miracles ; Thanks to all the people who have helped make this year be not a _complete_ clusterfuck; small update. more backlog clearing. Next will hopefully be exec/evasion cleanup, then the redteam page and adding actual 'team' content to it. Shoutout agin to S for the much appreciated criticism. Here's to hoping for no new pandemics/genocides/wars/complete collapse of society for at least the next year. #smallmiracles

---
## [theishiopian/ProjectPsi](https://github.com/theishiopian/ProjectPsi)@[a52730babb...](https://github.com/theishiopian/ProjectPsi/commit/a52730babbb0a30139af039439552e2f046261eb)
#### Friday 2021-02-19 02:03:59 by theishiopian

COMPLETELY REWROTE PLAYER SPAWNING BECAUSE IM A FUCKING IDIOT HAHA FUNNY

---
## [ccodwg/Covid19Canada](https://github.com/ccodwg/Covid19Canada)@[5ddfa00548...](https://github.com/ccodwg/Covid19Canada/commit/5ddfa00548b0c75fb81180afcb823a7ad67c631a)
#### Friday 2021-02-19 02:50:23 by Jean-Paul R. Soucy

New data: 2021-02-18: See data notes.

Revise historical data: cases (AB, BC, MB, NS, ON, QC, SK).

Note regarding deaths added in QC today: â€œ10 new deaths, but the total of deaths amounts to 10,264 due to the withdrawal of 4 deaths not attributable to COVID-19: 4 deaths in the last 24 hours, 4 deaths between February 11 and February 16, 2 deaths before February 11.â€ We report deaths such that our cumulative regional totals match todayâ€™s values. This sometimes results in extra deaths with todayâ€™s date when older deaths are removed.

Recent changes:

2021-01-27: Due to the limit on file sizes in GitHub, we implemented some changes to the datasets today, mostly impacting individual-level data (cases and mortality). Changes below:

1) Individual-level data (cases.csv and mortality.csv) have been moved to a new directory in the root directory entitled â€œindividual_levelâ€. These files have been split by calendar year and named as follows: cases_2020.csv, cases_2021.csv, mortality_2020.csv, mortality_2021.csv. The directories â€œother/cases_extraâ€ and â€œother/mortality_extraâ€ have been moved into the â€œindividual_levelâ€ directory.
2) Redundant datasets have been removed from the root directory. These files include: recovered_cumulative.csv, testing_cumulative.csv, vaccine_administration_cumulative.csv, vaccine_distribution_cumulative.csv, vaccine_completion_cumulative.csv. All of these datasets are currently available as time series in the directory â€œtimeseries_provâ€.
3) The file codebook.csv has been moved to the directory â€œotherâ€.

We appreciate your patience and hope these changes cause minimal disruption. We do not anticipate making any other breaking changes to the datasets in the near future. If you have any further questions, please open an issue on GitHub or reach out to us by email at ccodwg [at] gmail [dot] com. Thank you for using the COVID-19 Canada Open Data Working Group datasets.

- 2021-01-24: The columns "additional_info" and "additional_source" in cases.csv and mortality.csv have been abbreviated similar to "case_source" and "death_source". See note in README.md from 2021-11-27 and 2021-01-08.

Vaccine datasets:

- 2021-01-19: Fully vaccinated data have been added (vaccine_completion_cumulative.csv, timeseries_prov/vaccine_completion_timeseries_prov.csv, timeseries_canada/vaccine_completion_timeseries_canada.csv). Note that this value is not currently reported by all provinces (some provinces have all 0s).
- 2021-01-11: Our Ontario vaccine dataset has changed. Previously, we used two datasets: the MoH Daily Situation Report (https://www.oha.com/news/updates-on-the-novel-coronavirus), which is released weekdays in the evenings, and the â€œCOVID-19 Vaccine Data in Ontarioâ€ dataset (https://data.ontario.ca/dataset/covid-19-vaccine-data-in-ontario), which is released every day in the mornings. Because the Daily Situation Report is released later in the day, it has more up-to-date numbers. However, since it is not available on weekends, this leads to an artificial â€œdipâ€ in numbers on Saturday and â€œjumpâ€ on Monday due to the transition between data sources. We will now exclusively use the daily â€œCOVID-19 Vaccine Data in Ontarioâ€ dataset. Although our numbers will be slightly less timely, the daily values will be consistent. We have replaced our historical dataset with â€œCOVID-19 Vaccine Data in Ontarioâ€ as far back as they are available.
- 2020-12-17: Vaccination data have been added as time series in timeseries_prov and timeseries_hr.
- 2020-12-15: We have added two vaccine datasets to the repository, vaccine_administration_cumulative.csv and vaccine_distribution_cumulative.csv. These data should be considered preliminary and are subject to change and revision. The format of these new datasets may also change at any time as the data situation evolves.

https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/#c47900

Note about SK data: As of 2020-12-14, we are providing a daily version of the official SK dataset that is compatible with the rest of our dataset in the folder official_datasets/sk. See below for information about our regular updates.

SK transitioned to reporting according to a new, expanded set of health regions on 2020-09-14. Unfortunately, the new health regions do not correspond exactly to the old health regions. Additionally, the provided case time series using the new boundaries do not exist for dates earlier than August 4, making providing a time series using the new boundaries impossible.

For now, we are adding new cases according to the list of new cases given in the â€œhighlightsâ€ section of the SK government website (https://dashboard.saskatchewan.ca/health-wellness/covid-19/cases). These new cases are roughly grouped according to the old boundaries. However, health region totals were redistributed when the new boundaries were instituted on 2020-09-14, so while our daily case numbers match the numbers given in this section, our cumulative totals do not. We have reached out to the SK government to determine how this issue can be resolved. We will rectify our SK health region time series as soon it becomes possible to do so.

---
## [mamedev/mame](https://github.com/mamedev/mame)@[621c3415ae...](https://github.com/mamedev/mame/commit/621c3415ae5694cf974ed4935d0632d79dbd7238)
#### Friday 2021-02-19 03:39:09 by r09

fmtowns_cd.xml: 11 new dumps, 19 replacements, 3 missing floppies added (#7764)

fmtowns_cd.xml - Removed the floppy disks for 38-man Kilo no Kokuu and Powermonger, since they are user-created disks and the games only need blank disks to save
fmtowns_cd.xml - Replaced Lunatic Dawn II floppy with a cleaner unmodified copy [akira_2020]
fmtowns_cd.xml - Replaced Nobunaga no Yabou - Bushou Fuuunroku floppy with a cleaner unmodified copy [wiggy2k]
fmtowns_cd.xml - Replaced the "fake" Lipstick Adventure 3 floppy with an image dumped from the original disk [r09]
fmtowns_cd.xml - Added a missing floppy image to Nobunaga no Yabou - Tenshouki (it wasn't marked as unsupported but it didn't actually work correctly before) [wiggy2k]

New working software list additions
-----------------------------------

Ehon Writer School v1.1 L21 [redump.org]
Gakuen Bakuretsu Tenkousei! [redump.org]
Hana no Kioku - Dainishou [redump.org]
if 1-2-3 CD Collection [redump.org]
Ikazuchi no Senshi Raidy 2 (1996-08-01) [redump.org]
Kousoku Choujin [redump.org]
Misato-chan no Yume Nikki [redump.org]
The Silent Service - Chinmoku no Kantai [redump.org, wiggy2k]
Sotsugyou '93 - Graduation (older floppy disk) [redump.org, wiggy2k]
Time Stripper Mako-chan [redump.org]
Tougenkyou [redump.org]

Replaced software list items
----------------------------

Aeternam [redump.org]
Angel [redump.org]
Dungeon Master (1989-11-14) [redump.org]
Gendai Daisenryaku EX Special [redump.org]
Giga Mortion [redump.org]
Hana no Kioku [redump.org]
Kikou Shidan - Panzer Division [redump.org]
Kiwame II [redump.org]
Koko wa Rakuensou [redump.org]
Koko wa Rakuensou 2 [redump.org]
Okumanchouja II [redump.org]
Ring Out!! [redump.org]
Stronghold - Koutei no Yousai [redump.org]
Tom Snyder's Puppy Love 2 [redump.org]
Toushin Toshi II - Soshite, Sorekara... [redump.org]
Ultima Underworld - The Stygian Abyss [redump.org]
Veil of Darkness - Norowareta Yogen [redump.org]
Virtuacall [redump.org]
Xak III - The Eternal Recurrence [redump.org]

Software list items promoted to working
---------------------------------------

Record of Lodoss War II - Goshiki no Maryuu [wiggy2k]
Sangokushi III [wiggy2k]

---
## [Pubbus/wav2letter](https://github.com/Pubbus/wav2letter)@[96b0c07487...](https://github.com/Pubbus/wav2letter/commit/96b0c074870fb8ce9b96f7e7bd9e6a2080988e66)
#### Friday 2021-02-19 05:12:54 by Alex Gaziev

Throw error if no train examples found and readme improvement (#411)

Summary:
Hello! Thank you for excellent library!

When I was running train flow for the first time according to examples from https://github.com/facebookresearch/wav2letter/blob/master/docs/train.md - everything was looking fine, everything started, in logs as well everything was good at the start - arch loaded, nothing failed. And I left it to train for a night. I was surprised in the morning when I found out (reading source code) that I failed to provide list file path and provided directory path in `--train` flag, and it was silently ignored. My model trained whole night with 0 examples; it did 20k+ epochs successfully with zero loss and everything.

I want to change README a bit and to throw an error if no examples found.
Pull Request resolved: https://github.com/facebookresearch/wav2letter/pull/411

Differential Revision: D17590810

Pulled By: an918tw

fbshipit-source-id: 11772ee859eef8834d2e8c60af54b4c8d5e160e9

---
## [Seniru/pewpew](https://github.com/Seniru/pewpew)@[ade7a7099d...](https://github.com/Seniru/pewpew/commit/ade7a7099dfb6a878131a5c10522ec5f657c733a)
#### Friday 2021-02-19 05:30:37 by Seniru Pasan Indira

experiment: Do not open the commit description

What the fuck is this shit I hate coding

---
## [VoVanThanh1999/newsbyjava](https://github.com/VoVanThanh1999/newsbyjava)@[faedd9cf9d...](https://github.com/VoVanThanh1999/newsbyjava/commit/faedd9cf9dbf959c193a7a0238b6c36444aaac09)
#### Friday 2021-02-19 08:09:33 by VoÌƒ VÄƒn ThaÌ€nh

Merge pull request #7 from VoVanThanh1999/paginationFinal

:v: :v: If code is shits  :hankey:  then i love shits :heart:

---
## [deckiherdiawans/raven3fastapi](https://github.com/deckiherdiawans/raven3fastapi)@[ce12d66fb0...](https://github.com/deckiherdiawans/raven3fastapi/commit/ce12d66fb0878977865db003f1b35e3548ba4e10)
#### Friday 2021-02-19 10:00:38 by Decki Herdiawan Soepandi

Stuck at -String indices must be integer-. Goddamn fucking shit!

---
## [pifi-bz/linux](https://github.com/pifi-bz/linux)@[39afef8a28...](https://github.com/pifi-bz/linux/commit/39afef8a282b8ce63edb8d2ceb8a71e5440de059)
#### Friday 2021-02-19 10:32:24 by Douglas Anderson

pinctrl: qcom: Don't clear pending interrupts when enabling

commit cf9d052aa6005f1e8dfaf491d83bf37f368af69e upstream.

In Linux, if a driver does disable_irq() and later does enable_irq()
on its interrupt, I believe it's expecting these properties:
* If an interrupt was pending when the driver disabled then it will
  still be pending after the driver re-enables.
* If an edge-triggered interrupt comes in while an interrupt is
  disabled it should assert when the interrupt is re-enabled.

If you think that the above sounds a lot like the disable_irq() and
enable_irq() are supposed to be masking/unmasking the interrupt
instead of disabling/enabling it then you've made an astute
observation.  Specifically when talking about interrupts, "mask"
usually means to stop posting interrupts but keep tracking them and
"disable" means to fully shut off interrupt detection.  It's
unfortunate that this is so confusing, but presumably this is all the
way it is for historical reasons.

Perhaps more confusing than the above is that, even though clients of
IRQs themselves don't have a way to request mask/unmask
vs. disable/enable calls, IRQ chips themselves can implement both.
...and yet more confusing is that if an IRQ chip implements
disable/enable then they will be called when a client driver calls
disable_irq() / enable_irq().

It does feel like some of the above could be cleared up.  However,
without any other core interrupt changes it should be clear that when
an IRQ chip gets a request to "disable" an IRQ that it has to treat it
like a mask of that IRQ.

In any case, after that long interlude you can see that the "unmask
and clear" can break things.  Maulik tried to fix it so that we no
longer did "unmask and clear" in commit 71266d9d3936 ("pinctrl: qcom:
Move clearing pending IRQ to .irq_request_resources callback"), but it
only handled the PDC case and it had problems (it caused
sc7180-trogdor devices to fail to suspend).  Let's fix.

>From my understanding the source of the phantom interrupt in the
were these two things:
1. One that could have been introduced in msm_gpio_irq_set_type()
   (only for the non-PDC case).
2. Edges could have been detected when a GPIO was muxed away.

Fixing case #1 is easy.  We can just add a clear in
msm_gpio_irq_set_type().

Fixing case #2 is harder.  Let's use a concrete example.  In
sc7180-trogdor.dtsi we configure the uart3 to have two pinctrl states,
sleep and default, and mux between the two during runtime PM and
system suspend (see geni_se_resources_{on,off}() for more
details). The difference between the sleep and default state is that
the RX pin is muxed to a GPIO during sleep and muxed to the UART
otherwise.

As per Qualcomm, when we mux the pin over to the UART function the PDC
(or the non-PDC interrupt detection logic) is still watching it /
latching edges.  These edges don't cause interrupts because the
current code masks the interrupt unless we're entering suspend.
However, as soon as we enter suspend we unmask the interrupt and it's
counted as a wakeup.

Let's deal with the problem like this:
* When we mux away, we'll mask our interrupt.  This isn't necessary in
  the above case since the client already masked us, but it's a good
  idea in general.
* When we mux back will clear any interrupts and unmask.

Fixes: 4b7618fdc7e6 ("pinctrl: qcom: Add irq_enable callback for msm gpio")
Fixes: 71266d9d3936 ("pinctrl: qcom: Move clearing pending IRQ to .irq_request_resources callback")
Signed-off-by: Douglas Anderson <dianders@chromium.org>
Reviewed-by: Maulik Shah <mkshah@codeaurora.org>
Tested-by: Maulik Shah <mkshah@codeaurora.org>
Reviewed-by: Stephen Boyd <swboyd@chromium.org>
Link: https://lore.kernel.org/r/20210114191601.v7.4.I7cf3019783720feb57b958c95c2b684940264cd1@changeid
Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[a7a61e5ae4...](https://github.com/mrakgr/The-Spiral-Language/commit/a7a61e5ae4783f6aa4bc131af757e59d0a736a03)
#### Friday 2021-02-19 11:41:15 by Marko GrdiniÄ‡

"10:45am. I am up. Let me chill a little and then I will implement what I had in mind yesterday.

11:20am. Let me start.

```
nominal game_interface o s a r = {
    state : s
    reward : {(+) : r -> r -> r; (*) : r -> r -> r; index : r -> u8 -> f64}
    player : {
        action : s -> u8 -> array a -> (a * s -> r) -> r
        observation_add : s -> u8 -> o -> s
        path_mult : s -> u8 -> f64 -> s
        }
    }
```

Yesterday I did this. Let me start with the terminal node. Let me remove the state field from this. I'll have it be a separate param.

Also I want a better name for this.

```
inl terminal (pid,reward) (framework {reward={(*) (+)}}) =
    if pid = 0 then reward else -reward
```

Hmmm, negative `-` is unbound.

```
// Binary equals.
inl (=) forall t {prim}. (a : t) (b : t) : bool = !!!!EQ(a,b)
// Binary unequals.
inl (<>) forall t {prim}. (a : t) (b : t) : bool = !!!!NEQ(a,b)
```

Let me add the prim constraint to the language.

```
// Binary equals.
inl (=) forall t {prim}. (a : t) (b : t) : bool = !!!!EQ(a,b)
// Binary unequals.
inl (<>) forall t {prim}. (a : t) (b : t) : bool = !!!!NEQ(a,b)

// 32/64-bit float infinity
inl inf forall t {float}. : t = !!!!Infinity(`t)
// Unary negation.
inl (~-) forall t {number}. (x : t) : t = !!!!Neg(x)
// Evaluates an term and throws away the result.
inl ignore x = ()
// Returns an term after evaluating it.
inl id x = x
// Throws away the second argument and returns the first.
inl const x _ = x
// Applies the unit to the function.
// (() -> a) -> a
inl unconst x = x()
// Boolean negation.
inl not x = x = false
```

Extended the core a bit.

11:40am.

```
inl terminal (pid,reward) _ : f64 = if pid = 0 then reward else -reward
```

Now I can use `-` properly. Ok.

Doing these improvements a bit at a time is how the language gets better. This dedication is not something you can do if you feel squeezed for time.

```
inl sample_all dist next {observations=o1,o2 players} =
    ()
```

This is what I wanted to start yesterday. Let me make this the enumerative version.

```
observation_add_all : s -> o -> s
```

Let me add this field as well.

```
reward : {(+) : r -> r -> r; (*) : r -> f64 -> r; zero : r; index : r -> u8 -> f64}
```

Oh, I need the zero here as well.

```
inl f64 forall t {number}. (x : t) = $"<`f64>!x" : f64
```

Let me make this helper.

12:05pm.

```
inl sample_all_enumerate to_obs dist next (state, fr & framework {reward={(+) (*) zero} player={observation_add_all}}) =
    inl len = f64 (a64.length dist)
    a64.fold (fun r x => r + next x (observation_add_all state (to_obs x), fr)) zero dist * (1 / len)
```

Here is a very generic `sample_all_enumerate`. Let me make specific instance for my own need.

```
inl sample_all_enumerate' to_obs dist next (state, fr & framework {reward={(+) (*) zero} player={observation_add_all}}) =
    inl len = f64 (a64.length dist)
    a64.fold (fun r x => r + next x (observation_add_all state (to_obs x), fr)) zero dist * (1 / len)

inl sample_all_enumerate x = sample_all_enumerate' card_ x
```

Ah, who is going to deal with putting types on this.

12:10pm. Actually, I do not need that zero. I should just add reduce to the array modules.

```
// Similar to fold with the intial state as the first element of the array.
inl reduce f ar =
    inl nearTo = length ar
    if nearTo = 0 then failwith "The array must be greater than 0."
    for (from: 1 nearTo:) (fun i s => f s (index ar i)) (index ar 0)
```

Let me do it like this.

Hmmm...I am not going to use this.

```
inl sample_all_many' to_obs dist next (state, fr & framework {reward={(+) (*)} player={observation_add_all}}) =
    inl run i = inl x = a64.index dist i in next x (observation_add_all state (to_obs x), fr)
    inl nearTo = a64.length dist
    loop.for (from: 1 nearTo:) (fun i s => s + run i) (run 0) * (1 / f64 nearTo)
```

Let do `sample_all_many'` like this. Carrying out that zero might mean carrying an array and I do not want that. This way is much better.

12:30pm. I've started slacking already.

Actually, since I am pretty satisfied by this, I should stop here for breakfast. I'll do the `sample_all_one` later.

I feel like I have a good grasp on what I should be doing.

```
inl sample_all_many' to_obs dist next (state, fr & framework {reward={(+) (*)} player={observation_add_all}}) =
    inl run i = inl x = a64.index dist i in next x (observation_add_all state (to_obs x), fr)
    inl nearTo = a64.length dist
    loop.for (from: 1 nearTo:) (fun i s => s + run i) (run 0) * (1 / f64 nearTo)
inl sample_all_many x = sample_all_many' card_ x

inl sample_all_one' to_obs dist next (state, fr & framework {reward={(+) (*)} player={observation_add_all}}) =
    inl run x = next x (observation_add_all state (to_obs x), fr)
    run (sampling.sample dist)
inl sample_all_one x = sample_all_one' card_ x
```

I've done it now. Let me stop here. There is also `sample_all_n`, but I'll leave that for later. Actually, I don't need to do that one. Sampling chance nodes is not like external sampling of actions."

---
## [merlin230/Akash](https://github.com/merlin230/Akash)@[c93b35e348...](https://github.com/merlin230/Akash/commit/c93b35e3480a561b93a87c431e2aa5ff9a126dd3)
#### Friday 2021-02-19 12:16:05 by merlin230

www.fortunebusinessinsights.com/enquiry/request-sample-pdf/organic-tea-market-100804

The global organic tea market is set to gain momentum from the rising popularity of retail organic food and beverages on account of their easy consumption and wide availability. This information is given by Fortune Business Insightsâ„¢ in a new report, titled, â€œOrganic Tea Market Size, Share & COVID-19 Impact Analysis, Type (Black Tea, Green Tea, and Others), Form (Tea Bags, Loose Leaves, Loose Powder, and Ready-to-drink), Distribution Channel (Supermarkets/Hypermarkets, Convenience Stores, Specialty Stores, and Online Retail), and Regional Forecast, 2020 â€“ 2027.â€ The report further states that the market size was USD 820.8 million in 2019. It is projected to reach USD 1,918.7 million by 2027, exhibiting a CAGR of 11.2% during the forecast period.
COVID-19 Pandemic: Urgent Need to Enhance Immune Systems to Aid Growth
The COVID-19 pandemic has taken a huge toll on the entire food system worldwide. The supply chain of organic tea was disrupted owing to nationwide lockdown and social distancing measures. However, the rising concerns of people regarding their health and immune systems are expected to propel the demand for numerous nutritional beverages across the globe. It is likely to impact the market positively.

â€¢	A list of all the renowned organic tea providers operating in the global market:
â€¢	Associated British Foods plc (London, U.K.)
â€¢	Unilever plc (London, U.K.)
â€¢	Tata Consumer Products Limited (Mumbai, India)
â€¢	The Bigelow Tea Company (Connecticut, U.S.)
â€¢	The Republic of Tea, Inc. (California, U.S.)
â€¢	The Stash Tea Company (Oregon, U.S.)
â€¢	Tazo Tea Company (Washington, U.S.)
â€¢	Shangri La Tea Company (Nevada, U.S.)
â€¢	Newmanâ€™s Own, Inc. (Connecticut, U.S.)
â€¢	Organic India Pvt. Ltd. (Lucknow, India)

Browse Summary of this Research Report:
https://www.fortunebusinessinsights.com/industry-reports/organic-tea-market-100804

Highlight of the Report:  While making the report, we segmented the market on the basis of product, type, consumption, distribution channel, and region. Based on the segmentation, we made a list of companies and conducted a detailed analysis of their financial positions, product portfolios, and growth strategies. Our next step included the study of core competencies of key players and their market share to anticipate the degree of competition. The bottom-up procedure was conducted to arrive at the overall size of the market.

Drivers & Restraints-
High Demand for Nutrient-rich Food & Beverages to Bolster Growth: People nowadays are inclining rapidly toward nutrient-rich food & beverages for maintaining their overall health and wellness. They are looking for products that contain more functional ingredients to reduce the occurrences of lifestyle-related health disorders, such as obesity, cardiovascular conditions, and diabetes. Also, the increasing demand for ready-to-drink functional beverages from millennials would accelerate the organic tea market growth in the near future. However, this tea is expensive because of its limited production. It may obstruct growth.


Segment-
Black Tea Segment to Hold 77.76% Share in 2019 Based on type, the black tea segment generated 77.76% in terms of the organic tea market share in 2019. This growth is attributable to its possession of several health benefits. This tea has antioxidants  

Regional Insights: Increasing Awareness of Health Benefits to Spur Growth in North America
Geographically, North America procured USD 262.6 million in terms of revenue in 2019. It is set to lead the market throughout the forthcoming years on account of the rising awareness programs to educate people about the health benefits of this healthy tea. 
Asia Pacific, on the other hand, would grow steadily backed by the rising production of organic tea, especially in China. Coupled with this, the surging discretionary incomes of people would aid growth in this region. In Europe, the rising demand for premium specialty teas with authentic and unique flavors would propel growth.

Get Sample PDF Brochure:
https://www.fortunebusinessinsights.com/enquiry/request-sample-pdf/organic-tea-market-100804

Competitive landscape:   Key Players Focus on Introducing Innovative Products to Compete with Their Rivals The market has a moderately consolidated structure. It is majorly dominated by a handful of multinational organizations. They are presently focusing on new product launches, acquisitions, and partnership strategies to compete with their rivals in the market. Below are the two latest  
Industry Developments-
December 2020 : BanLabs unveiled a new line of organic green tea named the Care Tea basket. It is free from artificial preservatives and flavors. It has 5 packs of some innovative flavors that have been launched in India for the first time.
October 2019: Choice Organic Tea   shut down its Seattle headquarters because of its acquisition by Yogi Tea. The company aims to bring flavorful teas in the market by making a positive environmental and social impact. 


About us:  Fortune Business Insightsâ„¢ offers expert corporate analysis and accurate data, helping organizations of all sizes make timely decisions. We tailor innovative solutions for our clients, assisting them to address challenges distinct to their businesses. Our goal is to empower our clients with holistic market intelligence, giving a granular overview of the market they are operating in.
Our reports contain a unique mix of tangible insights and qualitative analysis to help companies achieve sustainable growth. Our team of experienced analysts and consultants use industry-leading research tools and techniques to compile comprehensive market studies, interspersed with relevant data.  
At Fortune Business Insightsâ„¢, we aim at highlighting the most lucrative growth opportunities for our clients. We, therefore, offer recommendations, making it easier for them to navigate through technological and market-related changes. Our consulting services are designed to help organizations identify hidden opportunities and understand prevailing competitive challenges.
Contact Us:
Fortune Business Insightsâ„¢ Pvt. Ltd.
308, Supreme Headquarters,
Survey No. 36, Baner, 
Pune-Bangalore Highway,
Pune - 411045, Maharashtra, India.
Phone:
US :+1 424 253 0390
UK : +44 2071 939123
APAC : +91 744 740 1245
Email: sales@fortunebusinessinsights.com

---
## [bazelbuild/bazel](https://github.com/bazelbuild/bazel)@[5a8a924893...](https://github.com/bazelbuild/bazel/commit/5a8a92489342d59ea74077174e29d8f10ac2989c)
#### Friday 2021-02-19 12:59:59 by aiuto

Automated rollback of changelist 260074256.

*** Reason for rollback ***

While this worked at the time. Upgrading rules_pkg to current versions requires adding rules_python to the test WORKSPACE.  This makes the complexity worse.

I'm falling back to a different solution where bazel builds in a mini-tar that is sufficient for these tests but is not tempting for users to use.

*** Original change description ***

Switch Android rules runtime deps builder to use rules_pkg for pkg_tar.

See https://github.com/bazelbuild/bazel/issues/8857

Thoughts:
- The change to discard_graph_edges_test.sh is ridiculous. The test is flaky in CI and super brittle.
- The fact that some integration tests rely on a WORKSPACE that matches that used to build bazel is odd. I should be able to use the built version of Bazel with my own workspace, with rules_cc and rules_pkg at a different revision level. We should have an integr...

***

RELNOTES: None
PiperOrigin-RevId: 358382248

---
## [yaminoacmodd/ACNHPoker](https://github.com/yaminoacmodd/ACNHPoker)@[f1a5fa7690...](https://github.com/yaminoacmodd/ACNHPoker/commit/f1a5fa76902d48828ddbcbbe4ee89a6b3d96326b)
#### Friday 2021-02-19 14:45:16 by Yamino Plays AC

enhancement to map regen icons

Both of these icons are lovely. Celeste is a beautiful character and one of my favs.
Fasil is a sweetheart and it warmed my heart to see her icon here.

These changes include imsge enhancing and resize of fasil.ico and made as a png! If you dont like it its okay! Thanks for all your amazing work in poker ðŸ™ŒðŸ’ž

---
## [l0unk/prostasia](https://github.com/l0unk/prostasia)@[6c38fbd26e...](https://github.com/l0unk/prostasia/commit/6c38fbd26e09d9cc3426b1ec8f6594b331b3f20f)
#### Friday 2021-02-19 15:55:48 by gstpsk

Fuck you lek you absolute twat NOW the gitignore is normal again

---
## [newstools/2021-sahara-reporters](https://github.com/newstools/2021-sahara-reporters)@[836b9992c7...](https://github.com/newstools/2021-sahara-reporters/commit/836b9992c7eca603b03fdcc97437d5c14686874c)
#### Friday 2021-02-19 16:09:23 by NewsTools

Created Text For URL [saharareporters.com/2021/02/19/woman-extorts-assaults-friend-allegedly-dating-her-boyfriend-films-and-posts-it-social]

---
## [hisahi/lrg](https://github.com/hisahi/lrg)@[c37834ec3f...](https://github.com/hisahi/lrg/commit/c37834ec3fc0bf9b5546371b95c2775a82f6eb26)
#### Friday 2021-02-19 17:14:26 by Sampo HippelÃ¤inen

optimize, restructure, get rid of fgets

time to write about historical baggage.

let's say you were to write a tool that allows you to view lines from a file
based on a line number, so that you can easily check what's on a specific line
on a text or source code file or whatever. you'll need some function to
actually *read* the lines from the file.

in POSIXland, you've got getline, which relies on memory allocation and is fine
until someone throws in a 16 GB one-liner at you and then complains how all
memory allocation and no printing makes using the tool a complete waste of time.

but huzzah, along comes the C standard library with this thing called "fgets".
you give it a buffer, its size and the file, and it reads you a line of text
into that buffer. excellent! exactly what you need. it even tells you if there
was an EOF or I/O error.

what if the line is too long now? fgets will simply not read past the buffer,
so it'll read a part of the line and then keep going the next time around.
the way fgets works is obviously catered towards how C strings work. so no
matter what, the buffer will have a null terminator at the very end.

now here's a question for you; how do you determine if fgets read in a complete
line of text or not? checking the actual end of the buffer is no good -- what
if we read in a really long line and a short line afterwards?

what about using ftell? no dice, since what if we're piping from stdin?
ftell will just give us -1.

well, there's a null terminator. why not use strlen? we can use that to figure
out where the line-ending null terminator is and thus find the "end" of the
data we read.

yet that is worth nothing when the files you deal with can contain null bytes.
sure, if it were up to someone more ambitious, they'd probably push for
making it a crime to have null bytes in text files, but I'm not the one making
the decisions on what files people are going to use this tool for.
thus, the tool needs to be able to gracefully handle null bytes in files and
we cannot rely on the null byte *in any way*. it's not like fgets stops
whenever it reads a null character either, so why should we?

so okay, another idea. we'll try to find the newline character from the buffer,
which is something memchr is perfectly suited for. except now we have to scan
through the buffer *twice*, the first time around to actually read it (as
fgets does) and the second time to figure out the length of the line. good
luck optimizing that!

wait, someone found a bigger problem with this approach. if we have a text file
ending in a line that does not have a newline character, we have *basically no
way* to know its true length. so, imagine this perfect storm: piping a text
file through stdin in which the final line does not have a newline but contains
null terminator bytes (again, I don't make the rules). now, if you use fgets,
you simply CANNOT tell in any reliable way how long the line you read actually
was. you cannot use ftell because of the pipe. you cannot use strlen because
the line might have null bytes in it. you cannot scan for a newline because
THERE ISN'T ONE. the only possible option is to maybe somehow fill the buffer
with -1 beforehand and then scan backwards for a null byte if we reach eof...
but good luck making that approach actually work with an acceptable level of
performance and it cannot handle all test cases (what if the file ends with
one or more -1 bytes?)

congratulations, fgets is broken. all of this could be solved if fgets would
simply return some information on how many bytes it read, be it a size_t or
ssize_t or int or whatever or a pointer to the end of the line (the "null
terminator" it places). this would require basically NO extra work from the
function because it must know where it'll be writing anyway.

so this is where we finally get to start talking about historical baggage.
strike one; fgets returns a pointer. this is (almost certainly) because it's
based on gets. this is not a problem if the pointer would point to the end of
the data we read. ...strike two; fgets returns a pointer *that is just a copy
of the pointer to the buffer given as a parameter*. this is (almost certainly)
because it's based on gets. this would have been a perfect opportunity to make
the return value of fgets actually make sense, but no. instead just parrot and
base it on a function that is so unsafe IT WAS REMOVED FROM THE C STANDARD!

so strike three; gets (may I be forgiven for uttering this word three times)
returns a pointer that is just a copy of the pointer to the buffer given as
a parameter. why? nobody knows. someone (perhaps even Ritchie himself) made
that decision a long time ago and we still have to live with its consequences.

so what are the alternatives? you can find the newlines yourself and just
read stuff into a buffer. POSIX read is great for this, fread not so much
because it is too hardheaded to stop reading until there's an EOF or the end of
buffer is reached. in other words, screw the terminal and pipes, keep giving me
more. I'm sure there's some great historical reasons for that as well.

sure, all this is minor compared to some other trainwrecks (locale system),
but it still further adds to the pile of things that suck in coding C.

---
## [blueberrycola/othello](https://github.com/blueberrycola/othello)@[139f4872ba...](https://github.com/blueberrycola/othello/commit/139f4872baad1254f59d2ca52b6b8d59e19cd885)
#### Friday 2021-02-19 18:33:40 by Chase Johnston

HELL YEAH MOTHERFUCKER

Fixed check_dir conditionals to complete last tests

---
## [Sxmurai/xtaism](https://github.com/Sxmurai/xtaism)@[5320aff92a...](https://github.com/Sxmurai/xtaism/commit/5320aff92a8c26fe6824761dba8348fee5960dda)
#### Friday 2021-02-19 19:41:34 by aesthetical

i hate java, and this needs to be rewritten holy shit

---
## [sdoran35/discordbot](https://github.com/sdoran35/discordbot)@[f7345004ff...](https://github.com/sdoran35/discordbot/commit/f7345004ff2aa2f3765e0395b6272d6139fecc78)
#### Friday 2021-02-19 19:52:39 by Snoo

Restyler change

Fuck you Restyler, just use prettier and stop being dumb. This should make it so it just uses Prettier and our configs.

---
## [ThomasHabets/dotfiles](https://github.com/ThomasHabets/dotfiles)@[28fe7d27ee...](https://github.com/ThomasHabets/dotfiles/commit/28fe7d27eead7cf81cd282005ad415b3b3e8f5a8)
#### Friday 2021-02-19 20:49:47 by Thomas Habets

FUCK YOU SYSTEMD. Of course I don't want you to kill my processes

---
## [rpherbig/dr-scripts](https://github.com/rpherbig/dr-scripts)@[ee65ec3438...](https://github.com/rpherbig/dr-scripts/commit/ee65ec343821092cc324e9ac29df24c08607ad5d)
#### Friday 2021-02-19 21:18:04 by Katoak

[script] [attunement] Add "health" option to train empathy

### Background
* Deneri in the empaths lich channel [asked](https://discord.com/channels/745675889622384681/745678251250417674/794988805525471252) if there was a script to do a "health walk" with T2.
* Kiriawen [answered](https://discord.com/channels/745675889622384681/745678251250417674/795021486854242315) that there wasn't, that `crossing-training` script trains empathy via its own code.
* Further discussion insued about tweaking this script to support "health walks" in addition to "power walks".

### Changes
* Add optional `health` argument that will do a "health walk" for Empaths
* Add new setting `perceive_health_rooms` to override the base-towns.yaml rooms for a "health walk" (analogous to existing `attunement_rooms` setting)

### Sample Config
```yaml
# Used by 'attunement' script.
# These override the default rooms where magic users will visit to
# train attunement via 'perceive' command.
# If not defined then the rooms are taken from base-towns.yaml.
# This is ignored for lunar mages and instead they train in their current room.
attunement_rooms:

# Used by 'attunement' script when called with the 'health' option.
# These override the default rooms where Empaths will visit to
# train empathy via 'perceive health' command.
# If not defined then the rooms are taken from base-towns.yaml.
perceive_health_rooms:
- 100
- 200
- 300
```

### Credits
Kiriawen was very helpful in outlining how to add "health walk" to the attunement script and nuances around how to train empathy in this manner.

## Tests

### Health Walk (new feature)
```
> ,attunement health

--- Lich: attunement active.

--- Lich: go2 active.

[go2: ETA: 0:00:02 (14 rooms to move through)]

...

[attunement]>perceive health

You're not ready to do that again, yet.
> 
[attunement]>perceive health

You close your eyes, drawing all your thoughts inward, and then slowly reach out to sense the life essences of those around you...

You fail to sense anything, however.
Roundtime: 11 seconds
> 
[attunement]>perceive health

You close your eyes, drawing all your thoughts inward, and then slowly reach out to sense the life essences of those around you...

You sense:
    The presence of a monk.
Roundtime: 11 seconds

...
```

### Power Walk (regression test)
```
> ,attunement

--- Lich: attunement active.

--- Lich: go2 active.

[go2: ETA: 0:00:00 (1 rooms to move through)]

[go2]>s

You limp south.

[go2: travel time: 0:00:03]

--- Lich: go2 has exited.

[attunement]>perceive

You reach out with your senses and see shimmering (9/21) streams of vibrant blue and white Life mana flowing through the area.
You sense the Gift of Life spell upon you, which will last for about thirteen roisaen.
You sense the Manifest Force spell surrounding you, which will last for sixteen roisaen or until it has endured six more blows.
You sense the Refresh spell upon you, which will last for about seventeen roisaen.
Roundtime: 7 sec.

...

--- Lich: attunement has exited.
```

---
## [7ep/r3z](https://github.com/7ep/r3z)@[7fe7375267...](https://github.com/7ep/r3z/commit/7fe7375267146148bdd24f5155058720c2173947)
#### Friday 2021-02-19 22:29:44 by Byron Katz

Trying new UI approaches for time entry (#86)

* Adjust classes and associated css

* Our system can now work on jdk 8

* Bringing back the flex(boxes)

* Refactoring UI tests

Many of our UI tests were highly redundant - doing the same thing again and again.  These changes remove some of that redundancy.  Additionally, we had several UI tests that took just as long to start up the browser as actually running the test.  Now we have far fewer UI tests, each takes a nice amount of time.

* More UI test refactors

Removed the smoke test, since it's mostly handled by the UITimeEntry tests and UIServerTests

* Fixing a bug in submissions

Oops.  When deserializing I was using the plainly wrong key.

This does bring up the idea of better, more careful testing for new features.  It's hard - you want to move fast, but then you just get yourself in trouble....

* This is relevant to the theme

* Fixing a bug in nextIndex

It occurred to me that we weren't regularly thoroughly testing the database restore process.  Our UI tests had been working in memory-only mode. I changed it to use a directory, and also to compare the before-restore and after-restore, and then I found a bug.

See, when you delete *all* the data in a particular type, for example sessions or submitted time periods, and then restart the system, the next index to be used was previously calculated by looking at the largest existing id and then adding one.  But what happens if there aren't any?  It sets the next index to merely 1.  This means that the database could have a nextIndex of 5 in memory but when restored has 1.

Now, every time data is persisted to disk, we also record the next index to its own file, and use that when restoring.

In order to find all this out, I added some code for better equality testing in a couple places as well.  When we compare big things like ConcurrentSet or ConcurrentLinkedQueue, we don't want to be distracted by the infinite details inside... just the main pieces.  Yes, there are complications involved - checking equality on those items is only _weakly_ consistent - it can be in the middle of changing and so on - but on the other hand we only use equality checking on tests anyway.  Hopefully :/

Well, that's the nature of code.  Horribly complex.  That's why we test the ever-lasting-heck outta it with automated tests.

* Light editing

* making UI tests more parallel

If I put each bundle of UI tests in its own class, it will run more in parallel

Co-authored-by: Matthew Taylor <matthew.taylor@coveros.com>
Co-authored-by: Byron Katz <byron.katz@coveros.com>

---
## [JoeBidenWhatAreYouHiding/kx](https://github.com/JoeBidenWhatAreYouHiding/kx)@[00eb22f5e9...](https://github.com/JoeBidenWhatAreYouHiding/kx/commit/00eb22f5e99cbf25bf506af616a18d9dd6b4cb95)
#### Friday 2021-02-19 22:59:56 by AmCath

i  have a Principels , and when some guy thinks he can mook with me or moock other people for only drama reasons so i cant accept this without saiyng nothing So dont you do play futher a Child wgo rans away from conflicts.even in the internet or why you gonna do ? Okey men , You seem to want to play  the cool cat here by calling up some folks to.make fun of me and even when you are not here to make gossip about  yaa . I know i know you dont want look like a weakling here because that would gave bad resputation But the whole action of you was when you go deep the quiet opposite . You biden prove here in front that you dont have the realy courage and capacity to have  fair conflict with me . No you fun away and post these unfunny things to avoid this You have prove  youself to be the loser here from us both think about it msn So Biden here congratulation that you have prove here the Server that you are the KING THE SUPER  CHAD  by avoiding the fair fight and run away like a girl . Mybe some of your ,, friends " will like that abit but manny people wgo have a good moral compass know that you have lost and sgow the server that you are a verr weak guy

---
## [ajvondrak/remote_ip](https://github.com/ajvondrak/remote_ip)@[b545c3a161...](https://github.com/ajvondrak/remote_ip/commit/b545c3a1612c3f85b16784ba33386e805c5c4115)
#### Friday 2021-02-19 23:01:39 by Alex Vondrak

Reimagine the debugging interface

The RemoteIp.Debug module was reworked in these key ways:

* It was renamed to RemoteIp.Debugger
* log/3 was renamed debug/3
* The __using__/1 callback now imports the module

The initial motivation for this came from RemoteIp.Headers and
RemoteIp.Options. The RemoteIp.Headers module is useful to keep public,
because I could see someone wanting to call parse/1 ad hoc. I also think
RemoteIp.Options would be useful for documenting how to configure
RemoteIp via the `@moduledoc`. But if it's publicly documented, that may
increase the chance someone would call its functions from outside the
RemoteIp.{call,from}/2 cycle, even if they're `@doc false` or otherwise
flagged as "don't do this".

Regardless, I think it would be unexpected to generate log statements
from calling, say, RemoteIp.Headers.take/2. This is especially true
since the messaging is kind of assuming it's being called from RemoteIp.
So I wanted to move all the debug information solely into the RemoteIp
module.

In doing so, the code got clunky with fully-qualified
RemoteIp.Debug.log/3 calls. Shit was hard to fit on single lines. Thus
the __using__/1 callback imports the macros so we can just spell it
without the module name.

But when I started using an unqualified log/3, the call sites looked
kind of confusing. The do-block based structure is inconsistent with the
Logger statements you'd probably (and rightly) associate with the word
"log". I decided a better unqualified name would be debug/3.

Noticing the naming pattern of Logger.log/3, the name Debug.debug/3 also
started looking more awkward. I renamed the module to Debugger, which
makes the `use` declaration in RemoteIp read better as well.

A benefit of this renewed interface is that the debug/3 calls are
agnostic to the backing implementation. They could be generating log
statements, telemetry events, or something else entirely. It nicely
abstracts over any number of reasonable things a debugger might do.

As a cosmetic change, the private RemoteIp.Debugger function enabled?/1
was renamed to debug?/1, along with the `@enabled` module attribute.
This makes them match the name of the app config key, so it's perhaps a
little better to read.

---
## [ScottPenhall98/Mind-Maker](https://github.com/ScottPenhall98/Mind-Maker)@[fd79db675a...](https://github.com/ScottPenhall98/Mind-Maker/commit/fd79db675a195926483c280af8f86250ef699dab)
#### Friday 2021-02-19 23:08:17 by ScottPenhall98

still looks fucken ugly as hell, However we have some more needed pacakges inluding laravels ziggy routes that works with JS and now this has an effect on active links, as well as buttons that take you to different routes

---
## [FallingStar-Games/outsiders-of-thunder-city](https://github.com/FallingStar-Games/outsiders-of-thunder-city)@[ee1626bf53...](https://github.com/FallingStar-Games/outsiders-of-thunder-city/commit/ee1626bf53e7a897b881c3b242e1076cad4dda5a)
#### Friday 2021-02-19 23:30:03 by NyxAsteria

We have something semi-playable! A little bit! Kind of!

-Ray and Black Flag have full movesets (kinda) with statted out damage formulas. I forgot to make Black Flag's Auras or Reactions cost overdrive, I will do that later
-The test Ray troop now has AI! You can have a full fight with him where he does different shit! It's not at all sophisticated but!!!
-Fortitude is gone and now Vulnerability and AuraVuln are separate stats
-Ray and Black Flag have proper stats now making their fight a real one (even though you can pretty easily evade most of his stuff right now)
-The CTB system was fixed up so there's no random initiative
-All random status effects are now sure to trigger unless the target is specifically immune to them

To-do: Polish up this battle more, fix the problems I forgot about, add in Hard Reads!!!

---

# [<](2021-02-18.md) 2021-02-19 [>](2021-02-20.md)

