# [<](2021-01-21.md) 2021-01-22 [>](2021-01-23.md)

2,699,900 events, 1,359,516 push events, 2,126,609 commit messages, 166,241,944 characters


## [Buildstarted/linksfordevs](https://github.com/Buildstarted/linksfordevs)@[ec2811cfaf...](https://github.com/Buildstarted/linksfordevs/commit/ec2811cfaf27e4bd5455bb31c465ecb81a1f53af)
#### Friday 2021-01-22 00:07:59 by Ben Dornis

Updating: 1/22/2021 12:00:00 AM

 1. Added: An Ode to Chess
    (https://paranoidenough.com/2021/01/18/An-Ode-to-Chess.html)
 2. Added: The widening gyre
    (https://laanwj.github.io/2021/01/21/decentralize.html)
 3. Added: So, You Want to CTF? (A Beginner’s Guide to CTFing)
    (https://jaimelightfoot.com/blog/so-you-want-to-ctf-a-beginners-guide/)
 4. Added: Why Electron is a Necessary Evil
    (https://federicoterzi.com/blog/why-electron-is-a-necessary-evil/)
 5. Added: Startup Franchises – Rebel Browser
    (https://yoavy.com/startup-franchises/)
 6. Added: Hacker leaks data of millions of Teespring users | ZDNet
    (https://www.zdnet.com/article/hacker-leaks-data-of-millions-of-teespring-users/)
 7. Added: microsoft/terminal
    (https://github.com/microsoft/terminal)
 8. Added: My Backup Strategy
    (https://crgwbr.com/2021-backup-strategy/)
 9. Added: Signal App UX irritation: “x just joined Signal” | Nitin Nain
    (https://nitinnain.com/signal-ux-irritation-x-just-joined/)
10. Added: Stepping up for a truly open source Elasticsearch | Amazon Web Services
    (https://aws.amazon.com/blogs/opensource/stepping-up-for-a-truly-open-source-elasticsearch/)
11. Added: Scott Finlay - The Agile Development of a Novel
    (https://www.scottfinlayauthor.com/articles/the-agile-development-of-a-novel)
12. Added: Explore the art world by using RESTful APIs - Learn
    (https://docs.microsoft.com/en-us/learn/modules/use-apis-discover-museum-art/?WT.mc_id=academic-13254-jelooper)
13. Added: Righteous, Expedient, Wrong
    (https://writing.kemitchell.com/2021/01/20/Righteous-Expedient-Wrong.html)

Generation took: 00:07:46.6712439

---
## [EvanGoldConn/Email-Scraper](https://github.com/EvanGoldConn/Email-Scraper)@[5b6dbe241a...](https://github.com/EvanGoldConn/Email-Scraper/commit/5b6dbe241a0a22cf86e9e87a54d385e50fb81d47)
#### Friday 2021-01-22 01:39:10 by EvanGoldConn

fucking finally finished cleaning the dataset

this took way too god damn long and there are still 4k duplicates. whatever.

---
## [git/git](https://github.com/git/git)@[36a317929b...](https://github.com/git/git/commit/36a317929b8f0c67d77d54235f2d20751c576cbb)
#### Friday 2021-01-22 01:42:47 by Jeff King

refs: switch peel_ref() to peel_iterated_oid()

The peel_ref() interface is confusing and error-prone:

  - it's typically used by ref iteration callbacks that have both a
    refname and oid. But since they pass only the refname, we may load
    the ref value from the filesystem again. This is inefficient, but
    also means we are open to a race if somebody simultaneously updates
    the ref. E.g., this:

      int some_ref_cb(const char *refname, const struct object_id *oid, ...)
      {
              if (!peel_ref(refname, &peeled))
                      printf("%s peels to %s",
                             oid_to_hex(oid), oid_to_hex(&peeled);
      }

    could print nonsense. It is correct to say "refname peels to..."
    (you may see the "before" value or the "after" value, either of
    which is consistent), but mentioning both oids may be mixing
    before/after values.

    Worse, whether this is possible depends on whether the optimization
    to read from the current iterator value kicks in. So it is actually
    not possible with:

      for_each_ref(some_ref_cb);

    but it _is_ possible with:

      head_ref(some_ref_cb);

    which does not use the iterator mechanism (though in practice, HEAD
    should never peel to anything, so this may not be triggerable).

  - it must take a fully-qualified refname for the read_ref_full() code
    path to work. Yet we routinely pass it partial refnames from
    callbacks to for_each_tag_ref(), etc. This happens to work when
    iterating because there we do not call read_ref_full() at all, and
    only use the passed refname to check if it is the same as the
    iterator. But the requirements for the function parameters are quite
    unclear.

Instead of taking a refname, let's instead take an oid. That fixes both
problems. It's a little funny for a "ref" function not to involve refs
at all. The key thing is that it's optimizing under the hood based on
having access to the ref iterator. So let's change the name to make it
clear why you'd want this function versus just peel_object().

There are two other directions I considered but rejected:

  - we could pass the peel information into the each_ref_fn callback.
    However, we don't know if the caller actually wants it or not. For
    packed-refs, providing it is essentially free. But for loose refs,
    we actually have to peel the object, which would be wasteful in most
    cases. We could likewise pass in a flag to the callback indicating
    whether the peeled information is known, but that complicates those
    callbacks, as they then have to decide whether to manually peel
    themselves. Plus it requires changing the interface of every
    callback, whether they care about peeling or not, and there are many
    of them.

  - we could make a function to return the peeled value of the current
    iterated ref (computing it if necessary), and BUG() otherwise. I.e.:

      int peel_current_iterated_ref(struct object_id *out);

    Each of the current callers is an each_ref_fn callback, so they'd
    mostly be happy. But:

      - we use those callbacks with functions like head_ref(), which do
        not use the iteration code. So we'd need to handle the fallback
        case there, anyway.

      - it's possible that a caller would want to call into generic code
        that sometimes is used during iteration and sometimes not. This
        encapsulates the logic to do the fast thing when possible, and
        fallback when necessary.

The implementation is mostly obvious, but I want to call out a few
things in the patch:

  - the test-tool coverage for peel_ref() is now meaningless, as it all
    collapses to a single peel_object() call (arguably they were pretty
    uninteresting before; the tricky part of that function is the
    fast-path we see during iteration, but these calls didn't trigger
    that). I've just dropped it entirely, though note that some other
    tests relied on the tags we created; I've moved that creation to the
    tests where it matters.

  - we no longer need to take a ref_store parameter, since we'd never
    look up a ref now. We do still rely on a global "current iterator"
    variable which _could_ be kept per-ref-store. But in practice this
    is only useful if there are multiple recursive iterations, at which
    point the more appropriate solution is probably a stack of
    iterators. No caller used the actual ref-store parameter anyway
    (they all call the wrapper that passes the_repository).

  - the original only kicked in the optimization when the "refname"
    pointer matched (i.e., not string comparison). We do likewise with
    the "oid" parameter here, but fall back to doing an actual oideq()
    call. This in theory lets us kick in the optimization more often,
    though in practice no current caller cares. It should never be
    wrong, though (peeling is a property of an object, so two refs
    pointing to the same object would peel identically).

  - the original took care not to touch the peeled out-parameter unless
    we found something to put in it. But no caller cares about this, and
    anyway, it is enforced by peel_object() itself (and even in the
    optimized iterator case, that's where we eventually end up). We can
    shorten the code and avoid an extra copy by just passing the
    out-parameter through the stack.

Signed-off-by: Jeff King <peff@peff.net>
Reviewed-by: Taylor Blau <me@ttaylorr.com>
Signed-off-by: Junio C Hamano <gitster@pobox.com>

---
## [ccodwg/Covid19Canada](https://github.com/ccodwg/Covid19Canada)@[cf6a743d28...](https://github.com/ccodwg/Covid19Canada/commit/cf6a743d281ff533d526bae0bcd612a0d672848b)
#### Friday 2021-01-22 02:33:16 by Jean-Paul R. Soucy

New data: 2021-01-21: See data notes for important messages.

Vaccine datasets:

- 2021-01-19: Fully vaccinated data have been added (vaccine_completion_cumulative.csv, timeseries_prov/vaccine_completion_timeseries_prov.csv, timeseries_canada/vaccine_completion_timeseries_canada.csv). Note that this value is not currently reported by all provinces (some provinces have all 0s).
- 2021-01-11: Our Ontario vaccine dataset has changed. Previously, we used two datasets: the MoH Daily Situation Report (https://www.oha.com/news/updates-on-the-novel-coronavirus), which is released weekdays in the evenings, and the “COVID-19 Vaccine Data in Ontario” dataset (https://data.ontario.ca/dataset/covid-19-vaccine-data-in-ontario), which is released every day in the mornings. Because the Daily Situation Report is released later in the day, it has more up-to-date numbers. However, since it is not available on weekends, this leads to an artificial “dip” in numbers on Saturday and “jump” on Monday due to the transition between data sources. We will now exclusively use the daily “COVID-19 Vaccine Data in Ontario” dataset. Although our numbers will be slightly less timely, the daily values will be consistent. We have replaced our historical dataset with “COVID-19 Vaccine Data in Ontario” as far back as they are available.
- 2020-12-17: Vaccination data have been added as time series in timeseries_prov and timeseries_hr.
- 2020-12-15: We have added two vaccine datasets to the repository, vaccine_administration_cumulative.csv and vaccine_distribution_cumulative.csv. These data should be considered preliminary and are subject to change and revision. The format of these new datasets may also change at any time as the data situation evolves.

Upcoming changes (specific dates to be announced soon):

- The data structure of time series data will change in response to user feedback. This will only consist of adding additional columns to make the data easier to work with. The core columns will remain the same, for now. More details to follow. Initially, the updated dataset will be provided alongside the new dataset. After a time, the new data format will completely replace the old format.

Recent changes:

- 2021-01-08: The directories cases_extra and mortality_extra have been moved to other/cases_extra and other/mortality_extra.

Revise historical data: cases (BC, MB, NT, ON, SK); testing (NT).

Note regarding deaths added in QC today: “The data also report 66 new deaths, but the total of deaths amounts to 9,273 due to the withdrawal of 1 death that the investigation has shown not to be attributable to COVID-19. Among these 66 deaths, 22 have occurred in the last 24 hours, 39 have occurred between January 14 and January 19, 4 have occurred before January 14 and 1 has occurred at an unknown date.” We report deaths such that our cumulative regional totals match today’s values. This sometimes results in extra deaths with today’s date when older deaths are removed.

https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/#c47900

Note about SK data: As of 2020-12-14, we are providing a daily version of the official SK dataset that is compatible with the rest of our dataset in the folder official_datasets/sk. See below for information about our regular updates.

SK transitioned to reporting according to a new, expanded set of health regions on 2020-09-14. Unfortunately, the new health regions do not correspond exactly to the old health regions. Additionally, the provided case time series using the new boundaries do not exist for dates earlier than August 4, making providing a time series using the new boundaries impossible.

For now, we are adding new cases according to the list of new cases given in the “highlights” section of the SK government website (https://dashboard.saskatchewan.ca/health-wellness/covid-19/cases). These new cases are roughly grouped according to the old boundaries. However, health region totals were redistributed when the new boundaries were instituted on 2020-09-14, so while our daily case numbers match the numbers given in this section, our cumulative totals do not. We have reached out to the SK government to determine how this issue can be resolved. We will rectify our SK health region time series as soon it becomes possible to do so.

---
## [MikeyFalk/LAB09-LINQ](https://github.com/MikeyFalk/LAB09-LINQ)@[d039eaea0c...](https://github.com/MikeyFalk/LAB09-LINQ/commit/d039eaea0c04d55bf0a2eb6a6f3276d19e6a5f19)
#### Friday 2021-01-22 06:49:01 by Mike Falk

wrote some shit down doesn't fucking work. Why can't we actually cove this shit in class so I'm not wasting hours of my time going in circles to just turn more really crappy shit?

---
## [odoo-dev/odoo](https://github.com/odoo-dev/odoo)@[c6555335b0...](https://github.com/odoo-dev/odoo/commit/c6555335b0790fc64b49417488d0643f3cc60164)
#### Friday 2021-01-22 07:27:52 by Xavier Morel

[IMP] tours: make chrome request a websocket port from the OS

This should be a smarter and properly reliable version of #42071: in
that, the runner requests a port, closes it, and gives the port to
Chrome. However this apparently turns out to be less reliable than
hoped for and the port we just released can immediately be picked up
by somebody else (the original PR assumed the allocation of ephemeral
ports would be random or FIFO but that may not be the case, especially
inside containers).

This uses the same technique of requesting port 0 so the OS allocates
one, but it's Chrome requesting & immediately connecting so there
should be no race condition possible, and we keep the property that as
long as ephemeral ports are available Chrome will be able to open one
without conflicts or overlaps.

This leaves the issue of *retrieving* the port chrome got: chrome
prints the ws URL on its stderr, but retrieving that is a pain in the
ass as we don't really want to spawn a thread continuously reading
from the pipe (to ensure chrome will not block on a full pipe) and
neither do we care about what chrome spouts out (which may eventually
change) so it's a bit of a mess.

Instead after an @Xavier-Do suggestion check what ports Chrome listens
to and assumes that's the websocket server (currently there's only
one, if we find more than one we'll log a warning and pick the first
one). This seems pretty reliable (and not too slow) and is not overly
complicated as psutil has built-in support, though WSL1 apparently
doesn't support it (e.g. netstat/ss don't work either).

An other option is some form of socket activation, however that didn't
pan out either: originally chrome added a way to pass a listening
socket by
fd (https://bugs.chromium.org/p/chromium/issues/detail?id=624837)
which would have suited our purposes perfectly (less changes to make)
however *that* was removed just a few months later and replaced by
pipes support (https://chromium-review.googlesource.com/954405). The
pipes system has the advantages that it doesn't consume ports, doesn't
require a websocket dependency, and has even less setup overhead, but
it uses its own protocol (nul-terminated JSON messages through the
pipe ends which chrome expects at fds 3 for input and 4 for output)
and so would be a much larger change as we'd need to rip out the
entire websocket (which TBF is largely contained into a few _websocket
methods whose implementation we might be able to just swap out).

Replaces #64758

---
## [maborak/iemaddon-installer](https://github.com/maborak/iemaddon-installer)@[e3344fae8d...](https://github.com/maborak/iemaddon-installer/commit/e3344fae8df11e7865486b04e7de613df7883b5f)
#### Friday 2021-01-22 10:52:31 by Wilmer Adalid (Alienware)

Updates for: Men love to wonder, and that is the seed of science.

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[90acf29369...](https://github.com/mrakgr/The-Spiral-Language/commit/90acf2936992b557263cfe2ac43e6c0d0c376bfb)
#### Friday 2021-01-22 10:59:33 by Marko Grdinić

"10:05am. I am scheming.

TODO: Monadic syntax.
TODO: Autocomplete.
TODO: Highlight unused vars.
TODO: List and array patterns and literals.
TODO: Guard against stack overflows in the partial evaluator. Try running it on a separate thread.
TODO: Make literal suffices (such as `i64`) be highlighted differently from the rest of the number.
TODO: Make a VS Code theme for Spiral.
TODO: Fix the package removal error. Probably the package errors are not being cleared and linger despite the file being erased.
TODO: Adjust the codegen so that the proxies aren't needed. Move the cases down.

Got rid of the key order on hover and added autocomplete and list and array patterns and literals.

10:10am. I am churning my brain thinking of the paths and what my moves should be.

Leaving the whole thing of making Spiral useful for other people aside, what am I most anxious of?

I've been obsessed about making the agents all this time. I anticipated the future and saw that making the ML libraries for future hardware as the bottleneck. But I sort of have that out of the way. Even algorithms aren't a problem anymore - ensembles and diversity are going to carry me far.

After a year of work I've finally started applying. I'll send out emails every week from here on out. Even if I do not get a reply from one company, I plan to keep sending them different pitches. If I can get them to initiate conversation, I should be able to convince them of Spiral's benefits. I'll only give up on a company if I get a clear reject.

I do not think my first pitch was too good. Maybe the mindset of not wanting to sell myself is wrong. Maybe I should sell both myself and Spiral? I'll try that pitch as well. I'll try composing a resume next time.

10:20am. This whole process of applying will be a slow and steady effort. I'll dedicate one day per week to it. That will be a good pace.

The patience to do it in weekly steps comes from trading for me. So does persistence. I really do feel like I've finally mastered it 6 years after giving up on it.

Back to the matter at hand, the thing I am most anxious of would be UI automation. Even if I had an agent, would it be that easy to interface with games and online sites with it. Not at all!

That particular task feels completely intimidating to me.

Ok, so compared to 2018, I no longer have access to GPU, and it would be a huge chore to build up that infrastucture again. But GPUs are shitty for that anyway, so I should be aiming to use the CPU.

I have Spiral, I can easily implement the latest and greatest CFR algorithms from the papers on it. In one of the papers they used unsupervised clustering to get the right features. I can get an lin alg library and implement K-means or whatever. It is no big deal. It would take me a few weeks of experimentation to get an agent that way.

I won't make my focus making the agent. I've already gone through that before.

Instead, what I need to master is what I haven't done before. 2020 was me growing up and learning UIs and concurrency. I have that down. In 2021 what I should learn is not so much how to make the agent, but how to actually use them. I should get some actual hacking skills.

I've been avoiding this for too long. This is what I should be aiming towards after I finish those TODOs. The TODOs won't take long. In a few weeks I will be through with them. Then I will need something to do if the companies start playing coy with me.

Interviewing and negotiations aren't a big deal. I'll get my chance eventually.

UI automation is what I need to put my effort into.

10:35am. Now let me see if I got any mail. Flakes. Figures.

On Wednesday I'll increase the batch size to 6. I have too many potential sponsors, so I want to increase the pace. If I am getting nothing after a month, I'll add the nano .NET sponsors to rotation as well.

10:50am. Let me do my morning chilling and then I will start.

I wrote the docs, and I finally made the first step forward into the real world. But these interviews are like stocks. You can buy a stock, but then pouring your desire into it will make a lick of difference whether it goes up or not.

I do not want to make a mistake in getting emotionally involved in these interviews and placing expectations on how things should go. Once the stone is cast, it should be let to fly on its own.

If I am going to get emotionally involved with something, that should be the actual programming that I do. Pouring my creativity and inspiration there will make a proportional difference. Unlike trading, the more effort is put into programming, the better the results will be.

10:55am. Besides UI automation, if the interviewing does not send any work my way, I should work towards building up the GPU capabilities back up again. The ML library that I had was good. It would not be bad to bring it back.

A Python backend would not be a bad idea either.

11am. The work never stops. I'll only get a break when I am dead.

11:30am. I am done chilling, but right now, it is exactly the time to have breakfast. Let me do it. Today, maybe I will take some time off from the screen. I've just presented my new motivation, but haven't really internalized it yet. Maybe I will rant for a while.

Work, work, it is always work.

It is lame. I made Spiral because I wanted to protect the functional style I had acquired in F#. I wanted to improve on it too.

But how can I prove it to others that this matters? How can I prove to others that they would benefit from adopting it? I am pessimistic. Back in high school the adventure never started.

And during my trading days, after 4 years of paper trading all I got is 3k to try it out and got nowhere for 2 years after that. So that is 10 years of failure tailing behind me. And now I struck out on my own in programming, but haven't had any success.

Will in the end my desire lead me to ruin?

The treeshold for success is so low, just one sponsor, but it could turn into a nightmare where I get nowhere for months and years. I am mostly saying this not to be pessimistic, but because it has happened to me. In fact, things not going my way is the standard rather than the exception.

11:40am. If my luck is really so shitty that all I can do is rely on myself, I'll make UI automation the last attempt. I'll absolutely master interfacing with the outside world through a virtual PC and employ agents in my undertaking. I'll use CPU-based agents, I'll build back the GPU capabilities of Spiral and use those, whatever.

Maybe I can win on my own. I do not want to have any regrets regarding this.

My 2018 attempt was in the direction of making an agent, sure. I made a GPU-based ML library and that was a great success. But I did not make creating an agent and putting it to real work use a priority. Instead I wanted to make their training completely roboust. I wanted to push my mind and exceed the perceived limitations of backprop.

This time I want to pursue my actual stated goal. And I will use Spiral v2 to do it. If Spiral is really as good as I imagine it to be, this will be its time to shine.

11:45am. There just isn't anything more that I can do apart from try it. Better language than Spiral will exist in the future, but they won't have particularly notable advantages over it. Not if they are made by humans.

Just like SML set the standard for statically typed functional languages, Spiral is the SML of the 21st century. It is the standard for a statically typed language with partial evaluation.

It is the language that has all the potential. If Spiral is not enough, nothing will be.

Right now I am at a pinnacle of my skill. If I cannot beat at least online poker using my current skills, then it is impossible.

What is a few years here and there? To reach my dreams I should be able to put in this kind of work. I am tired, but I was tired in 2015, 2016, 2017, 2018, 2019 and 2020.

2021 is not the year to take a vacation. Things will be busy here.

I am going to exceed my limit once more and master the most crucial skill for using agents in the real world. After that my potential will be bottomless.

11:55am. This is actually wonderful.

When it comes to getting sponsors I do not want to make the same mistake I did during my trading days where I just bought a stock and then spent my time dreaming about how rich I am going to get. I do not want to fire an email and start thinking how impressed the other side will be with Spiral and how great it would be for things to go my way.

During my trading days, I could have done programming on the side, but I did not. I won't allow myself to become mentally reliant on non-allies again. Instead my whole being should always be on cultivating my own abilities. That is the true path."

---
## [Antimatter543/Kaggle](https://github.com/Antimatter543/Kaggle)@[77b1dc69d8...](https://github.com/Antimatter543/Kaggle/commit/77b1dc69d85f43666fffdd7fd42586ee30a00903)
#### Friday 2021-01-22 12:32:18 by Anti Matter

N-Step-Alpha-beta-pruning (Not copy pasted)

This man.
https://www.youtube.com/watch?v=l-hh51ncgDI
Bless. Holy shit. What a fuckin legend.
By not copy pasted, I mean, I couldn't literally just copy paste kaggle code to do it. Maybe I could if I just searched for it on a public notebook, but I gave myself an 'honour' system of only allowing myself to use more of Kaggle's computational resources (search deeper) if I could prune without copy pasting.
Obviously, I used Wikipedia's pseudocode and the video above to help, though. Actually helped me to understand wtf minimax does, much more solidly. 
I also didn't copy paste the minimax and edit. Instead, I wrote out the whole algorithm from scratch because yeah.

---
## [LDR-Siren/EmilyC-SamanthaPrater-EruzaArto](https://github.com/LDR-Siren/EmilyC-SamanthaPrater-EruzaArto)@[5abd575155...](https://github.com/LDR-Siren/EmilyC-SamanthaPrater-EruzaArto/commit/5abd5751551c845e67c30daab5f2bafebb4944fc)
#### Friday 2021-01-22 13:39:37 by LDR

IP Lies and Emails

So yesterday was a lesson in idiocy. She attacked James's youtube with accusations that the Phones he has are not hers. I will be uploading the voice mails proving that those phones are hers. One in particular has her screaming "LEAVE MY PHONES ALONE!" As James says all the time "I just shit myself" because when I heard it, all doubt was removed. It will be a 2 part upload as James has over 218 voice mails from this psycho. 

Another thing she attacked him over was the IP address. Okay I have included in this commit, how Static IP works. Layman's terms: It is the permanent address on the phone itself. It is traceable. It is also possible for a phone to have up to 6 different IP address, but the static IP does not change. Also too sim cards are registered to a person, further identifying the device. So he has 2 phones with sim cards with her name all over it. And with static IP addresses connected to her. Funny how when you look up how things actually work, you find out the actual truth instead of cherry picking to fit your narrative, huh!

The ADA. She has been screaming that we are "Picking on her" over her disabilities. No. Just cause she was in Spec Ed does not mean we are picking on her. And the ADA does not cover internet dealings. What it does cover is discrimination in the work and business places. So for an example a work place can not discriminate against an individual with a disability. Same goes for business dealings. For example, if someone with a disability was trying to own a home, the brokerage could not discriminate against them. What it does not cover is trolling and internet dealings. I have disclosed the PDF file and the screen grab of that in this commit.

As well as these words. There are those of us who have been in SPEC ED, or have Family that are in Spec Ed. We know the laws and the workings of the disability acts because we live with them or advocates for them. What we are pointing out is her Actions, her constant harassment, lies, and other insane ramblings. As well as her Cyber Attacks on individuals if they chose to could press charges against her for said harassment and slander. And included in that the threats made against their physical lives, businesses, hobbies, and possible relations.

And the Grand FInale! So she posted her email lastnight. So I put it above the collab that was made showing that the phones james has, the email she recently sent him, and the blog post all show the SAME EMAIL ADDRESS. Yup. All 3 have the same Email address. This is so much better than a smoking gun.  Because not only did she confirm publicly that the email is hers, and you can tell its hers in all three images, but the fact that she can not decipher the truth of what was shown. Those emails have nothing to do with IP addresses or anything else like she claims, like hacking. It confirms she was using the Alias of Emily Rose to try and solicit sex/prostitution on craigslist. She was in fact using that name. IT confirms she has used that email to target her mom's boyfriend with hate.  It confirms that it is her that has done all this horrible acts. 

Evidence is in this repository and its backups.

---
## [maborak/iemaddon-installer](https://github.com/maborak/iemaddon-installer)@[64e174a923...](https://github.com/maborak/iemaddon-installer/commit/64e174a92302ae917af312ab22dddac91d50f3d0)
#### Friday 2021-01-22 13:44:29 by Wilmer Adalid (Alienware)

Updates for: The little pieces of my life I give to you, with love, to make a quilt
to keep away the cold.

---
## [Sampatbraide/Sampatbraide-third-milestone-project.io](https://github.com/Sampatbraide/Sampatbraide-third-milestone-project.io)@[2a4f210780...](https://github.com/Sampatbraide/Sampatbraide-third-milestone-project.io/commit/2a4f2107802c34c067eaa4073c11e400ae804bc0)
#### Friday 2021-01-22 15:38:00 by Samuel Braide

Add files via upload

BESTCAZS 
 
## BESTCAZS
Bestcazs is a website that portrays the series of luxurious cars from Mercedes Benz.

 
## UX
This website showcases Bestcazs as a Subsidiary of Mercedes
As Mercedes Benz remains "one of the largest manufacturers of premium passenger cars. In 2019 it sold nearly 2.4 million cars and more than 438,000 vans. In its two business divisions, Mercedes-Benz AG is continually expanding as stated by  
[Mercedes](http://https://www.mercedes-benz.com/en/company/)

 
## Features
The Home Page
The website is a one-page website 
with all existing links
of the 
Home link
Services link  
Gallery link
About link
and the
Contact link all navigates within the Home page.

The Home link links to the Home page

The Service links display varied types of services such as Full Service, Major Service, Interim Service and the Interim-hybrid Service. 

 The Gallery link displays various pictures of Mercedes Bens cars

The About link gives a brief history of Mercedes Benz
At the footer, there are some social media networks.

The Contact section gives the contact address of the Bestcazs Contact details.

The footer section displays page a photoshop link to various social media networks

 
## Future Improvements
I will add some content of Php, Phyton, mongo db into this project.

I will add various descriptions to all the spec of cars displayed in the Gallery Section
I will have to optimise the website to stand out among its competitors.

 
## The Technologies I have used
This includes HTML W3Schools, for adhering to the correct HTML syntax
CSS W3Schools for adhering to the correct CSS syntax
 downloads
I used this JS programming for creating some logic to the project work

 
## Validators
I used [HTML]  (https://validator.w3.org/) and [CSS]  (https://jigsaw.w3.org/css-validator/) to validate the web document. 
Minor errors appeared from its content and I made some corrections.

 
## Testing
The logo is displayed in bold colours to the top right of the page.

I am happy to browse through a website that is very easy to navigate through.

As a Car enthusiast, I am glad to visit cars online to learn about trending cars. 

Being a one-page website it is visible and easy to access at any given point in time.
 
At the footer, various Links to the social media network is displayed. 

 
## Home Page
This is the Index page, more so, the landing page once entered it takes the user to all the necessary details of the website.

 
## Header Section
It contains the names of the logo and the different sections of the links and its content.


## Outcome
The website is simple and working well,
At the moment I am taking care of my younger one during the day, While I work during the night and try to study in between.
I am still trying to learn all I could do to become a great Software Engineer.

## Bugs
I have not noticed any bug at the moment.

I am still carrying out some finding to see if there is any potential bug.

## Deployment
Deploying the GitHub Pages from my Desktop
Log into GitHub.
I will have to create a repository which is
 Sampatbraide/third-milestone-project.github.io
after doing that I will upload my project to the repository
this will take a couple of minutes.

 
Moreso I can also use
[MAKE A README](https://https://www.makeareadme.com/)
Type the document format it and transfer it to [GITHUB](http://github.com/)
As I could examine it a re-test by ensuring that everything is working as expected.

 
## Credits
I also got the inspiration for the project from these websites:

[HALFORDS](https://www.halfords.com/car-servicing/),

[QCDAUTOCENTRES] https://www.qcdautocentres.co.uk/servicing/hybrid-service/),

[MERCEDESBENZ] (https://www.mercedes-benz.com/en/company/),

[MERCEDESBENZ] (https://www.mercedes-benz.com/en/company/),

[ONEPAGE](https://github.com/WebCifar/one-page-website-html-css-project-for-practice),


 
Images for the Gallery Section from Google  
[GOOGLE] (https://www.google.com/search?q=mercedes+benz&safe/),
Images for the Service Section
[GOOGLE] (https://www.google.com/search?q=mercedes+benz+production&safe/)

 
## Acknowledgements
All Glory to God for seeing today.
I thanks my family and friends for their support.
I thank my Mentor, for her support and information.
Many thanks to Code institute Director, Lecturers, Student Care team, for their great support.

---
## [bmsa-cs/chatbot-hbaer24](https://github.com/bmsa-cs/chatbot-hbaer24)@[b39060b0cf...](https://github.com/bmsa-cs/chatbot-hbaer24/commit/b39060b0cf070b6330f361286ce7542836941edb)
#### Friday 2021-01-22 15:44:27 by Hope Baer

"""
Chatbot
Author:
Period/Core:

"""

import os
import importlib.util

import random

def run_tests():
  """
  This function will check for the pytest module
  before calling it to run the included tests.py
  """
  if importlib.util.find_spec('pytest') is None: # Check if pytest is installed
    os.system('python3 -m pip install -q pytest')

  command = "python3 -m pytest --tb=line -v -s tests.py"
  print(command)
  os.system(command)

def main():
  from colorama import Style
  import time
  import sys
  from time import sleep
  import random
  #print(Style.BRIGHT+"This is Bold")
  #print(Style.BRIGHT+"This is Bold")
  #Can also be dim/opposite of bold
  #print(Style.DIM+"This is Dim")
  #print(Style.DIM+"This is Dim")
  #Reset the style
  #print(Style.RESET_ALL+"This is normal")
  #print(Style.RESET_ALL+"This is normal")

  #Greeting and asking how you are.
  name = input("What is your name?")

  print(name)
  time.sleep(1)
  print("\n \nWelcome," +name)
  greeting = ("My name is Chatbot. I am going to display a few questions for you! You can answer them with a generic response. Let's get started!")
  for char in greeting:
    sleep(.1)
    sys.stdout.write(char)
    sys.stdout.flush()

  #Now beginning with the first question. This will ask for a set of responses from the user as to how they are feeling today!

    hru = input("\n \n How are you feeling today," +name + "? PLEASE REMEMBER TO TYPE WITH NO CAPITALS OR PUNCTUATIONS!")
    for char in hru:
      sleep(.1)
      sys.stdout.write(char)
      sys.stdout.flush()

    if  hru == "happy" or hru == "great" or hru == "good" or hru == "neutral" or hru =="alright" or hru == "fine" or hru =="fantastic" or hru == "excellent" or hru == "splendid" or hru =="decent" :
        list1 = print("I'm so glad to hear you are feeling " + hru + "!!")
        list2 = ["Awesome! I am happy to hear that you are " + hru + "!"]
        list3 = ["Splendid indeed! "]
        list4 = ["Perfect! "]
        list5 = ["YAYY!! "]
        list6 = ["It brings me joy to know you are feeling " +hru + "!!"]
        random.randint(0,6)

    elif hru == "sad" or hru == "angry" or hru == "frustrated" or hru == "irritated" or hru == "ok" or hru == "okay" or hru == "alright":
        list7 = ["Aww! I'm sorry that you are feeling" + hru + ". I hope you feel better!"]
        list8= ["Oh no! I would never wish for you to be" +hru + ". Best of wishes! We will proceed with questions momentarily."]
        list9 = ["Aw dang! I hope you will no longer feel" + hru + " once we are done!"]
        random.randint(0,3)
    else:
      raise TypeError ("You have typed a response that was either unrecognized or included a typo! Please restart or exit. :)")

if __name__ == "__main__":
  main()
  t = input("Run pytest? (y/n)").lower()
  if t == 'y':
    run_tests()

---
## [bmsa-cs/chatbot-hbaer24](https://github.com/bmsa-cs/chatbot-hbaer24)@[8a30160327...](https://github.com/bmsa-cs/chatbot-hbaer24/commit/8a30160327529c2a1b1bd4498db03f9b60c15eb3)
#### Friday 2021-01-22 16:15:01 by Hope Baer

"""
Chatbot
Author:
Period/Core:

"""

import os
import importlib.util

import random

def run_tests():
  """
  This function will check for the pytest module
  before calling it to run the included tests.py
  """
  if importlib.util.find_spec('pytest') is None: # Check if pytest is installed
    os.system('python3 -m pip install -q pytest')

  command = "python3 -m pytest --tb=line -v -s tests.py"
  print(command)
  os.system(command)

def main():
  from colorama import Style
  import time
  import sys
  from time import sleep
  import random
  #print(Style.BRIGHT+"This is Bold")
  #print(Style.BRIGHT+"This is Bold")
  #Can also be dim/opposite of bold
  #print(Style.DIM+"This is Dim")
  #print(Style.DIM+"This is Dim")
  #Reset the style
  #print(Style.RESET_ALL+"This is normal")
  #print(Style.RESET_ALL+"This is normal")

  #Greeting and asking how you are.
  name = input("What is your name? ")

  print(name)
  time.sleep(1)
  print("\n \nWelcome, " + name)
  greeting = ("My name is Chatbot. I am going to display a few questions for you! You can answer them with a generic response. Let's get started!")
  for char in greeting:
    sleep(.05)
    sys.stdout.write(char)
    sys.stdout.flush()

  #Now beginning with the first question. This will ask for a set of responses from the user as to how they are feeling today!

  hru = input("\n \n How are you feeling today," +name + "? PLEASE REMEMBER TO TYPE WITH NO CAPITALS OR PUNCTUATIONS!")
  for char in hru:
    sleep(.1)
    sys.stdout.write(char)
    sys.stdout.flush()

  if  hru == "happy" or hru == "great" or hru == "good" or hru == "neutral" or hru =="alright" or hru == "fine" or hru =="fantastic" or hru == "excellent" or hru == "splendid" or hru =="decent" :
    list_one = ["I'm so glad to hear you are feeling " + hru + "!!", "Awesome! I am happy to hear that you are " + hru + "!", "Splendid indeed! ", "Perfect! ", "YAYY!! ", "Great! I'm glad to know you are feeling " + hru + "!!"]
    print(list_one[random.randint(0,5)])

  elif  hru == "sad" or hru == "angry" or hru == "frustrated" or hru == "irritated" or hru == "ok" or hru == "okay" or hru == "alright":
    list_two =["Aww! I'm sorry that you are feeling " + hru + ". I hope you feel better!", "Oh no! I would never wish for you to be" + hru + ". Best of wishes! We will proceed with questions momentarily.", "Aw dang! I hope you will no longer feel " + hru + " once we are done!"]
    print(list_two[random.randint(0,2)])
  else:
   print("\n \nInteresting!")

  question_two = input("Next question! What is your favorite color?")
  list_three = [question_two + " is a cool color!", "That is interesting.", "Interesting!", "That's pretty cool.", "Nice!", question_two + " is pretty!"]
  print(list_three[random.randint(0,5)])

  question_three = input("Beaches, or mountains?\n")

  list_four = ["That's so cool! I couldn't decide on what to choose; theyre both awesome!", "The " + question_three + " is so pretty and scenic!", "So cool!", "Pretty!"]

---
## [fainat/LiveChat-with-Node.js](https://github.com/fainat/LiveChat-with-Node.js)@[d009d10eb8...](https://github.com/fainat/LiveChat-with-Node.js/commit/d009d10eb85b0857cb9d898d91800c02f2830c74)
#### Friday 2021-01-22 16:16:30 by Infab James

Delete node_modules folder

I am a very stupid Developer. Did you know my lovely Laptop

---
## [Innoviox/eydr](https://github.com/Innoviox/eydr)@[d71d423f31...](https://github.com/Innoviox/eydr/commit/d71d423f31683c0e6831b35c1722a88e75872869)
#### Friday 2021-01-22 21:47:58 by Simon Chervenak

man i love utilising xcode. what a wonderful experience

---

# [<](2021-01-21.md) 2021-01-22 [>](2021-01-23.md)

