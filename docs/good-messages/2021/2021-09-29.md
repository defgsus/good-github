# [<](2021-09-28.md) 2021-09-29 [>](2021-09-30.md)

3,233,697 events, 1,622,940 push events, 2,511,820 commit messages, 193,296,976 characters


## [Malax/libcnb.rs](https://github.com/Malax/libcnb.rs)@[0e73563fdf...](https://github.com/Malax/libcnb.rs/commit/0e73563fdf93b7c9b9e076e8b369791b3be6c18b)
#### Wednesday 2021-09-29 00:10:46 by Richard Schneeman

Spike of Builder for DetectContext

This commit is an implementation of a "consuming builder" for DetectContext https://doc.rust-lang.org/1.0.0/style/ownership/builders.html.

I'm looking for feedback on the high-level API. i.e., These method names:

```
let context = DetectContextBuilder::new("heroku-20")
    .buildpack_toml_from_string(include_str!("../examples/example-02-ruby-sample/buildpack.toml"))
    .from_temp_dir(&temp_dir)
    .build::<std::io::Error>()
    .unwrap();

detect(context);
```

I'm also interested in ways to improve the following problems:

- The generation of errors and values inside of `build()` is gnarly. It works for now...but it's brute force via match, not very clean.
- Ambiguous multiple value errors ("call ONLY one") don't list the values that are set, just says the developer set multiple values.
- I had to add a method to toml_file.rs to get error handling to work as I wanted. Maybe we can do it without that modification.
- I wrote code this to be in line with the code inside runtime.rs, which uses generics and including generic error. That means Rust needs to be able to resolve the error type even when it's not used (due to `.unwrap()` hence the funky:

```
.build::<std::io::Error>()
```

I talked to Terence about this, and he said since we know all the possible errors coming from this code invocation, there might be another way to split this out, but it would require refactoring how we're doing error handling in the project.

- Build method is huge
- The error handling was very difficult. I ended up "cheating" and adding an "Other" error type to pass in a string. I'm not sure what's a better way to do this.
- app_dir and buildpack_dir don't have any existence checks. The PathBuf is not guaranteed to exist.

Thoughts:

- I don't think it's possible to do this as a non-consuming builder. We would not be allowed to take any values that cannot be cloned. Right now, we're taking Platform and BuildpackToml<BM>. We could maybe re-work to require these to be clonable, but I think that's a considerable change.
- I renamed the interface `buildpack_descriptor` to `buildpack_toml` as I think it's less vague. I didn't touch the DetectContext interface and left it as `buildpack_descriptor`.
- We could get more or less magical as we choose. For instance, we could check to see if a buildpack.toml file exists based in the `buildpack_dir` and use it as a fallback.

---
## [peff/git](https://github.com/peff/git)@[57e4edf371...](https://github.com/peff/git/commit/57e4edf371bcf709458d7faf016c498dce5dd125)
#### Wednesday 2021-09-29 00:50:34 by Jeff King

commit: give a hint when a commit message has been abandoned

If we launch an editor for the user to create a commit
message, they may put significant work into doing so.
Typically we try to check common mistakes that could cause
the commit to fail early, so that we die before the user
goes to the trouble.

We may still experience some errors afterwards, though; in
this case, the user is given no hint that their commit
message has been saved. Let's tell them where it is.

Signed-off-by: Jeff King <peff@peff.net>

---
## [dipayan2/linux-dip](https://github.com/dipayan2/linux-dip)@[625d344978...](https://github.com/dipayan2/linux-dip/commit/625d3449788f85569096780592549d0340e9c0c7)
#### Wednesday 2021-09-29 02:49:08 by Jason A. Donenfeld

Revert "kernel/printk: add kmsg SEEK_CUR handling"

This reverts commit 8ece3b3eb576a78d2e67ad4c3a80a39fa6708809.

This commit broke userspace. Bash uses ESPIPE to determine whether or
not the file should be read using "unbuffered I/O", which means reading
1 byte at a time instead of 128 bytes at a time. I used to use bash to
read through kmsg in a really quite nasty way:

    while read -t 0.1 -r line 2>/dev/null || [[ $? -ne 142 ]]; do
       echo "SARU $line"
    done < /dev/kmsg

This will show all lines that can fit into the 128 byte buffer, and skip
lines that don't. That's pretty awful, but at least it worked.

With this change, bash now tries to do 1-byte reads, which means it
skips all the lines, which is worse than before.

Now, I don't really care very much about this, and I'm already look for
a workaround. But I did just spend an hour trying to figure out why my
scripts were broken. Either way, it makes no difference to me personally
whether this is reverted, but it might be something to consider. If you
declare that "trying to read /dev/kmsg with bash is terminally stupid
anyway," I might be inclined to agree with you. But do note that bash
uses lseek(fd, 0, SEEK_CUR)==>ESPIPE to determine whether or not it's
reading from a pipe.

Cc: Bruno Meneguele <bmeneg@redhat.com>
Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Cc: Steven Rostedt <rostedt@goodmis.org>
Cc: David Laight <David.Laight@ACULAB.COM>
Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Cc: Petr Mladek <pmladek@suse.com>
Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

---
## [HARDIntegral/Bal](https://github.com/HARDIntegral/Bal)@[c0138b0eec...](https://github.com/HARDIntegral/Bal/commit/c0138b0eec7dba559dcf3f50ef44ad88092902c3)
#### Wednesday 2021-09-29 04:13:16 by [HARD]Integral

getting sick of this fucking bug, aaaaaaaaaaa i hate C strings

---
## [hedyhli/dotfiles](https://github.com/hedyhli/dotfiles)@[983a29a69e...](https://github.com/hedyhli/dotfiles/commit/983a29a69ef9a8795ba31c3fcb174ce0e56b24f0)
#### Wednesday 2021-09-29 04:33:41 by Hedy Li

envs: Add LD_LIBRARY_PATH and PKG_CONFIG_PATH

I use ~/local for compiling packages without root. It emulates
/usr/local, basically. So sometimes it might have .pc files etc in
corresponding pkgconfig/ in there or .so files in corresponding lib/.

I do this because I almost always don't have root, because I work on
tildes primarily (tilde.cafe to be specific) so yeah. If a package is
written in go or similar where building would be easy, the basic
workflow is this:

    cd ~/local/src
    git clone git@example.com:user/repo
    cd repo
    make PREFIX="$HOME/local" install

If all goes well the binary would be available at ~/local/bin.

For apt packages there is a higher chance of build failing and most of
them need other dependencies (plus some other historical reasons idk) so
I don't use ~/local/src[1], here's the general workflow:

    cd ~/Downloads
    apt source pkgname
    cd pkgname
    ls -A
    less INSTALL
    ./configure --prefix=~/local
    make PREFIX=~/local
    make install PREFIX=~/local

And most likely it would complain about some package not found in the
configure step, in which case I woukd repeat the steps for that package.

Eventually (if I hadn't given up yet), the binary would be sitting in
~/local/bin nicely.

Sometimes the package needs a lot of dependencies, in that case it may
take up a shit ton of disk space, so I would pack it in a .tar.gz so it
can be saved for future use.

For meson projects:

    cd ~/local/src
    git clone git@example.com:user/repo
    ls -A
    meson setup build
    meson compile -C build
    meson install -C build --destdir ~/local
    rsync ~/local/usr/local/ ~/local/ -avr
    rsync ~/local/usr/ ~/local/ -avr && rm -rf ~/local/usr

I don't use meson often so I'm unaware of a way to easily specify
PREFIX, if any.

So that's my life of getting stuff installed without root. Thanks for
coming to my ted talk. One day I'll probably copy this entire commit msg
and make it into a blog post.

---
## [shredder67/IntellectualSystems](https://github.com/shredder67/IntellectualSystems)@[3a483f1a59...](https://github.com/shredder67/IntellectualSystems/commit/3a483f1a5980fa4bbbdd19c1a7e8a939b8e5b050)
#### Wednesday 2021-09-29 08:57:29 by shredder67

Man I hate my life, this is literally the worst day ever

---
## [NetBSD/pkgsrc](https://github.com/NetBSD/pkgsrc)@[f80aa58ab3...](https://github.com/NetBSD/pkgsrc/commit/f80aa58ab31cbbb1261ace47d212079eb95dd9ec)
#### Wednesday 2021-09-29 11:13:10 by wiz

mame: update to 0.236.

The big event of the day is here! MAME 0.236 is ready for your
enjoyment! Sadly, this month marked the passing of Sir Clive
Sinclair, who it could be argued did more to put computers into
the hands of everyday people than anyone. There’s a small update
to MAME’s ZX Spectrum software list in this release.

The effort to dump and preserve protection microcontrollers is
still going well. This month’s additions include Juuouki and Wonder
Planet. Protection simulation has been removed for Wonder Planet
and Space Harrier. Remember, this is a worthy cause that provides
multiple benefits: it improves accuracy by taking guesses out of
emulation, helps people maintain and repair ageing arcade boards,
and simplifies MAME’s code.

MAME’s NEC PC-8001 now supports floppy disks. The PC-8001 and
PC-8801 software lists have been reorganised to match, and a big
batch of items from the Neo Kobe collection have been added. MAME
continues to improve its NES/Famicom cartridge coverage. There are
a whole lot of games you can play now, including Chinese RPGs,
fighting game bootlegs, and pirate multi-game cartridges. Experience
a parallel universe of software of such inconsistent quality that
you can’t stop going down the rabbit hole! Saturn emulation has
seen a few improvements, with several games that didn’t boot
previously reaching playable status this month.

As you might expect, the FM Towns, PC-98 and V.Smile software lists
have been updated as usual. A couple of recently dumped prototypes
have been added to the SNES and Game Boy software lists. The
SpongeBob SquarePants Jellyfish Dodge game has been dumped and
emulated, and a Korean version of Sotsugyo Shousho known as Jor-eop
Jeungmyeongseo has been found. More pleasant surprises include
working emulation for the IDE protection dongle included in Killer
Instinct 2 upgrade kit, and some fixes for Atari 8-bit home computers
using the ANTIC video chip.

For people with more exotic tastes, MAME has added its oldest
working software list additions: Munching Squares and Punchy for
the MIT TX-0. There’s also a new disassembler for the DEC VAX
architecture. In more mundane news, you can now reduce the
proliferation of duplicate ROM sets for families of similar keyboards
and other devices.

---
## [sudiptoghosh8/hacktoberfest](https://github.com/sudiptoghosh8/hacktoberfest)@[9b96a50e62...](https://github.com/sudiptoghosh8/hacktoberfest/commit/9b96a50e625d1ec8cb73cfda44396732b2a01a05)
#### Wednesday 2021-09-29 13:47:23 by Sudipto Ghosh

Merge pull request #1 from sudiptoghosh8/sudiptoghosh8-patch-hacktoberfest

Update README.md
# Hacktoberfest ([Live Website](https://hacktoberfest.lingonsaft.com/)) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)


```[English]```
This is a beginner-friendly project to help you get started with your
[hacktoberfest](https://hacktoberfest.digitalocean.com/). This repository is dedicated to help beginners step up and join hands with the open source community. Feel free to start contributing. There are no wrong contributions. If you don't
know where to start, feel free to watch the videos linked below, and
read the contribution rules. Happy hacking <3 !!
By watching the video you will understand better about the working of hacktoberfest and how one will be able to create pull requests.
(P.S: Star and share this repository, if you had fun!)


```[Français]```
Ceci est un projet pour débutant qui vous permettra de commencer sur [hacktoberfest](https://hacktoberfest.digitalocean.com/). Si vous ne savez pas par ou commencer, vous pouvez regarder la vidéo(le liens se trouve plus bas) et lire les règles de contribution. Joyeux Hacking!!
Regarder la vidéo permet de mieux comprendre le fonctionnement de hacktoberfest et comment créer des pull request.


```[Português]```
Este é um projeto bom para iniciantes para ajudar você a começar a contribuir com o
[hacktoberfest](https://hacktoberfest.digitalocean.com/). Se você não
sabe por onde começar, fique à vontade para assistir aos vídeos relacionados abaixo e
leia as regras de contribuição. Bom hacking <3 !!
Ao assistir ao vídeo, você entenderá melhor sobre o funcionamento do hacktoberfest e como será possível criar pull requests.
P.S. Star e compartilhe este repositório, se você se divertiu!

![Alt Text](https://raw.githubusercontent.com/lauras5/hacktoberfest/master/images/hacktoberfest2018.gif)


## Videos/Vidéos/Vídeos

- [Hacktoberfest Intro](https://youtu.be/OsAFX_ZbgaE)
- [How to pull request [Overview]](https://youtu.be/DIj2q02gvKs)
- [Merge Conflict / comment](https://youtu.be/zOx5PJTY8CI)


## 
bution rules/Règles de contribution/Regras de contribuição

```[English]```
- The project must work when opening [index.html](https://github.com/lingonsaft/hacktoberfest/blob/master/index.html).
- You are allowed to make pull requests that break the rules. We just won't merge it ;).
- Do NOT add any build steps e.g npm install (we want to keep this a simple static site).
- Do NOT remove Videos, Rules, FAQ, or any other helpful content.
- Styling/code can be pretty, ugly or stupid, big or small as long as it works.
- Add your name to the [contributors.html](https://github.com/lingonsaft/hacktoberfest/blob/master/contributors.html) file.
- Try to keep pull requests small to minimize merge conflicts.

```[Français]```
- Ce projet doit fonctionner à l'ouverture de [index.html](https://github.com/lingonsaft/hacktoberfest/blob/master/index.html)
- Vous avez le droit de soumettre des pull request qui ne respectent pas les règles, mais nous ne les intégrerons pas
- Ne PAS ajouter d'étapes supplémentaires comme npm install ( nous souhaitons que le projet reste simple)
- Ne supprimez PAS les vidéos, règles, FAQ ou autre contenu utile.
- Le style/code peut être moche, élégant, stupide, petit ou grand à condition qu'il soit fonctionnel
- Ajoutez votre nom d'utilisateur au fichier [contributors.html](https://github.com/lingonsaft/hacktoberfest/blob/master/contributors.html)
- Essayez de garder les pull request petit pour minimiser les conflits.

```[Português]```
- O projeto deve funcionar ao abrir [index.html](https://github.com/lingonsaft/hacktoberfest/blob/master/index.html)
- Você tem permissão para fazer pedidos de pull que violam as regras. Nós apenas não vamos realizar o merge ;)
- NÃO adicione nenhuma etapa de compilação, por exemplo, npm install (queremos manter um site estático simples)
- NÃO remova Vídeos, Regras, FAQ ou qualquer outro conteúdo útil.
- O estilo/código pode ser bonito, feio ou estúpido, grande ou pequeno, desde que funcione
- Adicione seu nome ao arquivo [contributors.html](https://github.com/lingonsaft/hacktoberfest/blob/master/contributors.html)
- Tente manter os pull requests pequenos para minimizar conflitos de merge

## Getting Started/Pour commencer/Começando

- Fork this repo (button on top) / Forker le repo (bouton en haut de la page) / Faça fork desse repositório (botão no topo)

![alt text](https://github.com/iyerkritika/hacktoberfest/blob/master/images/fork.png) <!--replace iyerkritika with lingonsaft-->

- Clone on your local machine / Cloner sur votre machine en local / Faça clone para sua máquina local

![alt text](https://github.com/iyerkritika/hacktoberfest/blob/master/images/clone.png) <!--replace iyerkritika with lingonsaft-->

```terminal
git clone https://github.com/<your username>/hacktoberfest.git
cd hacktoberfest
```

- Create a new branch / Créer une nouvelle branche / Crie uma nova branch

```terminal
git checkout -b my-new-branch
```

- Add your contributions / Ajouter votre contribution / Adicione sua contribuição
- Commit and push

```terminal
git add .
git commit -m "your-commit-msg"
git push origin my-new-branch
```

- Create a new pull request from your forked repository /Créer une pull request à partir de votre repo / Crie um novo pull request do  repositório que você fez fork

-------------------------

## Avoid Conflicts (Syncing your fork) /Eviter les conflits (synchroniser le fork) / Evite conflitos (sincronize seu fork)

```[English]``` An easy way to avoid conflicts is to add an 'upstream' for your git repo, as other PR's may be merged while you're working on your branch/fork.

```[French]``` Une façon simple d'éviter les conflits est d'ajouter un 'upstream' pour votre repo, vu que d'autres PR pourraient avoir été incluses pendant que vous travailliez sur la votre.

```[Português]```
Uma maneira fácil de evitar conflitos é adicionar um 'upstream' para o seu repositório git, já que outros PRs podem ser mesclados enquanto você estiver trabalhando em seu branch / fork.

```terminal
git remote add upstream https://github.com/lingonsaft/hacktoberfest
```

```[English]``` You can verify that the new remote has been added by typing.

```[French]``` Il est possible de vérifier le fonctionnement en tapant

```[Português]``` Você pode verificar que seu novo controle remoto foi adicionado digitando

```terminal
git remote -v
```

```[English]``` To pull any new changes from your parent repo simply run.

```[French]``` Pour pull les nouveaux changements, il suffit de taper

```[Português]``` Para realizar pull de quaisquer novas mudanças para seu repositório, simplesmente execute.

```terminal
git merge upstream/master
```

```[English]```
This will give you any eventual conflicts and allow you to easily solve them in your repo. It's a good idea to use it frequently in between your own commits to make sure that your repo is up to date with its parent.

For more information on syncing forks [read this article from Github](https://help.github.com/articles/syncing-a-fork/).

```[French]```
Ceci vous donnera un aperçu des conflits éventuels et vous permet de les résoudre dans votre repo. Il est de bonne pratique de le faire régulièrement entre deux commits pour s'assurer que le repo est à jour.

Pour plus d'info, [lire cet article de Github](https://help.github.com/articles/syncing-a-fork/).

```[Português]```
Isso lhe dará eventuais conflitos e permitirá que você os resolva facilmente em seu repo. É uma boa ideia usá-lo com frequência entre seus próprios commits para garantir que o repo esteja atualizado com o pai.

Para mais informações sobre a sincronização de garfos [leia este artigo do Github] (https://help.github.com/articles/syncing-a-fork/).

-------------------------

## Ideas for contributions/Idees de contributions

- Style the index.html
- Add your own projects to the 'Helpful Material Page'
- Add helpful links/guides to the 'Helpful Material Page'
- Update Readme.md

## FAQs

- Who can contribute?

  - Anyone with a github account and who is signed up for [hacktoberfest](https://hacktoberfest.digitalocean.com/) :).

- Are you getting paid for this?

  - Sadly no. But we think we should. This is 100% unofficial and we do it for fun, fame and glory.

- Who are you and why are you doing this?
  - We are two programmers from Sweden [Richard](https://github.com/richie-south)
  and [Benny](https://github.com/BennyCarlsson). We are doing this because we love Open
  Source and Hacktoberfest. We want to make it easier for people to get started with Hacktoberfest and Open Source.
- Why are you not using digitalocean?
  - Because we only know JavaScript and suck at servers. We use [now](https://zeit.co/now) instead.
- Are you not the guys from that failed [CodeCardCodingCards](https://www.kickstarter.com/projects/lingonsaft/codecardcodingcards) kickstarter?
  - Yes...
- Should I come closer to the text saying 'Don't come closer' on the left side of the home tab?
  - Nope.
- How many pull request (PR) must be made, if I can get an awesome shirt from Hacktoberfest 2018?
  - 5
- How do I track my progress to get an awesome shirt from Hacktoberfest 2018?
  - go to : [https://hacktoberfest.digitalocean.com/stats/](https://hacktoberfest.digitalocean.com/stats/) (Scroll down to Check Out Your Own Stats).
- What is the duration of Hacktoberfest 2018?
  - It is from October 1st till October 31st, 2018.
- What is the event for?
  - For the open source community engagement.

### *We will do our best to merge as much as possible from everyone. However, time is limited and the merge conflicts are horrible ❤️*

---
## [XBIZART/Communist-Kernel](https://github.com/XBIZART/Communist-Kernel)@[efd0360304...](https://github.com/XBIZART/Communist-Kernel/commit/efd03603041ece24bcdd27be929bd822641176f5)
#### Wednesday 2021-09-29 15:27:19 by Jan Alexander Steffens (heftig)

ZEN: Implement zen-tune v4.20 over v4.14-arm64

4.9:
In a surprising turn of events, while benchmarking and testing
hierarchical scheduling with BFQ + writeback throttling, it turns out
that raising the number of requests in queue _actually_ improves
responsiveness and completely eliminates the random stalls that would
normally occur without hierarchical scheduling.

To make this test more intense, I used the following test:

Rotational disk1: rsync -a /source/of/data /target/to/disk1
Rotational disk2: rsync -a /source/of/data /target/to/disk2

And periodically attempted to write super fast with:
dd if=/dev/zero of=/target/to/disk1/block bs=4096

This wrote 10gb incredibly fast to writeback and I encountered zero
stalls through this entire test of 10-15 minutes.

My suspicion is that with cgroups, BFQ is more able to properly sort
among multiple drives, reducing the chance of a starved process.  This
plus writeback throttling completely eliminate any outstanding bugs with
high writeback ratios, letting the user enjoy low latency writes
(application thinks they're already done), and super high throughput due
to batched writes in writeback.

Please note however, without the following configuration, I cannot
guarantee you will not get stalls:

CONFIG_BLK_CGROUP=y
CONFIG_CGROUP_WRITEBACK=y
CONFIG_IOSCHED_CFQ=y
CONFIG_CFQ_GROUP_IOSCHED=y
CONFIG_IOSCHED_BFQ=y
CONFIG_BFQ_GROUP_IOSCHED=y
CONFIG_DEFAULT_BFQ=y
CONFIG_SCSI_MQ_DEFAULT=n

Special thanks to h2, author of smxi and inxi, for providing evidence
that a configuration specific to Debian did not cause stalls found the
Liquorix kernels under heavy IO load.  This specific configuration
turned out to be hierarchical scheduling on CFQ (thus, BFQ as well).

4.10:
During some personal testing with the Dolphin emulator, MuQSS has
serious problems scaling its frequencies causing poor performance where
boosting the CPU frequencies would have fixed them.  Reducing the
up_threshold to 45 with MuQSS appears to fix the issue, letting the
introduction to "Star Wars: Rogue Leader" run at 100% speed versus about
80% on my test system.

Also, lets refactor the definitions and include some indentation to help
the reader discern what the scope of all the macros are.

4.11:
Increase MICRO_FREQUENCY_UP_THRESHOLD from 95 to 85
Increase MIN_FREQUENCY_UP_THRESHOLD from 11 to 6

These changes should help make using CFS feel a bit more responsive when
working with mostly idle workloads, browsing the web, scrolling through
text, etc.

Increasing the minimum frequency up threshold to 6% may be too
aggressive though.  Will revert this setting if it causes significant
battery drain.

4.12:
Make bfq the default MQ scheduler

Reduce default sampling down factor from 10 to 1

With the world eventually moving to a more laptop heavy configuration,
it's getting more important that we can reduce our frequencies quickly
after performing work.  This is normal with a ton of background
processes that need to perform burst work then sleep.

Since this doesn't really impact performance too much, lets not keep it
part of ZEN_INTERACTIVE.

Some time ago, the minimum frequency up threshold was set to 1 by
default, but the zen configuration was never updated to take advantage
of it.

Remove custom MIN_FREQUENCY_UP_THRESHOLD for MuQSS / ZEN_INTERACTIVE
configurations and make 1 the default for all choices.

4.18:
Prefer bfq-mq when available if zen interactive is enabled

The bfq-mq elevator is typically one major kernel version ahead in
optimizations and bug fixes due to early access patches in the
algodev/bfq-mq github repository.  Since these patches are typically low
risk and almost always improve performance and/or increase stability,
prefer bfq-mq over bfq when available.

Switch from MuQSS to PDS-mq.

4.19:
Switch from PDS-mq back to MuQSS

4.20:
During some experimentation to influence MuQSS into consolidating strong
single threaded workloads to single cores, I found that the up_threshold
just ends up forcing all cores to run at a higher frequency.

Instead, raising up_threshold back to defaults (95 with micro sampling),
and raising the sampling down factor to 5, the individual cores MuQSS
selects (typically the first few), tend to properly stick to their max
speed and because they complete their tasks faster, MuQSS selects them
again to for the earliest eligible deadline, causing a reciprocal cycle
that improves single thread performance.

Completely fair scheduler (CFS), never really had this issue, but we'll
leave sampling down factor high with CONFIG_ZEN_INTERACTIVE since it'll
benefit CFS users that want higher performance anyway.

Raise minimum CFS latency to 4ms to match 250hz configs.
Raise minimum MuQSS latency to 4ms to match 250hz configs.

Use [defer+madvise] as default khugepaged defrag strategy:

For some reason, the default strategy to respond to THP fault fallbacks
is still just madvise, meaning stall if the program wants transparent
hugepages, but don't trigger a background reclaim / compaction if THP
begins to fail allocations.  This creates a snowball affect where we
still use the THP code paths, but we almost always fail once a system
has been active and busy for a while.

The option "defer" was created for interactive systems where THP can
still improve performance.  If we have to fallback to a regular page due
to an allocation failure or anything else, we will trigger a background
reclaim and compaction so future THP attempts succeed and previous
attempts eventually have their smaller pages combined without stalling
running applications.

We still want madvise to stall applications that explicitely want THP,
so defer+madvise _does_ make a ton of sense.  Make it the default for
interactive systems, especially if the kernel maintainer left
transparent hugepages on "always".

Reasoning and details in the original patch: https://lwn.net/Articles/711248/

Add a scheduler even to multi-queue block devices:
We prefer interactivity to throughput and want BFQ if possible.

Signed-off-by: Albert I <kras@raphielgang.org>
Signed-off-by: Udit Karode <udit.karode@gmail.com>

---
## [spnda/VSC-NML](https://github.com/spnda/VSC-NML)@[fd3188e940...](https://github.com/spnda/VSC-NML/commit/fd3188e940155530d5f4cf1a6f85f3d07a0d09b2)
#### Wednesday 2021-09-29 15:39:16 by sean

Holy fucking shit... I didn't want this to run every minute

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[8046767825...](https://github.com/mrakgr/The-Spiral-Language/commit/8046767825397ba1a1b423aab9498b29e60aab7f)
#### Wednesday 2021-09-29 17:03:00 by Marko Grdinić

"1:10pm. I spent like 3 hours writing the above. I guess I won't be writing Simulacrum after all.

Let me have breakfast here.

2pm. Actually, I won't paste the reply I got from Z because I do not want others to see the rate he quoted me, but not only does he want to work, but the rate he quoted me is high enough to move me. I had not gotten an actual offer yet, but as logistical problems in hiring me through Columbia are unlikely, and he himself seems willing to give me a trial I'll proceed with the assumption that I will get to work with him. As far as I am concerned the job hunt is over.

Phew. Forget writing, I'll get back to Simulacrum in the future. It is time to get serious. Let me put the reply I wrote through the Google Docs. After that, I'll start looking up some of the links he gave me.

I do not know when he will get back to me, but for the next month, I will be doing some serious studying. Zenna is right now at the very top of the list of people I need to please. I won't spare the effort in doing that.

2:40pm. He asked me for my background and I gave him 5 pages. Hope that is not too much. At any rate, I've replied and am done with that.

Let me bring in the links.

> Regarding resources, if you feel comfortable with the fundamentals of Julia, here are a few are some more advanced topics:

> Information on Julia's IR - https://docs.julialang.org/en/v1/devdocs/ssair/
> Nonstandard / contextual execution - https://github.com/JuliaLabs/Cassette.jl
> Tutorial on Type inference through abstract interpretation -  https://aviatesk.github.io/posts/data-flow-problem/
> Partial Evaluation and Abstract Interpretation (Mjolnir) - https://mikeinnes.github.io/2020/07/29/mjolnir.html

Also...

> I've actually started rewriting Omega to address some of the design issues.  Most of the new work is happening at https://github.com/zenna/Omega.jl/tree/lang

This is what I need to focus on. I'll go through it all in top down order.

3pm. Today I am a bit off my game, but it is no wonder. All the whiplash is doing this for me. It will take me some time to accelerate.

> - Project wise, I think I'd like you to either work on parametric inversion or infrastructure around Omega.

Ok, I've gone through the Julia IR page. I am probably not going to be working with this directly, but it is not like I haven't studied .NET IL or Assembly, so getting familiar with this is no problem. I'll take a look at a few tutorials on SSA to get familiar with the lingo. I expect that what Spiral is doing to be quite close to SSA.

> Nonstandard / contextual execution - https://github.com/JuliaLabs/Cassette.jl

Let me take a look at this next.

https://julia.mit.edu/Cassette.jl/latest/disclaimers.html

> Cassette can be a powerful tool for extending the Julia language, but it functions equally well as a loaded foot-gun. Here are some things one should know before using Cassette:

> Cassette, its API, and its documentation targets Julia package developers and/or those interested in doing compiler research using Julia. Cassette users are expected to have a working understanding of Julia's compiler, type system and metaprogramming facilities.

> Practical usage of Cassette will quite likely reveal both performance and correctness bugs caused by either Cassette or Julia itself (especially in this early stage of development). This is especially likely when doing nested overdubbing, or composing multiple Cassette contexts. Please file issues on the Cassette and/or Julia issue tracker where appropriate.

> The performance of Cassette's implementation of the contextual tagging system heavily depends on compiler improvements planned for the Julia 1.x release cycle. In theory, given these compiler improvements, the contextual tagging system could achieve performance comparable to alternatives (e.g. ForwardDiff's dual number implementation), but for now, the contextual tagging system is quite slow and allocation-heavy.

> Cassette enables interaction with many parts of the Julia compiler, a lot of which are undocumented or sparsely documented. It is extremely easy to accidentally implement a pass that breaks internal compiler assumptions in some subtle way. If (and when) you run into these scenarios, it would be helpful to open an issue on the Julia issue tracker proposing better documentation (or even a stable API) for a specific part of the compiler.

This seems like it will be fun to use. This is the kind of thing you want to go forward with recklessly and get familiar as you use it. If he really wants me to use this, I guess I'll be getting familiar with parts of the Julia compiler as a result.

3:35pm. The last point has links to some issues so I won't link to them lest this Spiral commit get referenced in them. I've gone over them to get a glimpse of what the problem is.

Let me go through the Cassette docs.

https://julia.mit.edu/Cassette.jl/latest/whycassette.html

> Cassette was originally motivated by the need for better language-level support for automatic differentiation, where the data structure used to accumulate program traces is often called a "tape" (since, of course, program traces really were stored on magnetic tapes back in the day).

Interesting.

Hmmm, so...this might be an alternative to the macro based approach that Turing, Suss and Gen take?

I am guessing this would give the benefits of having effect handlers in the language.

Let me start the Julia REPL.

4:10pm. https://julia.mit.edu/Cassette.jl/latest/contextualdispatch.html#Contextual-Dispatch-1

This is not too complicated.

If it just allows taking extra arguments then...

Well, then I suppose it would be possible to use to do the CPS transformation. After you have than, you have everything effect handlers have to offer. It is a cheapo monadic system for a language with dynamic types.

...No actually wait. While it is true that this might be able to add an extra argument to overcall, the CPS transform requires more than that. Based on what I've seen so far there is not enough here yet.

4:55pm.

```jl
using Cassette

Cassette.@context TraceCtx

mutable struct Trace
    current::Vector{Any}
    stack::Vector{Any}
    Trace() = new(Any[], Any[])
end

function enter!(t::Trace, args...)
    pair = args => Any[]
    push!(t.current, pair)
    push!(t.stack, t.current)
    t.current = pair.second
    return nothing
end

function exit!(t::Trace)
    t.current = pop!(t.stack)
    return nothing
end

Cassette.prehook(ctx::TraceCtx, args...) = enter!(ctx.metadata, args...)
Cassette.posthook(ctx::TraceCtx, args...) = exit!(ctx.metadata)

trace = Trace()
x, y, z = rand(3)
f(x, y, z) = x*y + y*z
Cassette.overdub(TraceCtx(metadata = trace), () -> f(x, y, z))

# returns `true`
trace.current == Any[
    (f,x,y,z) => Any[
        (*,x,y) => Any[(Base.mul_float,x,y)=>Any[]]
        (*,y,z) => Any[(Base.mul_float,y,z)=>Any[]]
        (+,x*y,y*z) => Any[(Base.add_float,x*y,y*z)=>Any[]]
    ]
]
```

Even considering the later example, I am not sure this way of implementing a stack is the simplest possible one. Nevermind that for now.

https://julia.mit.edu/Cassette.jl/latest/contextualpass.html

Let me focus on this for a bit.

> Some use cases, however, require the ability to access and/or alter properties of the execution trace that just can't be reached via simple method overloading, like control flow or the surrounding scope of a method call. In these cases, you probably do want to manually implement a compiler pass!

> To facilitate these use cases, Cassette allows users to write and inject their own arbitrary post-lowering, pre-inference compiler passes as part of the overdubbing process.

I am guessing this chapter will explain how to do a CPS transform.

5:55pm. Done with lunch.

https://gist.github.com/jrevels/64b03faabeca2985a1430375e91bf7e2

This is a bit much for me at the moment. I have a lot of programming experience, but macro slinging is something I am weak at.

6:05pm. https://julia.mit.edu/Cassette.jl/latest/contextualpass.html

Let me stop this in the middle. I am getting tired and losing focus. Let me just take a look at the other links.

6:35pm. Ok, I've gone over the rest. I'll study it more in depth tomorrow. I definitely should internalize how Julia's type inference algorithm works, but I'll leave that for later.

I know how I would do it in Spiral, but Julia presents some unique challenges to making a PPL.

1) I need to decide exactly what sort of addressing scheme would work best. I have a bunch of ideas, but I haven't really settled on what is the best.

2) More importantly, I still do not know how to implement the `sample` and `observe` statements in a way that would be ergonomic in Julia. Maybe Cassette will offer something in that domain. Otherwise I'll have to take the Soss approach to using macros.

Turing is just so bad in its coding style, Gen is huge, Soss is small and nible the best of all, but ideally I'd want to get familiar with all 3 of them, since this area will become a part of my expertise. Previously, wading through the macro jungle of Turing would be too much, but now things are different.

6:45pm. Zenna is pretty smart to stick the actual rate in his reply. If he hadn't done that one line, I would have spent my day writing Simulacrum instead. I don't really suspect that he is just stringing me along, even if he did, he would not gain anything from tricking me into doing these studies here. If that happens I'll be a bit richer in PPL experience which will be useful in the future, Simulacrum will be delayed, but that is about it.

Since this will be contract work, maybe I won't end up working 52 weeks per year. That will give me time to write. If I do end up working all the time for a few years, that would be great too. It won't take me too long to save up for retirement, especially given my trading skills. It really does feel like my life is getting back on track. Acquiring these programming skills was a big investment and risk, so I'll (most likely) get my proper reward.

6:50pm. Right now, I am tired. It is time to close for the day here. I'll properly master all the advanced aspect of Julia, look into Omega's dev branch and the rival PPLs, and start work on my own prototype PPL while I wait for the next step."

---
## [Khan/genqlient](https://github.com/Khan/genqlient)@[f4c981031e...](https://github.com/Khan/genqlient/commit/f4c981031e286a75b33b4d7b94884d1e7bc486c7)
#### Wednesday 2021-09-29 17:30:46 by Ben Kraft

Allow genqlient types to be marshaled safely (#120)

## Summary:
When genqlient generates output types, it generates whatever code is
necessary to unmarshal them.  Conversely, when it generates input types,
it generates whatever code is necessary to marshal.  This is all that's
needed for genqlient itself: it never needs to marshal output types or
unmarshal input types.

But maybe you do!  (For example, to put the responses in a cache, which
is the use case that @csilvers hit at Khan, although there are others
one can imagine.)  While we can't support every serialization format you
might want (at least not without adding plugins or some such), it's not
unreasonable to expect that since genqlient can read JSON, it can write
it too.  Sadly, in the past this was not true for types requiring custom
unmarshaling logic, for several reasons.

In this commit I implement logic to always write both marshalers and
unmarshalers whenever they're needed to be able to correctly round-trip
the types, even though genqlient doesn't do so.  I wasn't starting from
scratch, since of course we already write both marshalers and
unmarshalers in some cases.  But this ended up requiring surprisingly
large changes on the marshaling side, mostly to correctly support
embedding (which we use for named fragments).

Specifically, as the comments in `types.go` discuss, the most difficult
issue is spreads with duplicate fields, which translate to Go embedded
fields which end up hidden from the json-marshaler.  Ultimately, I had
to do things quite differently from unmarshaling, and essentially
flatten the type when we write marshaler.  But in the end it's not so
ugly -- indeed arguably it's cleaner!  Mainly it's just different.

One thing to note is that we do marshal `__typename` based on
what we know about the types; users need not fill it in (and if they
do we'll ignore it).  This seemed to me to be a better UX, and
didn't add much complexity.

In general, I begin to wonder whether using `encoding/json` at all is
really right for genqlient: we're doing a lot of work to appease it,
despite knowing what our types look like.  I think it would still be a
significant increase in lines of code to roll our own, but that code
would perhaps be simpler, and would surely be faster (although if we
just want the speed gains we could use another JSON-generator library,
see also #47).  Anyway, something to think about in the future.

## Test plan:
make tesc


Author: benjaminjkraft

Reviewers: csilvers, StevenACoffman, benjaminjkraft, dnerdy, aberkan, jvoll, mahtabsabet, MiguelCastillo

Required Reviewers: 

Approved By: StevenACoffman, dnerdy

Checks: ✅ Test (1.17), ✅ Test (1.16), ✅ Test (1.15), ✅ Test (1.14), ✅ Lint, ✅ Test (1.17), ✅ Test (1.16), ✅ Test (1.15), ✅ Test (1.14), ✅ Lint

Pull Request URL: https://github.com/Khan/genqlient/pull/120

---
## [xarion/EPM](https://github.com/xarion/EPM)@[a0cad4d993...](https://github.com/xarion/EPM/commit/a0cad4d9931eb7f37b1b748afed41cd8fa60058d)
#### Wednesday 2021-09-29 18:03:47 by xarion

major revision, removed lots of tensorflow stuff and moved to pytorch. i'm sorry but fuck you tensorflow for creating a very unsustainable environment for opensource contributors.

---
## [Auralcat/my-dotfiles](https://github.com/Auralcat/my-dotfiles)@[43e1673b0b...](https://github.com/Auralcat/my-dotfiles/commit/43e1673b0b047a63499c63102e7d491e035a6c17)
#### Wednesday 2021-09-29 18:22:44 by Miriam Retka

Don't auto-save files in text-mode derivatives

It's annoying to have Emacs auto-save Org-like files and clean out all
the whitespace and move my cursor when I'm in the middle of formulating
my thoughts and thinking without typing at the buffer.

We could also put a condition on the function to clear the whitespace to
skip running when auto-saving, but I think this is much easier, since I
have Git and version my Org files. There's also the local Emacs backups
in case something bad happens.

---
## [folio-org/stripes-core](https://github.com/folio-org/stripes-core)@[985178e1a0...](https://github.com/folio-org/stripes-core/commit/985178e1a009685230da588ca21370b3a5f1ae89)
#### Wednesday 2021-09-29 18:30:45 by Zak Burke

STCOR-558 replace babel-eslint with @babel/eslint-parser (#1105)

Glory
Glory
This is not another Jira
This is not another Slack
I refuse to push another PR now, never staying down
This is something REAL
It's a PR that you'll remember
It's a PR dressed to kill
Yeah it's gonna be the greatest PR now, watch out
It's a code change you can feel
And it goes something like

Oooooh, I am linting this code
Oooooh, I changed nothing
Oooooh, there's no stopping this
'Cause I was born for this
I lint code for the glory
I lint code for the GLORY

I choose red pills just like Neo
I'll be written in the sky
I will never be too afraid to click, typing fast, it's sick.
Even in vi
Oh, I started as pixel
Flashing on a CRT
Aw crap I am still a pixel
But at least now there's LCDs

And I say something like
Oooooh, I am linting this code
Oooooh, lint runs clean
Oooooh there's no stopping this
'Cause I was born for this
I lint code for the glory
I lint code for the GLORY

Refs STCOR-558, STRIPES-742

---
## [Panchajanya1999/msm-4.14](https://github.com/Panchajanya1999/msm-4.14)@[91beebc42a...](https://github.com/Panchajanya1999/msm-4.14/commit/91beebc42a0f37242c75dc208cf752243f7b9d67)
#### Wednesday 2021-09-29 18:43:39 by George Spelvin

lib/sort: make swap functions more generic

Patch series "lib/sort & lib/list_sort: faster and smaller", v2.

Because CONFIG_RETPOLINE has made indirect calls much more expensive, I
thought I'd try to reduce the number made by the library sort functions.

The first three patches apply to lib/sort.c.

Patch #1 is a simple optimization.  The built-in swap has special cases
for aligned 4- and 8-byte objects.  But those are almost never used;
most calls to sort() work on larger structures, which fall back to the
byte-at-a-time loop.  This generalizes them to aligned *multiples* of 4
and 8 bytes.  (If nothing else, it saves an awful lot of energy by not
thrashing the store buffers as much.)

Patch #2 grabs a juicy piece of low-hanging fruit.  I agree that nice
simple solid heapsort is preferable to more complex algorithms (sorry,
Andrey), but it's possible to implement heapsort with far fewer
comparisons (50% asymptotically, 25-40% reduction for realistic sizes)
than the way it's been done up to now.  And with some care, the code
ends up smaller, as well.  This is the "big win" patch.

Patch #3 adds the same sort of indirect call bypass that has been added
to the net code of late.  The great majority of the callers use the
builtin swap functions, so replace the indirect call to sort_func with a
(highly preditable) series of if() statements.  Rather surprisingly,
this decreased code size, as the swap functions were inlined and their
prologue & epilogue code eliminated.

lib/list_sort.c is a bit trickier, as merge sort is already close to
optimal, and we don't want to introduce triumphs of theory over
practicality like the Ford-Johnson merge-insertion sort.

Patch #4, without changing the algorithm, chops 32% off the code size
and removes the part[MAX_LIST_LENGTH+1] pointer array (and the
corresponding upper limit on efficiently sortable input size).

Patch #5 improves the algorithm.  The previous code is already optimal
for power-of-two (or slightly smaller) size inputs, but when the input
size is just over a power of 2, there's a very unbalanced final merge.

There are, in the literature, several algorithms which solve this, but
they all depend on the "breadth-first" merge order which was replaced by
commit 835cc0c8477f with a more cache-friendly "depth-first" order.
Some hard thinking came up with a depth-first algorithm which defers
merges as little as possible while avoiding bad merges.  This saves
0.2*n compares, averaged over all sizes.

The code size increase is minimal (64 bytes on x86-64, reducing the net
savings to 26%), but the comments expanded significantly to document the
clever algorithm.

TESTING NOTES: I have some ugly user-space benchmarking code which I
used for testing before moving this code into the kernel.  Shout if you
want a copy.

I'm running this code right now, with CONFIG_TEST_SORT and
CONFIG_TEST_LIST_SORT, but I confess I haven't rebooted since the last
round of minor edits to quell checkpatch.  I figure there will be at
least one round of comments and final testing.

This patch (of 5):

Rather than having special-case swap functions for 4- and 8-byte
objects, special-case aligned multiples of 4 or 8 bytes.  This speeds up
most users of sort() by avoiding fallback to the byte copy loop.

Despite what ca96ab859ab4 ("lib/sort: Add 64 bit swap function") claims,
very few users of sort() sort pointers (or pointer-sized objects); most
sort structures containing at least two words.  (E.g.
drivers/acpi/fan.c:acpi_fan_get_fps() sorts an array of 40-byte struct
acpi_fan_fps.)

The functions also got renamed to reflect the fact that they support
multiple words.  In the great tradition of bikeshedding, the names were
by far the most contentious issue during review of this patch series.

x86-64 code size 872 -> 886 bytes (+14)

With feedback from Andy Shevchenko, Rasmus Villemoes and Geert
Uytterhoeven.

Link: http://lkml.kernel.org/r/f24f932df3a7fa1973c1084154f1cea596bcf341.1552704200.git.lkml@sdf.org
Signed-off-by: George Spelvin <lkml@sdf.org>
Acked-by: Andrey Abramov <st5pub@yandex.ru>
Acked-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Reviewed-by: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
Cc: Geert Uytterhoeven <geert@linux-m68k.org>
Cc: Daniel Wagner <daniel.wagner@siemens.com>
Cc: Don Mullis <don.mullis@gmail.com>
Cc: Dave Chinner <dchinner@redhat.com>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Yousef Algadri <yusufgadrie@gmail.com>
Signed-off-by: Panchajanya1999 <panchajanya@azure-dev.live>

---
## [loafoflead/eensy-weensy-SDL2](https://github.com/loafoflead/eensy-weensy-SDL2)@[148764e1ed...](https://github.com/loafoflead/eensy-weensy-SDL2/commit/148764e1edcbea1e0a911abf1696070d3cee30c6)
#### Wednesday 2021-09-29 19:15:00 by loafoflead

spent days trying to fix a segfault 1/5 of all runs when loading entities. (images). turns out placing pngs in a seperate folder and trying to load them from the working directory results in a segfault and memory buffer error once every 5 runs. sick. anyway it forced me to do some much needed refactoring, entity now contains a hitbox seperate from what is drawn, althout i removed some maybe important things ive now forgotten about. i also moved the Entity into a seperate folder, bc it has nothing to do with the renderwrap??? wat was i thinkingsdjkhg anyway i need to re-do a bunch of code in the actual program folder and uncomment some shit in the entity dreeing funcs. c ya

---
## [infinitephantasm/VSH-Rewrite](https://github.com/infinitephantasm/VSH-Rewrite)@[10c983c6ab...](https://github.com/infinitephantasm/VSH-Rewrite/commit/10c983c6ab155900312d4420313aa07b8a0f0e1c)
#### Wednesday 2021-09-29 19:24:12 by infinite phantasm

Turn the Shortstop into a Pocket Rocket

this PR turns the Shortstop from an ordinary bullet firing gun into a tiny rocket launcher, with the same 'crit on aim' mechanic that all Soldier rocket launchers have, while being notably weaker in damage and slower firing than most Scout primaries to balance it out.

the following attributes are used to make this work:

- 280/override projectile type set to 2 - this changes the projectile type from a bullet, into a rocket.

- 2/damage bonus set to 400% - despite the weapon being weaker, i actually had to buff up the damage a bit to make it work. otherwise this thing does only like 15 damage a shot. generally it does around ~50 uncritted, and 144 critted.

- 103/Projectile speed increased set to 33% - makes it similar to the liberty launcher, but a bit more speedy, 25% vs. 33%.

- 5/fire rate penalty set to -50% - lowers the fire rate to make it slightly closer to rocket launcher firing speeds, but slightly above.

i thought it'd be neat to let Scout have a unique weapon with a firing projectile instead of bullets. something that can be alongside a Soldier, but not quite as powerful as one. and no, you can't really rocket jump with this. i tried it a few times and it doesn't really work. so it shouldn't make Scout more annoying to fight, escaping-wise when he has this out. i'm willing to change some of these values to lower ones or add additional 'negative' attributes to compensate, as i know something like this hasn't really been implemented in any way in VSH Rewrite before. because of that, please fucking tell me if some of this shit won't work or is broken

[a visual example of how this would look is available here.](https://streamable.com/cckfuo)

---
## [Perkedel/Kaded-fnf-mods](https://github.com/Perkedel/Kaded-fnf-mods)@[57133b789d...](https://github.com/Perkedel/Kaded-fnf-mods/commit/57133b789d921fc3082593b83a43ccc14e8826c4)
#### Wednesday 2021-09-29 20:35:55 by Joel Robert Justiawan

[skip ci] oh no somebody screwed up

attempt to block specific codebase for platform that doesn't support it. yeah, Lua things, yess.

okeh that's all complete screwup. the Audio system 1.7 using advanced OpenAL manipulation seems not compatible with HTML5 unfortunately. look, the web version of kade engine stuck at 1.6 someting-something.

install `Last Funkin Moment` replacement against `Friday Night Funkin` pop cooltext. the one that appears right before the flash title screen press enter one. yess.

https://github.com/KadeDev/Kade-Engine/issues/2375 oh no. the https://github.com/nebulazorua/linc_luajit/commit/e01b100a1a41ec303c792177cc146ddd9b53fa2d breaks everything! `error` identifier not found. Yeah, the xml file. those capitalization, one mistake screws it up!

Pipis is Egg, not to be confused with Urine loll! Pipi is also salt water clam (as Australian Contintent language said so) OMG, as an Indonesian, hearing `Pipis` made me laugh so hard and wtf man!! wkwkwkwkwkwkwkwkwkwkwk. it's also Bepis resemblance. Toby Fox, what do you think?

---
## [NameMCPlus/NameMCplus](https://github.com/NameMCPlus/NameMCplus)@[750bdb0a08...](https://github.com/NameMCPlus/NameMCplus/commit/750bdb0a081874bf449d61610425b5cd2590ec77)
#### Wednesday 2021-09-29 20:47:36 by Orius

Added "Tester" menu option to NameMC

That's right Faav I'm not gonna just redirect to mcuserna.me hahahaha fuck youuuu

---
## [ishtiakae/we-do-copy](https://github.com/ishtiakae/we-do-copy)@[be7681c6db...](https://github.com/ishtiakae/we-do-copy/commit/be7681c6db410cbbea1f0c847da49c6dc417fbc5)
#### Wednesday 2021-09-29 22:02:53 by Ishtiak Ahmed

added fucking 25000++ sqkm

fuck you saif
i told to resign

---

# [<](2021-09-28.md) 2021-09-29 [>](2021-09-30.md)

