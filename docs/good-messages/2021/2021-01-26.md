# [<](2021-01-25.md) 2021-01-26 [>](2021-01-27.md)

2,938,342 events, 1,495,432 push events, 2,411,818 commit messages, 186,644,619 characters


## [maborak/iemaddon-installer](https://github.com/maborak/iemaddon-installer)@[a6963d366b...](https://github.com/maborak/iemaddon-installer/commit/a6963d366bfb33d1b59063efecfa89d079a2d6b0)
#### Tuesday 2021-01-26 01:00:23 by Wilmer Adalid (Alienware)

Updates for: love, v.:
	I'll let you play with my life if you'll let me play with yours.

---
## [ccodwg/Covid19Canada](https://github.com/ccodwg/Covid19Canada)@[8ae0beb7a7...](https://github.com/ccodwg/Covid19Canada/commit/8ae0beb7a7277b2fc3534fcd861d9df03573d0f6)
#### Tuesday 2021-01-26 03:06:15 by Jean-Paul R. Soucy

New data: 2021-01-25: DATA ARE CHANGING. SEE NOTES.

Imminent upcoming changes:

2021-01-25: Due to the limit on file sizes in GitHub, we will implementing changes to the dataset on Wednesday, January 27, 2021, mostly impacting individual-level data (cases and mortality). Changes below:

1) Individual-level data (cases.csv and mortality.csv) will be moved to a new directory in the root directory entitled “individual_level”. These files will be split by calendar year and named as follows: cases_2020.csv, cases_2021.csv, mortality_2020.csv, mortality_2021.csv. The directories “other/cases_extra” and “other/mortality_extra” will also be moved into the “individual_level” directory.
2) Redundant datasets will be removed from the root directory. These files include: recovered_cumulative.csv, testing_cumulative.csv, vaccine_administration_cumulative.csv, vaccine_distribution_cumulative.csv, vaccine_completion_cumulative.csv. All of these datasets are currently available as time series in the directory “timeseries_prov”.
3) The file codebook.csv will be moved to the directory “other”.

We appreciate your patience and hope these changes cause minimal disruption. We do not anticipate making any other large scale updates to the datasets in the near future. If you have any further questions, please open an issue on GitHub or reach out to us by email at ccodwg [at] gmail [dot] com. Thank you for using the COVID-19 Canada Open Data Working Group datasets.

Vaccine datasets:

- 2021-01-19: Fully vaccinated data have been added (vaccine_completion_cumulative.csv, timeseries_prov/vaccine_completion_timeseries_prov.csv, timeseries_canada/vaccine_completion_timeseries_canada.csv). Note that this value is not currently reported by all provinces (some provinces have all 0s).
- 2021-01-11: Our Ontario vaccine dataset has changed. Previously, we used two datasets: the MoH Daily Situation Report (https://www.oha.com/news/updates-on-the-novel-coronavirus), which is released weekdays in the evenings, and the “COVID-19 Vaccine Data in Ontario” dataset (https://data.ontario.ca/dataset/covid-19-vaccine-data-in-ontario), which is released every day in the mornings. Because the Daily Situation Report is released later in the day, it has more up-to-date numbers. However, since it is not available on weekends, this leads to an artificial “dip” in numbers on Saturday and “jump” on Monday due to the transition between data sources. We will now exclusively use the daily “COVID-19 Vaccine Data in Ontario” dataset. Although our numbers will be slightly less timely, the daily values will be consistent. We have replaced our historical dataset with “COVID-19 Vaccine Data in Ontario” as far back as they are available.
- 2020-12-17: Vaccination data have been added as time series in timeseries_prov and timeseries_hr.
- 2020-12-15: We have added two vaccine datasets to the repository, vaccine_administration_cumulative.csv and vaccine_distribution_cumulative.csv. These data should be considered preliminary and are subject to change and revision. The format of these new datasets may also change at any time as the data situation evolves.

Recent changes:

- 2021-01-24: The columns "additional_info" and "additional_source" in cases.csv and mortality.csv have been abbreviated similar to "case_source" and "death_source". See note in README.md from 2021-11-27 and 2021-01-08.

Revise historical data: cases (AB, BC, MB, ON, SK).

Note: AB has a spike in cases today: 409 historical cases from Dec 7 to Jan 13 were added today. These were positive rapid diagnostic tests that due to a "system error" were never added to the totals. So the number for the past 24 hours is 362, but the total for the day will be 742, since these cases cannot be assigned to a specific date. (Although 362 + 409 != 742, but these are the numbers they gave) Regardless, our numbers match cumulative health region totals for the province for today.

Note regarding deaths added in QC today: “The data also report 43 new deaths, for a total of 9,521 deaths. Among these 43 deaths, 12 have occurred in the last 24 hours and 31 have occurred between January 18 and January 23.” We report deaths such that our cumulative regional totals match today’s values. This sometimes results in extra deaths with today’s date when older deaths are removed.

https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/#c47900

Note about SK data: As of 2020-12-14, we are providing a daily version of the official SK dataset that is compatible with the rest of our dataset in the folder official_datasets/sk. See below for information about our regular updates.

SK transitioned to reporting according to a new, expanded set of health regions on 2020-09-14. Unfortunately, the new health regions do not correspond exactly to the old health regions. Additionally, the provided case time series using the new boundaries do not exist for dates earlier than August 4, making providing a time series using the new boundaries impossible.

For now, we are adding new cases according to the list of new cases given in the “highlights” section of the SK government website (https://dashboard.saskatchewan.ca/health-wellness/covid-19/cases). These new cases are roughly grouped according to the old boundaries. However, health region totals were redistributed when the new boundaries were instituted on 2020-09-14, so while our daily case numbers match the numbers given in this section, our cumulative totals do not. We have reached out to the SK government to determine how this issue can be resolved. We will rectify our SK health region time series as soon it becomes possible to do so.

---
## [gitster/git](https://github.com/gitster/git)@[2f4ba2a867...](https://github.com/gitster/git/commit/2f4ba2a867f0390f139b622dbafcab766cb88e80)
#### Tuesday 2021-01-26 05:58:45 by Taylor Blau

packfile: prepare for the existence of '*.rev' files

Specify the format of the on-disk reverse index 'pack-*.rev' file, as
well as prepare the code for the existence of such files.

The reverse index maps from pack relative positions (i.e., an index into
the array of object which is sorted by their offsets within the
packfile) to their position within the 'pack-*.idx' file. Today, this is
done by building up a list of (off_t, uint32_t) tuples for each object
(the off_t corresponding to that object's offset, and the uint32_t
corresponding to its position in the index). To convert between pack and
index position quickly, this array of tuples is radix sorted based on
its offset.

This has two major drawbacks:

First, the in-memory cost scales linearly with the number of objects in
a pack.  Each 'struct revindex_entry' is sizeof(off_t) +
sizeof(uint32_t) + padding bytes for a total of 16.

To observe this, force Git to load the reverse index by, for e.g.,
running 'git cat-file --batch-check="%(objectsize:disk)"'. When asking
for a single object in a fresh clone of the kernel, Git needs to
allocate 120+ MB of memory in order to hold the reverse index in memory.

Second, the cost to sort also scales with the size of the pack.
Luckily, this is a linear function since 'load_pack_revindex()' uses a
radix sort, but this cost still must be paid once per pack per process.

As an example, it takes ~60x longer to print the _size_ of an object as
it does to print that entire object's _contents_:

  Benchmark #1: git.compile cat-file --batch <obj
    Time (mean ± σ):       3.4 ms ±   0.1 ms    [User: 3.3 ms, System: 2.1 ms]
    Range (min … max):     3.2 ms …   3.7 ms    726 runs

  Benchmark #2: git.compile cat-file --batch-check="%(objectsize:disk)" <obj
    Time (mean ± σ):     210.3 ms ±   8.9 ms    [User: 188.2 ms, System: 23.2 ms]
    Range (min … max):   193.7 ms … 224.4 ms    13 runs

Instead, avoid computing and sorting the revindex once per process by
writing it to a file when the pack itself is generated.

The format is relatively straightforward. It contains an array of
uint32_t's, the length of which is equal to the number of objects in the
pack.  The ith entry in this table contains the index position of the
ith object in the pack, where "ith object in the pack" is determined by
pack offset.

One thing that the on-disk format does _not_ contain is the full (up to)
eight-byte offset corresponding to each object. This is something that
the in-memory revindex contains (it stores an off_t in 'struct
revindex_entry' along with the same uint32_t that the on-disk format
has). Omit it in the on-disk format, since knowing the index position
for some object is sufficient to get a constant-time lookup in the
pack-*.idx file to ask for an object's offset within the pack.

This trades off between the on-disk size of the 'pack-*.rev' file for
runtime to chase down the offset for some object. Even though the lookup
is constant time, the constant is heavier, since it can potentially
involve two pointer walks in v2 indexes (one to access the 4-byte offset
table, and potentially a second to access the double wide offset table).

Consider trying to map an object's pack offset to a relative position
within that pack. In a cold-cache scenario, more page faults occur while
switching between binary searching through the reverse index and
searching through the *.idx file for an object's offset. Sure enough,
with a cold cache (writing '3' into '/proc/sys/vm/drop_caches' after
'sync'ing), printing out the entire object's contents is still
marginally faster than printing its size:

  Benchmark #1: git.compile cat-file --batch-check="%(objectsize:disk)" <obj >/dev/null
    Time (mean ± σ):      22.6 ms ±   0.5 ms    [User: 2.4 ms, System: 7.9 ms]
    Range (min … max):    21.4 ms …  23.5 ms    41 runs

  Benchmark #2: git.compile cat-file --batch <obj >/dev/null
    Time (mean ± σ):      17.2 ms ±   0.7 ms    [User: 2.8 ms, System: 5.5 ms]
    Range (min … max):    15.6 ms …  18.2 ms    45 runs

(Numbers taken in the kernel after cheating and using the next patch to
generate a reverse index). There are a couple of approaches to improve
cold cache performance not pursued here:

  - We could include the object offsets in the reverse index format.
    Predictably, this does result in fewer page faults, but it triples
    the size of the file, while simultaneously duplicating a ton of data
    already available in the .idx file. (This was the original way I
    implemented the format, and it did show
    `--batch-check='%(objectsize:disk)'` winning out against `--batch`.)

    On the other hand, this increase in size also results in a large
    block-cache footprint, which could potentially hurt other workloads.

  - We could store the mapping from pack to index position in more
    cache-friendly way, like constructing a binary search tree from the
    table and writing the values in breadth-first order. This would
    result in much better locality, but the price you pay is trading
    O(1) lookup in 'pack_pos_to_index()' for an O(log n) one (since you
    can no longer directly index the table).

So, neither of these approaches are taken here. (Thankfully, the format
is versioned, so we are free to pursue these in the future.) But, cold
cache performance likely isn't interesting outside of one-off cases like
asking for the size of an object directly. In real-world usage, Git is
often performing many operations in the revindex (i.e., asking about
many objects rather than a single one).

The trade-off is worth it, since we will avoid the vast majority of the
cost of generating the revindex that the extra pointer chase will look
like noise in the following patch's benchmarks.

This patch describes the format and prepares callers (like in
pack-revindex.c) to be able to read *.rev files once they exist. An
implementation of the writer will appear in the next patch, and callers
will gradually begin to start using the writer in the patches that
follow after that.

Signed-off-by: Taylor Blau <me@ttaylorr.com>
Signed-off-by: Junio C Hamano <gitster@pobox.com>

---
## [acbahr/Codewars](https://github.com/acbahr/Codewars)@[878259dbb8...](https://github.com/acbahr/Codewars/commit/878259dbb8f6733653d94b4facc571f31c70c149)
#### Tuesday 2021-01-26 06:22:27 by acbahr

Create Fibonacci, Tribonacci and Friends

If you have completed the Tribonacci sequence kata, you would know by now that mister Fibonacci has at least a bigger brother. If not, give it a quick look to get how things work.

Well, time to expand the family a little more: think of a Quadribonacci starting with a signature of 4 elements and each following element is the sum of the 4 previous, a Pentabonacci (well Cinquebonacci would probably sound a bit more italian, but it would also sound really awful) with a signature of 5 elements and each following element is the sum of the 5 previous, and so on.

Well, guess what? You have to build a Xbonacci function that takes a signature of X elements - and remember each next element is the sum of the last X elements - and returns the first n elements of the so seeded sequence.

xbonacci {1,1,1,1} 10 = {1,1,1,1,4,7,13,25,49,94}
xbonacci {0,0,0,0,1} 10 = {0,0,0,0,1,1,2,4,8,16}
xbonacci {1,0,0,0,0,0,1} 10 = {1,0,0,0,0,0,1,2,3,6}
xbonacci {1,1} produces the Fibonacci sequence

---
## [SweepyBoop/LibCooldownTracker-10](https://github.com/SweepyBoop/LibCooldownTracker-10)@[9e4440997b...](https://github.com/SweepyBoop/LibCooldownTracker-10/commit/9e4440997bfc036fa3406637a02e32994ce8d063)
#### Tuesday 2021-01-26 07:09:11 by SweepyBoop

Shadowlands ability updates

Updated the following abilities for shadowlands:

Demon Hunter:
- Netherwalk cooldown is 3 min, instead of 2 min

Druid:
- Barkskin is baseline, with 1 min cd
- Ironbark changed to 1.5 min cd
- Add Nature's Swiftness for Resto spec

Mage:
- Add Alter Time

Monk:
- Fortifying Brew is baseline, cd is different for Brewmaster

Paladin:
- Blessing of Sacrifice is baseline, remove 2 charges
- Divine Shield has optional lower cd of 210s, due to Unbreakable Spirit

Warlock:
- Unending Resolve should always be 3 min cd, there is no cd reduction. Remove the override

---
## [LDR-Siren/EmilyC-SamanthaPrater-EruzaArto](https://github.com/LDR-Siren/EmilyC-SamanthaPrater-EruzaArto)@[9f4dca7572...](https://github.com/LDR-Siren/EmilyC-SamanthaPrater-EruzaArto/commit/9f4dca75728b35f716dac21f585d2e5ad31c69ac)
#### Tuesday 2021-01-26 13:47:36 by LDR

Fetlife and Apologies

Good Morning,
The Big chunk of this is her fetlife. Lords help us all. She is asking for cash meet ups, which if you know anything about the world, that is dangerous and horribly dumb. But what do any of us know, besides don't do that!

The other thing that is in here is her "Apologies" which none of us believe she wrote. Not a single one of us. All her tells are missing. Its too well written. They use words she has never used in all the years any of us have been dealing with her.  Either someone else wrote them, or she plagarized them from somewhere else. Either way, more apologies no one believes.

---
## [idzan/web-2021](https://github.com/idzan/web-2021)@[1603c9e4e5...](https://github.com/idzan/web-2021/commit/1603c9e4e590e0b1dcb773037c3d909b85999e90)
#### Tuesday 2021-01-26 16:37:51 by Marko Idzan

sticky navbar done

fuck yeah, bit of css edits and it works, hell yeah :D
plus bit of styling XD
update: fixed colors for selection, on light mode it was fucking weird XD

---
## [newstools/2021-the-guardian-nigeria](https://github.com/newstools/2021-the-guardian-nigeria)@[8315cea72f...](https://github.com/newstools/2021-the-guardian-nigeria/commit/8315cea72faade162fe87caeebeab7dedb748401)
#### Tuesday 2021-01-26 18:03:13 by NewsTools

Created Text For URL [guardian.ng/life/food/cold-stone-creamery-welcomes-you-into-2021-with-love-3-new-love-flavours-amazing-offers/]

---
## [maborak/iemaddon-installer](https://github.com/maborak/iemaddon-installer)@[6d3d314141...](https://github.com/maborak/iemaddon-installer/commit/6d3d31414138d7250bbf597001ef7d1bae15ca60)
#### Tuesday 2021-01-26 18:07:18 by Wilmer Adalid (Alienware)

Updates for: Remember: Silly is a state of Mind, Stupid is a way of Life.
		-- Dave Butler

---
## [stonepillars/goonstation](https://github.com/stonepillars/goonstation)@[ef8dd81ce6...](https://github.com/stonepillars/goonstation/commit/ef8dd81ce6cc18d758a42dcca9cd222ae7142082)
#### Tuesday 2021-01-26 18:32:18 by Stonepillar

Add shoving crayons up others' noses

Crayons can now be shoved up the noses of carbon-based life.
Disgusting, I know. This is very vital to Clown and Mime gameplay.
It's a wonder this was not added sooner!

When shoved into someone's nose, a crayon will deal 15 BRAIN, and
add 3 units of lithium to the bloodstream of the victim, to induce
drooling and wonky movement.

In order to inflict severe brain damage, you must shove 4 crayons
into someone's nose. If you want to kill someone you must shove
an entire box of crayons, plus an extra finishing crayon (a total
of 8) in order to kill them.

Have fun!

---
## [maborak/iemaddon-installer](https://github.com/maborak/iemaddon-installer)@[bcd2cbf85e...](https://github.com/maborak/iemaddon-installer/commit/bcd2cbf85e4cadf56ca4bbcf7a430b78d106cfc8)
#### Tuesday 2021-01-26 20:49:19 by Wilmer Adalid (Alienware)

Updates for: When I woke up this morning, my girlfriend asked if I had slept well.
I said, "No, I made a few mistakes."
		-- Steven Wright

---
## [rebot333/rebot333.github.io](https://github.com/rebot333/rebot333.github.io)@[af909504dc...](https://github.com/rebot333/rebot333.github.io/commit/af909504dc9e4f6d989b484817c717d35b77dac9)
#### Tuesday 2021-01-26 20:59:01 by rebot333

Slash Code rewrite

barely changed css, just made the font not super tiny.
Man this css sucks honestly
I used to be a big dumb
Take this css into another editor and it is even worse
Tabs and spaces are mixed and shit and its ugly af

---
## [rebot333/rebot333.github.io](https://github.com/rebot333/rebot333.github.io)@[e0cafdee4b...](https://github.com/rebot333/rebot333.github.io/commit/e0cafdee4bb8f3a3d46964c79525109f9302c322)
#### Tuesday 2021-01-26 21:01:24 by rebot333

Slash Code rewrite

60% smaller!
100% better!
The old js sucked!
I had to completely rewrite it because no way in hell was I going to try to work with the old shit
The old shit sucked ass
it is so bad
thanks for coming to my ted talk

---
## [rndq/android_kernel_google_floral](https://github.com/rndq/android_kernel_google_floral)@[1ba94c23d7...](https://github.com/rndq/android_kernel_google_floral/commit/1ba94c23d78860edfe8dfb19ac0f14722f10424a)
#### Tuesday 2021-01-26 21:30:52 by Peter Zijlstra

sched/core: Fix ttwu() race

Paul reported rcutorture occasionally hitting a NULL deref:

  sched_ttwu_pending()
    ttwu_do_wakeup()
      check_preempt_curr() := check_preempt_wakeup()
        find_matching_se()
          is_same_group()
            if (se->cfs_rq == pse->cfs_rq) <-- *BOOM*

Debugging showed that this only appears to happen when we take the new
code-path from commit:

  2ebb17717550 ("sched/core: Offload wakee task activation if it the wakee is descheduling")

and only when @cpu == smp_processor_id(). Something which should not
be possible, because p->on_cpu can only be true for remote tasks.
Similarly, without the new code-path from commit:

  c6e7bd7afaeb ("sched/core: Optimize ttwu() spinning on p->on_cpu")

this would've unconditionally hit:

  smp_cond_load_acquire(&p->on_cpu, !VAL);

and if: 'cpu == smp_processor_id() && p->on_cpu' is possible, this
would result in an instant live-lock (with IRQs disabled), something
that hasn't been reported.

The NULL deref can be explained however if the task_cpu(p) load at the
beginning of try_to_wake_up() returns an old value, and this old value
happens to be smp_processor_id(). Further assume that the p->on_cpu
load accurately returns 1, it really is still running, just not here.

Then, when we enqueue the task locally, we can crash in exactly the
observed manner because p->se.cfs_rq != rq->cfs_rq, because p's cfs_rq
is from the wrong CPU, therefore we'll iterate into the non-existant
parents and NULL deref.

The closest semi-plausible scenario I've managed to contrive is
somewhat elaborate (then again, actual reproduction takes many CPU
hours of rcutorture, so it can't be anything obvious):

					X->cpu = 1
					rq(1)->curr = X

	CPU0				CPU1				CPU2

					// switch away from X
					LOCK rq(1)->lock
					smp_mb__after_spinlock
					dequeue_task(X)
					  X->on_rq = 9
					switch_to(Z)
					  X->on_cpu = 0
					UNLOCK rq(1)->lock

									// migrate X to cpu 0
									LOCK rq(1)->lock
									dequeue_task(X)
									set_task_cpu(X, 0)
									  X->cpu = 0
									UNLOCK rq(1)->lock

									LOCK rq(0)->lock
									enqueue_task(X)
									  X->on_rq = 1
									UNLOCK rq(0)->lock

	// switch to X
	LOCK rq(0)->lock
	smp_mb__after_spinlock
	switch_to(X)
	  X->on_cpu = 1
	UNLOCK rq(0)->lock

	// X goes sleep
	X->state = TASK_UNINTERRUPTIBLE
	smp_mb();			// wake X
					ttwu()
					  LOCK X->pi_lock
					  smp_mb__after_spinlock

					  if (p->state)

					  cpu = X->cpu; // =? 1

					  smp_rmb()

	// X calls schedule()
	LOCK rq(0)->lock
	smp_mb__after_spinlock
	dequeue_task(X)
	  X->on_rq = 0

					  if (p->on_rq)

					  smp_rmb();

					  if (p->on_cpu && ttwu_queue_wakelist(..)) [*]

					  smp_cond_load_acquire(&p->on_cpu, !VAL)

					  cpu = select_task_rq(X, X->wake_cpu, ...)
					  if (X->cpu != cpu)
	switch_to(Y)
	  X->on_cpu = 0
	UNLOCK rq(0)->lock

However I'm having trouble convincing myself that's actually possible
on x86_64 -- after all, every LOCK implies an smp_mb() there, so if ttwu
observes ->state != RUNNING, it must also observe ->cpu != 1.

(Most of the previous ttwu() races were found on very large PowerPC)

Nevertheless, this fully explains the observed failure case.

Fix it by ordering the task_cpu(p) load after the p->on_cpu load,
which is easy since nothing actually uses @cpu before this.

Fixes: c6e7bd7afaeb ("sched/core: Optimize ttwu() spinning on p->on_cpu")
Reported-by: Paul E. McKenney <paulmck@kernel.org>
Tested-by: Paul E. McKenney <paulmck@kernel.org>
Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Signed-off-by: Ingo Molnar <mingo@kernel.org>
Link: https://lkml.kernel.org/r/20200622125649.GC576871@hirez.programming.kicks-ass.net

---

# [<](2021-01-25.md) 2021-01-26 [>](2021-01-27.md)

