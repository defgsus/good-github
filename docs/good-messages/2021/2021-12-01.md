# [<](2021-11-30.md) 2021-12-01 [>](2021-12-02.md)

3,607,170 events, 1,881,299 push events, 2,839,564 commit messages, 231,742,204 characters


## [IsaacWoods/commonplace](https://github.com/IsaacWoods/commonplace)@[6089a18ca8...](https://github.com/IsaacWoods/commonplace/commit/6089a18ca82f68a7f899b75addba7a15ac79c034)
#### Wednesday 2021-12-01 00:01:29 by Isaac Woods

Support multiple platform builds via buildx in Dockerfile

Lmao this was the biggest pain in the ass, but it seems to FINALLY work.
0/10 Docker's actually a bit shit to use.

---
## [ElspethThePict/TeamForever-v4Decomp-1.3](https://github.com/ElspethThePict/TeamForever-v4Decomp-1.3)@[8cfdb84c98...](https://github.com/ElspethThePict/TeamForever-v4Decomp-1.3/commit/8cfdb84c984f70939ca2e9feb48aa94db5998364)
#### Wednesday 2021-12-01 00:11:13 by LittlePlanetCD

even FURTHER testing (will this be it?)

fucking hell fps problems are a bitch

---
## [NebulaSS13/Nebula](https://github.com/NebulaSS13/Nebula)@[fd7a45ce27...](https://github.com/NebulaSS13/Nebula/commit/fd7a45ce275b6a233482cb610be4fb59bbbb0b75)
#### Wednesday 2021-12-01 03:58:56 by PsyCommando

Cut up and reorganized the huma init code

My first idea didn't turn out as planned, so I've toned down the scope of the changes I wanted to make to something more manageable. Factories got messy and turned into a pain in the ass to use and a ton of barely useful subtypes.

* Moved code outside of Initialize into 2 procs, so they can be overriden or completely replaced by subclasses.
* Changed the set_species proc so it doesn't handle most of initializing the mob anymore and can be expected to do the bare minimum it should do.
* Moved the extra processing the set_species proc did to other procs so they can be overriden or skipped alltogether if neccessary.
* Moved verbs human mob verbs to human_verb.dm since the human.dm file is a bit big already.
* Moved the define for /mob/living/empty_stomach() to the living.dm file since it was randomly hiding in the human code and kinda bugged me.

-> Changed some of the code for changelings and the change_species proc with some untested code for now. Will need more work most likely.

---
## [crusewycoff1/crusewycoff1.github.io](https://github.com/crusewycoff1/crusewycoff1.github.io)@[709093cb9c...](https://github.com/crusewycoff1/crusewycoff1.github.io/commit/709093cb9c6b328280558f86fa87023dbc4869ba)
#### Wednesday 2021-12-01 04:24:12 by crusewycoff1

i honestly dont even know but i added a ton of buttons and did a shit ton of work on thrid impact but yeah theres a lot of changes made in here so good luck

---
## [bGielinor/b-resource](https://github.com/bGielinor/b-resource)@[d64d4d5089...](https://github.com/bGielinor/b-resource/commit/d64d4d508962ac3afbf894df5ecc789a8c10d8ae)
#### Wednesday 2021-12-01 04:42:59 by Bear Riley

Remove shitty pointless credit in files

Can provide credit to Blockbench usage in a README or something once instead of every god damn file

---
## [PhoenixBladez/SpiritMod](https://github.com/PhoenixBladez/SpiritMod)@[bd733cbc96...](https://github.com/PhoenixBladez/SpiritMod/commit/bd733cbc96bdecd00a69f2f729cb813f04c6023c)
#### Wednesday 2021-12-01 05:15:16 by zoroarkcity

fixed feral claws bug

I still dont know the underlying reason to why a melee speed buff fucks with projectile movement and honestly i dont  think i want to know

---
## [cnmalcom/EDLD651_Final](https://github.com/cnmalcom/EDLD651_Final)@[7ca50ac5a2...](https://github.com/cnmalcom/EDLD651_Final/commit/7ca50ac5a2b24453ea612267e16262e61324b4d8)
#### Wednesday 2021-12-01 06:16:41 by Cassandra Malcom

Peer Review by Cassie Malcom

	3 strengths: The graphs are very informative and well made, the faith table was interesting and provides context for the data, and you utilized well the pivot_longer & pivot_wider functions for your data.
	1 thing you learned: I learned that beliefs about family closeness during the COVID pandemic have changed and that trust in people was impacted.
       2 areas of improvement: Try to include annotations for the different R markdown chunk that will help reviewers follow along in both how you tidied the data and the data results; for example, some of the meanings behind labels in graphs like "A fair amount" could be explained in more detail in an annotation. The bottoms of the fourth and fifth graphs are labeled "Sex", but I'm not sure which facet is intended to refer to males and which is intended to refer to females, so I recommend clarifying that.

---
## [redis/redis](https://github.com/redis/redis)@[0e5b813ef9...](https://github.com/redis/redis/commit/0e5b813ef94b373f82bc75efcf3405f2c81af3dc)
#### Wednesday 2021-12-01 08:15:37 by yoav-steinberg

Multiparam config set (#9748)

We can now do: `config set maxmemory 10m repl-backlog-size 5m`

## Basic algorithm to support "transaction like" config sets:

1. Backup all relevant current values (via get).
2. Run "verify" and "set" on everything, if we fail run "restore".
3. Run "apply" on everything (optional optimization: skip functions already run). If we fail run "restore".
4. Return success.

### restore
1. Run set on everything in backup. If we fail log it and continue (this puts us in an undefined
   state but we decided it's better than the alternative of panicking). This indicates either a bug
   or some unsupported external state.
2. Run apply on everything in backup (optimization: skip functions already run). If we fail log
   it (see comment above).
3. Return error.

## Implementation/design changes:
* Apply function are idempotent (have no effect if they are run more than once for the same config).
* No indication in set functions if we're reading the config or running from the `CONFIG SET` command
   (removed `update` argument).
* Set function should set some config variable and assume an (optional) apply function will use that
   later to apply. If we know this setting can be safely applied immediately and can always be reverted
   and doesn't depend on any other configuration we can apply immediately from within the set function
   (and not store the setting anywhere). This is the case of this `dir` config, for example, which has no
   apply function. No apply function is need also in the case that setting the variable in the `server` struct
   is all that needs to be done to make the configuration take effect. Note that the original concept of `update_fn`,
   which received the old and new values was removed and replaced by the optional apply function.
* Apply functions use settings written to the `server` struct and don't receive any inputs.
* I take care that for the generic (non-special) configs if there's no change I avoid calling the setter (possible
   optimization: avoid calling the apply function as well).
* Passing the same config parameter more than once to `config set` will fail. You can't do `config set my-setting
   value1 my-setting value2`.

Note that getting `save` in the context of the conf file parsing to work here as before was a pain.
The conf file supports an aggregate `save` definition, where each `save` line is added to the server's
save params. This is unlike any other line in the config file where each line overwrites any previous
configuration. Since we now support passing multiple save params in a single line (see top comments
about `save` in https://github.com/redis/redis/pull/9644) we should deprecate the aggregate nature of
this config line and perhaps reduce this ugly code in the future.

---
## [xaynetwork/xayn_ai](https://github.com/xaynetwork/xayn_ai)@[e6d9a5f8f2...](https://github.com/xaynetwork/xayn_ai/commit/e6d9a5f8f2ebbf69cd4e6ea40cf7beb275ac447e)
#### Wednesday 2021-12-01 09:31:47 by janpetschexain

TY-2179 kpe correctness [1] (#315)

**References**

- [TY-2179]

**Summary**

- lowercase the key phrases during decoding: this reduces duplications and aligns with the original implementation, at the same time the tokenizer can still be configured to not lowercase the tokens to take advantage of case sensitive vocabularies and their corresponding embeddings
- update the decode and pipeline tests
- fix the cnn and classifier binparams: use the params from the bert joint model instead of the roberta joint model, already uploaded to the bucket
- replace `Array::zeros(shape)` with `Array::default(shape)`: this goes a different path and eventually calls `memcpy` instead of `memset` which seems to circumvent our qemu issue, performance wise this is pretty much the same
- add more debug assertions

to compare the kpe with the original implementation i took the test sequences from the research repo and ran them through the python code andthe rust code with the non-quantized model as well as the quantized model. the results are pretty similar and only vary slightly due to the quantization. i put the scores for better visibility of the differences, but they are not part of the output of the kpe, but only the key phrases are. below you can see the top 5 for each test sequence.

*"Russian chess grandmaster Ian Nepomniachtchi clinched victory at the Candidates Tournament on Monday, earning him the chance to challenge Norway Magnus Carlsen for the world title later this year."*:
| python | rust non-quantized| rust quantized |
| - | - | - |
| `"candidates tournament": 2.934950590133667` | `"candidates tournament": 2.9349513` | `"candidates tournament": 2.9128938` |
| `"ian nepomniachtchi": 2.929558277130127` | `"ian nepomniachtchi": 2.9295583` | `"ian nepomniachtchi": 2.6917644` |
| `"russian chess grandmaster": 2.0224971771240234` | `"russian chess grandmaster": 2.022496` | `"russian chess grandmaster": 1.7331984` |
| `"chess grandmaster": 1.3638781309127808` | `"chess grandmaster": 1.3638741` | `"chess grandmaster": 1.5507476` |
| `"chess": 0.9367392063140869` | `"chess": 0.93673766` | `"world title": 1.0421757` |

*"Paranoid schizophrenia is a psychotic disorder."*:
| python | rust non-quantized| rust quantized |
| - | - | - |
| `"paranoid schizophrenia": 3.4006059169769287` | `"paranoid schizophrenia": 3.4006069` | `"paranoid schizophrenia": 3.053503` |
| `"psychotic disorder.": 2.903540849685669` | `"psychotic disorder.": 2.9035397` | `"psychotic disorder.": 2.8526697` |
| `"schizophrenia": 1.9880062341690063` | `"schizophrenia": 1.9880033` | `"schizophrenia": 2.1258035` |
| `"paranoid": -0.1836133599281311` | `"paranoid": -0.18361469` | `"paranoid": 0.7293535` |
| `"disorder.": -0.2852359414100647` | `"disorder.": -0.28523594` | `"psychotic": -0.06573556` |

*"Berlin is the capital of Germany."*:
| python | rust non-quantized| rust quantized |
| - | - | - |
| `"berlin": 3.1970295906066895` | `"berlin": 3.19703` | `"berlin": 3.2181687` |
| `"germany.": 1.6476101875305176` | `"germany.": 1.6476078` | `"germany.": 1.7104346` |
| `"capital of germany.": 1.2701386213302612` | `"capital of germany.": 1.2701381` | `"capital of germany.": 1.3192337` |
| `"capital": 0.9426577687263489` | `"capital": 0.94265676` | `"capital": 1.0431908` |
| `"berlin is the capital": -2.0997655391693115` | `"berlin is the capital": -2.099763` | `"berlin is the capital": -1.8400929` |

*"Supervised learning, also known as supervised machine learning, is a subcategory of machine learning and artificial intelligence."*:
| python | rust non-quantized| rust quantized |
| - | - | - |
| `"supervised learning,": 4.123152256011963` | `"supervised learning,": 4.123152` | `"supervised learning,": 4.173371` |
| `"artificial intelligence.": 3.3956236839294434` | `"artificial intelligence.": 3.3956218` | `"artificial intelligence.": 3.2648902` |
| `"machine learning": 2.738740921020508` | `"machine learning": 2.7387404` | `"machine learning": 2.92315` |
| `"machine learning,": 2.257261276245117` | `"machine learning,": 2.2572598` | `"machine learning,": 2.399899` |
| `"supervised machine learning,": 1.8682597875595093` | `"supervised machine learning,": 1.868258` | `"supervised machine learning,": 1.7145393` |

*"State of the art definition is - the level of development (as of a device, procedure, process, technique, or science) reached at any particular time usually as a result of modern methods."*:
| python | rust non-quantized| rust quantized |
| - | - | - |
| `"definition": 3.355534791946411` | `"definition": 3.3555365` | `"definition": 3.2327096` |
| `"state of the art": 2.552528142929077` | `"state of the art": 2.552527` | `"state of the art": 2.331875` |
| `"modern methods.": 2.336472272872925` | `"modern methods.": 2.3364725` | `"modern methods.": 2.187481` |
| `"level of development": 1.5994861125946045` | `"level of development": 1.599487` | `"level of development": 1.7525568` |
| `"state of the art definition": 1.4022821187973022` | `"state of the art definition": 1.4022812` | `"art definition": 1.4388075` |

*"A challenging problem faced by researchers and developers of distributed real-time and embedded (DRE) systems is devising and implementing effective adaptive resource management strategies that can meet end-to-end quality of service (QoS) requirements in varying operational conditions."*:
| python | rust non-quantized| rust quantized |
| - | - | - |
| `"adaptive resource management": 2.5827958583831787` | `"adaptive resource management": 2.5827935` | `"adaptive resource management": 2.2490516` |
| `"quality of service": 2.3652701377868652` | `"quality of service": 2.3652692` | `"quality of service": 2.0012026` |
| `"adaptive resource management strategies": 1.763451099395752` | `"adaptive resource management strategies": 1.7634536` | `"resource management strategies": 1.7171625` |
| `"distributed real-time and embedded": 1.5346410274505615` | `"distributed real-time and embedded": 1.5346417` | `"resource management": 1.6924928` |
| `"resource management": 1.38322913646698` | `"resource management": 1.3832289` | `"adaptive resource management strategies": 1.5321714` |

*"The Taliban were one of the factions fighting in Afghanistan's civil war in the 1990s after the withdrawal of the Soviet Union. The group emerged in 1994 around the southern Afghan city of Kandahar. Their founder was Mullah Mohammad Omar, a local imam in the city, who led the militants until his death in 2013."*:
| python | rust non-quantized| rust quantized |
| - | - | - |
| `"taliban": 3.7115745544433594` | `"taliban": 3.7115746` | `"taliban": 3.466772` |
| `"afghanistan's civil war": 2.517509937286377` | `"afghanistan's civil war": 2.517508` | `"mullah mohammad omar,": 2.3020673` |
| `"kandahar.": 2.444540023803711` | `"kandahar.": 2.4445388` | `"civil war": 2.2738624` |
| `"mullah mohammad omar,": 2.4329581260681152` | `"mullah mohammad omar,": 2.43296` | `"afghanistan's civil war": 2.204691` |
| `"civil war": 2.35225772857666` | `"civil war": 2.3522582` | `"kandahar.": 2.068139` |

*"Blog Tokyo 2020 Olympics - LIVE BLOG - Women's marathon underway at start of busy Saturday Tokyo 2020 | Olympic Games. Next Games 04 - 20 Feb 2022."*:
| python | rust non-quantized| rust quantized |
| - | - | - |
| `"tokyo 2020 olympics": 3.256546974182129` | `"tokyo 2020 olympics": 3.256544` | `"tokyo 2020 olympics": 3.171133` |
| `"marathon": 2.969186305999756` | `"marathon": 2.9691875` | `"marathon": 2.5788279` |
| `"women's marathon": 1.2069082260131836` | `"women's marathon": 1.2069075` | `"women's marathon": 1.2984582` |
| `"blog": 0.6994484066963196` | `"blog": 0.6994498` | `"tokyo": 0.6820054` |
| `"olympic games.": 0.47504761815071106` | `"olympic games.": 0.47504336` | `"tokyo 2020": 0.60414904` |

**Todo**

- ~rebase once #310 and #316 are merged~


[TY-2179]: https://xainag.atlassian.net/browse/TY-2179?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ

---
## [JeanetteNXT/A-passionate-fullstack-developer-to-a-Innovative-AI-company-of-the-future-](https://github.com/JeanetteNXT/A-passionate-fullstack-developer-to-a-Innovative-AI-company-of-the-future-)@[42c09008a2...](https://github.com/JeanetteNXT/A-passionate-fullstack-developer-to-a-Innovative-AI-company-of-the-future-/commit/42c09008a27c746d66438a8c87036e14e323f3c4)
#### Wednesday 2021-12-01 10:21:39 by JeanetteNXT

Add files via upload

Hi all,
Are you a passionate fullstack developer who wants to join a Innovative AI company of the future?
 
“We believe in giving our employees freedom, responsibility, and opportunities to grow!”  

About the company
Wavr Tech AB is leading the development of next level proactive health and safety services. Do you want to join a startup company where you will have the opportunity to influence and impact the journey ahead? Right now, we are expanding our development team in Gothenburg, and are looking for a C# .NET fullstack Software Developer. You will be part of a development team with complete ownership for a number of different systems: customer and internal web systems, DevOps, tools and APIs. We believe in building a lot of our own tools and software in a low level fashion. 

Job description and responsibilities
As part of the team your development skills will strengthen our ability to develop and deliver new and better products to our customers. You are naturally interested in modern technologies with a focus on the Microsoft stack even though we welcome your broad technical knowledge and experience. We follow agile principles and being self-driven is a must, but we naturally think that communication and collaboration within the team is vital for us to grow together. We enjoy an open, helpful and cheerful atmosphere. The tasks will include but not be limited to, design, code, code review, test, document and operate features using technologies like C# .NET, .NET Core, ASP.NET, Blazor, Service Fabric, ZeroMQ, Microsoft Sql Server, Git, Windows, Azure DevOps, Azure CLI, and more.

Who are you?
You will have a Computer Science degree or something equivalent education-wise
Learn fast and are eager to take on challenges and like to share your skills and teach your colleagues
Take responsibility of and own the products you help to deliver

Qualifications
Skilled C# .NET, .NET Core developer

Skilled with multiple databases

Experience designing and building scalable high-availability systems

Experience with test automation

Experience with continuous integration and continuous delivery

Experience with various web technologies

Fluent either in swedish or english

Meriting

Azure infrastructure experience.

Experience with Infrastructure automation tools.

Service Fabric infrastructure and development knowledge.

Machine learning frameworks (e.g Tensorflow, Pytorch, ML.NET)
 

Reason to join us
We are a company where you can influence how we work and be a part of the decision making in how to move forward. Our team is friendly and humble, we lift each other and teach each other. You’ll have the possibility to work remotely and we have flexible hours.


Does this sound interesting?
Selections and interviews will take place on an ongoing basis so do not wait with your application!

NXT Interim and NXT Rekrytering is a niche and innovative company active in the consulting and recruitment industry.
We are active in HR, IT, Finance and Marketing& Sales. We offer packaged services that the traditional companies do not offer today. We have over 20 years of experience in the industry and 3000 unique contacts to help you. 
Our goal is to go from being an innovative challenger in the industry to the company in the industry that everyone wants to beat, contact us today and we will do everything to help you. We have offices in Stockholm, Gothenburg, Malmö, Linköping and Kalmar

How do I proceed
If you are interested, take a first step in showing your interest in this ad. We process the applications on an ongoing basis so do not hesitate but apply today! If you have any questions, please contact Gig Manager Jeanette Ångman on phone: 0704 98 75 56 or email:jeanette.angman@nxtinterim.se

---
## [gjoseph92/stackstac](https://github.com/gjoseph92/stackstac)@[81d475f51b...](https://github.com/gjoseph92/stackstac/commit/81d475f51b45fcb8e7e4cac109a88dbe5016f214)
#### Wednesday 2021-12-01 10:40:59 by Gabe Joseph

Notes to self about why `show` is so laggy:

It seems to be something broken with BatchedSend (what a surprise!).
_maybe_ something to do with visualizing something that's been persisted
(Futures that depend on other Futures)? Locally at least, commenting out
the `persist()` seems to make things work smoothly.

But the main problem we see is messages getting stuck in the BatchedSend
and not getting sent. If you look at `client.scheduler_comm` when things
should be computing but aren't, you'll usually see that there are
messages in the buffer.

In these cases, `scheduler_comm.waker` is not set. This seems wrong;
calling send should set the event. Unless the deadline is set.

But also, `waker._waiters` is empty, as though nothing is waiting on the
event either. I suppose this would be the case while `background_send`
is awaiting the `comm.write`. Or there's some broken thread-safety
(https://github.com/dask/distributed/issues/5552).

Another thing I've noticed is that `scheduler_comm.next_deadline -
scheduler_comm.loop.time()` goes very, very negative (up to hundreds of
seconds) while there are things in the buffer. As in it's hundreds of
seconds behind when it should have sent.
One question is what happens the deadline for `waker.wait` has already
passed. The "avoid sprious wakeups" logic is assuming that so long as
any deadline is set, the coroutine is going to wake up soon anyway. This
would only be the case if that timeout actually works. It's possible
that a `comm.write` takes longer than the interval, and by the time we
come back around to `waker.wait`, the deadline has already passed. If
the wait returns immediately in that case, then we're fine. But if
tornado schedules the callback into the ether, then we'll never wake up.
Though this still doesn't line up with the empty `_waiters` on the
event.

I guess the last explanation is just that `await comm.write` is really,
really, really slow. If it takes hundreds of seconds to do the write
(including serialization), then of course the next batch wouldn't be
sent yet. Websocket comms do have some ridiculous copying. And maybe
because the binder machines and network are so wimpy, it's just extra
slow there? Feel like this doesn't quite add up though.

---
## [x-zvf/dotfiles](https://github.com/x-zvf/dotfiles)@[a02b0f9767...](https://github.com/x-zvf/dotfiles/commit/a02b0f976711b7cb9420f8d95adc90d3b566cf94)
#### Wednesday 2021-12-01 17:31:45 by xzvf (Péter Bohner)

Fuck you intel WiFi, fuck you! This script yeets the drivers to fix them

---
## [17Amir17/SSE-Chat](https://github.com/17Amir17/SSE-Chat)@[6ca82fd11f...](https://github.com/17Amir17/SSE-Chat/commit/6ca82fd11f3910079a7d521cf4a1d2213fe903d7)
#### Wednesday 2021-12-01 18:33:02 by 17Amir17

Fucking proxy fuck my 4 hours wasted on this shit

sry for being salty

---
## [jakllsch/NetBSD-pkgsrc](https://github.com/jakllsch/NetBSD-pkgsrc)@[354f64746e...](https://github.com/jakllsch/NetBSD-pkgsrc/commit/354f64746ec6a35a973e30467070825912986be3)
#### Wednesday 2021-12-01 18:39:08 by gutteridge

meta-pkgs/xfce4: update to 4.16

Project summary of changes:

Today, after 1 year and 4 months of work, we are happy to announce the release of the Xfce desktop 4.16, a new stable version that supersedes Xfce 4.14.

4.16 was a special cycle in many respects (not only pandemic-wise, but also). One of the corner-stones of the non-code changes concerns our migration to GitLab, which is a change in development workflow and a huge step forward in terms of becoming more contributor-friendly and welcoming. In parts, the humungous changelog of Xfce 4.16 can be attributed to new contributors proposing merge requests (288 merge requests were merged or closed against our core components alone!). We also created a reference Docker container (xfce/xfce-build) and added CI pipelines to all components to ensure we don´t break the build. None of this would have been possible without our hosting being sponsored by Gandi and Fosshost!

Another big change concerns our visual identity, which we updated from a strange mix of random (partly Tango-based) icons and not following any naming scheme to a new, visually consistent set (following the freedesktop.org naming specification and a fixed color palette). We´re aware this will generate some work for icon theme maintainers (if they really want to override our gorgeous icons ;)) but we believe the longterm benefit outweighs this one-time effort.

And then finally we did some housekeeping (e.g. by dropping Gtk2 support code) and we also added features and improvements - all while sticking to a reasonable release cycle timeframe.

So without further ado, here go the main highlights of this release:

    The window manager received lots of updates and improvements again in the area of compositing and GLX. If a primary display was set, the alt-tab dialog will now only be shown there. Furthermore some handy new options to zoom the cursor along with rest of the display as well as an option to keep minimized windows in the most recently used list complement this release.
    We added a new plugin to the panel dubbed "statustray" which combines both StatusNotifier and legacy Systray items. An animated autohide transition now clearly shows the user "where the panel has gone" and a dark mode (enabled by default) makes the panel drop into the background a bit more with bright themes like the Gtk default Adwaita. Quite a few more smaller improvements were also introduced like accessing desktop actions from a Launcher´s right-click menu, the Window Buttons plugin now offering to `Launch a new instance` of an application and the Workspace Switcher now optionally showing automatic numbering for workspaces.
    Support for fractional scaling was added to the display dialog, along with highlighting the preferred mode of a display with an asterisk and adding aspect ratios next to resolutions. Falling back to a working mode after misconfiguring the display layout has also been made more robust.
    A new tab in the "About Xfce" dialog shows basic system information like CPU or GPU type. Furthermore the layout and visuals of the dialog were improved.
    The settings manager has improved search and filter capabilities. Furthermore all settings dialogs now use window decorations drawn by Gtk (client side decorations).
    The "Mime Settings" and "Preferred Applications" dialogs were merged into the "Default Applications" dialog - making it easier for users to set which application handles which filetype or action from one place.
    Our file manager Thunar received a boatload of fixes and quite a few notable features, including pause for copy/move operations, support for queued file transfer, remembering view settings per directory and support for transparency in Gtk themes.
    Our thumbnailing service tumbler became more flexible by being able to exclude paths. Furthermore support for .epub (e-book format) was added.
    The session manager offers improved support for GPG agent 2.1 and the setting dialog was visually improved.
    The power manager received a lot of bugfixes and some smaller features - among them a cleanup of its settings dialog, an optional visual indicator for when `Presentation Mode` is enabled, more accurate battery status icons and automatically dismissing low-power notifications upon the connection of a charger.
    The desktop mostly received bugfixes and small improvements - and the new default wallpaper!
    Our menu library garcon received new APIs and now doesn´t launch applications as children of the process hosting the menu anymore. The previous behavior led to applications crashing along with e.g. the panel.
    The applicaton finder now allows for sorting applications by "frecency" - a combination of frequency and recency.
    Dependency updates: Drop Gtk2, add LibGTop, bump Gtk >= 3.22, GLib and GDBus >= 2.50

---
## [RP-Lens/RandomCProgs](https://github.com/RP-Lens/RandomCProgs)@[f1886fa346...](https://github.com/RP-Lens/RandomCProgs/commit/f1886fa346682e6aa2b40f46cbd3f474c3b76050)
#### Wednesday 2021-12-01 18:42:48 by RP-Lens

Merge pull request #3 from weathers0/patch-3

ay fuck you

---
## [Araxxas/tamberlane-transcripts](https://github.com/Araxxas/tamberlane-transcripts)@[0b9f49204d...](https://github.com/Araxxas/tamberlane-transcripts/commit/0b9f49204de464a94f0b30eaa1605ee185be800b)
#### Wednesday 2021-12-01 19:02:00 by Araxxas

Add files via upload

"Laff daff" is a snuffled "Lass das"- as you would say "fpop fap!" instead of "stop that" when someone sticks something into your mouth or nose.
Reminds me of a joke:
"I woke my girlfriend with oral sex this morning."
"Oh yeah? What did she say?"
"Fpop fap crap!" XD

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[9fc0dd0c5f...](https://github.com/mrakgr/The-Spiral-Language/commit/9fc0dd0c5f3eb5666283a9f9a7f6074c2ae770b6)
#### Wednesday 2021-12-01 19:14:05 by Marko Grdinić

"10:45am. It is the first of December. To think when I did the half yearly review I thought that I was only a few weeks away from making an elite player.

10:55am. Let me read Frieren and Kage, and then I'll get started on the review. I'll give sculpting a break for today.

11:40am. Let me get started.

///

In early November the pen tablet arrived and I've been practicing drawing and sculpting. My current project is to replicate Flycat's base mesh. I got the ears right, and I just have to finish the rest [of the head](https://youtu.be/VzMAh66ofq0?t=786), retopo it and I will have completed my first project. After that I'll go back to drawing. Right now I do not have anything to showcase yet. I like the tablet quite a bit. Though I feel my dexterity has improved, digital art so far has not been like the traditional. You have limitless ability to undo and correct, so there is less of a requirement to be good with one's hands than you'd think. There is less of a barrier to entry in digital art. Even if you have a wobbly hand you could use something like Lazy Nezumi to get smooth lines. What really matters is planning and breaking things down hierarchically into progressively simpler shapes.

This is quite similar to how programming works. I might be able to get good at this. The sculpt itself thus far looks quite good, but I haven't tested myself in 2d yet. If I can get a result on the same level as the 3d sculpt in 2d, there is no reason why I could not make rapid progress at this.

Every time you change paths, you end up having a lot of [regrets](https://www.reddit.com/r/MachineLearning/comments/r3g7kd/d_looking_for_a_sponsor_for_a_functional/) and this time it is no different. It is true that I applied to a bunch of places in the past few months, but I am not a fan of doing paid work so my reward would be yet even more unpaid bashing my head against the wall in RL. My expectation was that since it is 2021 that the current day algos would be good enough to get something decent on a toy game like poker which would support both my fundamental research and continuing progress in ML. Maybe if I got a job, and opened the wallet to really scale ML things would work, but I am not interested in this kind of money burner. Opening your wallet every time something breaks is just a stupid way of operating. The Pluribus guys could set up the environment and have the pros tackle their agent directly in the domain of their choosing, but if I tried that in the real world, I'd have people trying to hunt down an AI user. My view is that I simply do not have any leeway in my algorithms being unreliable. They have to be as solid as the tabular ones for them to be useful in the real world.

For the past 3 months I've been particularly obsessed about getting those burgeoning AI chips. Getting better hardware would allow me to cheaply scale existing algos which might make the plan still viable, but you can see the overall sentiment towards anything new in that thread. The deleted post which got a lot of upvotes said something to the effect that Python + PyTorch will be good for the next few decades. I think the people who are upvoting that post have forgotten what the hype behind ML is about. I guess they expect the AGI to come from some PyTorch model.

I thought that Spiral might serve as a wedge into some of these companies, but it doesn't seem they are on the lookout for any such offerings. At any rate, I can't waste my time hollering outside the window trying to get these companies' attention.

I've had many disappointments and I think I want a path that will support me from start to finish. From 10$ a month to 10k a month to 10m. I do not want a slightest gap to be missing. I do not care if I can only make 10$/month at the start, but I do not want it to be that I need some higher amount otherwise my project is dead in the water and I have to change my lifestyle. Never again. If languages aren't important, who am I to argue against that? They can have C. The more I dwell on past mistakes the more I am lessened as a person. There is a lot of variance when applying to companies directly, it is like being a ball on a roulette wheel. Who knows where you will land. I do not want my life and future development to be decided by a roll of the dice. The way to reduce the variance is to increase the quantity of hands played so instead of serving a particular company I'll want a business that targets as far and wide as possible.

I think that with the new wave the algos themselves should improve.

Even if the neuroscience guys continue being as useless as they have been and do not manage to figure out what the brain is doing directly, there is a threshold of collecting enough low level data after which evolutionary algorithms could infer what the high level composition should be. This is not some great insight, it is just that with my current level of hardware I would not even think of trying this out because I absolutely do not have the computation for such research. But this line should become viable for the big labs this decade.

I simply have no idea what the algos are. My view is that most likely there exist specific models for which specialized optimization and credit propagation schemes exist which are much more apt than the very general backpropagation. A precedent for this is tabular RL. CFR in particular covers credit assignment and optimization between nodes of categorical distribution models. It works very well in its restricted domain and has no connection to backprop. What is needed is something more fancier than it.

Looking at my past efforts, it was just getting hyped about random things and trying them out which is not a reliable method of doing research. Rather than learning anything about intelligence, I just ended up learning about specific methods which put me no closer to my goal. Rather than trying to get better at AI in such a manner, the way to learn is to get the algorithms up front from somewhere and learn their principles. It is kind of a cheat, but the real work actually starts once you get a canvas onto which to etch your will. I shouldn't be slaving myself to death over the equivalent of going to the store to buy a bunch of paper.

The kind of game where I am hoping from is where I move from strength to strength rather than from weakness to weakness. I hope that the great game will be about adapting the principles of intelligence for the particular situation rather than the guy with the biggest computer winning at everything forevermore because there is only one omnipotent, general purpose algorithm. Until it starts, I'll tidy up the rest of my char sheet.

Right now my programming skills are very strong if useless, but adding visuals and art on top of that should bring me to the apex of humanity in terms of creative ability. Money is my weakness, but I should not let raw skill be the same way. I might not have acquired much during the past decades, but I have developed a cultivator's mindset.

///

1:20pm. This shuold be good. Let me get breakfast. I'll put it through the Docs tool after that.

2:35pm. Done with breakfast and chores. What is going on with SSA Megia Record ep 8. Half the lines aren't subtitled.

https://nyaa.si/view/1436992

> https://files.catbox.moe/hlfl4k.srt
> Use this subtitles file from bilibili
> Funimation decided they won’t translate half the script this episode for some reason

3:15pm. Let me put the above reivew through a checker tool and then I will resume my studies.

Ok done. Is the thread up? Nope.

Let me watch the RL evo lecture for a bit and then I'll study Flycat's head retopo and some head sculpting tuts.

https://youtu.be/7J5KK-tYoXc
RLVS 2021 - Day 5 - Evolutionary Reinforcement Learning

So far I've only watch the first 20m, let me watch another.

3:25pm. https://youtu.be/7J5KK-tYoXc?t=1322

Watching this, I am really struck how good the OpenAI ES algorithm is. Apart from missing the input whitening part of KFAC, it is almost perfect. This on the other hand just stupidly selects new points. Now if only I knew how to go beyond backprop I could make so many gains.

https://youtu.be/7J5KK-tYoXc?t=1849

Oh, this is quite similar to what was in the OpenAI paper, but that one did not normalize. This one would have the added benefit of being be invariant to scale of the rewards. This is remarkable.

4:05pm. https://youtu.be/7J5KK-tYoXc?t=3202

I did not know about this paper.

https://youtu.be/7J5KK-tYoXc?t=3378

I am still watching this. Ah what the hell. Let me watch it all. That 3d model is not going to run away. I'll put in some overtime to make up for it.

https://youtu.be/7J5KK-tYoXc?t=3444

Ah, that KFAC thing I had in mind, maybe I could use a factored CMA-ES instead?

Ah, right, but even a single layer might have too many params for a covariance matrix to keep track of, let alone in deep nets. Still it might be possible to do a factored representation of the covariance matrix.

https://youtu.be/7J5KK-tYoXc?t=3598

It says here that applying CMA-ES is an open challenge for the reason I noted.

A Simple Modification in CMA-ES Achieving Linear Time and Space Complexity
https://hal.inria.fr/inria-00287367/document

This is a paper from 2008. Not quite KFAC, but who knows.

4:50pm. I am completely entranced with my idea. This could actually work and improve the state of the art significantly. Could this give me my vaunted poker agent? It could be.

7pm. Done with lunch. I've been intensely thinking about CMA. I thought about various avenues of merging it with KFAC, but it would not work. If I tried making the input part of the big covariance matrix using the inputs, it would become sensitive to meaningless inputs.

So raw ES as it is has unique properties that get lost if I try bringing in stuff from regular NN training.

All those avenues are dead ends.

But I am thinking what if instead of breaking down the covariance matrix by hacking the backprop rules like in KFAC, there is a way to break it down in just a bunch of linear matrices.

I mean, the NN has a lot of structure that gets lost if you just flatten the whole of it into a single parameter vector.

Maybe using CMA-ES, but being smarter about factorizing the layers is the way to go.

7:10pm. I do not know, let me finish the video.

In the end, I am back to where I started and just wasted a day thinking about this. When will I sculpt?

7:50pm. Tomorrow, tomorrow I will sculpt. I really hate second order methods. They tempt me, but then move out of reach. If I had something like CMA-ES that had O(log N) complexity, it is very likely I would not have had to change paths. Come to think of it, I spent most of 2018 messing around with them as well.

A life without the self improvement capability. Can you call that anything other than a movie? Entering the self improvement loop is like putting the hands on the sterring wheel for the first time. I want to experience it more than anything. You can't call the life I lead now truly being alive.

Forget CMA. The regular algos will have to do the job when it comes to evolving better ones. For AIs, they will simply have to evolve to the point where they are capable of controlling their own evolution if they aren't smart enough like I am suspecting myself right now.

It has to start somewhere.

I am going to place my hope on ES next because only algos like it have the necessary roboustness properties, but I won't really use it until I get the necessary hardware to do some mad science. Right now it would absolutely fail. But backprop itself is hopeless, both in general and for research purposes. ES could open many doors for me.

The most promising way would be to figure out a specific class of models that have specialized optimization algos. Or the direction I thought of earlier to take some smaller nets and try to evolve a specialized optimizer just for that. Something like a way to factorize large scale covariance matrices efficiently.

Nothing much came from these kinds of research initiatives yet. There were some papers that tried evolving better rules than the backprop ones, and better architectures, but nothing particularly noteworthy. Nothing came out of symbolic regression and genetic programming to really move the field itself.

8:05pm. I'll have to dream about it. I spent my youth dreaming about omnipotence before finding the self improvement loop, so maybe if I keep it steady, I'll find another step to narrow the gap between dreams and reality.

Right now let me rest a bit. Tomorrow I am going to get the face sculpt out of the way."

---
## [sepanou/ocr](https://github.com/sepanou/ocr)@[7b85fc2914...](https://github.com/sepanou/ocr/commit/7b85fc2914112de84b45bd08ae9e980d03921edd)
#### Wednesday 2021-12-01 19:18:36 by Michalon Loïc

Fixed Maxence's bug :clown:. Fuck Maxence's unreadable code, all my homies hate Maxence's unreadable code :sunglasses: :100: :fire: :flushed:

---
## [Luxyah/vsDavePsych](https://github.com/Luxyah/vsDavePsych)@[1a86718015...](https://github.com/Luxyah/vsDavePsych/commit/1a8671801580ed3c8950de1efb1b66e7d1d2218a)
#### Wednesday 2021-12-01 20:01:37 by Luxyah

you know what fuck you *makes unfairness 10 times harder*

---
## [ComputerScienceHouse/netbox-images](https://github.com/ComputerScienceHouse/netbox-images)@[69c4b1ba56...](https://github.com/ComputerScienceHouse/netbox-images/commit/69c4b1ba56e073d19893545ba255debcacf34541)
#### Wednesday 2021-12-01 20:32:40 by Mary Strodl

Containerfile: apt -> apt-get

Fuck you @galenguyer

---
## [NoComment1105/Iris](https://github.com/NoComment1105/Iris)@[e66a1f25b5...](https://github.com/NoComment1105/Iris/commit/e66a1f25b5d4efcf418b40b83e515660f2fc11f9)
#### Wednesday 2021-12-01 20:46:30 by NoComment1105

bloody hell that action takes ages lets cache this shit

---
## [cmangos/tbc-db](https://github.com/cmangos/tbc-db)@[e15de22a67...](https://github.com/cmangos/tbc-db/commit/e15de22a674ff992291c81bfc31c4eaab39f8c55)
#### Wednesday 2021-12-01 21:07:30 by killerwife

TBCDB: Release 1.9.0 The Last Vengeance

Big thanks to the whole cmangos and vengeance teams.
Killerwife, AnonXS, MantisLord, Saltgurka
Grz3s, Cyberium, Xfurry, Cala, Tobi

Features:

Feature completeness of all TBC content. All game_events off the ground. All bosses implemented. All quests implemented or at least doable.
Missing major features going forward:
10 hour war for AQ war effort
Naxxramas invasions
Brewfest dark iron attack every 30 minutes

Buggy major thing requiring revisit:
Shartuuls Transporter event

Thank you to everyone involved, there is still plenty of work to go about, but we now are capable of a solid experience out of the gate.
Happy playing to everyone.

PS: Help in dire need as always :P

---
## [r-JaidenAnimations-Discord/Tofu-Bot](https://github.com/r-JaidenAnimations-Discord/Tofu-Bot)@[f23172b014...](https://github.com/r-JaidenAnimations-Discord/Tofu-Bot/commit/f23172b0142244747313cfb167364ad843374398)
#### Wednesday 2021-12-01 21:11:22 by TeraBaito

Remove unnecessary tantrums
fuck you and your feelings

---
## [Stridsvagn69420/AdventOfCode](https://github.com/Stridsvagn69420/AdventOfCode)@[8263127dcf...](https://github.com/Stridsvagn69420/AdventOfCode/commit/8263127dcf24024e9ae6441fd72284f25ba384fb)
#### Wednesday 2021-12-01 21:38:01 by Stridsvagn69420

Revert "I am LaSunVoid, LeMoonStar's evil twin brother, and I love Windows-exclusive products!"

This reverts commit 4f1f503256914908b26c70a7ba34d2add181a251.

Yeah, go back to normal state

---
## [noah-nuebling/mac-mouse-fix](https://github.com/noah-nuebling/mac-mouse-fix)@[47aa9af296...](https://github.com/noah-nuebling/mac-mouse-fix/commit/47aa9af2969142d7e66a96328f98772c6c1b0c9d)
#### Wednesday 2021-12-01 21:59:19 by Noah Nuebling

Got remapsDict-based scroll modification working.

Unfortunately there are some usability issues with the current implementation:

1. Event phases for zoom events are now based on the animationPhases that our animator generates. This is nice and elegant on paper but in practise it leads to bad performance. When you produce a string of zoom events that each start with an event with phase "began" and end with a phase "ended" in quick succession, then macOS will start acting weird and performance will drop. This is not our issue. The same thing happens when pinching several times in a row on the trackpad. The solution is to make all scroll swipes that occur while the zoom modification is active appear as one long, big pinch to the system (only a single "began" and a single "ended event"). This is what we did in the older MMF version. This also has some issues but works much better.
2. When there is a modifiedScroll and a modifiedDrag effect on the same button (and clickLevel) then it's easy to trigger one while trying to trigger the other. When I'm trying to zoom via modifiedScroll and only move the mouse slightly, then the modifiedDrag will become active and stop me from zooming. The solution is to somehow prevent other modifications once a modification enters "in use" state or sth.

Edit: I played around a bit with having drag to "Scroll & navigate pages" on the same button&clickLvl as scroll to "Zoom in and out".
I thought it might be useful to use both at the same time. But it doesn't work. macOS acts really weird when you do both at the same time. So this convinces me that we need to implement a mechanism to stop dragModifications from being used after a scrollModification comes into use on the same modificationPrecondition and vice versa.

Edit2: I've played around some more with having a dragModification, a scrollModification and a buttonModification on the same modificaitonPrecondition. I've come to the conclusiont that we don't want to disable buttonModifications of a certain modificationPrecondition, once that modificationPrecondition has been used to activate a dragModification or a scrollModification. That's because it's really easy to accidentally scroll or accidentally move the mouse slightly while trying to press a button (but slightly before actually pressing the button)

Edit3: There is a hierarchy of "while doing x it's easy to accidentally do y". Let x be any item in this list and y any item below x:
1. Pressing button
2. Scrolling
3. Dragging

The main problem only arises when accidentally doing y while trying to do x and then y disrupting x somehow.
E.g. while trying to *scroll* to zoom it's easy to accidentally *drag* the mouse and start a simulated three finger drag. The three finger drag will interrupt the zooming - that's the issue.
To prevent this, we want to switch off modified dragging, while a modifiedScroll is active.
This isn't as much of a problem for button clicks because they are one and done there isn't a time period that they are "in use".

But similar issues can arise when having weird setups, for example having an action on double click while having a modifiedDrag / modifiedScroll on single click. It's easy to accidentally move the mouse after the first click and activate the modified scroll when you're trying to double click. I don't think there is a technical solution to this though. Because if you did anything to make the double click easier to reach that would mean making the modifiedScroll harder to reach. So these kinds of setups just inherently suck a little bit.

The only way I see to make this situation better is to disable modifiedDrag while a modifiedScroll is in use. This would only be of benefit when the modifiedDrag effect is a threeFingerSwipe (Mission Conrol and Space) (which deactivates any effects we would want to assign to modifiedScroll when it enters the inUse state).
If the modifedDrag action is a twoFingerSwipe (Scroll and navigate pages) then it would only be awkward to disable it once the modifiedScroll enters the inUse state. That's because the modifiedScroll won't interrupt the modifiedScroll and it even has some benefits to use both at the same time. Especially if it's not symmetric, the user will ask "Why can I drag to scroll and then scroll to zoom but not scroll to zoom and then drag to scroll?" It doesn't make any sense for that not to be symmetric. So we would want mutual exclusion for modifiedDrag and modifiedScroll to be in use.

But is that really worth it?

Pro (mutual exclusion of modifiedDrag and modifiedScroll to be in use):
- modifiedScroll won't be accidentally interrupted when mouse is moved and threeFingerSwipe comes into use
- Zooming while scroll is in progress doesn't even work in Preview, so we would make behaviour more consistent.

Contra
- Can't use modifiedScroll to zoom/rotate at the same time as using modifedDrag to scroll
- We won't have to do any extra work if we don't implement the exclusion. And for most users these accidental drags while trying to scroll shouldn't be a huge issue anyways.

The only other issue I can see is that when moving the mouse AND scrolling AND zooming (This happens when you start a modifiedScroll to zoom by scrolling and then while that's active, you start a modifiedDrag to scroll or the other way around) then Safari and Preview (and probably other apps) act al little weird. It seems we can fix this by disabling one of these three (moving mouse, scrolling, and zooming) while the other two are active. We'll probably disable moving the mouse during modified drag to scroll anyways, so this shouldn't be an issue.

So there are several paths to go forward here:

1. Do nothing about this issue (It's not really that big anyways)
2. Prevent modifiedDrag activation (or deactivate if it's already activated) while modifiedScroll is in use
3. Do 2. and also prevent modifedScrollActivation while modifiedDrag is in use.
4. Make modifedDrag, modifiedScroll, and modifiedButton mutually exclusive.

Edit4:
I have a better idea!
Our hierarchy of accidentality was

    1. Pressing button
    2. Scrolling
    3. Dragging

What we truly, basically want is this:
- If we inted to use a modifed scroll, but we accidentally drag, we still want to have our modifiedScroll take effect.
- If we intend to use a modifiedButton, and we accidentally scroll OR drag, then we still wan our modifiedButton to take effect.

Buttt in certain scenarios this hierarchy isn't so clear. (e.g. If there's a modifiedDrag on the scrollWheel button, the it's also easy to accidentally scroll while trying to drag....)

So the optimal way I see, is that scroll and drag are first come first serve, and pressing button takes precedence over both.

So if modifiedScroll comes into use, then modifiedDrag can't come into use on the same modificationPrecondition and vice versa.
But if modifiedScroll or modifiedDrag is in use then a buttonTrigger with the same modificationPrecondition comes in, then the buttonTrigger should still take effect, and maybe even cancel the modifiedScroll or modifiedDrag that is in use.
The only reason I can think of for having the buttonTrigger cancel the other stuff is if the other stuff prevents the effect of the buttonTrigger. I can't think of any examples of this though, so this is not worth spending time on now.

So the plan is to have a first come first serve mechanism for modifiedScroll and modifiedDrag.

Edit 5:

God this is confusing.
Sooo actually, practically it's probably better to have the modifedScroll take absolute precedence over the modifiedDrag. So even if you accidentally drag *before* scrolling, the modifiedScroll still becomes active. The only scenario where first come first server would be preferable is if you put a modifiedScroll and a modifiedDrag on the modificationPrecondition of the scrollWheelButton. Because only in this scenario, is it realistic to accidentally scroll while trying to drag. But only a monster would do this.
To make this work even more seemlessly in all scenarios we could suspend the modifiedDrag while the modifiedScroll is active and then resume it. (Not sure why I thought that that would be better) Or we could measure the originOffset of the modifiedDrag and switch between activating modifiedScroll and modifiedDrag based on that? Or maybe we could simply increase the usageThreshold of the modifiedDrag to prevent these accidental activations.

I think my thinking now is that ideally, we would have no interference between the modications at all. But since there inevitably is this one important interference between the threeFingerSwipe and the scrollEffects (threeFingerSwipe deactivates the scrollEffects) and since it's easy to accidentally drag while trying to scroll we need to do something.

The goal is to minimize the interference. By either
- Making it harder to accidentally use modifiedDrag when trying to use modifiedScroll
- By making modifiedScroll still work, even when accidentally dragging

The best ways I can think of for this is:
- Increasing modifiedDrag usageThreshold. Maybe depending on context
- By canceling / suspending modifiedDrag when modifiedScroll comes into use.

---
## [HuskyGameDev/2021f-team2](https://github.com/HuskyGameDev/2021f-team2)@[578cdf2826...](https://github.com/HuskyGameDev/2021f-team2/commit/578cdf28262e8e7e5cb1033979ac67bef295075c)
#### Wednesday 2021-12-01 22:58:52 by Maritza Gonzalez

Horrible name

Sorry this is a shitty edscription i am driving rn and cant describe well.

Mashing mingame, game switches to new scene after the round where the minigame takes place. mashing minigame. There is a timer in the mashing minigame

When a player wins the minigame it takes them to one of three scenes;

one scene where p1 has a buff, one where p2 has a buff, and one where neither do (they tied the minigame)

---
## [TrinityCore/TrinityCore](https://github.com/TrinityCore/TrinityCore)@[519e3c9ab7...](https://github.com/TrinityCore/TrinityCore/commit/519e3c9ab718ce50dbaf66a50d15f5ead2dc9885)
#### Wednesday 2021-12-01 23:41:12 by jackpoz

Core/Commands: Fix .cheat god command letting you die

Fix .cheat god command still letting you die with Area Aura like Slime near Thaddius, broken since 777b287dff8bce806849a26d59fe40f864c385ed

(cherry picked from commit f26f716714fefa2af4c6e3eea263206682d45236)

---

# [<](2021-11-30.md) 2021-12-01 [>](2021-12-02.md)

