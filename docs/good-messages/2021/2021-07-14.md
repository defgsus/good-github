# [<](2021-07-13.md) 2021-07-14 [>](2021-07-15.md)

2,981,073 events, 1,472,730 push events, 2,426,823 commit messages, 278,690,602 characters


## [CUDEPIA/Senhor-Bolo-System](https://github.com/CUDEPIA/Senhor-Bolo-System)@[174a8d9956...](https://github.com/CUDEPIA/Senhor-Bolo-System/commit/174a8d99569db8a4aee73053a490b8cc39141f74)
#### Wednesday 2021-07-14 00:03:29 by Que fei

*Notices penis-kyun is happy to see me >.<

Rawr x3 nuzzles how are you pounces on you you're so warm o3o notices you have a bulge o: someone's happy :wink: nuzzles your necky wecky~ murr~ hehehe rubbies your bulgy wolgy you're so big :oooo rubbies more on your bulgy wolgy it doesn't stop growing ·///· kisses you and lickies your necky daddy likies (; nuzzles wuzzles I hope daddy really likes $: wiggles butt and squirms I want to see your big daddy meat~ wiggles butt I have a little itch o3o wags tail can you please get my itch~ puts paws on your chest nyea~ its a seven inch itch rubs your chest can you help me pwease squirms pwetty pwease sad face I need to be punished runs paws down your chest and bites lip like I need to be punished really good~ paws on your bulge as I lick my lips I'm getting thirsty. I can go for some milk unbuttons your pants as my eyes glow you smell so musky :v licks shaft mmmm~ so musky drools all over your cock your daddy meat I like fondles Mr. Fuzzy Balls hehe puts snout on balls and inhales deeply oh god im so hard~ licks balls punish me daddy~ nyea~ squirms more and wiggles butt I love your musky goodness bites lip please punish me licks lips nyea~ suckles on your tip so good licks pre of your cock salty goodness~ eyes role back and goes balls deep mmmm~ moans and suckles

---
## [DexterHaslem/standing-desk-setter-pic16lf](https://github.com/DexterHaslem/standing-desk-setter-pic16lf)@[1afe2fe1ee...](https://github.com/DexterHaslem/standing-desk-setter-pic16lf/commit/1afe2fe1eef952d4644f7db9a4a370239956e5fe)
#### Wednesday 2021-07-14 00:05:25 by Dexter Haslem

add vl53l1x distance mode and timing budget config:

this is the absolutely worst I2C interface and 'use'
of I2C registers i've EVER seen in my entire career
and by a very large margin. whoever designed the timing
budget and distance mode registers was not in this
spacetime we share. VL53L1X is a memorable name
after all

having to set several registers to random magical values
and depending on the distance mode/timing budget instead
of simply writing the desired values to a single register
is mysterious. if this was a hobbyists first time adding
a control mcu to a sensor and interfacing with i2c or
something that'd be a different story. but this is an
expensive, long running STsensor that says state of the
art in the data sheet. it very may well be with its 940nm
invisible laser but it's hard to care when the interface
is this so insanely bad to use. I can only imagine what
kinda of internal cruft and years of legacy ineptitude
is in the way (VL53L0X prob?) from making this register
set not total ass to use.

slightly annoyed but its done. now i can set fast mode :3

---
## [willior/Action_RPG_1](https://github.com/willior/Action_RPG_1)@[d6b5dabe4e...](https://github.com/willior/Action_RPG_1/commit/d6b5dabe4ef00934ed394eadfde74a3cdf82c561)
#### Wednesday 2021-07-14 01:11:50 by willior

controls dict setup working for FormulaTargetScreen

depending on who casts, the controls get set properly.
unfortunately, this is not easy to do for the Pause menu and the Level up screen because navigating those involves control nodes and shifting focus, which is done via the input events that begin with "ui_", which are built-in to the engine. clearly, the Input system was not designed with multiplayer in mind.
i guess it might be possible to interpret player input events during menus, then depending on the Player inputting, either allowing the input event to propogate or not. i just can't think of a way of doing that cleanly.
right now the menus are coded very haphazardly.
i have had to hard-code the Pause Menu to ignore input events that correspond with the player that DID NOT open the pause screen, which is absurd. the same with the level Up screen.
even worse, these hard-coded keys to ignore do not include whether a modifier key like ALT or SHIFT is being held when the key is struck. meaning, Player1 can "confirm" Player2's buttons by holding SHIFT and pressing their attack key. it's fucking absurd, and it's fucking terrible, and i can't do fucking shit about it because the Engine is built this way. it's fucking absurdly fucking bad. it's fucking horrible.
why are control nodes inherently tied to "actions" that begin with "ui_"? why is there no way to stop that from happening? it's so fucking badly designed. it's such a colossal waste of time to have to deal with this. having to program separate input handlers JUST TO IGNORE EVERY KEY BUT THE ONES YOU WANT.
the cleanest way i can think of doing this, and it's fucking stupid, and fucking overly complex for something that should be stupidly fucking easy, is to have every "ui_" action empty by default, then assign keys to them when menus are opened, then to make them empty again when the menus disappear. i'm assuming InputMap events can even be set via code, which i don't know if they can. what a fucking nightmare and a bunch of time is going to be spent on this. fuck menus, fuck UI, fuck input events. the amount of unpredictable/straight-up fucking terrible behaviour out of these systems is mind-boggling. i cannot believe anybody can reasonably put up with how fucking awfully designed this entire mess is.

---
## [pantsbuild/pants](https://github.com/pantsbuild/pants)@[8742dfae4d...](https://github.com/pantsbuild/pants/commit/8742dfae4d104e80ce7f1003bd1b1fbe518eb0c2)
#### Wednesday 2021-07-14 01:25:53 by Eric Arellano

Add `[python-setup].experimental_lockfile` to consume lockfiles (#12316)

This allows you to use the new lockfile format, generated by pip-tools via `./pants --tag=-lockfile_ignore lock ::` and https://github.com/pantsbuild/pants/pull/12300. 

A lockfile cannot be used at the same time as a constraints file. This makes the code easier to implement and means that we don't break any prior APIs. We will likely deprecate constraints when the dust settles.

There are several major deficiencies:

- Only `pex_from_targets.py` consumes this lockfile. This means that tool lockfiles will now have no constraints and no lockfile, for now.
- Does not handle requirements disjoint to the lockfile.
- Does not support multiple user lockfiles, which, for example, is necessary to properly handle `platforms` with `pex_binary` and `python_awslambda`: we need one lockfile per platform, as demonstrated in https://github.com/Eric-Arellano/lockfile-platforms-problem/tree/main/multiple_pex__stu_proposal.


### Lockfile vs. constraints file (and `[python-setup].resolve_all_constraints`)

We're currently using pip's `--constraints` file support, which allows you to specify constraints that may not actually be used. At the same time, we default to `[python-setup].resolve_all_constraints`, which _does_ first install the entire constraints file, and then uses Pex's repository PEX feature to extract the relevant subset. This is generally a performance optimization, but there are some times `--resolve-all-constraints` is not desirable:

1. It is not safe to first install the superset, and you can only install the proper subset. This especially can happen when `platforms` are used. See https://github.com/pantsbuild/pants/issues/12222.
     - We proactively disable `--resolve-all-constraints` when `platforms` are used.
2. User does not like the performance tradeoff, e.g. because they have a huge repository PEX so it's slow to access.

--

In contrast, this PR stops using `--constraints` and roughly always does `[python-setup].resolve_all_constraints` (we now run `pex -r requirements.txt --no-transitive` and use repository PEXes). Multiple user lockfiles will allow us to solve the above issues:

> 1. It is not safe to first install the superset, and you can only install the proper subset.

We'll have a distinct lockfile for each `platform`, which avoids this situation. See https://github.com/Eric-Arellano/lockfile-platforms-problem/tree/main/multiple_pex__stu_proposal for an example.

> 2. User does not like the performance tradeoff

They can use multiple lockfiles to work around this.

--

Always using `[python-setup].resolve_all_constraints` reduces complexity: less code to support, fewer concepts for users to learn.

Likewise, if we did still want to use `--constraints`, we would also need to upgrade Pex to use Pip 21+, which gained support for URL constraints. We [hacked around URL constraints before](https://github.com/pantsbuild/pants/pull/11907), but that isn't robust. However, Pip 21+ drops Python 2 and 3.5 support: we'd need to release Pex 3 w/o Py2 support, and upgrade Pants to have workarounds that allow Py2 to still be used. To avoid project creep, it's better to punt on Pex 3.

[ci skip-rust]
[ci skip-build-wheels]

---
## [openeuler-mirror/kernel](https://github.com/openeuler-mirror/kernel)@[32adb09969...](https://github.com/openeuler-mirror/kernel/commit/32adb099691a873781ca452aae8d8eda822930ef)
#### Wednesday 2021-07-14 02:10:15 by Matthew Wilcox (Oracle)

mm: introduce and use mapping_empty()

mainline inclusion
from mainline-v5.13-rc1
commit 7716506adac4664793a9d6d3dfa31ffddfa98714
category: feature
bugzilla: https://gitee.com/openeuler/kernel/issues/I3ZE5V
CVE: NA

-------------------------------------------------

Patch series "Remove nrexceptional tracking", v2.

We actually use nrexceptional for very little these days.  It's a minor
pain to keep in sync with nrpages, but the pain becomes much bigger with
the THP patches because we don't know how many indices a shadow entry
occupies.  It's easier to just remove it than keep it accurate.

Also, we save 8 bytes per inode which is nothing to sneeze at; on my
laptop, it would improve shmem_inode_cache from 22 to 23 objects per
16kB, and inode_cache from 26 to 27 objects.  Combined, that saves
a megabyte of memory from a combined usage of 25MB for both caches.
Unfortunately, ext4 doesn't cross a magic boundary, so it doesn't save
any memory for ext4.

This patch (of 4):

Instead of checking the two counters (nrpages and nrexceptional), we can
just check whether i_pages is empty.

Link: https://lkml.kernel.org/r/20201026151849.24232-1-willy@infradead.org
Link: https://lkml.kernel.org/r/20201026151849.24232-2-willy@infradead.org
Signed-off-by: Matthew Wilcox (Oracle) <willy@infradead.org>
Tested-by: Vishal Verma <vishal.l.verma@intel.com>
Acked-by: Johannes Weiner <hannes@cmpxchg.org>
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Liu Shixin <liushixin2@huawei.com>
Reviewed-by: Tong Tiangen <tongtiangen@huawei.com>
Signed-off-by: Zheng Zengkai <zhengzengkai@huawei.com>

---
## [newstools/2021-naija-news-agency](https://github.com/newstools/2021-naija-news-agency)@[a2e4098a6e...](https://github.com/newstools/2021-naija-news-agency/commit/a2e4098a6ebc80528c14f3545155351954473dd5)
#### Wednesday 2021-07-14 08:47:51 by Billy Einkamerer

Created Text For URL [naijanewsagency.com/sad-story-how-solider-allegedly-rapes-kills-girlfriend-and-cut-off-her-finger-over-cheating/]

---
## [maborak/iemaddon-installer](https://github.com/maborak/iemaddon-installer)@[2d047a3583...](https://github.com/maborak/iemaddon-installer/commit/2d047a3583c9fb23bde8adb1b131b9b83e02aa0f)
#### Wednesday 2021-07-14 09:15:11 by Wilmer Adalid

Updates for: A woman has got to love a bad man once or twice in her life to be
thankful for a good one.
		-- Marjorie Kinnan Rawlings

---
## [scylladb/scylla](https://github.com/scylladb/scylla)@[9d07ce3cb6...](https://github.com/scylladb/scylla/commit/9d07ce3cb6de8493c246423f54f2814e75373812)
#### Wednesday 2021-07-14 11:57:56 by Nadav Har'El

test/alternator: add marker for "veryslow" tests

Until now, Alternator test have all been very fast, taking milliseconds
or at worst seconds each - or a bit longer on DynamoDB. However,
sometimes we need to write tests which take a huge amount of time - for
example, tests for the TTL feature may take 10 minutes because the item
expiration is delayed by that much. Because a 10 minute test is
ridiculous (all 500 Alternator tests together take just one minute
today!), we would normally run such test once, and then mark it "skip"
so will never run again.

One annoying thing about skipped tests is that there is no way to
temporarily "unskip" them when we want to run such a test anyway.
So in this patch, we introduce a better option for these very slow tests
instead of the simple "skip":

The patch introduces a marker "@pytest.mark.veryslow". By default, a
test with this marker is skipped. However, an command-line option
"--runveryslow" is introduced which causes tests with the veryslow
mark to be run anyway, and not skipped.

Signed-off-by: Nadav Har'El <nyh@scylladb.com>

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[75d69107a8...](https://github.com/mrakgr/The-Spiral-Language/commit/75d69107a87fb3619bf2fea11e056a51654ecae0)
#### Wednesday 2021-07-14 16:13:53 by Marko Grdinić

"10:40am. I am so tired from going to bed early. It was so hard to fall asleep as my brain was working at full blast. Let me chill a bit here first and then I'll watch the UCB video.

I've decided what I want to do. Instead of doing a curriculum, I'd be much better off in reducing the variance through full TD learning.

11:25am. Dex is finally updating again and I am catching up with Kaiji.

11:55am. Let me have breakfast here. I'll watch the vid while I eat.

12:35pm. The UCB algorithm is different from the SAU one as it does not incorporate variance in its decision making.

Based on that SAU-UCB is definitely superior to the original one. Damn, I wish I could have figured it out myself, figuring this out is a great accomplishment.

Me? I only fail.

Here are my current thoughts - I spent a lot of time mastering tabular CFR, but once I've come to Holdem, I was deeply disturbed that it cannot train even against the static callbot. The places where it was successful was where the sequences were either 1 (Flop vs callbot) or 2-3 at most (Flop vs self).

A part of it might be due to the architecture, but even with a MLP it should be able to beat the callbot. This should not be that difficult.

Also I bet it would work better if I only train it on the last round of the episode. It is a given that the MC behavior of CFR is what is creating these difficulties. In the tabular regime, the variance of the magnitudes caused by the importance sampling is not a problem, but in the neural regime where that states can be recursive and the nodes are heavily shared, that is a huge problem.

I can think of a few solutions to the problem of training on Holdem:

* Train it on a smaller game like Flop or River vs a callbot so it learns to hand read first and then move to full Holdem.
* Train it on just the last round of the Full Holdem game.

But really the main problem is the variance of MC training. The real solution is to just use Q learning to cut the variance down. I need to ditch the VR MCCFR updates in favor of something that stands a chance of working with NNs.

12:55pm. Sigh, I could have just done this from the start and it would have saved me a lot of effort.

You win some, you lose some. I've at least managed to figure out the semi tabular updates. That will give me an enduring advantage. And I am really lucky to find the SAU paper.

1:10pm. Doing some Reddit posting. I'll also post the AGAC paper. But before I do that, what is M supposed to be?

1:15pm. I have no idea. Let me just post it with the flair the previous paper had.

1:25pm. Ok, with that out of the way, I need to aright my thinking.

I've made my resolve replace the MCCFR style of doing things. I am thinking whether I should go full Q learning for the actor updates, or whether I should include the MC return on the action that was selected, and I am thinking I'll go all the way this time.

I'll go all the way.

1:30pm. I am going to finish this. The SAU paper has given me a lead on how to do exploration. The noisy key idea that I had even if I managed to tune the noise input somehow would still be a MC method in the end.

Losing the policy would be too much of a loss

1:40pm. There is something that comes to mind. Previously, I would be multiplying by the policy probability, but now I should consider propagating the max Q value.

For the net that is not being optimized, I should use the usual VR MCCFR update. So I'll get something from that at least.

1:55pm. The CQL paper is so complicated, I can barely tell what the algorithm is. Forget it.

2:05pm. I think enumerative CFR would have worked if for the agent being trained I returned the max value instead. The way it was structured though it is supposed to work for simultaneous updates and that is where returning the max Q value would break.

I think that actually returning the max value would reduce the variance for the actor since there is less moving around based on the future self actions.

From the perspective of RL being reasoning, it certainly makes sense to propagate the max value instead of the action probability value. One of the reasons for the noisy key idea was that - this would not be the case in reality, but in theory having fully deterministic actions would allow it to plan ahead.

2:45pm. Had to take a break.

Yeah, definitely - Q learning will work for learning poker agents. But the really important part is the variance reduction aspect of the VR MCCFR update for the opponent! This is probably why past attempts at making Q learning work on multiplayer games failed. I've been thinking about it and concluded that if the sample prob is equal to the policy prob, and the agent is good at predicting, that will act to contract the values being passed on.

2:50pm. If I go with my idea I will have function approximation, off policy updates and bootstrapping. The deadly triad in full bloom.

2:55pm. I do not have any choice, but to go down this route. I already know that MC will not cut in on Holdem. The architectural innovations that I've done will have to be the ones to overcome the triad. It will work. I should just believe in myself and try one last time. At the end of this I will either have the superhuman agent and will be able to proceed with my plan, or I will give up and get a job.

3:05pm. I am so tired. Let me take a nap here. I'll finish rolling the Q learning ideas in my head and attune myself to the transformers. Today I won't stop at 6pm either. Once I start, I'll deal with the transformers quickly and get through all of this. Even with all my hesitation, being done with all of this by the end of the month is doable.

...

I am thinking back to the Baird's counter example. Yes, the linear inputs can make it diverge, but consider what was going on. There were a bunch of one hot vectors, and there there was a two hot vector at the end. With the gradient update rules that would lead to the credit being assigned twice. It is like having a channel that amplifies the incoming signal.

Instead if the input was probabilistic I doubt the blow up would have happened.

As trite as it seems, the semi tabular updates I've come up with could overcome the issues with Q learning, both the instability and overestimation.

3:10pm. When I said in one of the previous updates that the algorithm was complete, I really was arrogant. I am just a frog in the well in the end. I need to work on climbing out of it.

5pm. Was I in bed this long? This is so harsh on me. It is not easy to keep doing this.

I've made some decisions. I am not going to propagate the max value, instead I'll weight it by the policy probs just as before. The reason for that is that if I propagate the max values then the opponent will not have the proper weightings when it passes through it.

So even if is a bit less optimal from the ideal reasoning perspective, the opponent variance will be a lot better if did it like this. I could train two value nets one max and one policy prob, but I do not want to increase the computation. It will work either way, and adding more modules is just increasing my risk. It is more important that it works, than that it works well.

And it will work well either way.

The other thing I want to talk about is my failed attempt to break into 4/5 with upside down RL.

The decision transformer would make completely sense if it was an energy based model. In an energy based model, I could just clamp the actions and observe what the rewards end up being. Or have a reward slot for each action.

Furthermore, having the action predictor not give good results when I take its features for a linear actor freaked me out. I remember how in the greedy infomax paper they got good results by interleaving the layers, but that is not the solution. What is needed is a gurantee that if one module updates, the other won't be damaged.

It was a blow to me that I keep thinking about.

If there is a module B (some RL agent) on top of a module A (some GAN agent), meaning that B is using A's features, like having connections to the top layer of the discriminator then the updates to the GAN agent will inevitably damage B's performance.

There are some solutions like interleaving layers, or doing the updates in tandem, but none that strikes a chord with me.

I understand well enough - a NN is like a program. A change in some part will inevitably necessitate refactoring that could potentially require changes throughout the whole system. This is a principle of programming.

And without this, composing modules is out of the question. This is a problem with deep learning. It is successful at many things, but ultimately all these tasks are toy ones. And where it has been successful, it has been one goal at a time.

5:15pm. Deep learning does not have an answer to composability of modules much like it does not have an answer to the long term credit assignment issue.

Energy based models do. In the brain, the real inputs would carve out energy valleys through the manifold. Then to do task specific learning, all the brain has to do is let the water flow like a river through those valleys. There is no need to keep around traces. The weights themselves are the ideal traces.

Enegy based models also have an answer to problem of module composability. If the GAN training in such a model wanted to change the composition of itself, then the energy changes would be propagated to all its connectors. This is different than in a deep need where all the connections are forward, and backprop just goes the trace build by them. Energy changes would be effected through the entire model and there would not be distinctions between the forward and backward connections.

5:20pm. It is not that the human brain a complete mystery. We just do not have the hardware to run those kinds of models. And we do not have the algorithms to emulate them on the GPU.

I might not know the algorithms the brain uses, but I know quite a lot about its operating principles despite that, derives purely through the power of imagination. I know what is right and wrong.

I know what I need to break through to 4/5. I need better algorithms and I need better hardware for this different breed of models. If I can fulfil those requirements I could firmly solidify my position in that realm. Then I'll be able to think about 5/5, and that realm is the last of humanity. Saying I could step into 5/5 would be like saying I could cause the Singularity.

5:25pm. Maybe it is ironic, but the knowledge discovered in deep learning is rather generic and should carry over into the next realm.

Right now, I feel it is hopeless to try and combine unsupervised learning with RL. Deep learning just violates principles of composability. It makes sense on isolated tasks, but does not scale beyond that.

5:35pm. Why are there so many stupid trash ML papers? I read the Loco paper and start thinking that interleaving layers is the answer to composability issues. Do 90% of all ML papers just exist to mislead the reader?

I only noticed the problem with my assumptions because I keep obsessively thinking about it. One one hand I am a fool for important principles of learning, but on the other hand I am a genius for being able to feel them out at all. But a feeling is just a feeling, to move forward I need the algorithms.

The Inspired get the glory, and the pursuers get the struggle.

5:40pm. I guess I'll embrace it for one last try. I know I am at my limit with deep learning. It will never be realistic for me to train billion parameter models on GPUs on timescales it would take for intelligence to emerge. Its too much to expect that complex intelligent systems will be trainable using backprop.

So one more try is all I need. I just need enough to master Holdem.

I won't bother stuggling to plug an RL agent on top of a GAN and things like that. When it is time to tackle Dota and Starcraft, I will be sure to do it deep from the 4/5 realm.

6pm. Done with lunch. I think I will close here at the usual time. Tomorrow, I will see whether I can finaly get started on the transformers.

Just one more step, that is all I need to take and then I will be done with the deep learning nonsense.

6:05pm. Master Holdem. If I can deal with a game on such scale, I'll solve my small money problems in one swoop. Wouldn't it better to end the chapter with a success rather than a failure? It is too harsh to go through life failing and living day to day like an animal. Life is sweet when a plan comes together.

6:10pm. Tomorrow, I am going to give it my all to put a toy transformer together. And I will try it out on Leduc. If that woks I will follow up my success by making a multiheaded transformer. One I have that, I'll have everything I need.

None of this is hard. I thought it through. I just need to find the courage to take one step forward."

---
## [Yurk-do/New](https://github.com/Yurk-do/New)@[11b04198ef...](https://github.com/Yurk-do/New/commit/11b04198efdefdc716c1e424cf77c22febb5a298)
#### Wednesday 2021-07-14 19:46:49 by Yurk-do

Merge pull request #2 from Yurk-do/develop2

fuck you

---
## [khonsulabs/pliantdb](https://github.com/khonsulabs/pliantdb)@[4455df17b5...](https://github.com/khonsulabs/pliantdb/commit/4455df17b5e72c86c0a63f275ffa55b3ee281809)
#### Wednesday 2021-07-14 20:18:58 by Jonathan Johnson

Initial implementation of the vault

This branch is working towards user authentication. Daxpedda's excellent
custodian-password crate uses a system in which the server needs to
persistently store a file that essentially is a private key file of
sorts. This isn't exactly true, because of the nature of how OPAQUE-PAKE
works, there is no actual data leaked if the file is compromised.
However, with it, someone in theory could issue login challenges if
they could get a legitimate client to connect to their endpoint, so, I
wanted to store it securely.

A couple of weeks ago, I opined about at-rest encryption
(https://community.khonsulabs.com/t/at-rest-encryption/68), and I
decided this was the best time to start down this path.

This initial commit is very rough, and it doesn't solve all the
problems. However, it's at a good stopping point, and some games are
calling. Here's what this *does* accomplish:

- Implements random key generation, and payload encryption using what my
research shows is the current leading technology (although not fully
audited in the Rust ecosystem yet). Given this is an experimental
database, it seemed prudent to adopt what will likely be the standard in
the coming years. This is provided by the excellent chacha20-poly1305
crate. We are using XChaCha20-Poly1305 to be specific, with randomly
generated nonces.
- All of the key types implement Debug without logging the actual
values.
- Creates a sealing Vault type that provides a separation of master key
storage from the vault.
  - During first initialization, a master key and a sealing key are
  randomly generated. The master key is encrypted using the sealing key,
  and stored on the MasterKeyStorage. The sealing key is stored locally
  on the filesystem inside of the database. This storage mechanism
  ensures that if the master key storage is compromised, the master keys
  are not actually lost.
  - On subsequent initialization, the master key is retrived from the
  MasterKeyStorage. The local sealing key decrypts the master key.
- Creates a unique id mechanism to identify the database uniquely. This
will be useful when multi-server setups are a thing. The
MasterKeyStorage stores each server's master keys independently, and
each server has its own unique sealing key. In general, the randomly
generated value should work great, but there is a configuration option
to override it.
- Begins creating the network types for CreateUser/Login, hooking up
custodian-password.

Sounds great, right? But, there's a lot left. I started thinking the
Vault was a server-only feature. That's one todo left: fix all the docs
that imply references to server things. But, that's easy.

When updating the Document header to contain the information necessary
to decrypt the document, I realized that once I had key-rolling features
that each key could have multiple versions. I'm not a cryptographer, I
just know that many smart people recommend rotating cryptographic keys
at least annually. So, the document is going to need to know the id of
the key, but also the specific revision of the key.

See, I knew this, but I didn't think of it when I wrote the initial
master key code, and when it hit me, I was in a different area of code.
At the time, I thought, "I can finish an initial version without it."

Lastly the actual encryption/decryption of documents needs to be
handled. The idea I had is to move all the serialization and
deserialization into a single method, and put the encryption code in
that method. I haven't figured out how I want to store the nonce that
will be generated during this. The only thing I know is that it should
be part of the encrypted contents payload, not part of the header. The
nonce shouldn't leave the server.

Once this is working, we can simply store a PasswordConfig using
KeyId::Master, and it will encrypt the document using the master key.

The last elephant in the room is permissions. Currently, local has no
concept of permissions. I had a dream that encryption and decryption
would check permisions to use these keys. This would mean that local
needs to understand permissions at some level. I'm just not sure how I
want that to work.

---
## [DaveFeed/DanBotHostingStats](https://github.com/DaveFeed/DanBotHostingStats)@[ae61df307e...](https://github.com/DaveFeed/DanBotHostingStats/commit/ae61df307e0fe220c3a88bc8937e80023d5b2f23)
#### Wednesday 2021-07-14 21:11:08 by Dave

Fixed the worst bug ever

This fucking typo was making me go wild, thank god its being fixed by a god programmer like me. Holy god, please accept this as a good deed so i can get to heaven fast. Thanks <3

---
## [LeonardGombert/KUBIKA](https://github.com/LeonardGombert/KUBIKA)@[847c646cc1...](https://github.com/LeonardGombert/KUBIKA/commit/847c646cc15be2b8fcb5ebff1ae1dc260d2d2f01)
#### Wednesday 2021-07-14 22:05:01 by Léonard

Game Camera is another giant problem. I don't know how I'll finish this.

Seriously, I feel like every step I take, I'm thrown back 12. I just spent the entire day and all of last night trying to get movement up and running, and I'm still not satisfied with the result. The code isn't clean - hardly legible, it's full of small necessary patchwork fixes that are necessary to get the machine running. All of that frustration later, only to discover that maybe non of what I'm doing is really that efficient. The Game Camera is going to be a massive pain because I've locked myself in this tiny shitty little box with constraints left and right. The simple solution would be to rotate the Kubo struture on its Y axis, but I can't do that because then none of the cubes know where the fuck they are anymore, and things go haywire.
The solution seems not only complex, but way out of reach for the moment. All this for a mechanic that should be simple. Trivial. Nothing to even really worry about.

It's killing me bruh.

---
## [m-hops/summer-2021-research-project](https://github.com/m-hops/summer-2021-research-project)@[9a3e4f6ec9...](https://github.com/m-hops/summer-2021-research-project/commit/9a3e4f6ec949e6c0db7ddc1c0bb2fa049a6470eb)
#### Wednesday 2021-07-14 22:22:11 by rabbit-isdead

V00717 - 2021-07-14

PAPER PROTOTYPING IS NEARLY COMPLETE.

AS IT STANDS, I HAVE MEDICAL CHARTS, FINANCIAL INCENTIVES, PERSONAL INCENTIVES, AND SOME MORAL INCENTIVES FINISHED, BUT I'M STILL MISSING ONE FACTOR. I DON'T FEEL THE GAME HAS ENOUGH WEIGHT BEHIND THE MORALITY OF THE CHOICES THE PLAYER MADE, BUT I WANT TO AVOID DICTATING MORALITY AS MUCH AS POSSIBLE.

THE FEELING I WANT THE PLAYER TO HAVE IS MORE ON THE SIDE OF THE MORALITY OF CHOOSING ONE LIFE OVER ANOTHER AND THEN LET THE PLAYER REFLECT ON THOSE FEELINGS AT THE END. TO THAT EFFECT, I HAVE DECIDED TO INCLUDE BASIC DEMOGRAPHIC INFORMATION TO EACH CHARACTER THAT WILL BE RELAYED TO THE PLAYER AT THE END SO THEY CAN REFLECT ON THEIR DECISIONS. AN EXAMPLE WOULD BE:

    YOU SAVED 15 PEOPLE
    YOU DONATED 3 PEOPLE
    YOU WERE MORE LIKELY TO SAVE SOMEONE WITH MORE WEALTH
    YOU WERE LESS LIKELY TO SAVE SOMEONE WITH MORE LONGEVITY
    ETC.

AS I WRITE THIS, I JUST REALIZED A POTENTIAL SOLUTION TO THE AFOREMENTIONED ISSUE OF HOW TO LEVY THE FULL MORAL WEIGHT OF THE PLAYERS DECISIONS. I'M GOING TO CREATE A LIMITED INSTRUCTION SET FOR THE GAME THAT DOESN'T MENTION WINNING CONDITIONS BUT ONLY RESPONSIBILITIES AND TIME FRAME. HOPEFULLY THIS CREATES AN ENDING WHERE IT'S LESS OF WHETHER YOU WON OR LOST, BUT MORE YOU'VE COME TO THE END AND NOW YOU NEED TO REFLECT ON YOUR DECISIONS.

TONIGHT I WILL START WORKING ON SKETCHING OUT THE WORKFLOW OF THE ENGINE AND HOW ALL THE PIECES INTERACT WITH EACH OTHER. SPEAKING OF THE ENGINE, THERE APPEARS TO BE BOTH GOOD AND BAD NEWS ON THAT FRONT. THE GOOD NEWS IS MENU STATES, MUSIC CONTROL, ANIMATION SYSTEM, AND DIALOG BOXES ARE ALL THINGS THAT CAN BE USED PRETTY MUCH AS IS. THE BAD NEWS IS I WILL HAVE TO COME UP WITH A NEW JSON INPUT SYSTEM FOR THE NPCS AS THE MOST EFFICIENT WAY TO LINK EVERYTHING UP WOULD BE TO HAVE A SINGLE JSON FILE FOR EACH CHARACTER THAT IS ACCESSED AND MODIFIED BY THE APPS IN GAME. CONSIDERING I (SOMEHOW) MANAGED TO FIGURE OUT HOW TO MAKE IT WORK IN A BASIC SENSE, I THINK I CAN MAKE THIS HAPPEN.

---
## [tauds/Google-Play-Store-apps-and-reviews](https://github.com/tauds/Google-Play-Store-apps-and-reviews)@[31cbcd8e55...](https://github.com/tauds/Google-Play-Store-apps-and-reviews/commit/31cbcd8e553cf995a3870b226206d3918c887220)
#### Wednesday 2021-07-14 22:26:24 by tauds

Create 10. Sentiment analysis of user reviews

Mining user review data to determine how people feel about your product, brand, or service can be done using a technique called sentiment analysis. User reviews for apps can be analyzed to identify if the mood is positive, negative or neutral about that app. For example, positive words in an app review might include words such as 'amazing', 'friendly', 'good', 'great', and 'love'. Negative words might be words like 'malware', 'hate', 'problem', 'refund', and 'incompetent'.

By plotting sentiment polarity scores of user reviews for paid and free apps, we observe that free apps receive a lot of harsh comments, as indicated by the outliers on the negative y-axis. Reviews for paid apps appear never to be extremely negative. This may indicate something about app quality, i.e., paid apps being of higher quality than free apps on average. The median polarity score for paid apps is a little higher than free apps, thereby syncing with our previous observation.

In this notebook, we analyzed over ten thousand apps from the Google Play Store. We can use our findings to inform our decisions should we ever wish to create an app ourselves.

---
## [tauds/DataCamp-Analyzing-TV-Data](https://github.com/tauds/DataCamp-Analyzing-TV-Data)@[f69ec8e438...](https://github.com/tauds/DataCamp-Analyzing-TV-Data/commit/f69ec8e438e1dbe14ec7c28d8fb8bd30c7fd56ba)
#### Wednesday 2021-07-14 22:41:08 by tauds

Create 1. TV, halftime shows, and the Big Game

Whether or not you like football, the Super Bowl is a spectacle. There's a little something for everyone at your Super Bowl party. Drama in the form of blowouts, comebacks, and controversy for the sports fan. There are the ridiculously expensive ads, some hilarious, others gut-wrenching, thought-provoking, and weird. The half-time shows with the biggest musicians in the world, sometimes riding giant mechanical tigers or leaping from the roof of the stadium. It's a show, baby. And in this notebook, we're going to find out how some of the elements of this show interact with each other. After exploring and cleaning our data a little, we're going to answer questions like:

What are the most extreme game outcomes?
How does the game affect television viewership?
How have viewership, TV ratings, and ad cost evolved over time?
Who are the most prolific musicians in terms of halftime show performances?
Left Shark Steals The ShowLeft Shark Steals The Show. Katy Perry performing at halftime of Super Bowl XLIX. Photo by Huntley Paton. Attribution-ShareAlike 2.0 Generic (CC BY-SA 2.0).

The dataset we'll use was scraped and polished from Wikipedia. It is made up of three CSV files, one with game data, one with TV data, and one with halftime musician data for all 52 Super Bowls through 2018. Let's take a look, using display() instead of print() since its output is much prettier in Jupyter Notebooks.

---
## [GerHobbelt/qiqqa-open-source](https://github.com/GerHobbelt/qiqqa-open-source)@[2bed2e8693...](https://github.com/GerHobbelt/qiqqa-open-source/commit/2bed2e869362bd47721b8f9aeea2ec7ea7346f25)
#### Wednesday 2021-07-14 23:12:03 by Ger Hobbelt

trialed Obsidian (https://obsidian.md/) after having read about it and other PKM tools and having dissatisfactory experiences with others in previous years: hooked. doc-src subjected to an evening of working with OBsidian. Lovely! (Obsidian b0rks with black screen on original doc-src/ tree so I had to mess about to make it behave. Whether it's the fonts submodule or the getsatisfaction HTML postprocessed mirror, I don't know, but this way Osidian was working as expected.

---

# [<](2021-07-13.md) 2021-07-14 [>](2021-07-15.md)

