# [<](2021-07-28.md) 2021-07-29 [>](2021-07-30.md)

2,872,566 events, 1,443,647 push events, 2,338,469 commit messages, 170,545,850 characters


## [NoComment1105/periodic-mod-minecraft](https://github.com/NoComment1105/periodic-mod-minecraft)@[71f79ae8fc...](https://github.com/NoComment1105/periodic-mod-minecraft/commit/71f79ae8fc5c8312dd5f3a97502e759d15d677bf)
#### Thursday 2021-07-29 04:35:59 by NoComment1105

Update Loom + Quiltflower

Fuck you Fernflower, it's time for **Quiltflower**

---
## [mrakgr/The-Spiral-Language](https://github.com/mrakgr/The-Spiral-Language)@[ab8c58b270...](https://github.com/mrakgr/The-Spiral-Language/commit/ab8c58b2709e7cf2eadb9e13077cf4ff7ee1a452)
#### Thursday 2021-07-29 10:12:34 by Marko Grdinić

"8:20am. I went to bed later than usual yesterday and got up earlier than usual. Right now I am super groggy. Maybe I'll go back to bed for an hour or so.

9:35am. I went to bed for a bit, but I did not get rest. At best, in these situations all you can do is get over the groginess.

10am. Let me finally start.

I will dedicate myself to making another dent in this today. In the end, maybe I will win. Maybe I will lose. But I can be sure that I am going to complete my theme of making a NN which only weights things against each other. NNs should be relative, not absolute.

Come to think of it, the semi tabular update for the state probability gradients themselves that I had originally was that kind of thing. It was matching with the theme, but it did not work well so instead I went for the backprop update instead.

That was the first chink in the armor - violating the theme I set out to embody.

But categorical DRL matches it exactly and without flaw. The only critism of the original algorithm that I could make is that it uses the linear basis instead of the exponential one, but that is something I've corrected.

Once I implement categorical DRL and replace `log_softmax` with `catpow`, my journey here will be complete. I'll be done with programming the agent instead and will be able to focus on training it.

I won't be able to exceed what I here very easily. If there are significant improvements to be made, the inspiration for them will have to come from the outside. Yes, there is merging what I have here with unsupervised representation learning, but I do not know how to compose that in a smooth manner in a deep learning setting.

It will also be computationally demanding and I do not have what it takes to meet them right now. This matter is a future one. I'll seriously consider it once I get my hands on AI chips.

10:15am. Shall we end it? I started this journey towards becoming a good programmer 6.5 years ago. But my original intent was always RL itself. I tried filling in the self perceived holes in my panoply of skills, but in the end what I have to do to win is simple.

Implement the agent. And then do real world RL like I said I would. There is no need for excuses over how long it took. There is no need to feel sadness over not getting to this level a decade ago.

I might end up living for an eternity and this short segment of my life will be an insignificant blip on the timeline. I might live forever, but under the condition that I do not stop pursuing power now.

Just what is a decade or two for somebody who lives for trillions of years? And no fixed amount hoever large can compare to eternity. When you live forever, the only thing that matters in your survival is your own will. Boredom, depression and lethargy are just spooks. There is no way God would ever get bored.

10:25am. Eternal Life with the Inspired Desire would be true heaven. Let me pursue it.

```
inl vs_self (combine, to_cat, empty : _ * (_ -> tensor) * _) game (batch_size, p) =
```

Let me move these arguments to the right.

```
inl vs_self game (combine, to_cat, empty : _ * (_ -> tensor) * _) (batch_size, p) =
```

Good. Now I'll be able to partially apply the game.

```
inl Game =
```

I want to put a join point on these games.

```
let game x = game () x
```

Let me do this.

```
let game a b = game a b
```

And this for Holdem. This should squeeze down the size of the game in the compiled code.

10:40am. Ok, focus me. I moved those arguments. Now I need to add the cat versions.

```
open leduc
type present = list (choice2 card action)
type future = list (choice2 card card)
type agent_dict = agent.tabular.agent_dict present future
inl main () =
    inl vs_self = namedtuple "VsSelf" {scalar=train.vs_self leduc.game; cat=train_cat.vs_self leduc.game}
    inl vs_one = namedtuple "VsOne" {scalar=train.vs_one leduc.game; cat=train_cat.vs_one leduc.game}
    inl neural = train.neural agent.neural_leduc.extractor agent.neural_leduc.schema()
    inl uniform_player : ra u64 (pl2 card action * leduc_state * u8 * a u64 action) -> a u64 (log_prob * action) * (a u64 r2 -> a u64 r2) =
        agent.uniform.policy
    inl tabular =
        inl create_policy : agent_dict * bool * bool * f32 -> ra u64 (pl2 card action * leduc_state * u8 * a u64 action) -> a u64 (log_prob * action) * (a u64 r2 -> a u64 r2) =
            agent.tabular.policy agent.neural_leduc.extractor
        inl create_agent () : agent_dict = dictm.empty
        inl optimize : agent_dict -> () = agent.tabular.optimize
        inl average : agent_dict * agent_dict -> () = agent.tabular.average
        inl head_multiply_ : agent_dict * _ -> _ = agent.tabular.head_multiply_
        namedtuple "Tabular" {create_policy create_agent head_multiply_ optimize average}

    record {vs_self vs_one neural uniform_player tabular}
```

This is good.

```
    inl vs_self x = namedtuple "VsSelf" {scalar=train.vs_self (game x); cat=train_cat.vs_self (game x)}
    inl vs_one x = namedtuple "VsOne" {scalar=train.vs_one (game x); cat=train_cat.vs_one (game x)}
```

Here is the holdem version. Let me compile the Leduc version and then I will take a look at `control_leduc`.

10:55am.

```py
    def run(is_avg=False):
        static = neural_player(neural,modules,model_exploit)
        for _ in range(5):
            eval(neural_player(neural,modules,model_explore,True,False),static)
        # eval(neural_player(neural,modules,model_explore,False,True),static)
```

Let me just go through updating of the value nets for now.

```
for _ in range(iter_batch): vs_one.cat(batch_size,pla,plb); vs_one(batch_size,plb,pla)
```

Right it does not have to be vs one. It can be vs_self just as well if I am passing TD values through.

```
    // `exp`ected and `cat`egorical
    inl vs_self = namedtuple "VsSelf" {exp=train.vs_self leduc.game; cat=train_cat.vs_self leduc.game}
    inl vs_one = namedtuple "VsOne" {exp=train.vs_one leduc.game; cat=train_cat.vs_one leduc.game}
```

Let me actually do it like this.

11:10am. Ok, I've adjusted control Leduc. Let me take a short break and I will run the thing for the first time. I need to mentally prepare myself for the debugging session. After I get through it, I will have the categorical DRL agent working.

11:35am. I am back. I knew I forgot something - the projector. I also realized what the poor feeling I had yesterday was.

```py
    def to_cat(self,r,device='cuda'):
        """
        Creates the categorical eqivalent of a scalar float Numpy vector.
        """
        da, = r.shape
        x = torch.zeros(da,self.num_supports,device=device)
        x[:,self.half_dim] = 1.0
        return self.add(x,r.view(da,1))

    def combine(self,*args):
        """
        Args are supposed to be index list/PyTorch tensor flattened pairs.
        """
        assert 1 < len(args), 'Expected two args at least.'
        assert len(args) % 2 == 0, 'Expected an even number of args.'
        c = 0
        for i in range(0,len(args),2): c += len(args[i+1])
        x = torch.empty(c,self.num_supports,dtype=args[1].dtype,device=args[1].device)
        for i in range(0,len(args),2):
            a, b = args[i], args[i+1]
            assert len(a) == len(b), 'Expected the pairs to have the same outer dimension.'
            x[a] = b
        return x

    def empty(self,device='cuda'):
        """
        Returns a tensor of size zero that has the number of supports the projector has.
        """
        return torch.empty(0,self.num_supports,device=device)
```

While I was writing `torch.empty(c,self.num_supports,dtype=args[1].dtype,device=args[1].device)` I really got the sense that I was making a mistake getting the device and the type from the arguments themselves, but I could think of an alternative.

I could have gotten that information from the support.

```py
    def to_cat(self,r):
        """
        Creates the categorical eqivalent of a scalar float Numpy vector.
        """
        da, = r.shape
        x = torch.zeros(da,self.num_supports,device=self.support.device)
        x[:,self.half_dim] = 1.0
        return self.add(x,r.view(da,1))

    def combine(self,*args):
        """
        Args are supposed to be index list/PyTorch tensor flattened pairs.
        """
        assert len(args) % 2 == 0, 'Expected an even number of args.'
        c = 0
        for i in range(0,len(args),2): c += len(args[i+1])
        x = torch.empty(c,self.num_supports,device=self.support.device)
        for i in range(0,len(args),2):
            a, b = args[i], args[i+1]
            assert len(a) == len(b), 'Expected the pairs to have the same outer dimension.'
            x[a] = b
        return x

    def empty(self):
        """
        Returns a tensor of size zero that has the number of supports the projector has.
        """
        return torch.empty(0,self.num_supports,device=self.support.device)
```

I must have gotten too tired too think properly towards the end of yesterday's session. It happens.

Now let me plug the projector into the module list.

```
avg_modules = list(map(lambda x: AveragedModel(x,avg_fn=avg_fn),modules))
```

Instead of a map, let me use a list comprehension here.

```
        value.square_l2.fill_(0.0)
        value.t.fill_(0.0)
```

Let me clean this up. I'll put it in the head.

```
            if value_head.track_errors:
                value_head.square_error += ((index_selected_actions(values) - proj.mean(rewards)).square() * regret_probs).sum()
                value_head.square_error_count += regret_probs.sum()
```

This is cleaner now.

11:55am.

```py
def neural_create_model(size,dim_head=2 ** 4,dim_emb=2 ** 5):
    proj = LinearProjector(13,27)
    value = EncoderList(0,dim_head,dim_emb,size.value)
    value_head = Head(dim_head*dim_emb,size.action,27,8,True)
    policy = EncoderList(0,dim_head,dim_emb,size.policy)
    policy_head = Linear(dim_head*dim_emb,size.action)
    return proj.cuda(), value.cuda(), value_head.cuda(), policy.cuda(), policy_head.cuda()
```

I swapped value and policy heads by accident perviously. After I am done with this, I'll consider modifying TopEncoder so it has residual connections and uses inf cube activations.

```py
    def mse_clear(self): self.square_error.fill_(0.0); self.square_error_count.fill_(0.0)
    @property
    def mse(self): return (self.square_error / self.square_error_count).sqrt_()
    @property
    def mse_and_clear(self): x = self.mse; self.mse_clear(); return x
```

```py
list(map(lambda x: x.module,avg_modules))
```

```py
with open(f"dump leduc/nn_agent_{i}.nnavg",'wb') as f: torch.save([x.module for x in avg_modules],f)
```

Let me replace that list map with a list comprehension here.

Ok...

It is strange how Python has something taken straight from Haskell.

```py
vs_self, vs_one = vs_self.cat(proj.combine,proj.to_cat,proj.empty), vs_one.cat(proj.combine,proj.to_cat,proj.empty)
```

This should do it.

12:10pm. At this point I think I am ready to actually try running it.

Instead grinding that right now, let me have breakfast and then I will start debugging after I am done."

---
## [Spixa/Suschat](https://github.com/Spixa/Suschat)@[7c76ea0113...](https://github.com/Spixa/Suschat/commit/7c76ea011309159d7f9a963bd135284d73662493)
#### Thursday 2021-07-29 11:22:23 by phnixir

RUST GUI CLIENT HAS STABILIZED!!!!

- rust gui can read and send to the server
- rust gui looks absolutely stunning
- i love the rust gui
- linted and rustfmt'd the rust gui source code, it still is unreadable garbage but eh
- moved rust gui to clients
- adjustments to .gitignore

---
## [jappavoo/bu-cs-book-dev](https://github.com/jappavoo/bu-cs-book-dev)@[7db0717e47...](https://github.com/jappavoo/bu-cs-book-dev/commit/7db0717e476c6e96b615f89daecc1894fc066b23)
#### Thursday 2021-07-29 13:50:18 by Jonathan Appavoo

With much pain seem to have "found" a config that both works on
opf and meets all my constraints.
1)  Not sure why my previous version of the bu-cs-book-dev failed
    to start properly on opf.  I assume something got screwed up
    on version of packages with respect to the juypterhub-singlesever
    not starting correctly.  What I observed was that the container
    got started but then things hung/timed out which assume is because
    the jupyterhub-single server did not start correctly.
    However, if I used my prior conda based version but using pip
    to install jupyter-books I got all the right version of jupyter-books,
    all my extensions started and it boots correctly on opf

2) Things are now sperated into three images
   a) bu-cs-book-dev-base : from jupyter-minimal plus all the linux
      packages I want the user to have : gcc, vim, emacs, etc.
   b) bu-cs-book-dev-base-unmin: from above but with the unminize
      command run... blots image but ensures that manpages are
      available -- makes the container feel more like a full fledged
      UNIX system for a terminal based user
   c) bu-cs-book-dev: from bu-cs-book-dev-base-unmin plus all my
      customization to make the user experience a little nicer
      - adds all the python packages and enable various jupyter notebook
        extension that I think should be
        there and that the SLS books require.
      - ensure that joyvan home dir has the right permissions
      - touch .hushlogin to supress errors generated by system wide
        bashrc that uses groups command to give user info about sudo
        access but fails due to group id of opf user not begin present
      - added a few things to .bashrc
      - set TERM to linux to avoid problems with emacs
      - removed default work directory from joyvan user

3) Have confirmed that nbgitpuller can correctly be triggered by
   default use of jupyter-book juypterhub interactive launch button
   see SOS book examples.

4) User state is ephemeral as without changes jupyter-book default behaviour
   is to have a joyvan default user who's home dir is present, has all the
   jupyter config and from where the jupyter interface server is run from.
   This directory is not on the persistent storage mounted into the container
   by opf so user state is bound to the lifetime of the server.

---
## [tjysdsg/tan](https://github.com/tjysdsg/tan)@[a722b7ce2b...](https://github.com/tjysdsg/tan/commit/a722b7ce2b82fc0a3e715d39e5f16966aa0f74ec)
#### Thursday 2021-07-29 17:14:53 by tjysdsg

Fix error fucking piece of shit, fuck you microsoft

---
## [desertrat-io/tortle](https://github.com/desertrat-io/tortle)@[2e986947e3...](https://github.com/desertrat-io/tortle/commit/2e986947e3a2e9c7df6e59b22e7d87dde03872f2)
#### Thursday 2021-07-29 17:24:31 by Mike Lawson

Tortle 38 (#40)

* migration commit

* tortle-38 migration commit

* travis fix

* travis fixes

* stg node

* fucking do the thing travis

* wtf travis for the love of fuck

* tortle-38 fucking coverage

* stuff

---
## [wincent/wincent](https://github.com/wincent/wincent)@[7fb2174038...](https://github.com/wincent/wincent/commit/7fb217403834c4133432b01f5fd518d852a69ae2)
#### Thursday 2021-07-29 17:41:29 by Greg Hurrell

feat(dotfiles): set up binding to show clipboard contents

At times I am paranoid* that I am about to paste the wrong thing in a
public channel. For example I might have tried to grab something out of
a text document, but it silently fails for whatever reason (maybe I
pressed the wrong key), and so I end up pasting the thing that I
previously put in the clipboard, which could be my bank account number,
a confession, or anything.

So, set up Alt (that is Option) + V to preview the clipboard contents.
As far as I can tell, Alt+V's default behavior is not that useful; in my
testing it seems to just insert "√".

[*]: But, if they really _are_ out to get you, is that paranoia?

---
## [brianSalk/stl_impementation](https://github.com/brianSalk/stl_impementation)@[30c715923f...](https://github.com/brianSalk/stl_impementation/commit/30c715923f5fbb5f6eda5ad435887103166687bd)
#### Thursday 2021-07-29 17:45:38 by brianSalk

I did this on my girlfriends computer, which is a chromebook which sucks so I could not get c++20 features to work, so I needed to comment stuff out. that is why I created this new branch

---
## [SpikyLlama/spikyllama.github.io](https://github.com/SpikyLlama/spikyllama.github.io)@[a0fb77e7f8...](https://github.com/SpikyLlama/spikyllama.github.io/commit/a0fb77e7f855788e35ac7f88139116bd21a2d374)
#### Thursday 2021-07-29 17:58:02 by SpikyLlama

boy do i love ctrl-c ctrl-v'ing people's code and changing it to fit my use case

---
## [LunarWatcher/Dragon](https://github.com/LunarWatcher/Dragon)@[6a5b7f249c...](https://github.com/LunarWatcher/Dragon/commit/6a5b7f249ccd0b5f4b1d634021f36236336e996a)
#### Thursday 2021-07-29 20:58:14 by Olivia

Expand and harden regexes

The TL;DR:
* Better capitalization
* Avoid capitalization of I if followed by a :, for list purposes
* Disable capitalization of list items. Doing and not doing both have
  side-effects
* Make the noGreetings regex work again (fuck you Python for not
  complaining about undefined escape sequences like any sane language
  would)
* Expand a few regexes to cover more cases
* Change a few strings to raw strings to make the regexes actually work.
  (Fuck you Python)
* Make legalNames work on titles too

---
## [AakashSharma7269/linkOSs](https://github.com/AakashSharma7269/linkOSs)@[8e31c085a1...](https://github.com/AakashSharma7269/linkOSs/commit/8e31c085a1baebce3498404244c4d38d50e907e3)
#### Thursday 2021-07-29 21:11:10 by AakashSharma7269

Fixed the hostname so it says root@linkOSs on boot and edited passwd
file to make the new user, idk if this is alright and might break the
build but i'm too lazy to test it so fuck you

---
## [theIDinside/cxg](https://github.com/theIDinside/cxg)@[25d45750b1...](https://github.com/theIDinside/cxg/commit/25d45750b1d5dd0a0458341226cda51a2d85ca43)
#### Thursday 2021-07-29 23:51:08 by cx

Rendering selection *finally* fucking works, after 7 hours of mind-fuckblowing painfulness.
This seems also *fucking insanely* ridiculously un-algorithmic the way I've done it. But it works.
It will panic however, if we try to select *more* than a "page's" worth. We'll fix that tomorrow.

---

# [<](2021-07-28.md) 2021-07-29 [>](2021-07-30.md)

