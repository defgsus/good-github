# [<](2021-02-02.md) 2021-02-03 [>](2021-02-04.md)

3,107,533 events, 1,507,865 push events, 2,377,399 commit messages, 189,058,215 characters


## [sameer-1997/Movielens-Case-Study@40a507f73c...](https://github.com/sameer-1997/Movielens-Case-Study/commit/40a507f73c85f339dcaa9718f5d08fccd88e120c)
##### 2021-02-03 00:13:12 by sameer-1997

Add files via upload

DESCRIPTION

Background of Problem Statement :

The GroupLens Research Project is a research group in the Department of Computer Science and Engineering at the University of Minnesota. Members of the GroupLens Research Project are involved in many research projects related to the fields of information filtering, collaborative filtering, and recommender systems. The project is led by professors John Riedl and Joseph Konstan. The project began to explore automated collaborative filtering in 1992 but is most well known for its worldwide trial of an automated collaborative filtering system for Usenet news in 1996. Since then the project has expanded its scope to research overall information by filtering solutions, integrating into content-based methods, as well as, improving current collaborative filtering technology.

Problem Objective :

Here, we ask you to perform the analysis using the Exploratory Data Analysis technique. You need to find features affecting the ratings of any particular movie and build a model to predict the movie ratings.

Domain: Entertainment

Analysis Tasks to be performed:

Import the three datasets
Create a new dataset [Master_Data] with the following columns MovieID Title UserID Age Gender Occupation Rating. (Hint: (i) Merge two tables at a time. (ii) Merge the tables using two primary keys MovieID & UserId)
Explore the datasets using visual representations (graphs or tables), also include your comments on the following:
User Age Distribution
User rating of the movie “Toy Story”
Top 25 movies by viewership rating
Find the ratings for all the movies reviewed by for a particular user of user id = 2696
Feature Engineering:
            Use column genres:

Find out all the unique genres (Hint: split the data in column genre making a list and then process the data to find out only the unique categories of genres)
Create a separate column for each genre category with a one-hot encoding ( 1 and 0) whether or not the movie belongs to that genre. 
Determine the features affecting the ratings of any particular movie.
Develop an appropriate model to predict the movie ratings
Dataset Description :

These files contain 1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 MovieLens users who joined MovieLens in 2000.

Ratings.dat
    Format - UserID::MovieID::Rating::Timestamp

Field	Description
UserID	Unique identification for each user
MovieID	Unique identification for each movie
Rating	User rating for each movie
Timestamp	Timestamp generated while adding user review
UserIDs range between 1 and 6040 
The MovieIDs range between 1 and 3952
Ratings are made on a 5-star scale (whole-star ratings only)
A timestamp is represented in seconds since the epoch is returned by time(2)
Each user has at least 20 ratings
 

Users.dat
Format -  UserID::Gender::Age::Occupation::Zip-code

Field	Description
UserID	Unique identification for each user
Genere	Category of each movie
Age	User’s age
Occupation	User’s Occupation
Zip-code	Zip Code for the user’s location
All demographic information is provided voluntarily by the users and is not checked for accuracy. Only users who have provided demographic information are included in this data set.

Gender is denoted by an "M" for male and "F" for female
Age is chosen from the following ranges:
 

Value	Description
1	"Under 18"
18	"18-24"
25	"25-34"
35	"35-44"
45	"45-49"
50	"50-55"
56	"56+"
 

Occupation is chosen from the following choices:
Value
 	Description
0	"other" or not specified
1	"academic/educator"
2	"artist”
3	"clerical/admin"
4	"college/grad student"
5	"customer service"
6	"doctor/health care"
7	"executive/managerial"
8	"farmer"
9	"homemaker"
10	"K-12 student"
11	"lawyer"
12	"programmer"
13	"retired"
14	 "sales/marketing"
15	"scientist"
16	 "self-employed"
17	"technician/engineer"
18	"tradesman/craftsman"
19	"unemployed"
20	"writer”

Movies.dat
Format - MovieID::Title::Genres

Field	Description
MovieID	Unique identification for each movie
Title	A title for each movie
Genres	Category of each movie
 

 Titles are identical to titles provided by the IMDB (including year of release)
 

Genres are pipe-separated and are selected from the following genres:
Action
Adventure
Animation
Children's
Comedy
Crime
Documentary
Drama
Fantasy
Film-Noir
Horror
Musical
Mystery
Romance
Sci-Fi
Thriller
War
Western
Some MovieIDs do not correspond to a movie due to accidental duplicate entries and/or test entries
Movies are mostly entered by hand, so errors and inconsistencies may exist

---
## [spaghettiweaver/YWPolarisVore@fc91485466...](https://github.com/spaghettiweaver/YWPolarisVore/commit/fc91485466cb1b6be160150b67edefc31d8f5737)
##### 2021-02-03 00:39:59 by Wickedtemp

ML3M Rebalancing

Originally, the ML3M was intended to be a little bit stronger. The healing values for the Brute, Burn, Omni, Toxin, and Antirad cells, have been adjusted according to what was initially planned. 
Base Tier's now heal 10 per shot, for a total of 40 damage healed, up from 20.
Second Tier's now heal 20, instead of 10.
Third Tier's heal 40, instead of 20. 

Omni 1 heals 5's for brute, burn, and toxin, and 30 for oxy, up from half those values. Omni 2, is 10's and 60, and Omni 3 is 20's and 120. 

Antirad Cell had its toxin heal bumped up from 2.5 to 5, and its radiation-heal from 150, to 350. I wasn't originally going to touch this one, but the text said "It's 150 because that's equal to five units of arithrazine", and... it wasn't. So, I bumped it up to actually be equal to 5u of Arithrazine's worth of radiation healing.

Stabilizer Cell, CorpseMend, Resistance, Haste, and the size-changing cells, were not touched.
The reasons for this are as follows:

- The healing laser was simply not strong enough to ever tend to more than one patient. Healing 20-40 damage per cell just isn't enough, even if you had several clips full of cells, it just wasn't viable.
- As a result of this, it was seldom if ever used. Field Medics rarely if ever took it with them. In nearly every round I've played, it was left exactly where it was spawned, collecting dust. 
- I'd like to make it a more proper treatment option. It wouldn't be equal to reagents used in your usual Medbay setting, or surgical repair, but if it's modified to actually fulfill its niche as a rapid, contact-free treatment option, it could be relied on more by Field Medics. There is so much potential for this device as an "in the field" healing tool, and I'd like to see it done well. We have no shortage of people who would like to see non-chemical-based treatment options. We might as well make it useful enough to actually use.

Here are a few issues people brought up in Discord when I floated this idea.
"But, Tempest, you're doubling everything? That's a huge change! Won't this result in the ML3M overshadowing other treatment options?"
Certainly not. Currently, with tier-2 cells that only heal up to 40 damage, this is actually worse than basic first-aid in terms of raw healing ability, as the cutoff for first aid healing is 50 damage on a limb. First aid and reagents will still be the most convenient, most readily available, and overall most-used manner of treatment for injuries that can be treated using those methods. All this change would do is allow the ML3M to also have its uses, and stop being overshadowed by everything else. 

"Okay, but what if it DOES actually become The New Meta and becomes the favored tool for healing?"
I wouldn't see it as an issue if Chemistry gets dethroned, in all honesty. They'd both take quite a bit of prep-work to use. You have to make multiples of every chem if you want a solid stock, and you'd need multiples of every cell if you want proper coverage and healing-ability, since even with these changes you're expending 1-3 cells per patient. And, unless you get multiple ML3M's made, only folks who are gonna have one are the CMO, and whoever nabs the spawned one first. 

"But wouldn't this result in less departmental cooperation between Medical and Science now that Medical will require fewer cells?"
Most likely, no. If anything, I'd think there would be an increase, round-to-round, if this becomes a more viable and wanted tool, more people will ask for cells. Personally, my list of requested cells would stay the same, but I'd be sending that request in more often since I know it'll actually be useful rather than having it just to have it. Tier 2 cells are still going to be desirable, and I'm still probably not going to order Tier 3's because of the cost, but that's just me. It's still going to be incredibly weak at roundstart, and better cells will be that much nicer to obtain.

"But Tempest! If you get the highest tiers of cells, and a lot of them, you could fix anything that doesn't require surgery!"
Well, if Science had the time and mats, then sure, you could gather up a large enough collection of cells, and you probably could indeed do this for one or two badly injured patients... ... ...and I could accomplish the same goal if I'm given 20 seconds in a chem-lab. The ML3M is more costly to use, the cells cost resources, have to be recharged after 4 shots, and you only start with a base tier Burn, Brute, and Stabilizer cell. Each shot from a base level burn/brute cell is the equivalent of 1.25u of bicaridine or kelotane. This change would make it 2.5. Base level cells are still going to be next to useless for anything other than the most minor of injuries. Chemistry will still be the dominating powerhouse it always has been, but at least you can use this tool, provided the PR goes through, instead, more often.

"Tempest, this thing just wasn't intended to be used to fully heal people..."
A couple people have said this, and to be honest, it's silly. In our medical system, there's very little distinction between what can "heal a little bit" and what can "heal fully", because it all comes down to the fact that everything works off of damage values. If Option A heals 5 damage, and Option B heals 50... Both are capable of "healing fully" if you have enough Option A, it's just a question as to whether or not that's practical. Currently, the ML3M's healing values can't really even be used to even partially heal injuries, unless you have a large number of cells. You'd expend all of your charges on one patient and then you've got a paperweight taking up storage space until you can get to a recharger. 

Now, as for issues that I personally see? Biggest one is probably the Toxin cell. If I remlember correctly, the base Toxin cell is the same tech requirement as the Second Tier Brute/Burn cells. This PR doesn't fix that, and I don't really see it as a huge priority since I don't think anyone uses the toxin cells as it is, but yeah. Might need to be fixed at some point if this PR goes through.

And, absolute worst case scenario, let's say that this PR screws everything up, turns the Tether upside down, and now Medbay is dominated by a bunch of blue laser beams flying everywhere like it's the new Star Wars Trilogy (but actually better because those movies kinda set a low bar)... this PR was really easy to do. The only long part about it was typing all of this up. We can just bump the numbers down if this ends up sucking really bad, ezpz.

Thank you for coming to my ted talk.

---
## [wimax-grapl/grapl@6137fd7042...](https://github.com/wimax-grapl/grapl/commit/6137fd704231e48a4f29229018c140658f8ad181)
##### 2021-02-03 02:18:49 by wimax-grapl

Begin to migrate python S3/SQS clients to a FromEnv equivalent (#541)

* On the road to Rust-like Fargate Stuff

yeah sure whatever

Fixed up typechecks

blep blep

It should work, but it doesn't.

I think it should work potentially

It fucking succeeded asdfgh

Yes yes it works yes

e2e works

sysmon works

okay time to rip out more garbage

it work

* readd removed logging driver none thing

* woops two tabs

* Remove the thing that caused pytype failure

* Lock test requirements

* change some prints to logger calls

---
## [mrkn/arrow@90e474d8ab...](https://github.com/mrkn/arrow/commit/90e474d8ab845115f23675e6b6f6aec73a429af4)
##### 2021-02-03 04:03:11 by Xavier Lange

ARROW-5123: [Rust] Parquet derive for simple structs

A rebase and significant rewrite of https://github.com/sunchao/parquet-rs/pull/197

Big improvement: I now use a more natural nested enum style, it helps break out what patterns of data types are . The rest of the broad strokes still apply.

Goal
===

Writing many columns to a file is a chore. If you can put your values in to a struct which mirrors the schema of your file, this `derive(ParquetRecordWriter)` will write out all the fields, in the order in which they are defined, to a row_group.

How to Use
===

```
extern crate parquet;
#[macro_use] extern crate parquet_derive;

#[derive(ParquetRecordWriter)]
struct ACompleteRecord<'a> {
  pub a_bool: bool,
  pub a_str: &'a str,
}
```

RecordWriter trait
===

This is the new trait which `parquet_derive` will implement for your structs.

```
use super::RowGroupWriter;

pub trait RecordWriter<T> {
  fn write_to_row_group(&self, row_group_writer: &mut Box<RowGroupWriter>);
}
```

How does it work?
===

The `parquet_derive` crate adds code generating functionality to the rust compiler. The code generation takes rust syntax and emits additional syntax. This macro expansion works on rust 1.15+ stable. This is a dynamic plugin, loaded by the machinery in cargo. Users don't have to do any special `build.rs` steps or anything like that, it's automatic by including `parquet_derive` in their project. The `parquet_derive/src/Cargo.toml` has a section saying as much:

```
[lib]
proc-macro = true
```

The rust struct tagged with `#[derive(ParquetRecordWriter)]` is provided to the `parquet_record_writer` function in `parquet_derive/src/lib.rs`. The `syn` crate parses the struct from a string-representation to a AST (a recursive enum value). The AST contains all the values I care about when generating a `RecordWriter` impl:

 - the name of the struct
 - the lifetime variables of the struct
 - the fields of the struct

The fields of the struct are translated from AST to a flat `FieldInfo` struct. It has the bits I care about for writing a column: `field_name`, `field_lifetime`, `field_type`, `is_option`, `column_writer_variant`.

The code then does the equivalent of templating to build the `RecordWriter` implementation. The templating functionality is provided by the `quote` crate. At a high-level the template for `RecordWriter` looks like:

```
impl RecordWriter for $struct_name {
  fn write_row_group(..) {
    $({
      $column_writer_snippet
    })
  }
}
```

this template is then added under the struct definition, ending up something like:

```
struct MyStruct {
}
impl RecordWriter for MyStruct {
  fn write_row_group(..) {
    {
       write_col_1();
    };
   {
       write_col_2();
   }
  }
}
```

and finally _THIS_ is the code passed to rustc. It's just code now, fully expanded and standalone. If a user ever changes their `struct MyValue` definition the `ParquetRecordWriter` will be regenerated. There's no intermediate values to version control or worry about.

Viewing the Derived Code
===

To see the generated code before it's compiled, one very useful bit is to install `cargo expand` [more info on gh](https://github.com/dtolnay/cargo-expand), then you can do:

```
$WORK_DIR/parquet-rs/parquet_derive_test
cargo expand --lib > ../temp.rs
```

then you can dump the contents:

```
struct DumbRecord {
    pub a_bool: bool,
    pub a2_bool: bool,
}
impl RecordWriter<DumbRecord> for &[DumbRecord] {
    fn write_to_row_group(
        &self,
        row_group_writer: &mut Box<parquet::file::writer::RowGroupWriter>,
    ) {
        let mut row_group_writer = row_group_writer;
        {
            let vals: Vec<bool> = self.iter().map(|x| x.a_bool).collect();
            let mut column_writer = row_group_writer.next_column().unwrap().unwrap();
            if let parquet::column::writer::ColumnWriter::BoolColumnWriter(ref mut typed) =
                column_writer
            {
                typed.write_batch(&vals[..], None, None).unwrap();
            }
            row_group_writer.close_column(column_writer).unwrap();
        };
        {
            let vals: Vec<bool> = self.iter().map(|x| x.a2_bool).collect();
            let mut column_writer = row_group_writer.next_column().unwrap().unwrap();
            if let parquet::column::writer::ColumnWriter::BoolColumnWriter(ref mut typed) =
                column_writer
            {
                typed.write_batch(&vals[..], None, None).unwrap();
            }
            row_group_writer.close_column(column_writer).unwrap();
        }
    }
}
```

now I need to write out all the combinations of types we support and make sure it writes out data.

Procedural Macros
===

The `parquet_derive` crate can ONLY export the derivation functionality. No traits, nothing else. The derive crate can not host test cases. It's kind of like a "dummy" crate which is only used by the compiler, never the code.

The parent crate cannot use the derivation functionality, which is important because it means test code cannot be in the parent crate. This forces us to have a third crate, `parquet_derive_test`.

I'm open to being wrong on any one of these finer points. I had to bang on this for a while to get it to compile!

Potentials For Better Design
===

 - [x] Recursion could be limited by generating the code as "snippets" instead of one big `quote!` AST generator. Or so I think. It might be nicer to push generating each columns writing code to another loop.
 - [X] ~~It would be nicer if I didn't have to be so picky about data going in to the `write_batch` function. Is it possible we could make a version of the function which accept `Into<DataType>` or similar? This would greatly simplify this derivation code as it would not need to enumerate all the supported types. Something like `write_generic_batch(&[impl Into<DataType>])` would be neat.~~ (not tackling in this generation of the plugin)
 - [X] ~~Another idea to improving writing columns, could we have a write function for `Iterator`s? I already have a `Vec<DumbRecord>`, if I could just write a mapping for accessing the one value, we could skip the whole intermediate vec for `write_batch`. Should have some significant memory advantages.~~ (not tackling in this generation of the plugin, it's a bigger parquet-rs enhancement)
 - [X] ~~It might be worthwhile to derive a parquet schema directly from a struct definition. That should stamp out opportunities for type errors.~~ (moved to #203)

Status
===

I have successfully integrated this work with my own data exporter (takes postgres/couchdb and outputs a single parquet file).

I think this code is worth including in the project, with the caveat that it only generates simplistic `RecordWriter`s. As people start to use we can add code generation for more complex, nested structs. We can convert the nested matching style to a fancier looping style. But for now, this explicit nesting is easier to debug and understand (to me at least!).

Closes #4140 from xrl/parquet_derive

Lead-authored-by: Xavier Lange <xrlange@gmail.com>
Co-authored-by: Neville Dipale <nevilledips@gmail.com>
Co-authored-by: Bryant Biggs <bryantbiggs@gmail.com>
Co-authored-by: Sutou Kouhei <kou@clear-code.com>
Signed-off-by: Neville Dipale <nevilledips@gmail.com>

---
## [GregariousJB/RetroPie-Docs@44e558a22e...](https://github.com/GregariousJB/RetroPie-Docs/commit/44e558a22e5689de714200e85074d0c0202f4db8)
##### 2021-02-03 07:58:57 by GregariousJB

Update Updating-RetroPie.md

Just going to update this screenshot of retropie_setup to the latest version and ask a few questions.

That whole section beneath the screenshot feels overkill. It's listing every single option in the script instead of just keeping it relevant to the point of this page - updating. I'm still new to this project so correct me if I'm wrong, but doesn't the `Update` section  update ***everything***, including the retropie-setup script and all optional packages? If so, ideally only that should be mentioned.

After that, I think the "Manage packages" section can certainly be mentioned to update individual things, but with the knowledge that it's not necessary if the user uses the "Update" function (again, correct me if I'm wrong). I think I can cut down a lot of fluff on this page.

I'm not overly familiar with Binary and Source updates so I'd just leave that alone.

I wonder if the Making a Backup section should be it's own page, but not a big deal.  After having used win32diskimager once to try to get 40 GB of a 128 GB SD card flashed onto a 64 GB SD card and failing, I'll probably want to mention that. And after doing some Googlin' and seeing how other people circumvent this SD card limitation by just backing up certain folders, like `/home/pi/RetroPie/roms` and `/opt/retropie/configs/all/emulationstation/gamelists`, I'm thinking of mentioning all the "important" folders but I don't know all of them yet. WinSCP is great at gzipping folders that can be dragged anywhere for backups. Might be worth a mention: https://i.imgur.com/iK5EUsR.png

Thoughts?

On a side note, I'm just randomly picking pages. Is there a page you can think of that needs more help than most? My discord is `GregariousJB#6350` if you're feeling chatty. If not, no worries. I'm content with these little Github love letters if you are.

---
## [sindhu-siripuram/Hello-World@d060101bd8...](https://github.com/sindhu-siripuram/Hello-World/commit/d060101bd8126a90004d52748634a3a0eeaa96df)
##### 2021-02-03 10:26:37 by sindhu-siripuram

Update README.md

hello there.

this is sindhu.
i am a dentist by profession. i would like to enter into the world of programming/coding..
its coz i dnt want to be bound at a place and want to move around(different countries), come out of the box which unfortunately is not possible with my profession,as my degree is not valid in most of the countriesand its inflexibility to moe around.
i found the lifestyle of my friends from other profession very flexible and interesting and i was so much attracted and fascinated with the black magic screen. then i decided this would be the way to my dreams and made up my mind to learn programming. now as am just a beginner and would love to use help/tips from any.
this is all about me.

thank you!

---
## [mrakgr/The-Spiral-Language@6699df71ad...](https://github.com/mrakgr/The-Spiral-Language/commit/6699df71ada2899592173c791e02404e54f10d91)
##### 2021-02-03 11:22:36 by Marko Grdinić

"9:25am. I am up. Let me change some things from yesterday. I'll remove the RNN link from the resume as it was not the optimized RNN that I did. That thing is buried in a past commit somewhere.

...Oh, it has been removed. It seems I fixed that already. Good. Let me just make sure that runtime casting has no overhead.

```
import numpy
cimport numpy
cdef class Tuple0:
    cdef readonly signed long v0
    cdef readonly double v1
    def __init__(self, signed long v0, double v1): self.v0 = v0; self.v1 = v1
cdef class Tuple1:
    cdef readonly signed long v0
    cdef readonly double v1
    cdef readonly double v2
    def __init__(self, signed long v0, double v1, double v2): self.v0 = v0; self.v1 = v1; self.v2 = v2
cpdef void main():
    cdef numpy.ndarray[object,ndim=1] v0
    cdef Tuple1 v1
    v0 = numpy.empty(10,dtype=object)
    v0[0] = Tuple0(1, 2.000000)
    v1 = v0[0]
```

Will this give me an error at runtime?

```
TypeError: Cannot convert testm.Tuple0 to testm.Tuple1
```

It does a checked cast.

```
v1 = <Tuple1>v0[0]
```

I can disable them like so though.

9:35am. Let me see if there have been any updates in the issues I opened yesterday.

Ok, the size 0 bug has been known for a while.

10:10am. Did some talking in the Cython issues.

What a waste of time this is. It took me 4 days to do the backend, and the array issue and Cython limitations wasted a few extra of them. I am done with this garbage. I do not care if there is a performance impact from safe casting. I'll stick with this.

Let me chill a bit today. I want to watch some Cython talks. After that I'll ease myself into ML. I do not want to bother myself with interviews for the rest of the week.

Forget Spiral. I finally fixed the 64-bit array, string and hashing issues. The codegen isn't doing any usafe conversion under the hood that could corrupt data at runtime.

Spiral is done.

TODO: Monadic syntax.
TODO: Autocomplete.
TODO: Highlight unused vars.
TODO: List and array patterns and literals.
TODO: Guard against stack overflows in the partial evaluator. Try running it on a separate thread.
TODO: Make literal suffices (such as `i64`) be highlighted differently from the rest of the number.
TODO: Make a VS Code theme for Spiral.
TODO: Spiral build option: Compile monomorphic functions in file. This will allow modules to be compiled as C style libraries. Monomorphic functions would be compiled without name mangling.

I will these TODOs far later.

10:15am. I do not want to think about the compiler, applying to companies or boosting my prestige. None of that matter.

10:20am. I thought of what I should do to raise me prestige, and I've gotten an idea. Wrap around the PyTorch library and extend it. Do with Spiral what would not be otherwise possible.

But this will happen naturally if traverse the main path. I won't need to have to put special effort on the side to this.

...

These weird language issues aside, I am actually quite enjoying Cython. It opened a huge range of possibilities for me.

10:25am. I gained a huge power now that I have it.

I didn't want to menion it, but now that I've positioned myself like this, I can stick it to Julia. The way I am doing it with Spiral is the right way to devour Python. I finally have a credible response to competitor languages in this space.

10:40am. https://www.youtube.com/watch?v=I1xyjc-JgGM
Tools for High Performance Python - Ian Ozsvald | ODSC Europe 2019

Let me watch this for a bit.

11:20am. Had to take a break. Let me watch this for a bit and I will have breakfast.

So far, I got up at a record early time, but completely wasted the advantage.

https://pytorch.org/get-started/locally/#windows-anaconda
`conda install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch`

Let me run this.

Maybe I should also get Cuda 11. Ah, it seems Anaconda will install this as well.

PyTorch itself is 1Gb.

11:45am. It is a good thing I rememberd to do this in advance.

11:55am.

https://www.youtube.com/watch?v=NfnMJMkhDoQ
Easy wins with Cython: fast and multi-core by Caleb Hattingh

Let me watch this. After that comes breakfast. I'll want to watch all the Cython talks eventually. Some of them are 3.5h long.

https://www.youtube.com/watch?v=gMvkiQ-gOW8
Cython: Blend the Best of Python and C++ | SciPy 2015 Tutorial | Kurt Smith

Let me check this out for a bit. I'll watch it while having breakfast."

---
## [Tristimdorion/Lab-Rats-2@aee83586da...](https://github.com/Tristimdorion/Lab-Rats-2/commit/aee83586da52be57f0228675fc85a2fc51f17e52)
##### 2021-02-03 13:29:27 by Tristimdorion

Modified: fuck date, every round the chance increases that her boyfriend calls / gets home.

---
## [RishuRajan/Data-Structure-And-Algorithm-with-Competitive-Programming@67460d8f7f...](https://github.com/RishuRajan/Data-Structure-And-Algorithm-with-Competitive-Programming/commit/67460d8f7f52a49e2df33ad818a1c82e6f42a6c0)
##### 2021-02-03 17:25:31 by Rishu Rajan

Is Love with Prime

Little Arjit is in love with Deepa. They have always thought of themselves as the ideal couple - the best, possible match they could've managed. (No kidding!) And like every other couple, they promised each other not to fight after every other fight. But, when has that happened before?

But, this is a different couple - this is a programming couple - and they argue on weird things, like Fibonacci numbers, prime numbers, Sterling numbers, and what not!

Their recent fight might seem silly to a lot of people, but it is a matter of serious concern for both of them. They have bought a cake, and they weighed it in milligrams - the weight of the cake is always even and now they wish to divide the cake between them in some way, that both of them are satisfied.

Arjit challenges Deepa that if she can divide the weight of the cake as sum of two prime numbers between them, she can have the entire cake - and if she fails to do so, he'll get the cake.

The argument is getting more, and more heated now - please help them sort out their stupid arguments or an easier way would be to help them figure out who is going to have the cake.

Input Format:
The first line will contain a number, tc, denoting the number of test cases.

The next tc lines will contain an even number, denoting the weight of the cake in milligrams.

Output Format:
Print "Arjit" or "Deepa" according to the winner.

Constraints:
1 <= tc <= 100
1 <= n <= 100000
1 is NOT a prime number.

SAMPLE INPUT 
2
4
8
SAMPLE OUTPUT 
Deepa
Deepa
Explanation
4 can be represented as 2 + 2, so Deepa wins. 8 can be represented as 5 + 3, so Deepa wins.

---
## [TheRedstom/Her-gard@dd25017906...](https://github.com/TheRedstom/Her-gard/commit/dd25017906822b3bd8ea58477d6832ccbbe1b283)
##### 2021-02-03 18:52:50 by sonico10

Update Hergard-book.json

1.2
Revision and/or rebalance of:
Chilling Gaze
Celkilor's Syphon
Flame Blade
Focus Bolt
Freezing Smite
Hand of Heol
Ice Spear
Ludmilla's Dream Shape
Phantom Workshop
Raw Magic Burst
Roam
Shadowgaze
Corrected acid rain's school to evocation from abjuration.
Subclass Changes
1.2
Barbarian
•	Jötunnkyn: Name corrected in all occurrences
Cleric
•	Fate Domain: 2nd level Domain Spell blur changed to fortune's favor
•	Secrecy Domain: In Domain Spells, illusory script spell name corrected
Fighter
•	Blademaker: Blademake and Maneuvering Barrage revision
Monk
•	Four Elements: Become the Teapot grammar corrected
•	Sun Soul: Revised version added
Paladin
•	All extra 3rd level subclass features removed
Sorcerer
•	Bloodline Spells added and brought up to Tasha's standard for all subclasses
•	Blood Mage: All features revised
•	Dreamwalker: All features revised
•	Fey-Touched: All features revised
•	Oracle Bloodline: All features revised
Wizard
•	Unified the introductory wording of all primary 2nd level features to "When you adopt this tradition at 2nd level,..."
•	Hedge Magic All features revised
•	School of Herbology: Herbology Savant revised
Race Changes
1.2
•	Veneris: Venomous Bite reworded
•	Succubus/Incubus: Devil's Shapechange and Draining Kiss revised
Miscellaneous Changes
1.2
•	"Spell save DC" format unification so the s in save is not capitalized
•	Classes intro text change
•	Removed instances of "&shy;" from the document to clean up code and weirdly meticulous word separation

---
## [jakobbbb/pvs-uebung-5@37ba908cc2...](https://github.com/jakobbbb/pvs-uebung-5/commit/37ba908cc2a4ebe0babbcc3b007f4832d765acea)
##### 2021-02-03 20:41:53 by Jakob Ruckel

Fixed it

Oh boy, do I _enjoy_ randomly changing around magic numbers until my
assert() stops fucking failing all the god-damn time.

---
## [tgstation/tgstation@1611aaa70a...](https://github.com/tgstation/tgstation/commit/1611aaa70a1268392f8076e688b6181b6fbd4b18)
##### 2021-02-03 22:37:07 by necromanceranne

Pipeguns: Elitism Edition (#56322)

About The Pull Request

The core of the PR:

The improvised shotgun that was is dead and removed.

Now we have Pipeguns. Pipeguns are bolt action rifles that have a damage multiplier that reduces their damage to 75%, and can be modified to fit the rare 7.62mm bullets. If you want to that is.

The pipegun also slowly increases in misfire probability for every shot at a rate of 5% per shot.

Pipeguns can also be upgraded to Regal Pipeguns. These contain more bullets, don't misfire and don't have a damage multiplier. To acquire one is a maint secret, only available to lucky assistants who come across the diary of a dead assistant. The probability of finding the book is quite, quite low.

Bandoliers now fit individual 7.62mm. Because why not. Currently they're available in stripper clips that fit into most combat belts so this is mostly a style preference at the moment

Other shit

Ammo modification and misfire behaviour is now generalized to all ballistics. You can now make any gun misfire and any internal magazine gun swap ammunition.

Misfires are not a flat chance. Instead, they increment as the gun fires over time.

Ports over this PR Citadel-Station-13/Citadel-Station-13#12274 which I felt was pretty neat conceptually for making some weapons weaker.

Makes the icemoon hermit's mosin into a regal pipegun, just to get mosins out of easy access.
Why It's Good For The Game

Improvised shotguns were one of my favourite weapons to horribly abuse while they were utterly broken a nice alternative, but I fully support moving towards curbing gun power curve. Part of that should include looking at improvised weapons like this which are seeing considerable usage with the removal of buckshot and slugs.

Initially I wanted to pair this with a PR of my own to bop Mosins on the skull along with it, but #56319 is already doing that, and while it's a very lenient approach to my own (I was going to remove them entirely from cargo), I respect it.

Changelog

cl
add: Replaces improvised shotguns with Pipeguns (with a special variant for those willing to go through arbitrary bullshit to acquire it and sheer good luck).
add: Now all guns can be set to misfire and swap ammunition.
add: Misfire chance is incremental as you fire the weapon, and not a flat static chance. This can be reset by using a piece of cloth on the gun and 10 seconds of cleaning.
balance: This has been applied to the detective revolver, but it only increments while using .357 bullets.
add: Guns can have damage multipliers attached for the bullets they fire. The pipegun (but not the regal version) is the first example with a 75% damage output.
balance: The Ice Hermit now has a regal pipegun instead of a Mosin Nagant.
balance: The bandolier fits 7.62mm.
balance: You can construct receivers and rifle stocks in the crafting menu.
balance: Detaches the magical rifles from the boltaction subtype, since they are just basically not using any variables attached to that subtype and made from a series of early returns.
/cl

---

# [<](2021-02-02.md) 2021-02-03 [>](2021-02-04.md)

