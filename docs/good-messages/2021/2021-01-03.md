# [<](2021-01-02.md) 2021-01-03 [>](2021-01-04.md)

1,899,973 events, 1,108,701 push events, 1,541,384 commit messages, 90,329,608 characters


## [ajkourabi/Project-Lionheart](https://github.com/ajkourabi/Project-Lionheart)@[872219e614...](https://github.com/ajkourabi/Project-Lionheart/commit/872219e614e7bf482f80d9ea9326e92ba698bf63)
#### Sunday 2021-01-03 00:39:51 by ajkourabi

Create Project-Lionheart .py

Machine learning program that evaluates inputs such as cholesterol,
resting bpm and sex to determine if you will experience Angina related chest pains during exercise. Made for and during MLH hackathon "New Year, New Hacks".

---
## [sanusanth/javascript-basic-program](https://github.com/sanusanth/javascript-basic-program)@[cfa3c9378d...](https://github.com/sanusanth/javascript-basic-program/commit/cfa3c9378deea9cd0bf6f39e505d01ac9b0e2250)
#### Sunday 2021-01-03 00:40:10 by Sanusanth Dowmi

Add files via upload

What is JavaScript and what does it do?
Before you start learning something new, it’s important to understand exactly what it is and what it does. This is especially useful when it comes to mastering a new programming language.

In simple terms, JavaScript is a programming language used to make websites interactive. If you think about the basic makeup of a website, you have HTML, which describes and defines the basic content and structure of the website, then you have CSS, which tells the browser how this HTML content should be displayed—determining things like color and font. With just HTML and CSS, you have a website that looks good but doesn’t actually do much. JavaScript brings the website to life by adding functionality. JavaScript is responsible for elements that the user can interact with, such as drop-down menus, modal windows, and contact forms. It is also used to create things like animations, video players, and interactive maps.

Nowadays, JavaScript is an all-purpose programming language—meaning it runs across the entire software stack. The most popular application of JavaScript is on the client side (aka frontend), but since Node.js came on the scene, many people run JavaScript on the server side (aka backend) as well. When used on the client side, JavaScript code is read, interpreted, and executed in the user’s web browser. When used on the server side, it is run on a remote computer. You can learn more about the difference between frontend and backend programming here.

JavaScript isn’t only used to create websites. It can also be used to build browser-based games and, with the help of certain frameworks, mobile apps for different operating systems. The creation of new libraries and frameworks is also making it possible to build backend programs with JavaScript, such as web apps and server apps.

Is it still worth learning JavaScript in 2021? The world of web development is constantly moving. With so many new tools popping up all the time, it can be extremely difficult to know where you should focus your efforts. As an aspiring developer, you’ll want to make sure that what you’re learning is still relevant in today’s industry. If you’re having doubts about JavaScript, it’s important to know that, since its creation in 1995, JavaScript is pretty much everywhere on the web—and that’s not likely to change any time soon. According to the 2020 StackOverflow developer survey, JavaScript is the most commonly used programming language for the eighth year in a row. It is currently used by 94.5% of all websites and, despite originally being designed as a client-side language, JavaScript has now made its way to the server-side of websites (thanks to Node.js), mobile devices (thanks to React Native and Ionic) and desktop (courtesy of Electron).

As long as people are interacting with the web, you can assume that JavaScript is highly relevant—there’s no doubt that this is a language worth knowing! With that in mind, let’s look at some of the key benefits of becoming a JavaScript expert.

Why learn JavaScript?

The most obvious reason for learning JavaScript is if you have hopes of becoming a web developer. Even if you haven’t got your heart set on a tech career, being proficient in JavaScript will enable you to build websites from scratch—a pretty useful skill to have in today’s job market!

If you do want to become a web developer, here are some of the main reasons why you should learn JavaScript:

JavaScript experts are versatile

JavaScript is an extremely versatile language. Once you’ve mastered it, the possibilities are endless: you can code on the client-side (frontend) using Angular and on the server-side (backend) using Node.js. You can also develop web, mobile, and desktop apps using React, React Native, and Electron, and you can even get involved in machine learning.

If you want to become a frontend developer, JavaScript is a prerequisite. However, that’s not the only career path open to you as a JavaScript expert. Mastering this key programming language could see you go on to work in full-stack development, games development, information security software engineering, machine learning, and artificial intelligence—to name just a few!

Ultimately, if you want any kind of development or engineering career, proficiency in JavaScript is a must.

JavaScript experts are in-demand (and well-paid) JavaScript is the most popular programming language in the world, so it’s no wonder that JavaScript is one of the most sought-after skills in the web development industry today.

According to the Devskiller IT Skills and Hiring Report 2020, 72% of companies are looking to hire JavaScript experts. Enter the search term “JavaScript” on job site Indeed and you’ll find over 40,000 jobs requiring this skill (in the US). Run the same search on LinkedIn and the results are in excess of 125,000.

At the same time, the global demand for JavaScript seems to outweigh the expertise available on the market. According to this 2018 HackerRank report, 48% of employers worldwide need developers with JavaScript skills, while only 42% of student developers claim to be proficient in JavaScript. And, in their most recent report for 2020, HackerRank once again reports that JavaScript is the most popular language that hiring mangers look for in a web developer candidate.

Not only are JavaScript experts in demand—they are also well-paid. In the United States, JavaScript developers earn an average yearly salary of $111,953 per year. We’ve covered this topic in more detail in our JavaScript salary guide, but as you can see, learning JavaScript can really boost your earning potential as a developer.

JavaScript is beginner-friendly

Compared to many other programming languages, JavaScript offers one of the more beginner-friendly entry points into the world of coding. The great thing about JavaScript is that it comes installed on every modern web browser—there’s no need to set up any kind of development environment, which means you can start coding with JavaScript right away!

Another advantage of learning JavaScript as your first programming language is that you get instant feedback; with a minimal amount of JavaScript code, you’ll immediately see visible results. There’s also a huge JavaScript community on sites like Stack Overflow, so you’ll find plenty of support as you learn.

Not only is JavaScript beginner-friendly; it will also set you up with some extremely valuable transferable skills. JavaScript supports object-oriented, functional, and imperative styles of programming—skills which can be transferred to any new language you might learn later on, such as Python, Java, or C++. JavaScript provides a crucial introduction to key principles and practices that you’ll take with you throughout your career as a developer.

Should you learn plain JavaScript first or can you skip to frameworks and libraries? When deciding whether or not to learn JavaScript, what you’re really asking is whether or not you should learn “vanilla” JavaScript. Vanilla JavaScript just means plain JavaScript without any libraries or frameworks. Let’s explore what this means in more detail now.

What is meant by vanilla JavaScript, libraries, and frameworks?

If you research the term “vanilla JavaScript”, you might run into some confusion; however, all you need to know is that vanilla JavaScript is used to refer to native, standards-based, non-extended JavaScript. There is no difference between vanilla JavaScript and JavaScript—it’s just there to emphasize the usage of plain JavaScript without the use of libraries and frameworks.

So what are libraries and frameworks?

JavaScript libraries and frameworks both contain sets of prewritten, ready-to-use JavaScript code—but they’re not the same thing. You can think of a framework as your blueprint for building a website: it gives you a structure to work from, and contains ready-made components and tools that help you to build certain elements much quicker than if you were to code them from scratch. Some popular JavaScript frameworks include Angular, React, Vue, and Node.js.

Frameworks also contain libraries. Libraries are smaller than frameworks, and tend to be used for more specific cases. A JavaScript library contains sets of JavaScript code which can be called upon to implement certain functions and features. Let’s imagine you want to code a particular element into your website. You could write, say, ten lines of JavaScript from scratch—or you could take the condensed, ready-made version from your chosen JavaScript library. Some examples of JavaScript libraries include jQuery, Lodash, and Underscore.

The easiest way to understand how frameworks and libraries work together is to imagine you are building a house. The framework provides the foundation and the structure, while the library enables you to add in ready-made components (like furniture) rather than building your own from scratch.

You can learn more about the relationship between languages and libraries in this post explaining the main differences between JavaScript and jQuery. For now, let’s go back to our original question: How important is it to learn vanilla JavaScript?

Should you learn vanilla JavaScript first?

When it comes to learning JavaScript, it can be tempting to skip ahead to those time-saving frameworks and libraries we just talked about—and many developers do. However, there are many compelling arguments for learning plain JavaScript first.

While JavaScript frameworks may help you get the job done quicker, there’s only so far you can go if you don’t understand the core concepts behind these frameworks. Frontend developer Abhishek Nagekar describes how not learning vanilla JavaScript came back to bite him when he started learning the JavaScript frameworks Node and Express:

“As I went to write more and more code in Node and Express, I began to get stuck at even the tiniest problems. Suddenly, I was surrounded with words like callbacks, closures, event loop and prototype. It felt like I got a reintroduction to JavaScript, but this time, it was not a toddler playing in its cradle, it was something of a mysterious monster, challenging me on every other step for not having taken it seriously.”

The above Tweet references a long-running joke within the developer community, and although it dates way back to 2015, it’s still highly relevant today. If you want to become a developer who can innovate, not just execute, you need to understand the underlying principles of the web—not just the shortcuts. This means learning vanilla JavaScript before you move on to frameworks. In fact, understanding plain JavaScript will help you later on when it comes to deciding whether to use a framework for a certain project, and if so, which framework to use.

Why Study JavaScript?

JavaScript is one of the 3 languages all web developers must learn:

HTML to define the content of web pages
CSS to specify the layout of web pages
JavaScript to program the behavior of web pages
Learning Speed

In this tutorial, the learning speed is your choice.
Everything is up to you. If you are struggling, take a break, or re-read the material. Always make sure you understand all the "Try-it-Yourself" examples. The only way to become a clever programmer is to: Practice. Practice. Practice. Code. Code. Code ! Commonly Asked Questions How do I get JavaScript? Where can I download JavaScript? Is JavaScript Free? You don't have to get or download JavaScript. JavaScript is already running in your browser on your computer, on your tablet, and on your smart-phone.
JavaScript is free to use for everyone.

© 2021 GitHub, Inc.

---
## [0ctobot/neutrino_kernel_oneplus_sm8250](https://github.com/0ctobot/neutrino_kernel_oneplus_sm8250)@[cce654a95f...](https://github.com/0ctobot/neutrino_kernel_oneplus_sm8250/commit/cce654a95f045f8944cd455697447032a858cf71)
#### Sunday 2021-01-03 02:42:42 by Adam W. Willis

oneplus: Silence gratuitous OEM logging

For the love of god, I do not require my every input logged to dmesg.

Signed-off-by: Adam W. Willis <return.of.octobot@gmail.com>

---
## [Fargowilta/FargowiltasSouls](https://github.com/Fargowilta/FargowiltasSouls)@[f33df687c0...](https://github.com/Fargowilta/FargowiltasSouls/commit/f33df687c0311928a26cd532a431fc6c0cf8bbb1)
#### Sunday 2021-01-03 03:47:33 by Terry N. Muse

reduced life slightly
 eridanus
 abominationn
 mutant (yes i know you can one cycle now)
prime
 p2 spin star delay adjusted
 p2 active limbs use a different dust for better visibility
 p2 melee limb delay adjusted
eow has 50% DR on head, 25% DR on the two BODY segments behind head (doesn't apply to tail segments)
wof
 ichor reworked, pushes you to far side of arena (previously forced you up)
 nerfed max speed more (the above would fuck you up otherwise)
marked for death places a skull above you

---
## [crimsobot/crimsoBOT](https://github.com/crimsobot/crimsoBOT)@[b11a867b56...](https://github.com/crimsobot/crimsoBOT/commit/b11a867b56f66f697d81dfc0f8ff00faa9610f0b)
#### Sunday 2021-01-03 04:13:15 by Kaylynn

Update input handling

yep
Small fix

yeah
Wrong quotes kaylynn you fucking idiot


I really am not having a good day

hhhh
server_bonus

fix that

---
## [vinothmdev/xi-editor](https://github.com/vinothmdev/xi-editor)@[3fa345a411...](https://github.com/vinothmdev/xi-editor/commit/3fa345a411df6b3ad2a421cdb0111b87da2431a3)
#### Sunday 2021-01-03 04:35:33 by Colin Rofls

Implement comment toggling in the syntect plugin

This adds syntax-aware comment toggling.

The implementation is sort of weird, in a way that maybe
highlights some of the general weirdness around this feature,
and also maybe illustrates some future directions for plugin-
provided commands.

Basically: comment toggling, like auto-indent, is syntax
dependant. Unlike auto-indent, however, it is also the result
of an explicit user action.

This is a funny case. It seems silly to add a 'toggle_comment'
command to the RPC protocol. We do need to route through core,
because we need to extract the lines to be commented; plugins
do not currently have access to selection state. However we only
expect this to be handled by one plugin.

So: this is a hack. This has given me some ideas about how
plugins can declare their capabilities, though; I'll open an
issue for that in a little bit.

In the meantime, this is a useful feature.

---
## [BUGBOUNTYchrisg8691/nvim-config](https://github.com/BUGBOUNTYchrisg8691/nvim-config)@[d9307c8ff2...](https://github.com/BUGBOUNTYchrisg8691/nvim-config/commit/d9307c8ff22c0ea82a694d279da0c656e58a6a37)
#### Sunday 2021-01-03 08:47:41 by Christopher Girvin

done for the night jan 03, 2021; holy shit, I just realized it was 2021, nice

---
## [KeinR/Danzun](https://github.com/KeinR/Danzun)@[7e6a0a4047...](https://github.com/KeinR/Danzun/commit/7e6a0a4047fc8614172bc440f3fab1f9ca1b02a6)
#### Sunday 2021-01-03 09:34:44 by Orion Musselman

Wow that one was a doozy
Wow
New
Wow
Oh
god
why
why
whyw
wuhfuwe
ee
ger
ge
h
shr
h
ersh
e
h
erh
e
h
erh
er
ger
t
e
t

AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
MY HEAD IS KILLING ME
THE ONLY THING I HAVE HAD TO DRINK TODAY IS A CUP OF GREEN TEA.
FUCK
OW
WHY

---
## [CraftRom/android_device_xiaomi_onclite-twrp](https://github.com/CraftRom/android_device_xiaomi_onclite-twrp)@[4d597f9902...](https://github.com/CraftRom/android_device_xiaomi_onclite-twrp/commit/4d597f99022faf1edbcaa54c5508dbad01375799)
#### Sunday 2021-01-03 11:02:08 by melles1991

onclite: remove loop.max_part for android 11 support

BOARD_KERNEL_CMDLINE += loop.max_part=7
Removed to support Android 11 - NOTE: Max value is 255, but only 21 should currently be needed for TWRP
For the love of all that is holy, please do not include this in your ROM unless you really want TWRP to not work correctly!

---
## [mexisme/nixos-hardware](https://github.com/mexisme/nixos-hardware)@[9adc977684...](https://github.com/mexisme/nixos-hardware/commit/9adc9776849ed3e7f6477278aef574156de97aa2)
#### Sunday 2021-01-03 12:49:52 by mexisme

Initial port from github.com/linux-surface/linux-surface, vendorising the patches and firmware binaries.

Add MS Surface Kernel patches from github.com/linux-surface/linux-surface

Add MS Surface Firmware from github.com/linux-surface/linux-surface

Add MS Surface Hardware config from github.com/linux-surface/linux-surface

Tie-together the Microsoft Surface .nix files

Set to use explicit version of Linux (5.4.7)

- Add the config for Linux 5.4.7

Add kernel 5.4.11

Add kernel 5.4.13

Remove unsupported patches

Revert to kernel 5.4.7 for now

- Problems initialising touchscreen & pen

Add kernel 5.4.15 and 5.4.16

Build kernel 5.4.16, instead

Add kernel 5.4.22

Update the patches for kernel 5.4

Placeholder for Linux kernel 5.5

Copy the IPTS kernel patch from the 5.5 dir to the 5.4 dir.

Conversation on https://gitter.im/linux-surface/community suggested this would
reenable IPTS on 5.4:

-----
@matrixbot Feb 29 15:33
hpfr Blaž Hrastnik (Gitter): thanks for the mention. mexisme (Gitter) finally, someone who actually knows Nix and isn't just a config nerd writing proper NixOS Surface configs! I am stuck on 4.19 at the moment because IPTS is now a proper reverse-engineered kernel driver (https://github.com/linux-surface/intel-precise-touch) instead of just a blob package, and I haven't had time to look at how to package that for Nix. If you're on 5.5, are you just not using IPTS? Would love to help out on packaging that for NixOS
hpfr also, development conversations seem to happen more at #linux-surface on freenode, which you can connect to with matrix via https://matrix.to/#/!OXIGGPCpnzaNVeGtCA:matrix.org if you don't like IRC clients

@matrixbot Feb 29 15:39
hpfr Also, I'm not using jakeday's patches, I'm using the more recent ones from the linux-surface/linux-surface repo, but yeah, for 4.19, so they're a bit different from the 5.x patchsets. afaik 4.19 is still supported because it's the last LTS release that supports the "official" IPTS blob before Linux made changes that required reverse engineering a driver that didn't use GuC submission (I'm just quoting here, I have no idea what that is haha)

@matrixbot Feb 29 19:27
Blaž > now a proper reverse-engineered kernel driver
Should be similar to before, we just offer it as a patch
Blaž https://github.com/linux-surface/linux-surface/blob/master/patches/5.5/0007-ipts.patch
Blaž Anyway I'm keeping an eye out on your NixOS builds since I'm thinking about giving it a try

@matrixbot Feb 29 19:32
Blaž Currently running Arch but using nix as a way to manage development environments for various projects

@matrixbot Mar 01 10:41
hpfr Blaž: well shoot is that patch all that’s necessary for building in-tree? It does all the things the linux-surface/intel-precise-touch repo does?

Dorian Stoll @StollD Mar 01 12:56
Yes
Just adds all the files from the repo to drivers/input/touchscreen and adds the necessary glue to drivers/input/touchscreen/{Makefile, Kconfig}

@matrixbot Mar 02 09:13
hpfr Dorian Stoll (Gitter): oof. Could’ve been on 5.4+ all this time!

Move kernnel *.nix packages under their respective kernel dirs

Use lib.mkDefault

Update to kernel 5.4.24

Update to kernel 5.5.8

Typo

Drivers are modules by default

Revert to 5.4.24 until can fix the config failures

---
## [PainKiller3/packages_apps_FluidLauncher](https://github.com/PainKiller3/packages_apps_FluidLauncher)@[e6e4a62e1e...](https://github.com/PainKiller3/packages_apps_FluidLauncher/commit/e6e4a62e1e6131c8debca21de6df4a2df5341d76)
#### Sunday 2021-01-03 15:41:29 by Alex Cruz

Launcher3: Restart with change only on exit

This change allow the user to change everything they have to inside the
homescreen activity and only restart on exit. Previously this was a pain
in the fucking ass because you had to go in and set each option one by one
with a restart inbetween. At least now is not that big of a pain.

- Restart on destroy (hitting the back button, actionbar arrow)
- Restart when a chance is made and the home button is pressed

** Thanks "Jack" for code to detect home button
https://stackoverflow.com/a/27956263

- Cleaned up restart code

@eyosen adapted to 10

Change-Id: I4962916ae0bd59d08247b59de585a97a2b9da3a1
Signed-off-by: DennySPb <dennyspb@gmail.com>

---
## [ghc/ghc](https://github.com/ghc/ghc)@[7ccb760b1a...](https://github.com/ghc/ghc/commit/7ccb760b1a8034b28171d7540712fd195f65d1fd)
#### Sunday 2021-01-03 16:58:26 by Simon Peyton Jones

Reduce result discount in conSize

Ticket #18282 showed that the result discount given by conSize
was massively too large.  This patch reduces that discount to
a constant 10, which just balances the cost of the constructor
application itself.

Note [Constructor size and result discount] elaborates, as
does the ticket #18282.

Reducing result discount reduces inlining, which affects perf.  I
found that I could increase the unfoldingUseThrehold from 80 to 90 in
compensation; in combination with the result discount change I get
these overall nofib numbers:

        Program           Size    Allocs   Runtime   Elapsed  TotalMem
--------------------------------------------------------------------------------
          boyer          -0.2%     +5.4%     -3.2%     -3.4%      0.0%
       cichelli          -0.1%     +5.9%    -11.2%    -11.7%      0.0%
      compress2          -0.2%     +9.6%     -6.0%     -6.8%      0.0%
   cryptarithm2          -0.1%     -3.9%     -6.0%     -5.7%      0.0%
         gamteb          -0.2%     +2.6%    -13.8%    -14.4%      0.0%
         genfft          -0.1%     -1.6%    -29.5%    -29.9%      0.0%
             gg          -0.0%     -2.2%    -17.2%    -17.8%    -20.0%
           life          -0.1%     -2.2%    -62.3%    -63.4%      0.0%
           mate          +0.0%     +1.4%     -5.1%     -5.1%    -14.3%
         parser          -0.2%     -2.1%     +7.4%     +6.7%      0.0%
      primetest          -0.2%    -12.8%    -14.3%    -14.2%      0.0%
         puzzle          -0.2%     +2.1%    -10.0%    -10.4%      0.0%
            rsa          -0.2%    -11.7%     -3.7%     -3.8%      0.0%
         simple          -0.2%     +2.8%    -36.7%    -38.3%     -2.2%
   wheel-sieve2          -0.1%    -19.2%    -48.8%    -49.2%    -42.9%
--------------------------------------------------------------------------------
            Min          -0.4%    -19.2%    -62.3%    -63.4%    -42.9%
            Max          +0.3%     +9.6%     +7.4%    +11.0%    +16.7%
 Geometric Mean          -0.1%     -0.3%    -17.6%    -18.0%     -0.7%

I'm ok with these numbers, remembering that this change removes
an *exponential* increase in code size in some in-the-wild cases.

I investigated compress2.  The difference is entirely caused by this
function no longer inlining

WriteRoutines.$woutputCodes
  = \ (w :: [CodeEvent]) ->
      let result_s1Sr
            = case WriteRoutines.outputCodes_$s$woutput w 0# 0# 8# 9# of
                (# ww1, ww2 #) -> (ww1, ww2)
      in (# case result_s1Sr of (x, _) ->
              map @Int @Char WriteRoutines.outputCodes1 x
         , case result_s1Sr of { (_, y) -> y } #)

It was right on the cusp before, driven by the excessive result
discount.  Too bad!

Happily, the compiler/perf tests show a number of improvements:
    T12227     compiler bytes-alloc  -6.6%
    T12545     compiler bytes-alloc  -4.7%
    T13056     compiler bytes-alloc  -3.3%
    T15263     runtime  bytes-alloc -13.1%
    T17499     runtime  bytes-alloc -14.3%
    T3294      compiler bytes-alloc  -1.1%
    T5030      compiler bytes-alloc -11.7%
    T9872a     compiler bytes-alloc  -2.0%
    T9872b     compiler bytes-alloc  -1.2%
    T9872c     compiler bytes-alloc  -1.5%

Metric Decrease:
    T12227
    T12545
    T13056
    T15263
    T17499
    T3294
    T5030
    T9872a
    T9872b
    T9872c

---
## [ishersagay/Kotlin_Tasks](https://github.com/ishersagay/Kotlin_Tasks)@[4bc7a9a0d6...](https://github.com/ishersagay/Kotlin_Tasks/commit/4bc7a9a0d60e81ae69e3d5b7614ff78cbdf79759)
#### Sunday 2021-01-03 17:11:08 by Isher Sagay

Create Grains

There once was a wise servant who saved the life of a prince. The king promised to pay whatever the servant could dream up. Knowing that the king loved chess, the servant told the king he would like to have grains of wheat. One grain on the first square of a chess board, with the number of grains doubling on each successive square.

There are 64 squares on a chessboard (where square 1 has one grain, square 2 has two grains, and so on).

Write code that shows:

how many grains were on a given square, and
the total number of grains on the chessboard

---
## [darkhz/revvz_sakura](https://github.com/darkhz/revvz_sakura)@[ec5da1652b...](https://github.com/darkhz/revvz_sakura/commit/ec5da1652bfcef85d6dcf8f7b398299c0cd8b690)
#### Sunday 2021-01-03 17:55:55 by darkhz

mm: process_reclaim: Modified the driver to kill processes.

This is marked HIGHLY EXPERIMENTAL. Use at your own risk.

If you want to test this, ZRAM/SWAP must be enabled!

Background
==========
While playing around with various low memory solutions on Android, like
the stock Android LowMemoryKiller and Sultan's Simple LMK,
I was unsatisfied with the way with which they handled low memory.

Here are my reasons,but I may be wrong/unclear.Please do feel free to correct me.

- Android LMK is too aggressive,but setting minfrees/adjs help to an
  extent.During my testing,I found that LMK depletes swap-pages to 0,
  and a thrashing situation ensues.When this thrashing situation
  continues for a long time,OOM Killer comes into play,and starts
  killing tasks at random.This is undesirable.

- Sultan's SLMK is a bit better,but still aggressive,in the sense that
  it starts to kill tasks even if there is a short memory spike.This is
  undesirable, as there may be a situation wherein many swap pages are
  available,but since tasks are being killed when those memory spikes
  occur,swap pages may not be used as much as they are freed.These kind
  of situations are frequent when using SLMK during my testing.

In short,I was unable to keep many apps open as per the potential of my
device's RAM and ZRAM.The above-mentioned solutions also killed Android
services at random, which proved to be annoying, for example when I had a
music player and apps in the background,the music player would abruptly be
killed.

My objective is to:

- Keep important tasks like Android services running
  until they are closed by the user.

- Kill apps as little as possible,or specifically,killing apps based
  on the total time spent on it.This means that, apps with larger usage
  time get killed more rarely,and apps with lesser usage times get
  killed frequently.

Solution
========
This is my humble(flawed?) attempt at handling a low-memory situation in a
better manner.

I used the Process Reclaim driver as the base for this purpose.
The reason why I used this driver was that,its function was to reclaim
ANONYMOUS(MM_ANON) pages from each scanned task as much as possible(according to per_swap_size),
so that apps never get killed,and memory gets reclaimed in the end.

In theory,this sounds good.While testing though,I ran into a very
serious problem: system freezes.Too much memory pressure and less ANONYMOUS
pages to reclaim rendered the system unusable for a while,which was NOT cool.

Therefore,the only way to prevent these system freezes was to kill some
tasks,but at the appropriate time.This is the approach I took:

- We keep reclaiming pages if they are above defined threshold
  (free_swap_limit).

- Once the swap goes below a percentage(free_percent) above/below the threshold,
  we start to collect tasks to kill.

- We then sort those tasks based on their last accessed (stime+utime),
  and then start killing the tasks with the lowest (stime+utime).We stop
  killing tasks once the number of swap pages are above the threshold
  (free_swap_limit).
  I specifically sorted according to acct_timexpd,see kernel/tsacct.c for
  more details(CONFIG_TASK_XACCT).

So, in theory, this should reclaim ANONYMOUS pages more often, and kill
tasks less,depending on the memory pressure.

Other Changes
=============
- I've renamed some variables in the driver, so that their values don't
  get reset by the values set by the ROM, specifically,
  init.qcom.post_boot.sh

- Removed min_score_adj, I've now added a blacklist of OOM_SCORE_ADJ's
  so that the ones in the blacklist don't get their MM_ANON pages
  reclaimed.This is important,because some running services/apps may
  glitch(this happens rarely).For example, while playing music, I
  experienced crackling sounds at random intervals.

- Added functionality to wake up oom_reaper after killing a task,so that
  once the task is killed,all its pages(?) will be reaped.
  (Taken from the lowmemorykiller.c code)

- Added some code bits from SLMK(marked in the comments).

- Removed traces from the driver.

Credits
=======
Minchan Kim and Vinayak Menon for the Process Reclaim driver, and
Sultan AlSawaf(kerneltoast) for the appropriate code bits.

Signed-off-by: darkhz <kmachanwenw@gmail.com>

---
## [jmasch/Lab-4-Final-Project](https://github.com/jmasch/Lab-4-Final-Project)@[fb0732a32d...](https://github.com/jmasch/Lab-4-Final-Project/commit/fb0732a32df3b3371df708a72191c02d5ba000e0)
#### Sunday 2021-01-03 18:27:00 by jmasch

Update Lab4.py

##(12.26.20) Entry 2: 8:00 p.m. Start 9:40 p.m. End... didn't add it to GitHub until today. It was really frustrating at times because I do not think I had a very strong grasp on what a prime factor was, let alone how to find the largest one in a number. I had found someone explaining how you could find it with coding but that was not helpful to me really because I ended up spending an hour writing a code that did not make very much sense. I decided to start over and just google how to solve for the largest prime factor without coding—just arithmetically. This helped a lot more and I was able to write what I thought was a much simpler code in the end. I was really surprised when the number actually came out to be correct because I questioned my logic on this problem. Especially using a while loop inside of a for loop—that was something that I had trouble with for a while but the math.ceil helped simplify it quite a bit.

---
## [csrakowski/terminal](https://github.com/csrakowski/terminal)@[539a5dc0af...](https://github.com/csrakowski/terminal/commit/539a5dc0af26f072f6eac450d07d2d1243a34432)
#### Sunday 2021-01-03 18:55:02 by Austin Lamb

Greatly reduce allocations in the conhost/OpenConsole startup path (#8489)

I was looking at conhost/OpenConsole and noticed it was being pretty
inefficient with allocations due to some usages of std::deque and
std::vector that didn't need to be done quite that way.

So this uses std::vector for the TextBuffer's storage of ROW objects,
which allows one allocation to contiguously reserve space for all the
ROWs - on Desktop this is 9001 ROW objects which means it saves 9000
allocations that the std::deque would have done.  Plus it has the
benefit of increasing locality of the ROW objects since deque is going
to chase pointers more often with its data structure.

Then, within each ROW there are CharRow and ATTR_ROW objects that use
std::vector today.  This changes them to use Boost's small_vector, which
is a variation of vector that allows for the so-called "small string
optimization."  Since we know the typical size of these vectors, we can
pre-reserve the right number of elements directly in the
CharRow/ATTR_ROW instances, avoiding any heap allocations at all for
constructing these objects.

There are a ton of variations on this "small_vector" concept out there
in the world - this one in Boost, LLVM has one called SmallVector,
Electronic Arts' STL has a small_vector, Facebook's folly library has
one...there are a silly number of these out there.  But Boost seems like
it's by far the easiest to consume in terms of integration into this
repo, the CI/CD pipeline, licensing, and stuff like that, so I went with
the boost version.

In terms of numbers, I measured the startup path of OpenConsole.exe on
my dev box for Release x64 configuration.  My box is an i7-6700k @ 4
Ghz, with 32 GB RAM, not that I think machine config matters much here:

|        | Allocation count    | Allocated bytes    | CPU usage (ms) |
| ------ | ------------------- | ------------------ | -------------- |
| Before | 29,461              | 4,984,640          | 103            |
| After  | 2,459 (-91%)        | 4,853,931 (-2.6%)  | 96 (-7%)       |

Along the way, I also fixed a dynamic initializer I happened to spot in
the registry code, and updated some docs.

## Validation Steps Performed
- Ran "runut", "runft" and "runuia" locally and confirmed results are
  the same as the main branch
- Profiled the before/after numbers in the Visual Studio profiler, for
  the numbers shown in the table

Co-authored-by: Austin Lamb <austinl@microsoft.com>

---
## [systemsthinking-dev/featureclicker](https://github.com/systemsthinking-dev/featureclicker)@[004a359c8e...](https://github.com/systemsthinking-dev/featureclicker/commit/004a359c8e57bf47492eafbd6890ea1527723466)
#### Sunday 2021-01-03 20:40:44 by Jessica Kerr

Turn off eslint

The camelcase rule can't be turned off, it keeps complaining about it anyway
FUCK YOU ESLINT

---
## [klaude/foaas-php](https://github.com/klaude/foaas-php)@[78bc47734c...](https://github.com/klaude/foaas-php/commit/78bc47734c207c04ad9f72a17db3f5ca785fb660)
#### Sunday 2021-01-03 22:49:46 by Kevin Laude

Update that fuckin copyright year

Fuck you, 2020. And fuck you, 2021!

---
## [emkelley/Samurai-Zero-Frontend](https://github.com/emkelley/Samurai-Zero-Frontend)@[9f096c5ec2...](https://github.com/emkelley/Samurai-Zero-Frontend/commit/9f096c5ec2c84b7c4a9161d9c10ee3f5da0f4dee)
#### Sunday 2021-01-03 22:58:10 by Eric Kelley

honestly a bunch of shit got changed, I don't remember

---
## [AfonsoCunha22/EstudassesPlus](https://github.com/AfonsoCunha22/EstudassesPlus)@[8cc5a0b53c...](https://github.com/AfonsoCunha22/EstudassesPlus/commit/8cc5a0b53c7a4367b4c1968f89f1c34fd371d028)
#### Sunday 2021-01-03 23:15:27 by MiguelSquilo

Create strings.xml

Cock and ball torture from Wikipedia, the free encyclopedia at en.wikipedia.org. Cock and ball torture, CBT, is a sexual activity involving torture of the male genitals. This may involve directly painful activities such as wax play, genital spanking, squeezing, ball busting, genital flogging, urethera play, tickle torture, erotic electro stimulation, or even kicking. The recipient of such activities may receive direct physical pleasure via masochism through knowledge that the play is pleasing to a sadistic dominant. Image: electro stimulation applied on a penis. Contents Section 1: In pornography Section 2: Ball stretcher Section 3: Parachute Section 4: Humbler Section 5: Testicle Cuff Section 1: In pornography. In addition to it's occational role in BDSM pornography, temakeria, literally ball kicking, is a separate genre in Japan. One notable actress in temakeria is Erika Negai, who typically uses her martial art skills to knee or kick men in the testicles. Section 2: Ball stretcher.

---

# [<](2021-01-02.md) 2021-01-03 [>](2021-01-04.md)

