## *good gosh*

It's so many stuff on **github**! Here's one more attempt to *get a grip*. And
an [index](docs/messages.md).

---

# [2023-06-22](docs/good-messages/2023/2023-06-22.md)


there were a lot of events recorded by [gharchive.org](https://www.gharchive.org/) of which 2,148,489 were push events containing 3,435,110 commit messages that amount to 275,367,687 characters filtered with [words.py@e23d022007...](https://github.com/defgsus/good-github/blob/e23d022007992279f9bcb3a9fd40126629d787e2/src/words.py) to these 69 messages:


## [morrowwolf/cmss13](https://github.com/morrowwolf/cmss13)@[ce818246c1...](https://github.com/morrowwolf/cmss13/commit/ce818246c107cf97525a05f6f3a66e120117b8c3)
#### Thursday 2023-06-22 00:05:25 by QuickLode

The Hazmat Joe (#3259)

# About the pull request
This pull request resprites the entire Working Joe from toes to head. It
also gives two additional uniforms which are meant for hazardous use,
and this PR should act as a foundation for future implementation of the
Hazmat Joe into CM's gameplay. Additionally, I may just set this to
draft and let it be reviewed while I work on the actual implementation.

They are complete with distinctive loadouts, which focus more on
hazardous situations, repair, and firefighting. Though may tweak things
depending on how its implemented.

<!-- Remove this text and explain what the purpose of your PR is.

Mention if you have tested your changes. If you changed a map, make sure
you used the mapmerge tool.
If this is an Issue Correction, you can type "Fixes Issue #169420" to
link the PR to the corresponding Issue number #169420.

Remember: something that is self-evident to you might not be to others.
Explain your rationale fully, even if you feel it goes without saying.
-->

# Explain why it's good for the game
This adds a fan favorite variation of your inexpensive, reliable friend!
You've seen him in quite a few places, and now he's coming to CM!

Also, the resprite of the Joe fixes up some minor sprite issues that
were encountered on previous models.

More content, more roleplay possibilities! ARES! Get me some Joes to put
that reactor fire out ASAP!
# Testing Photographs and Procedure

https://cdn.discordapp.com/attachments/490668342357786645/1104748917398175795/image.png

https://media.discordapp.net/attachments/490668342357786645/1105643891107049572/image.png
Ran several tests and they went well.


# Changelog
:cl:QuickLoad,Frans_Feiffer,nauticall
add: Adds The Hazmat Joe with two minor variations. This is a Working
Joe equipped to handle hazardous situations, dangerous repairs and
firefighting! They are complete with their own gear, tasks, job and
purpose. Forget the trashbag, get that wall fixed before we get spaced!
imageadd: Adds a new Working Joe model made by Frans Feiffer!
imageadd: Adds two variations of the Working Joe, aka the Hazmat Joe.
Complete with accessories! Beautiful sprites by Frans Feiffer!
add: Android Maintenance Stations / Synthetic Repair Stations will
remove shrapnel & fix organ damage. Working Joes no longer have knives,
and should report to the stations for repair. Gigantic thanks to
nauticall for her work on this!!
imagedel: Removes(replaces) the old Working Joe model.
add: Working Joes receive some basic equipment, and are slightly
resilient to disarms.
add: Working Joes will start at 3, with a maximum of 6 depending on
population.
add: Joes can access a Synthetic vendor to replace their uniform if it
is damaged.
fix: Minor changes to PO Uniform.
/:cl:

---------

Co-authored-by: naut <nautilussplat@gmail.com>
Co-authored-by: BeagleGaming1 <56142455+BeagleGaming1@users.noreply.github.com>

---
## [lcbjrrr/btt](https://github.com/lcbjrrr/btt)@[47d6f526bf...](https://github.com/lcbjrrr/btt/commit/47d6f526bf0bd46d48d1b96f3049555036361582)
#### Thursday 2023-06-22 00:39:11 by Luiz Barboza

Add files via upload

Thanksgiving 2015
This directory contains the data behind the story Here’s What Your Part of America Eats On Thanksgiving.

Using a SurveyMonkey poll, we asked 1,058 respondents on Nov. 17, 2015 the following questions about their Thanksgiving:

Do you celebrate Thanksgiving?
What is typically the main dish at your Thanksgiving dinner?
Other (please specify)
How is the main dish typically cooked?
Other (please specify)
What kind of stuffing/dressing do you typically have?
Other (please specify)
What type of cranberry sauce do you typically have? 
Other (please specify)
Do you typically have gravy?
Which of these side dishes are typically served at your Thanksgiving dinner? Please select all that apply.
Brussel sprouts
Carrots
Cauliflower
Corn
Cornbread
Fruit salad
Green beans/green bean casserole
Macaroni and cheese
Mashed potatoes
Rolls/biscuits
Vegetable salad
Yams/sweet potato casserole
Other (please specify)
Which type of pie is typically served at your Thanksgiving dinner? Please select all that apply. 
Apple
Buttermilk
Cherry
Chocolate
Coconut cream
Key lime
Peach
Pecan
Pumpkin
Sweet Potato
None 
Other (please specify)
Which of these desserts do you typically have at Thanksgiving dinner? Please select all that apply.
Apple cobbler
Blondies
Brownies
Carrot cake
Cheesecake
Cookies
Fudge
Ice cream
Peach cobbler
None
Other (please specify)
Do you typically pray before or after the Thanksgiving meal?
How far will you travel for Thanksgiving?
Will you watch any of the following programs on Thanksgiving? Please select all that apply. 
Macy's Parade
What's the age cutoff at your "kids' table" at Thanksgiving?
Have you ever tried to meet up with hometown friends on Thanksgiving night?
Have you ever attended a "Friendsgiving?"
Will you shop any Black Friday sales on Thanksgiving Day?
Do you work in retail?
Will you employer make you work on Black Friday?
How would you describe where you live? 
Age
What is your gender?
How much total combined money did all members of your HOUSEHOLD earn last year?
US Region

---
## [Apogee-dev/Shiptest](https://github.com/Apogee-dev/Shiptest)@[8744738e59...](https://github.com/Apogee-dev/Shiptest/commit/8744738e5955c02834d67db6f14201c28c9ac61c)
#### Thursday 2023-06-22 00:43:50 by Arturlang

Updates TGUI and adds bin folder for .bat scripts (#2011)

<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may
not be viewable. -->
<!-- You can view Contributing.MD for a detailed description of the pull
request process. -->

## About The Pull Request
Updates TGUI and build tools and .vscode files to what TG has.
Does not actually update UI's, but does have fixes for a couple
including the join game UI's tabs not working.

<!-- Describe The Pull Request. Please be sure every change is
documented or this can delay review and even discourage maintainers from
merging your PR! -->

## Why It's Good For The Game
Not needing to have a local installation of yarn to run dev-mode is
nice.
Updating TGUI is a annoying chore that helps in the future when porting
more interfaces
<!-- Please add a short description of why you think these changes would
benefit the game. If you can't justify it in words, it might not be
worth adding. -->

## Changelog

:cl:
code: Adds a bin folder with dev scripts, updates TGUI, .vscode folder
to what TG has.
fix: Fixes the input in the bottom right being white in darkmode, no
more unreadable text
fix: You can now use the tab buttons in the join ship menu.
qol: The outpost mission menu now looks a whole lot better
fix: The input bar no longer randomly becomes white and unreadable on
darkmode
/:cl:

<!-- Both :cl:'s are required for the changelog to work! You can put
your name to the right of the first :cl: if you want to overwrite your
GitHub username as author ingame. -->
<!-- You can use multiple of the same prefix (they're only used for the
icon ingame) and delete the unneeded ones. Despite some of the tags,
changelogs should generally represent how a player might be affected by
the changes rather than a summary of the PR's contents. -->

---------

Co-authored-by: Mark Suckerberg <29362068+MarkSuckerberg@users.noreply.github.com>

---
## [lcbjrrr/btt](https://github.com/lcbjrrr/btt)@[339e145684...](https://github.com/lcbjrrr/btt/commit/339e145684d95aad66413eda0a52f6a15b1864b3)
#### Thursday 2023-06-22 00:45:13 by Luiz Barboza

Add files via upload

Young People Survey
Explore the preferences, interests, habits, opinions, and fears of young people
Cover image

Data Card

Code (156)

Discussion (5)
About Dataset
Introduction
In 2013, students of the Statistics class at FSEV UK were asked to invite their friends to
participate in this survey.

The data file (responses.csv) consists of 1010 rows and 150 columns (139
integer and 11 categorical).
For convenience, the original variable names were shortened in the
data file. See the columns.csv file if you want to match the data with the original names.
The data contain missing values.
The survey was presented to participants in both electronic and written form.
The original questionnaire was in Slovak language and was later translated
into English.
All participants were of Slovakian nationality, aged between 15-30.
The variables can be split into the following groups:

Music preferences (19 items)
Movie preferences (12 items)
Hobbies & interests (32 items)
Phobias (10 items)
Health habits (3 items)
Personality traits, views on life, & opinions (57 items)
Spending habits (7 items)
Demographics (10 items)
Research questions
Many different techniques can be used to answer many questions, e.g.

Clustering: Given the music preferences, do people make up
any clusters of similar behavior?
Hypothesis testing: Do women fear certain phenomena
significantly more than men? Do the left handed people have different
interests than right handed?
Predictive modeling: Can we predict spending habits of a person
from his/her interests and movie or music preferences?
Dimension reduction: Can we describe a large number of human
interests by a smaller number of latent concepts?
Correlation analysis: Are there any connections between music and
movie preferences?
Visualization: How to effectively visualize a lot of variables
in order to gain some meaningful insights from the data?
(Multivariate) Outlier detection: Small number of participants often cheats and randomly answers the questions. Can you identify them? Hint: Local outlier factor may help.
Missing values analysis: Are there any patterns in missing responses? What is the optimal way of imputing the values in surveys?
Recommendations: If some of user's interests are known, can we predict the other? Or, if we know what a person listen, can we predict which kind of movies he/she might like?
Past research
(in slovak) Sleziak, P. - Sabo, M.: Gender differences in the prevalence of specific phobias. Forum Statisticum Slovacum. 2014, Vol. 10, No. 6. [Differences (gender + whether people lived in village/town) in the prevalence of phobias.]

Sabo, Miroslav. Multivariate Statistical Methods with Applications. Diss. Slovak University of Technology in Bratislava, 2014. [Clustering of variables (music preferences, movie preferences, phobias) + Clustering of people w.r.t. their interests.]

Questionnaire
MUSIC PREFERENCES
I enjoy listening to music.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I prefer.: Slow paced music 1-2-3-4-5 Fast paced music (integer)
Dance, Disco, Funk: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Folk music: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Country: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Classical: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Musicals: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Pop: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Rock: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Metal, Hard rock: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Punk: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Hip hop, Rap: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Reggae, Ska: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Swing, Jazz: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Rock n Roll: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Alternative music: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Latin: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Techno, Trance: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Opera: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
MOVIE PREFERENCES
I really enjoy watching movies.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
Horror movies: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Thriller movies: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Comedies: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Romantic movies: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Sci-fi movies: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
War movies: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Tales: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Cartoons: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Documentaries: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Western movies: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
Action movies: Don't enjoy at all 1-2-3-4-5 Enjoy very much (integer)
HOBBIES & INTERESTS
History: Not interested 1-2-3-4-5 Very interested (integer)
Psychology: Not interested 1-2-3-4-5 Very interested (integer)
Politics: Not interested 1-2-3-4-5 Very interested (integer)
Mathematics: Not interested 1-2-3-4-5 Very interested (integer)
Physics: Not interested 1-2-3-4-5 Very interested (integer)
Internet: Not interested 1-2-3-4-5 Very interested (integer)
PC Software, Hardware: Not interested 1-2-3-4-5 Very interested (integer)
Economy, Management: Not interested 1-2-3-4-5 Very interested (integer)
Biology: Not interested 1-2-3-4-5 Very interested (integer)
Chemistry: Not interested 1-2-3-4-5 Very interested (integer)
Poetry reading: Not interested 1-2-3-4-5 Very interested (integer)
Geography: Not interested 1-2-3-4-5 Very interested (integer)
Foreign languages: Not interested 1-2-3-4-5 Very interested (integer)
Medicine: Not interested 1-2-3-4-5 Very interested (integer)
Law: Not interested 1-2-3-4-5 Very interested (integer)
Cars: Not interested 1-2-3-4-5 Very interested (integer)
Art: Not interested 1-2-3-4-5 Very interested (integer)
Religion: Not interested 1-2-3-4-5 Very interested (integer)
Outdoor activities: Not interested 1-2-3-4-5 Very interested (integer)
Dancing: Not interested 1-2-3-4-5 Very interested (integer)
Playing musical instruments: Not interested 1-2-3-4-5 Very interested (integer)
Poetry writing: Not interested 1-2-3-4-5 Very interested (integer)
Sport and leisure activities: Not interested 1-2-3-4-5 Very interested (integer)
Sport at competitive level: Not interested 1-2-3-4-5 Very interested (integer)
Gardening: Not interested 1-2-3-4-5 Very interested (integer)
Celebrity lifestyle: Not interested 1-2-3-4-5 Very interested (integer)
Shopping: Not interested 1-2-3-4-5 Very interested (integer)
Science and technology: Not interested 1-2-3-4-5 Very interested (integer)
Theatre: Not interested 1-2-3-4-5 Very interested (integer)
Socializing: Not interested 1-2-3-4-5 Very interested (integer)
Adrenaline sports: Not interested 1-2-3-4-5 Very interested (integer)
Pets: Not interested 1-2-3-4-5 Very interested (integer)
PHOBIAS
Flying: Not afraid at all 1-2-3-4-5 Very afraid of (integer)
Thunder, lightning: Not afraid at all 1-2-3-4-5 Very afraid of (integer)
Darkness: Not afraid at all 1-2-3-4-5 Very afraid of (integer)
Heights: Not afraid at all 1-2-3-4-5 Very afraid of (integer)
Spiders: Not afraid at all 1-2-3-4-5 Very afraid of (integer)
Snakes: Not afraid at all 1-2-3-4-5 Very afraid of (integer)
Rats, mice: Not afraid at all 1-2-3-4-5 Very afraid of (integer)
Ageing: Not afraid at all 1-2-3-4-5 Very afraid of (integer)
Dangerous dogs: Not afraid at all 1-2-3-4-5 Very afraid of (integer)
Public speaking: Not afraid at all 1-2-3-4-5 Very afraid of (integer)
HEALTH HABITS
Smoking habits: Never smoked - Tried smoking - Former smoker - Current smoker (categorical)
Drinking: Never - Social drinker - Drink a lot (categorical)
I live a very healthy lifestyle.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
PERSONALITY TRAITS, VIEWS ON LIFE & OPINIONS
I take notice of what goes on around me.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I try to do tasks as soon as possible and not leave them until last minute.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I always make a list so I don't forget anything.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I often study or work even in my spare time.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I look at things from all different angles before I go ahead.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I believe that bad people will suffer one day and good people will be rewarded.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I am reliable at work and always complete all tasks given to me.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I always keep my promises.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I can fall for someone very quickly and then completely lose interest.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I would rather have lots of friends than lots of money.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I always try to be the funniest one.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I can be two faced sometimes.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I damaged things in the past when angry.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I take my time to make decisions.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I always try to vote in elections.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I often think about and regret the decisions I make.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I can tell if people listen to me or not when I talk to them.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I am a hypochondriac.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I am emphatetic person.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I eat because I have to. I don't enjoy food and eat as fast as I can.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I try to give as much as I can to other people at Christmas.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I don't like seeing animals suffering.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I look after things I have borrowed from others.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I feel lonely in life.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I used to cheat at school.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I worry about my health.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I wish I could change the past because of the things I have done.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I believe in God.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I always have good dreams.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I always give to charity.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I have lots of friends.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
Timekeeping.: I am often early. - I am always on time. - I am often running late. (categorical)
Do you lie to others?: Never. - Only to avoid hurting someone. - Sometimes. - Everytime it suits me. (categorical)
I am very patient.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I can quickly adapt to a new environment.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
My moods change quickly.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I am well mannered and I look after my appearance.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I enjoy meeting new people.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I always let other people know about my achievements.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I think carefully before answering any important letters.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I enjoy childrens' company.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I am not afraid to give my opinion if I feel strongly about something.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I can get angry very easily.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I always make sure I connect with the right people.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I have to be well prepared before public speaking.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I will find a fault in myself if people don't like me.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I cry when I feel down or things don't go the right way.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I am 100% happy with my life.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I am always full of life and energy.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I prefer big dangerous dogs to smaller, calmer dogs.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I believe all my personality traits are positive.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
If I find something the doesn't belong to me I will hand it in.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I find it very difficult to get up in the morning.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I have many different hobbies and interests.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I always listen to my parents' advice.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I enjoy taking part in surveys.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
How much time do you spend online?: No time at all - Less than an hour a day - Few hours a day - Most of the day (categorical)
SPENDING HABITS
I save all the money I can.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I enjoy going to large shopping centres.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I prefer branded clothing to non branded.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I spend a lot of money on partying and socializing.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I spend a lot of money on my appearance.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I spend a lot of money on gadgets.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
I will hapilly pay more money for good, quality or healthy food.: Strongly disagree 1-2-3-4-5 Strongly agree (integer)
DEMOGRAPHICS
Age: (integer)
Height: (integer)
Weight: (integer)
How many siblings do you have?: (integer)
Gender: Female - Male (categorical)
I am: Left handed - Right handed (categorical)
Highest education achieved: Currently a Primary school pupil - Primary school - Secondary school - College/Bachelor degree (categorical)
I am the only child: No - Yes (categorical)
I spent most of my childhood in a: City - village (categorical)
I lived most of my childhood in a: house/bungalow - block of flats (categorical)

---
## [Opentrons/opentrons](https://github.com/Opentrons/opentrons)@[5271d4fbc4...](https://github.com/Opentrons/opentrons/commit/5271d4fbc473bb8f2506a90b2c929535c82892f6)
#### Thursday 2023-06-22 01:03:12 by Seth Foster

feat(api,shared-data): error codes in PE (#12936)

On the python side of our code, we want our new enumerated exceptions to
be gradually integratable, and we also want to make sure that any errors
that we didn't yet get the chance to give error codes end up with error
codes. To do this in a programmatic way, we can add some automated
methods for wrapping python exceptions.

All enumerated errors now get to wrap errors. These are optional
sequences of more enumerated errors that are considered to have caused
the top-level one - in most cases, this will be because the enumerated
error explicitly was instantiated to wrap a python exception, but it
could also be if it was raised from one.

Since we only wrap other enumerated errors, we need a way to make
exceptions enumerated errors. A new exception type (but not code - it's
just a GeneralError) called PythonException has this capability; it lets
you give it BaseExceptions in addition to other EnumeratedErrors, and
it's capable of walking the python memory model internals to try and get
the other exceptions in a stack of raise from ... raise from ... calls
that are reasonably popular in our code. This is functionality that is
promoted out of The Dunder Zone in python 3.11, so I feel pretty good
using it (this is what ExceptionGroups are).

So now, as in the tests, if you catch an exception and give it to a
PythonException you bless it with an error code and save all the
exceptions and their stack traces for later inspection. Cool!

ProtocolEngine is the first place we'll go through and add places that
actually use these error codes, since it's in a lovely high-leverage
middle spot in our stack. That means we both get to test the upward
interface of how these things will be represented in the HTTP API and
how they'll be created from lower exceptions.

ProtocolEngine already has its own very large and robust set of custom
exceptions, which is awesome. We can make them inherit from the
enumerated errors pretty easily, but unfortunately we have to add a
bunch of stuff to their constructors to pass along things like the
ability to wrap other exceptions and so on. Luckily that's just typing.

Once we've done that, at the three points we catch all missed exceptions
we have to switch over to creating the new style. ProtocolEngineErrors
get passed on; uncaught legacy errors get captured as PythonExceptions;
and uncaught errors in the normal core do too.

Finally, we have to represent this new style of error in the
ErrorOccurrence objects. This is the fun part. Previously, we'd added
error codes to those objects; this was sort of a big deal because we
want them to be required when you make new ErrorOccurrences and when
clients look, but we don't want things to break when we deserialize old
ones. We can extend that trick pretty easily to add new things. What's
not quite as easy is this concept of wrapping errors. Our errors are now
essentially trees, and we need tree structure here. Luckily, jsonschema
and pydantic are actually pretty good at type-recursive schema and
object definitions, so we can plop a list of other error occurrences in
there.

Now, when we catch one of these errors that's bubbled up from hardware,
we give it a name and we capture its entire history in an inspectable
way, and I think that's really cool.

---
## [Gijs-Pro/Azul](https://github.com/Gijs-Pro/Azul)@[d75aefc9ac...](https://github.com/Gijs-Pro/Azul/commit/d75aefc9aca68f4f3782735fc11a313fba65cd18)
#### Thursday 2023-06-22 01:14:16 by Gijs Turkenburg

holy shit eindelijk werkt BU mijn god, nu nog reeksen en experiment

---
## [Latentish/Shiptest](https://github.com/Latentish/Shiptest)@[7468161f7e...](https://github.com/Latentish/Shiptest/commit/7468161f7ec2180c7752cd2cc99b164522a3540a)
#### Thursday 2023-06-22 01:24:12 by FalloutFalcon

Trickwines! Again! (#1914)

<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may
not be viewable. -->
<!-- You can view Contributing.MD for a detailed description of the pull
request process. -->

## About The Pull Request

Trickwines are a set of new reagents aimed at improving tribal/srm style
ships
The core concept are wines crafted out of mob drops and plants that
provide a buff on drinking and a debuff on throwing with bonus effects
against fauna
To facilitate the transfer of booze to target it also adds breakaway
flasks, 50u glass bottles that shatter violently on contact providing
extra throw force as well as a 25u gulp size which forces the user to
choose between buff or debuff
I plan on adding a fair few more Trickwines and the SRM Barrel Class
Brewer Vessel (SRM could really use one then 1 original ship) in later
prs to build on this concept
This HackMD will provide descriptions for the wines as well as a place
of information for all Trickwine-related content
https://hackmd.io/eUIddN2dS3mpeU1CThFGng

<!-- Describe The Pull Request. Please be sure every change is
documented or this can delay review and even discourage maintainers from
merging your PR! -->

## Why It's Good For The Game
Adds a fun new option for ships that lack proper chemistry and forces
them to choose which effect they actually want.

<!-- Please add a short description of why you think these changes would
benefit the game. If you can't justify it in words, it might not be
worth adding. -->

## Changelog

:cl: FalloutFalcon
add: Trickwines
add: Breakaway flasks!
add: Basic Trickwine brewing equipment to the SRM glaive
imageadd: Sprites for breakaway flasks along with trick wine icons for
them!
code: Breakaway_flask_icon_state = null used for the same purpose as the
glass and shot glass versions
/:cl:

<!-- Both :cl:'s are required for the changelog to work! You can put
your name to the right of the first :cl: if you want to overwrite your
GitHub username as author ingame. -->
<!-- You can use multiple of the same prefix (they're only used for the
icon ingame) and delete the unneeded ones. Despite some of the tags,
changelogs should generally represent how a player might be affected by
the changes rather than a summary of the PR's contents. -->

I DIDNT KNOW IF YOU RENAME A BRANCH IT CLOSES PRS RELATED TO IT?? I
THOUGHT IT JUST KNEW!!
3rd times a charm!

---------

Signed-off-by: FalloutFalcon <86381784+FalloutFalcon@users.noreply.github.com>
Signed-off-by: Mark Suckerberg <mark@suckerberg.gay>
Co-authored-by: Mark Suckerberg <mark@suckerberg.gay>

---
## [Latentish/Shiptest](https://github.com/Latentish/Shiptest)@[0e6f7fa646...](https://github.com/Latentish/Shiptest/commit/0e6f7fa64649dfbf52b8e4b71756e6625e50fdd0)
#### Thursday 2023-06-22 01:24:12 by Imaginos16

TileTest Part 1: Big Sweeping Changes! (#2054)

<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may
not be viewable. -->
<!-- You can view Contributing.MD for a detailed description of the pull
request process. -->
## !! WARNING !!
This is a multi-parter PR. Due to the fact that tiles here on shiptest
are an unholy amalgam of decals, greyscale sprites and multiple
spread-out files, things are *bound* to look weird. If they do, feel
free to report it and it will be addressed in future PRs.

## About The Pull Request

This PR finally accomplishes the promise I made to @triplezeta a year
ago, creating a unique tileset for the server that people may enjoy!

To put every single microscopic change I have made would take forever,
so I will instead provide a series of screenshots of it in action!


![image](https://github.com/shiptest-ss13/Shiptest/assets/77556824/00e9cec0-335a-4367-90f9-1adc572595f3)


![image](https://github.com/shiptest-ss13/Shiptest/assets/77556824/497310ab-fe06-4b31-8774-70e79338a7d8)


![image](https://github.com/shiptest-ss13/Shiptest/assets/77556824/80991d0b-c48b-404b-b4a6-cbb1c4c6af3a)


![image](https://github.com/shiptest-ss13/Shiptest/assets/77556824/cc06d43e-3873-499e-aa12-51a0d7a37c98)

<!-- Describe The Pull Request. Please be sure every change is
documented or this can delay review and even discourage maintainers from
merging your PR! -->

## Why It's Good For The Game
Utilizing an unique, modernized tileset for our server to differentiate
from our competitors is something that has been requested, and I was
more than happy to lend my hand to make it a reality!
<!-- Please add a short description of why you think these changes would
benefit the game. If you can't justify it in words, it might not be
worth adding. -->

## Changelog

:cl: PositiveEntropy
del: Removes several unused floor types, as well as completely
annihilating the "monofloor" and "dirty" floor types, and the "edge"
decal type.
imageadd: Redoes the floors using the TileTest tileset!
/:cl:

<!-- Both :cl:'s are required for the changelog to work! You can put
your name to the right of the first :cl: if you want to overwrite your
GitHub username as author ingame. -->
<!-- You can use multiple of the same prefix (they're only used for the
icon ingame) and delete the unneeded ones. Despite some of the tags,
changelogs should generally represent how a player might be affected by
the changes rather than a summary of the PR's contents. -->

---------

Co-authored-by: Bjarl <94164348+Bjarl@users.noreply.github.com>

---
## [Blacklion567/Little-Projects-HTML-CSS-JS](https://github.com/Blacklion567/Little-Projects-HTML-CSS-JS)@[002012b62d...](https://github.com/Blacklion567/Little-Projects-HTML-CSS-JS/commit/002012b62d7e8dcdd796675804ab64e789f09ffa)
#### Thursday 2023-06-22 02:06:17 by Blacklion567

Little-Projects-HTML-CSS-JS

I'm sorry for the delay upload, Because of small problems. 

1. "When you have a dream, you've got to grab it and never let go."
— Carol Burnett

2. "Nothing is impossible. The word itself says 'I'm possible!'"
— Audrey Hepburn

3. "There is nothing impossible to they who will try."
— Alexander the Great

4. "The bad news is time flies. The good news is you're the pilot."
— Michael Altshuler

5. "Life has got all those twists and turns. You've got to hold on tight and off you go."
— Nicole Kidman

---
## [Bubberstation/Bubberstation](https://github.com/Bubberstation/Bubberstation)@[146cd5d7ff...](https://github.com/Bubberstation/Bubberstation/commit/146cd5d7ffb364ee08d816778006bd3a93e88da1)
#### Thursday 2023-06-22 02:47:59 by Cyprex

Oversized quirk changes (#271)

<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may
not be viewable. -->
<!-- You can view Contributing.MD for a detailed description of the pull
request process. -->

## About The Pull Request

Yeah so 15 brain damage for forgetting to toggle walk intent when
walking through an airlock is really harsh. They have various benefits
and disadvantages, I think even with these changes the are weaker.

## Changelog

<!-- If your PR modifies aspects of the game that can be concretely
observed by players or admins you should add a changelog. If your change
does NOT meet this description, remove this section. Be sure to properly
mark your PRs to prevent unnecessary GBP loss. You can read up on GBP
and it's effects on PRs in the tgstation guides for contributors. Please
note that maintainers freely reserve the right to remove and add tags
should they deem it appropriate. You can attempt to finagle the system
all you want, but it's best to shoot for clear communication right off
the bat. -->

:cl:
balance: Oversized people no longer get bonuses to their grabs/their
chance to break out of being grabbed
add: Vehicle bays have been expanded to allow oversized people inside!
del: Oversized people, Nanotrasen has heard you: We've introduced a
brand new line of airlocks, extra tall- And yes it's definitely our
compassion and not the medical bills your brain injuries have caused
you... fucking hell, can't even look out for themselves... oh fuck this
thing is still on!!
/:cl:

<!-- Both :cl:'s are required for the changelog to work! You can put
your name to the right of the first :cl: if you want to overwrite your
GitHub username as author ingame. -->
<!-- You can use multiple of the same prefix (they're only used for the
icon ingame) and delete the unneeded ones. Despite some of the tags,
changelogs should generally represent how a player might be affected by
the changes rather than a summary of the PR's contents. -->

---
## [larryv/arq-helpers](https://github.com/larryv/arq-helpers)@[194c52f247...](https://github.com/larryv/arq-helpers/commit/194c52f247ea35a016fc4ef9c5235a2b30a9c9d4)
#### Thursday 2023-06-22 03:34:34 by Lawrence Velázquez

Convert indentation from spaces to tabs

I've long favored four-space indentation but find Matt Wilcox's pro-tab
counterargument [1][2] compelling, if needlessly condescending:

    This is your occasional reminder:
    Tabs are what should be used for indentation.

    Why?  Because spaces for indentation are:

    - Harder for people using assistive technology
    - Harder for people with reading comprehension issues who want more
      indentation.

    The tab is *user customisable* to be any level of indentation per
    tab character.  It is the semantically correct character.

    Please; use tab characters in any public code.  If you don't like
    how "deep" they are; adjust your editor's rendering.

    (If you are already cringing or railing against this idea because it
    would look weird to you... have a deep think.  A real deep think.)

    Spaces as indentation are self-centred and selfish.  They enforce
    *your* preference on others, when tabs would allow you *and others*
    their own preference of indentation for the same code - because they
    are user configurable.

    Yes, all editors can configure the tab to render as 1, 2, 4, 6, 8 or
    any number of spaces wide.  Learn your editor.

I've always prioritized my aesthetic preferences, deeming indentation of
two columns to be too shallow and eight, too deep.  I know tab stops are
widely configurable, but I stubbornly insist on viewing tabs at their
"natural" width of eight columns because I want to see them as everyone
else does.  (Who actually changes their tab stops?  Come on.)  Thus, the
only way to get al dente indentation that looks the same to everyone is
to use four spaces.

I've thought about switching to tabs before.  The Linux kernel coding
style guide espouses 8-column indentation on the grounds that it's very
clear and highlights excessively deep nesting [3] -- interesting ideas,
but not so interesting that I'd switch teams.

Well, Wilcox's accessibility angle has convinced me, although I still
think 8 columns is a bit much.  I'll get over it.

Reindent source code using tabs.  Do not reindent prose because it looks
awful, and I can't bring myself to do it (code is already ugly, so it's
easier to swallow).

  [1]: https://mstdn.social/@mattwilcox/110451855256437660
  [2]: https://mstdn.social/@mattwilcox/110451875354616267
  [3]: https://www.kernel.org/doc/html/latest/process/coding-style.html#indentation

---
## [RealmsMud/RealmsCode](https://github.com/RealmsMud/RealmsCode)@[00a76f1f64...](https://github.com/RealmsMud/RealmsCode/commit/00a76f1f645f5334945d092ba52233e7d71ed8d3)
#### Thursday 2023-06-22 04:33:30 by ocelot134269

Fix wall spells (#171)

* Update communication.cpp

parsing problem with the speak command causing a couple of the languages to not work. FIxed.

* Update communication.cpp

missed one

* fixing wall spells crash bug

-Fixing crash bug caused by functions calling getReturnExit() passing targetRoom as a nullptr.
-fixing knock command
-Adjusted outputs and removed print() and replaced with c++ style

* updates and bug fixes

-Added functionality for dispel command to remove exit and room effects owned by player
-Fixed dispel-magic on permanent exit effects
-Added effect vs level strength to dispel-magic and disintegrate spells
-Added wall-of-lighting and wall-of-sleet spells/effects, and all supporting code for them
-Refactored wall spell redundant code
-Fixed/updated a bunch of output, and replaced a lot of c sytle print() with cout

* fix stupid hatesEnemy() GIGO error

runaway switch statement had logic totally broke dick as fuck.

* Update creatures.cpp

minor change

---
## [Kapu1178/daedalusdock](https://github.com/Kapu1178/daedalusdock)@[8f0512b923...](https://github.com/Kapu1178/daedalusdock/commit/8f0512b92377a891a728e83d1d269820e4c1d5f8)
#### Thursday 2023-06-22 05:25:14 by Kapu1178

Spatialgridports (#352)

* adds an error message to movables not being removed from the grid... again (#75161)

<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may
not be viewable. -->

I swear i didnt fail at this like 3 times i tested it this time.

adds a descriptive error of what spatial grid cells a movable is stuck
in, and in what channels. This only runs during unit tests. hopefully
this should be enough information to go off of to fix the spurious
cockroach error. if its not then i can try tracking all grid cell
changes during unit tests.
error looks like this:
```
[2023-05-03 04:16:34.009] runtime error: /mob/living/trolls_the_maintainer instance, which is in nullspace, and thus not be within the contents of any spatial grid cell, was in the contents of 2 spatial grid cells when it was only supposed to be in one! within the contents of the following cells: {(221, 119, 11), within channels: hearing}, {coords: (136, 136, 14), within channels: hearing}. (code/controllers/subsystem/spatial_gridmap.dm:581)
```
for something located in nullspace but still in the contents of >0 cells
and:
```
runtime error: /mob/living/trolls_the_maintainer instance, which is supposed to only be in the contents of a spatial grid cell at coords: (136, 136, 14), was in the contents of 6 spatial grid cells when it was only supposed to be in one! within the contents of the following cells: {(68, 153, 2), within channels: hearing}, {coords: (221, 170, 3), within channels: hearing}, {coords: (255, 153, 11), within channels: hearing}, {coords: (170, 238, 13), within channels: hearing}, {coords: (204, 119, 14), within channels: hearing}, {coords: (136, 136, 14), within channels: hearing}.
```
if its not in nullspace but its within more than 1 grid cell.

the coordinates here are translated from the index of the given cell to
world coordinates.

mothblocks has been standing outside my house for weeks i am fearing for
my life

---------

Co-authored-by: Mothblocks <35135081+Mothblocks@users.noreply.github.com>

* fixes contents not being removed from the spatial grid when deleted during movement between 2 grid cells (#75658)

## About The Pull Request
fixes the flaky test reports for cockroaches being stuck in the spatial
grid (which mothblocks seems to have closed all of)

cockroaches get deleted when they die, so theres a spurious unit test
failure where if a cockroach is on a tile in grid cell A and moves to a
lava tile in grid cell B, they will get killed when lava.Entered() is
called, then deleted, and when /atom/movable/Destroy() is called we try
to take them out of grid cell B (because their loc is the lava tile) but
they were never added to that cell yet because their movement never
finished, so that doesnt do anything. THEN moveToNullspace() is called,
that movement finishes before the first movement, and then in
Moved(old_loc = lava turf) we try to remove it from grid cell B which
again doesnt work, and then the first movements Moved(old_loc = original
turf) is called where we can actually remove them from the correct grid
cell, except we cant because in exit_cell() we subtract
`old_target.important_recursive_contents[channel]` from the cells
content lists, and since the target is deleted by this point it doesnt
have important_recursive_contents. so the fix here is changing this so
it subtracts `old_target.important_recursive_contents?[type] ||
old_target` instead, which works if the target is deleted.

also fixes some Entered() overrides that dont call parent and improves
documentation on spatial grid defines
## Why It's Good For The Game
fixes it without needing the change_loc() setter

* update for us

* missed this

---------

Co-authored-by: Kylerace <kylerlumpkin1@gmail.com>
Co-authored-by: Mothblocks <35135081+Mothblocks@users.noreply.github.com>

---
## [tgstation/tgstation](https://github.com/tgstation/tgstation)@[a8e16030f8...](https://github.com/tgstation/tgstation/commit/a8e16030f83911aef695ba9f28d565c41c99c3e6)
#### Thursday 2023-06-22 05:54:22 by LemonInTheDark

Optimizes timer insertion by 80% (W QDEL_IN micro) (#76214)

<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may
not be viewable. -->
<!-- You can view Contributing.MD for a detailed description of the pull
request process. -->

## About The Pull Request

[Reduces timer insertion cost by
80%](https://github.com/tgstation/tgstation/commit/c9e5b285ed74e60108fddd3f6b45d6d3995c92a8)

Timer name generation involved a LOT of string shit, some in ways where
the string only existed for a moment.
This costs a good bit of time, and can be reduced with only minimal
impacts on the end product, so let's do that. Includes a compile flag to
flip it back if we ever have trouble in future.

This is about 0.1s off init, since we do a lot of timer stuff then too

[Removes STOPPABLE flag from QDEL_IN, moves it to a bespoke
macro](https://github.com/tgstation/tgstation/commit/e7a5d7f2a78fcf0dce4742ced258c9505411b202)

Its a waste most of the time, tho I would LOVE to analyze at compile
time to work out if we care
## Why It's Good For The Game

I like it when we don't spend all of our cpu time just setting the name
var on timers. that's good and not bad.
This saves time fucking everywhere. 15% off explosions, 0.1 seconds off
init, bunch of time off foam. it's just good.

Cherry picked out of #76104 since that was too cluttered (sannnnnn)

<!-- Argue for the merits of your changes and how they benefit the game,
especially if they are controversial and/or far reaching. If you can't
actually explain WHY what you are doing will improve the game, then it
probably isn't good for the game in the first place. -->

<!-- Both :cl:'s are required for the changelog to work! You can put
your name to the right of the first :cl: if you want to overwrite your
GitHub username as author ingame. -->
<!-- You can use multiple of the same prefix (they're only used for the
icon ingame) and delete the unneeded ones. Despite some of the tags,
changelogs should generally represent how a player might be affected by
the changes rather than a summary of the PR's contents. -->

---
## [tgstation/tgstation](https://github.com/tgstation/tgstation)@[5c032cc098...](https://github.com/tgstation/tgstation/commit/5c032cc098f9a1d62f9f9dee133ae7c3e4489dca)
#### Thursday 2023-06-22 06:05:46 by LemonInTheDark

Adds border smoothing! (Look ma I'm upstreaming) (#76134)

## About The Pull Request

Ok so we currently have 1 (count em) border object that wants to smooth
with other border objects. That's the tram window.

It currently does this manually, via map edits, but that's kinda crappy
so lets be better.

This pr adds a new smoothing mode to handle border objects. 
Unlike other smoothing modes, it returns a bitfield of directions the
border object connects in.

I do this by memorizing a calculation of which dirs "connect" at init,
and reading out of a global list with border object direction, direction
between objects, and if it's a border object, the other object's dir.

I'm doing this primarily because it's become useful for wallening (a
spriter saw the tram thing and is doing the same thing to pod windows,
and I want to support that)

I do think it's potentially useful in other applications too tho, and I
like dehardcoding tram windows.

Also fun bonus (or maybe downside), it's nearly 0 cost because I pulled
the bitmask smoothing define into 2 subdefines, and am swapping the
handler one out to do what I want.
Oh also I got rid of a for loop in smoothing code, redundant and costs
time in list iteration

[Moves tram windows over to the new border object
smoothing](https://github.com/tgstation/tgstation/commit/114873679c94d680788edee9665fa18dba8108c0)

Also replaces some typepath chicanery with a setDir override, for
redundancy in future
Oh and there's a update paths script too, to be nice

## Why It's Good For The Game

More visual possibility in future, fixes a hack we have currently, and
makes some spriters happy.

## Changelog
:cl:
fix: Dehardcodes some stuff with tram windows, they'll be easier to map
with now
refactor: Border objects can now smooth with each other. I'm sure
something cool will come of this
/:cl:

---
## [EndCredits/android_kernel_xiaomi_sm8350](https://github.com/EndCredits/android_kernel_xiaomi_sm8350)@[d27e046d59...](https://github.com/EndCredits/android_kernel_xiaomi_sm8350/commit/d27e046d59a401adf9f0204c0a75b3f26e13b579)
#### Thursday 2023-06-22 06:11:45 by EndCredits

zram: Switch default compression algorithm to zstd

 * Yeah. Thanks to god damn Tencent and other applications. They are
   ating our memory insinely

Signed-off-by: EndCredits <endcredits@crepuscular-aosp.icu>

---
## [newstools/2023-daily-post-nigeria](https://github.com/newstools/2023-daily-post-nigeria)@[33fe077da0...](https://github.com/newstools/2023-daily-post-nigeria/commit/33fe077da0261f9b9d5eb4c5e7a1ada831da8bf6)
#### Thursday 2023-06-22 06:14:32 by Billy Einkamerer

Created Text For URL [dailypost.ng/2023/06/22/i-made-mistake-neymar-apologises-publicly-after-cheating-on-pregnant-girlfriend/]

---
## [ghostsheet/cmss13](https://github.com/ghostsheet/cmss13)@[d1d23352eb...](https://github.com/ghostsheet/cmss13/commit/d1d23352eb41452a98d0c66c7fbf5c5ea4143ffe)
#### Thursday 2023-06-22 06:32:29 by fira

Reduces SG Full Auto Scatter (#3556)

# About the pull request

<!-- Remove this text and explain what the purpose of your PR is.

Mention if you have tested your changes. If you changed a map, make sure
you used the mapmerge tool.
If this is an Issue Correction, you can type "Fixes Issue #169420" to
link the PR to the corresponding Issue number #169420.

Remember: something that is self-evident to you might not be to others.
Explain your rationale fully, even if you feel it goes without saying.
-->

It's been bugging me for a long time, but when you fire for a good dozen
seconds with the standard issue smartguns, the bullets start scattering.
So, so far you'll say, good Fira, that's soulful!

However, we have no ACTUAL recoil or similar mechanic. So letting go of
the LMB for just even 20 miliseconds is enough to reset scatter to start
of firing. **It's just a noobtrap with zero real gameplay elements.**

This reduces the max scatter so that bullets don't just start (after
EIGHTY shots!) spraying a (roughly) 48° angle cone, but instead 12°
which mostly stays on the same actual turfs. At this value the targeting
impact is vastly minimized, but the projectile visuals retain
significant scattering.

I don't think this ACTUALLY qualifies as a "balance" change due to how
irrelevant the "mechanic" was, but i'll slap it on.

# Explain why it's good for the game
Less of a noobtrap and pointless purely mechanical micromanagement so
people can focus on playing the game.

I'd rather we get a recoil mechanic to make this meaningful but it's bit
of a bigger problem...

# Changelog
:cl:
qol: Reduced USCM SG max scattering on Full Auto fire so you don't have
to periodically let go of the fire button to keep it from firing way
wide.
/:cl:

---
## [Kapu1178/daedalusdock](https://github.com/Kapu1178/daedalusdock)@[27941db27b...](https://github.com/Kapu1178/daedalusdock/commit/27941db27b0d58bf36e105054465502d73d614ad)
#### Thursday 2023-06-22 06:37:36 by LemonInTheDark

Optimizes timer insertion by 80% (W QDEL_IN micro) (#76214)

<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may
not be viewable. -->
<!-- You can view Contributing.MD for a detailed description of the pull
request process. -->

[Reduces timer insertion cost by
80%](https://github.com/tgstation/tgstation/commit/c9e5b285ed74e60108fddd3f6b45d6d3995c92a8)

Timer name generation involved a LOT of string shit, some in ways where
the string only existed for a moment.
This costs a good bit of time, and can be reduced with only minimal
impacts on the end product, so let's do that. Includes a compile flag to
flip it back if we ever have trouble in future.

This is about 0.1s off init, since we do a lot of timer stuff then too

[Removes STOPPABLE flag from QDEL_IN, moves it to a bespoke
macro](https://github.com/tgstation/tgstation/commit/e7a5d7f2a78fcf0dce4742ced258c9505411b202)

Its a waste most of the time, tho I would LOVE to analyze at compile
time to work out if we care

I like it when we don't spend all of our cpu time just setting the name
var on timers. that's good and not bad.
This saves time fucking everywhere. 15% off explosions, 0.1 seconds off
init, bunch of time off foam. it's just good.

Cherry picked out of #76104 since that was too cluttered (sannnnnn)

<!-- Argue for the merits of your changes and how they benefit the game,
especially if they are controversial and/or far reaching. If you can't
actually explain WHY what you are doing will improve the game, then it
probably isn't good for the game in the first place. -->

<!-- Both :cl:'s are required for the changelog to work! You can put
your name to the right of the first :cl: if you want to overwrite your
GitHub username as author ingame. -->
<!-- You can use multiple of the same prefix (they're only used for the
icon ingame) and delete the unneeded ones. Despite some of the tags,
changelogs should generally represent how a player might be affected by
the changes rather than a summary of the PR's contents. -->

---
## [mentalisttraceur/home](https://github.com/mentalisttraceur/home)@[9377974490...](https://github.com/mentalisttraceur/home/commit/9377974490ceaf9ff62688ffd58b060515c0108b)
#### Thursday 2023-06-22 06:42:10 by Alexander Kozhevnikov

.emacs: make ":q" in vi work sensibly

This has been a pain-point for me at least since I started
using Evil, if not earlier. How does it make sense for ":q"
to close the current window instead of the buffer in that
window!? (not even in addition to! just instead!)

Anyway, to me, it makes far more sense to have ":q" close
the buffer/file, because it's the inverse of opening a
file, and opening a file does not normally create a new
window. So why would I want my previously-set-up window
killed when doing my "close this file" muscle memory? And
why would I want the file to NOT close when doing CLOSE.
THE. FILE. muscle memory?

Maybe this makes slightly more sense inside Vim (it would
still be objectively worse and wronger but let's pretend
that I might be wrong on that point), but Emacs is less
like a vi-style editor and more like the shell, terminal
multiplexer, and one or more vi-style editors launched in
it. When I type ":q", that's far more like closing a vi
instance which just has that file open, than it is like
closing a pane/split/whatever-they-call-it inside a vim.

I kept putting up with it because I had other priorities,
although over the past month or two I glanced at how I'd
solve it for a few minutes here or there.

Finally fed up enough (and other priorities cleared) to
give it a more in-depth look, and luckily it didn't take
me very long to hone in on this solution (initially I
tried setting a different function in `evil-ex-commands`,
but advising `evil-quit` works more globally and reliably
with less lines of config/change - in particular, that
one advice also fixes ":wq" and doesn't break with-editor).

---
## [smeenai/craftinginterpreters](https://github.com/smeenai/craftinginterpreters)@[a1e7da2671...](https://github.com/smeenai/craftinginterpreters/commit/a1e7da2671060f31420df7fc8a2d7ac7f1f8333c)
#### Thursday 2023-06-22 07:05:09 by Shoaib Meenai

[jlox-in-rust] Implement expression evaluator

This completes Chapter 7.

Unlike in my C++ interpreter, all operators are implemented on Value
instead of in the interpreter (using overloading where possible and
named functions otherwise). Having proper sum types lends itself to that
nicely. I could have accomplished the same in C++ by wrapping my Value
std::variant in a struct, but it didn't occur to me.

My C++ interpreter had string values which either referred to the source
strings directly or were heap allocated; the Rust interpreter only has
heap allocated strings. This is partly for simplicity (the lifetimes
would be kinda annoying to deal with), but I also don't think the
additional heap allocations will cause any issues in practice.

Having a static mutable interpreter will be annoying because Rust will
require `unsafe` around all accesses to it. I'll cross that bridge when
I get to it, but I'll probably have to reconsider the design. For now I
just cheated and made the interpreter a local variable.

---
## [RubisetCie/mmm-m9k-remastered](https://github.com/RubisetCie/mmm-m9k-remastered)@[81df2e686e...](https://github.com/RubisetCie/mmm-m9k-remastered/commit/81df2e686e68f33e73e4982b5abd203796a72fe3)
#### Thursday 2023-06-22 08:26:10 by Meteor

Version 2.0

The Gameplay is unaffected. All the controls are the same as before and everything should feel just like it always has with the exception of being less jank and less prone to glitching out.
Base SWEP files now feature Dev Notes so that developers will have an easier time making weapons using the bases.
The Gameplay should feel better overall for people with a high ping as lag compensation was added wherever it was needed.

LEFT HAND SUPPORT! wow. I know. "m9k_lefthanded 1" in console to enable left-hand mode. Clientside only. Do note that Weapons that make use of viewmodel projection cannot be flipped and therefor will still be right-handed.

General:
- Major performance improvements in pretty much every file.
- Script files have been made more readable in general.
- Code has been separated between CLIENT and SERVER for a slight performance increase and improved readability.
- Various improvements to sound scripts, should take up less memory and reduce load times.
- Improved idle animations. They're now Lua-level, meaning jank/broken idle animations are automatically replaced.
- Every bullet fired now has a tracer.
- You can no longer use IronSights on some shotguns as it was just weird and its pointless anyway.
- Improved the Shotgun-base reload animations for thirdperson view.
- Slightly adjusted the position of the machete viewmodel.
- Categories have been renamed from "M9K (Weapon Type)" to "M9kR: (Weapon Type)"
- Admin Weapons have been removed. As fun as they were, they were causing far too many issues to be worth it. There MIGHT be an expansion in the future featuring these Weapons and new ones.
- Slightly adjusted the Ironsight position and angles of the m249lmg.
- The Honeybadger and KAC_PDW now also have a scope in thirdperson view and when dropped.
- The Remington 1858 no longer fires multiple shots like a shotgun in the remastered balance and can no longer make use of ironsights. They were unusable and hilariously bad.
- Changed the holdtype of the tec9 to "SMG" to more accurately represent the viewmodel.
- Disabled ironsights for the Magpul PDR. I wanted to add a scope to it but the viewmodel doesn't allow it and aiming down the rail was dumb.
- The Harpoon now does more damage on melee attacks.
- Increased the RPM of the m9k_m202 and the Reloading is now a bit faster.
- Reduced the spread penalty from moving from *6 to *2. Bullets going sideways are a thing of the past now.
- The Flaregun and Peashooters have been moved to the "M9kR: Other" Category.
- Frag Grenade has been renamed to M61 Grenade.
- Added IED ammo crate and 40mm Grenades ammo crate
- Sticky Grenades stick to all entities now.
- The Knife, Machete, and Harpoon stick to surfaces way easier as the logic for that has been overhauled.
- Ammo Entities have gotten a [B] tag which stands for "BASE" in their name at the start now.
- RPG crate has been renamed to Propelled Rockets crate.
- Countless of other improvements for all entities.

New Weapons:
- Orbital Strike Cannon. Yes, it is back and better than ever! With c_hands! wow!
- IED Detonator. They make use of c_hands through model projection and they do not crash your game when you spam a ton of them! wow! Also matching world models! wow!
- Davy Crockett. A lot of people requested for this weapon to return. I didn't want to bring it back as this single Weapon has 8 lua files associated with it and it is a crazy amount of work to do. I did it anyway. You're welcome.
> The Davy Crockett no longer changes the models of players and NPCs to charpels. Changing models causes more issues than you think.

Base Improvements:
- Recoil of Weapons has been improved drastically for People that have a high ping.
- Weapons can now be reloaded even when full. Unused ammo is refunded. (Exception: Most Shotguns) - This means that you can also UNLOAD Weapons, wow!
- Added a new var that allows weapons to fire underwater if set to true.
- Added a new var that allows you to modify the volume of a firing sound.
- Sounds are more immersive in general as the loudness of the sounds actually make sense now. Though they're not as loud as they would be IRL since that would be annoying.
- For more fluid gameplay you're now allowed to reload while deploying the weapon.
- Scope logic is now handled serverside for bobs_scoped_base.lua based weapons which fixed countless of issues related to it.
- Throwing melee Weapons now always gets rid of the Weapon. No more knife/harpoon spamming! At least not that efficiently.
- You can now only throw melee Weapons by pressing the Reload key. Consistency!
- Lag compensation everywhere!

New Features:
- Dynamic Reload Sounds! All Weapons have received Dynamic Reload sound compatibility.
> This means that reload sounds are now played for other players as well, while the thirdperson animation may not match the sounds, at least you can now tell if someone is reloading and what the reload progress is.
> This also means that sounds are now properly synced with the firstperson animation which was not the case with some weapons before.
> Bolt-Action weapons are also affected. The sounds of the bolt being pulled back and released are now played for other players as well.
> Dynamic sounds have been synced using host_timescale 0.1 - It took a really really long time..

- Balance Switch. You can choose between the Legacy balancing and the Remastered balancing. m9k_balancemode 0/1. By default this mod now uses the Legacy balancing as it should have from the very beginning.
> This can be changed whenever and all active weapons get updated on the fly. Yes, it really happened!
> 0 = Legacy balancing | 1 = Remastered balancing.
> Do note that when using the Legacy balance.. You're still subject to the Remastered Recoil system that imitates CS:S Recoil behavior.

- Base Hooks. The majority of Weapon functions now have a "Hooked" call whenever they are executed.
> This allows Developers to expand on the Weapon functions instead of having to copy & paste the code from the base and then modifying it.
> CLIENT & SERVER
> Initialize > IntializeHooked
> ResetInternalVars > ResetInternalVarsHooked
> Deploy > DeployHooked
> Equip > EquipHooked
> Reload > ReloadHooked - Note: Can be blocked by returning true in ReloadHooked (Serverside only)
> Think > ThinkHooked
> SERVER
> OnDrop > OnDropHooked
> PrimaryAttack > PrimaryAttackHooked
.. And many more!

ConVars:
- Better help text for all ConVars.
- ConVars were moved to their respective bases.
- New Serverside print that tells you about all available ConVars and what they do.

Bug fixes:
- Fixed a bug with the bases that would cause the reload and ironsights to break after reloading a file.
- Fixed a bug with the ironsights sometimes getting stuck in the aiming position when reloading.
- Fixed a bug with m9k_spawn_with_ammo that was allowing players to duplicate ammo.
- Fixed a bug with m9k_spawn_with_reserve that was allowing players to duplicate ammo.
- Fixed scopes sometimes not working as intended. (Going out of sync, getting stuck, and more.)
- Fixed an error with meteors_grenade_base_model.lua attempting to get the information of non-existent bones on some world/view models. This used to happen with badly rigged models. Thanks to wrefgtzweve on GitHub for reporting this error.
- Fixed a bug with the m9k_minigun where the left pinkie finger becomes unwilling to grip the handle after reloading. You can't make this shit up man.
- Fixed the muzzleflash of the mp9 coming out of the shell ejection mechanism while aiming down the sights. This weapon does not have a muzzleflash parent bone and therefor should never have a muzzleflash.
- Implemented code that replaces missing textures with the appropriate materials automagically. The original creators of M9k really messed up here.
- Fixed sound loops caused by the Flaregun.

Known bugs:
- When switching m9k_zoomtoggle on and off while using a scope it can sometimes start at ZoomStage 2 instead of 1 as values cannot reset when m9k_zoomtoggle is set to 0. This is not really a problem as it fixes itself when using the scope again.
- In most environments the automatic dropping of armed grenades on player death will not work.

>> Singleplayer only:
- Shell ejection remains broken while aiming down the sights.
- The flaregun reload animations glitch out.
- Viewmodel projection is sometimes incorrectly oriented.
- The Reload animation is missing for the Matador.

COMPATIBILITY NOTE:
- If you had made custom weapons that use an M9kR base, they will most likely be broken now.
	> This had to be done as the general state of M9kR before this update was just bad.
	> Sacrifices have to be made sometimes if the result is something outstanding.

- NPCs remain unsupported. This MIGHT change in the future.
- Still no c_hands. I want them too but I'm not gonna rework hundreds of models. They're used wherever possible through viewmodel projection.

PLANNED FEATURES:
- Attaching Silencers to Weapons that used to be able to be silenced ( ACR, g36, hk416, Vikhr, KAC_PDW, and probably more that I'm forgetting about! )
- Selecting Firemodes	(MAYBE)
- Bullet Ricochet		(MAYBE) - It will always be jank so most likely not!

---
## [rust-lang/miri](https://github.com/rust-lang/miri)@[d16b5733e2...](https://github.com/rust-lang/miri/commit/d16b5733e2c98617f77e50e080a2e6ebbdfa4d88)
#### Thursday 2023-06-22 08:41:19 by bors

Auto merge of #112320 - compiler-errors:do-not-impl-via-obj, r=lcnr

Add `implement_via_object` to `rustc_deny_explicit_impl` to control object candidate assembly

Some built-in traits are special, since they are used to prove facts about the program that are important for later phases of compilation such as codegen and CTFE. For example, the `Unsize` trait is used to assert to the compiler that we are able to unsize a type into another type. It doesn't have any methods because it doesn't actually *instruct* the compiler how to do this unsizing, but this is later used (alongside an exhaustive match of combinations of unsizeable types) during codegen to generate unsize coercion code.

Due to this, these built-in traits are incompatible with the type erasure provided by object types. For example, the existence of `dyn Unsize<T>` does not mean that the compiler is able to unsize `Box<dyn Unsize<T>>` into `Box<T>`, since `Unsize` is a *witness* to the fact that a type can be unsized, and it doesn't actually encode that unsizing operation in its vtable as mentioned above.

The old trait solver gets around this fact by having complex control flow that never considers object bounds for certain built-in traits:
https://github.com/rust-lang/rust/blob/2f896da247e0ee8f0bef7cd7c54cfbea255b9f68/compiler/rustc_trait_selection/src/traits/select/candidate_assembly.rs#L61-L132

However, candidate assembly in the new solver is much more lovely, and I'd hate to add this list of opt-out cases into the new solver. Instead of maintaining this complex and hard-coded control flow, instead we can make this a property of the trait via a built-in attribute. We already have such a build attribute that's applied to every single trait that we care about: `rustc_deny_explicit_impl`. This PR adds `implement_via_object` as a meta-item to that attribute that allows us to opt a trait out of object-bound candidate assembly as well.

r? `@lcnr`

---
## [yarnpkg/berry](https://github.com/yarnpkg/berry)@[3626ea2ae3...](https://github.com/yarnpkg/berry/commit/3626ea2ae3e48ee26771b15b92292a28afe3d49d)
#### Thursday 2023-06-22 08:42:36 by Maël Nison

Adds support for running native binaries without JS intermediaries (#5508)

**What's the problem this PR addresses?**

Yarn currently cannot run native binaries without going through a JS
jumper script. Other package managers don't have this restriction, and
it makes the `yarn run` overhead worse on some scripts for little
reasons - or doesn't work at all when packages don't use jumper scripts.

**How did you fix it?**

Two mechanisms are used:

- First we check for the binary extension
- Then we check its magic number

If one of the two match a predetermined list, the binary is spawned
without going through Node. This ensures that this logic is called only
when the binary is truly a native binary, and will not affect the
behaviour of other existing scripts.

**Checklist**
<!--- Don't worry if you miss something, chores are automatically
tested. -->
<!--- This checklist exists to help you remember doing the chores when
you submit a PR. -->
<!--- Put an `x` in all the boxes that apply. -->
- [x] I have read the [Contributing
Guide](https://yarnpkg.com/advanced/contributing).

<!-- See
https://yarnpkg.com/advanced/contributing#preparing-your-pr-to-be-released
for more details. -->
<!-- Check with `yarn version check` and fix with `yarn version check
-i` -->
- [x] I have set the packages that need to be released for my changes to
be effective.

<!-- The "Testing chores" workflow validates that your PR follows our
guidelines. -->
<!-- If it doesn't pass, click on it to see details as to what your PR
might be missing. -->
- [x] I will check that all automated PR checks pass before the PR gets
reviewed.

---
## [ved-websites/fullstacked](https://github.com/ved-websites/fullstacked)@[c5dfdb85b2...](https://github.com/ved-websites/fullstacked/commit/c5dfdb85b2c0a0ade740cfff4dc850670252b6da)
#### Thursday 2023-06-22 08:47:34 by Guillaume Marcoux

implement whole login logout behavior

where to begin with this commit

frontend :
- the cookie is handled by sveltekit, and it is a cookie instead of a localStorage item because it needs to be sent to the sveltekit backend (could potentially be changed through a function in the `+layout.svelte` file, using a localstorage function getter)
- urql setup now uses authExchange, making it more resilient and no only adding mere fetchOptions (the refreshAuth still needs to be implemented, as no backend route was created yet to refresh the bearer token)
- mutation were completely overhauled to allow to run define them on component initialization, and calling them later. much less boilerplate to send data update requests directly in the frontend!
- navbar shows proper user updates with easy typing
- you can login without javascript, but the logout button, while working without javascript, requires javascript to show up, so javascript is needed to escape the hell hole of the websites I will create, muahahahaha

backend :
- lucia is now using v2-beta, which means that authentication header is available, which is what I need because my frontend and backend are cross-origin
- unfinished auth handler, but login and logouts are dealt with
- decorators allow for easy retrieving of the session and the lucia auth object
- Lucia module and Auth modules are separated to allow for greater flexibility : Auth will probably stay extremely similar while the lucia module is volatile based on backend infrastructure (and now actually works instead of breaking everything pushing me to almost want to purchase nestjs devtools)
- schema was updated to reflect cleaner lucia v2 structure (tho I kinda wish to update the table names, will see in the future)
- Lucia now has proper typing of the data used! and so is the express locals! typing rejoince
- lots-a gulp plugins are not used anymore so goodbye! as the gulp prompts was removed, so is the types folder. one root-ish folder less!
- hooks setup property getters, which can or need to be event dependent, so it doesn't statically use the event on init only

oh and also :
- graphql generator now handles all common files containing queries (`.graphql`, `.svelte`, `.server.ts`), and when it breaks oh boy does it break, typescript needs to compile for the generator to work
- Prisma fixture is officially broken as it was designed to be used with autogenerated number sequences in mind

---
## [Neonyxia/tgstation](https://github.com/Neonyxia/tgstation)@[c7f57ea1a4...](https://github.com/Neonyxia/tgstation/commit/c7f57ea1a46905e7330b5bde2f50d730530c6e6b)
#### Thursday 2023-06-22 08:53:49 by MrMelbert

Fixes a sneaky antag tell with RDS / adds policy support (#76071)

## About The Pull Request

Fixes being able to tell you are a special role via RDS

Adds policy support to RDS

## Why It's Good For The Game

Someone informed me that RDS was a 100% accurate antag tell you rolled a
delayed spawn antag (like headrev), and that's... a little bad, you can
usually insinuate you may be a headrev but straight up knowing isn't
ideal - doesn't keep everyone on equal playing field.

And while I was there I was like "y'know people might want to set policy
for this" so yeah

## Changelog

:cl: Melbert
fix: Fixed a cheeky way RDS revealed you were an antag before you
actually got antag. Sorry, you know who you are.
config: RDS now has policy.json support, to allow customization of the
roundstart "anti-grief" message.
/:cl:

---
## [khushi-411/pytorch](https://github.com/khushi-411/pytorch)@[ea384cd377...](https://github.com/khushi-411/pytorch/commit/ea384cd377e53a4f5c1ca99001dc072c11823828)
#### Thursday 2023-06-22 09:13:32 by Mark Saroufim

torch.compiler public namespace (#102182)

# torch.compiler public API

## Goal

The goal of this document is to describe the public facing API for torchdynamo and torchinductor.

Today both dynamo and torchinductor are in `torch/_dynamo` and `torch/_inductor` namespace with the only public function

`torch.compile()` which is directly placed in `torch/__init__.py`

This poses a few problems for users trying to take dependencies on PyTorch 2.0
1. Unclear BC guarantees
2. No builtin discovery mechanism outside of reading the source code
3. No hard requirements for docstrings or type annotations

Most importantly it mixes two personas the PyTorch 2.0 developer vs the PyTorch 2.0 customer so this is an attempt to address this. We draw a lot of inspiration from the `functorch` migration to the `func` namespace.

## Alternate names

We did discuss some other alternative names

1. `torch.compile` -> problem is this would break BC on the existing `torch.compile` function
2. `torch.dynamo` -> `dynamo` is so far not something we've deliberately hidden from users but problem is now figuring out what it's `_dynamo` vs `dynamo` might be confusing
3. `torch.compiler` -> 1 would be better but to keep BC this is a good compromise

# The general approach
## Proposal 1
In https://github.com/pytorch/pytorch/blob/main/torch/_dynamo/__init__.py

We have function called `reset()`, this function is essential if users are trying to `torch.compile()` a model under different settings

```python
# in _dynamo/
def reset():
    do_reset_stuff()
```

Instead we propose

```python
# in compiler/
def reset():
    do_reset_stuff() # As in copy paste the logic from _dynamo.reset

# in _dynamo/
import warnings
import inspect

def reset():
    function_name = inspect.currentframe().f_code.co_name
    warnings.warn(f"{function_name} is deprecated, use compiler.{function_name} instead", DeprecationWarning)
    return compiler.reset()

```
## Proposal 2

```python
# in compiler/
def reset():
    “””
    Docstrings here
    “””
    _dynamo.reset()

# in _dynamo/
No changes
```
Consensus so far seems to be proposal 2 since fewer warnings will be less jarring and it’ll make it quite easy to merge the public API

## Docstrings

The above was an example of a function that has no inputs or outputs but there are other functions which could use an improvement in their docstrings, for example allow_in_graph actually works over lists of functions but that’s not mentioned anywhere in the example only if you read the source code.

def allow_in_graph(fn):
    """
    Customize which functions TorchDynamo will include in the generated
    graph. Similar to `torch.fx.wrap()`.

    Parameters:
        fn (callable or list/tuple): The function(s) to be allowed in the graph.

    Returns:
        callable or list/tuple: The input function(s) included in the graph.

    Examples:
        Customize inclusion of a single function:
        ::
            torch._dynamo.allow_in_graph(my_custom_function)

        Customize inclusion of multiple functions:
        ::
            torch._dynamo.allow_in_graph([my_custom_function1, my_custom_function2])

        @torch._dynamo.optimize(...)
        def fn(a):
            x = torch.add(x, 1)
            x = my_custom_function(x)
            x = torch.add(x, 1)
            return x

        fn(...)

    Notes:
        The `allow_in_graph` function allows customization of which functions TorchDynamo
        includes in the generated graph. It can be used to include specific functions that
        are not automatically captured by TorchDynamo.

        If `fn` is a list or tuple, `allow_in_graph` will be called recursively on each
        element in the sequence.

        Once a function is allowed in the graph using `allow_in_graph`, it will be captured
        in the graph generated by TorchDynamo. This customization enables more fine-grained
        control over the functions included in the graph.

        Note that `allow_in_graph` expects the input `fn` to be a callable.

    """
    if isinstance(fn, (list, tuple)):
        return [allow_in_graph(x) for x in fn]
    assert callable(fn), "allow_in_graph expects a callable"
    allowed_functions._allowed_function_ids.add(id(fn))
    allowed_functions._disallowed_function_ids.remove(id(fn))
    return fn

So to make the API public, we’d have to write similar docstrings for all public functions we’d like to create.

The benefit of this approach is that
1. No BC risks, internal and external users relying on our tooling can slowly wean off the private functions.
2. We will also have to write correct docstrings which will automatically make our documentation easier to maintain and render correctly on pytorch.org
3. We already have some BC guarantees already, we don’t kill OptimizedModule, we rejected the PR to change the config system

The con of this approach is that
Will be stuck with some potentially suboptimal functions/classes that you can’t kill

## Testing strategy
If the approach is to mostly make a public function call an already tested private function then all we need to do is ensure that the function signatures don't change

## Which functions should be in the public API

Our heuristic for deciding whether something should be public or not is are users already relying on it for lack of other options or have we recommended some non public functions for users to debug their PT 2.0 programs.

Heuristic for not putting something in public is that it’s an experimental subsystem with the goal of turning it on by default, it’s very core dev centric, meta centric, a bunch of different configs that should be batched into a single user facing one, or something that needs to be renamed because the name is confusing

#### Top level
`torch.compile()` -> already is a public API it does require some minor improvements like having configs be passed in to any backend and not just inductor (EDIT: This was already done https://github.com/pytorch/pytorch/pull/99645l) and renaming `mode=reduce-overhead` to `mode=cudagraph`

To make sure that PT 2.0 is supported with a given pytorch version users can create a new public function and this would replace the need for `try/except` blocks around `import torch._dynamo` that has been populating user code.

```python
def pt2_enabled():
    if hasattr(torch, 'compile'):
        return True
    else:
        return False
```

For all of the below they will be translated to `torch.compiler.function_name()`

#### From _dynamo

As a starting point we looked at https://github.com/pytorch/pytorch/blob/main/torch/_dynamo/__init__.py and we suggest redefining these functions in `pytorch/torch/compiler/__init__.py`

It might also make sense to split them over multiple files and import them in `__init__.py` but because the number of functions is small it'd probably be fine to add them all into a single compiler/__init__.py until this list becomes larger

1. `reset()`
2. `allow_in_graph()`
10. `list_backends()`
12. `compile()`:  torch.compile() would be mostly a shell function passing arguments to torch.compiler.compile()
13. `assume_constant_result()`: TODO: Double check how this is useful
15. `torch._dynamo.disable()`

Some notable omissions
11. `explain()`: We need to clean up the output for this function, make it a data class and pretty printable
1. `forbid_in_graph()`: Considered adding this but should instead consolidate on `disallow_in_graph`
2. `optimize_assert()`: Already covered by `torch.compile(fullgraph=True)`
3. `check_if_dynamo_supported()`: this would be supplanted by pt2_enabled()
4. `compilation_metrics`, `graph_breaks_reasons` ..: would all be accessed via `torch.compiler.explain()`
5. `replay` does not seem useful to end customers
6. . `graph_break()`: Mostly useful for debugging or unit tests
9. `register_backend()`: End users will just pass a string backend to torch.compile, only devs will create new backends
10. `export()` : Eventually this needs to public but for now it’s not ready so just highlighting that it will be in the public API eventually
11. `disallow_in_graph()`: Usage is limited
12. `mark_static()`: we can keep this private until dynamic=True is recommended in stable
13. `mark_dynamic()`:  we can keep this private until dynamic=True is recommended in trunk
14. 8. `OptimizedModule`: This is the only class that we'd expose but is crucial since users are running code like `if isinstance(mod, OptimizedModule): torch.save(mod._orig_mod)` EDIT: because we fixed pickling we no longer need to
expose this
15. `is_compiling()`: Still not clear how this useful to end users

There are also config variables which we need to expose https://github.com/pytorch/pytorch/blob/main/torch/_dynamo/config.py

Some of our configs are useful dev flags, others are to gate experimental functionality and others are essential debugging tools and we seperate out the essential debugging and logging tools to a public facing config.

TODO: I still need to think of a good way of porting the config in a BC way here are some ideas
1. Just make all passes available and controllable via `torch.compile(options={})` but only show docstrings for the ones users should care about.

The current problem with our config system is we have 3 ways of setting them once via `options={}`, environment variables and variables in `config.py`, it'd be worth settling on one source of truth and have that be the public API.

The configs we should make public are
1. `log_file_name`
2. `verbose`
3. `cache_size_limit`
4. `repro_level` and `repro_after`: Although we can rename these to minifier and give human readable names to the levels

Everything else should stay private in particular

1. `print_graph_breaks`, `print_specializations`: should be supplanted by `explain()` for public users
2. dynamic shape configs : Users should only have to worry about `torch.compile(dynamic=True/False)`
3. The distributed flags, hook or guard configs: If we tell a user to use FSDP and DDP then the flag should be enabled by default or be in a private namespace
4. The fbcode flags: Obviously no need to be user facing
5. Skip/Allow lists: Not something normal users should play around with

#### From _inductor
Very little of inductor should be exposed in a public facing API, our core audience as in people writing models mostly just need information on what certain passes mean and how to control them a high level and they can do this with `torch.compile(options={})` so the goal here should be more to make available passes clearer and ideally consolidate them into `torch.compile()` docstrings or modes.

There are some exceptions though from https://github.com/pytorch/pytorch/blob/main/torch/_inductor/__init__.py

1. `list_mode_options()`
2. `list_options()`: this needs an additional pass to hide internal or debug options

For both of these we’d rename them to compiler.inductor_list_mode_options and compiler.inductor_list_options() since they would be in the same init file as the one for dynamo

Notable omissions
1. `_inductor.compile()`: Because of users are coming in with their own fx graph, they are likely developers
2. `_inductor.aot_compile()`:Again this is about capturing and modifying fx graphs so users APIs don't need to be public

However the configs are a slightly different story, because we can choose to either
1. Make all configs public
2. Make some configs public and keep most of the private ones. If public config is set it should override the private version
3. Make all configs controllable via `torch.compile(options={})` but make list_options() hide more things

For now 3 seems like the most reasonable choice with some high level configs we’ll keep like TORCH_COMPILE_DEBUG

Regardless here's what should probably be public or advertised more
1. `disable_progress` and verbose_progress:  Combine and enable by default
2. `fallback_random`: We could make the case this shouldn't be public if a top level deterministic mode enables this
3. `profile_bandwidth`: Or could make the case that this should be in TORCH_COMPILE_DEBUG

Notable omissions
1. Any config that would generally improve performance for most that we should probably enable by default but might be disabled in the short term because of stability: example `epilogue_fusion`, `pattern_matcher`, `reordering`
2. Autotuning flags: Should just sit behind `torch.compile(mode="max-autotune")` like `max_autotune`, `max_autotune_gemm`
3. `coordinate_descent_tuning`: This one I'm a but mixed about, maybe it just also fall into `mode="max-autotune"`
4. `trace`: `TORCH_COMPILE_DEBUG` is the best flag for all of this
5. `triton.cudagraphs`: Default should be `torch.compile(mode="reduce-overhead")` - I'd go further and rename the `mode=cudagraph` and we can keep reduce-overhead for BC reasons
6. `triton_unique_kernel_names`: Mostly useful for devs debugging
7. `dce`: which doesnt really do anything
8. `shape_padding`: Elias is working on enabling this by default in which case we also remove it

## Mechanics

This PR would include the public functions with their docstrings

Another PR will take a stab at the configs

And for work where the APIs are still being cleaned up whether its minifier or escape hatches, export or dynamic shapes, aot_inductor etc.. we’ll keep them private until a public commitment can be made

Pull Request resolved: https://github.com/pytorch/pytorch/pull/102182
Approved by: https://github.com/jansel, https://github.com/albanD

---
## [DataDog/libdatadog](https://github.com/DataDog/libdatadog)@[ce8f6e8f8a...](https://github.com/DataDog/libdatadog/commit/ce8f6e8f8ac98c4222d07c0ec7d46ea441e08faf)
#### Thursday 2023-06-22 10:37:27 by Ivo Anjo

[PROF-7645] Add support for attaching internal metadata in profiling exporter

**What does this PR do?**:

This PR adds support for attaching internal metadata to profiles sent
via the profiling exporter.

This is a (small) breaking API change, since the signatures of
both `ProfileExporter::build` and `ddog_prof_Exporter_Request_build`
now take an extra argument.

FYI if you're upgrading libdatadog, you'll probably want to supply
`None` / `null` until in the future you figure out that you want
to send internal metadata.

**Motivation**:

The intention of this internal metadata is to allow profilers to attach
extra pieces of information to profiles that are not very interesting
to show to customers by default (such as Ruby's
"no_signal_workaround_enabled" or Go's "execution_trace_enabled").

For more details on this, check the Datadog internal
"RFC: Attaching internal metadata to pprof profiles".

**Additional Notes**:

Design-wise, I could've gone in a few different directions for:

a. How to represent the internal metadata in `ProfileExporter::build`
b. How to represent the internal metadata across the FFI in
   `ddog_prof_Exporter_Request_build`

Starting with a: Since the information is going to be represented in
JSON, I opted to "leak" this implementation detail by making the
parameter a `serde_json::Value`. This means that callers can take full
advantage of JSON to send whatever they want (e.g. nested objects,
types other than string, etc), rather than being constrained to some
smaller subset (e.g. if I imposed a list of pairs of strings).

This seemed a reasonable trade-off; I don't expect we'll go away from
JSON for encoding this info anytime soon, and even if we do, we can
always put a JSON string inside whatever we end up going with.

Concerning b: Getting complex types across the FFI boundary is really
really really annoying, for both libdatadog (which needs to expose a
bunch of types, and handle them), and the caller (which needs to think
about how they're going to manage lifetimes and whatnot of the whole
thing). To avoid this, I chose to instead represent the parameter as a
raw JSON string across the FFI. This allows ffi users the same
expressiveness as Rust users in terms of what they can send as internal
metadata, with the trade-off that ffi callers need to serialize their
stuff as JSON and libdatadog needs to deserialize it again.

Since internal metadata is something that gets passed along only once
per minute AND it's not expected to have high complexity, I think the
small overhead of throwing JSON strings across the ffi boundary is
worth the simplification to code on both sides.

**How to test the change?**:

I have expanded the tests to test the `event.json` file, including
the new parameter.

You should shortly see linked in this PR the Ruby PR to make use
of this feature to send the `no_signal_workaround_enabled`
parameter.

---
## [wrye-bash/wrye-bash](https://github.com/wrye-bash/wrye-bash)@[8b6df0c995...](https://github.com/wrye-bash/wrye-bash/commit/8b6df0c9951a10b83848928b0b302617e73c0652)
#### Thursday 2023-06-22 11:01:09 by MrD

Squash of ut-336-219-353 with fixups:

Nit and small fixes/opts: TTT

In `ext in bush.game.espm_extensions` ext used to be cs - it's not
anymore so this is a fixup. I ended up using EAFP here, hence dropping
the top_level_espm check - should be as fast as before and it's simpler.
Took the opportunity to prune an especially nasty use of getGhosted - a
few str operations should be faster than listing. Note that when
calling process_data_dir from update_data_SizeCrcDate getGhosted()
would be called twice.

Re: skipExts:

I run into an esp.ghost.ghost file - since we neither want to add those
to InstallersData.data_SizeCrcDate (ModInfos should skip those too) nor
in Installer.refreshDataSizeCrc I added them to skipExts TTT

bain.py  180 calc_crcs: Failed to calculate crc for D:\GAMES\TESIV\Oblivion\Data\New Mod--.esp.ghost - please report this, and the following traceback:
Traceback (most recent call last):
  File "C:\Dropbox (Personal)\eclipse_workspaces\python\wrye-bash\Mopy\bash\bosh\bain.py", line 174, in calc_crcs
    with open(asFile, u'rb') as ins:
         ^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\GAMES\\TESIV\\Oblivion\\Data\\New Mod--.esp.ghost' <--  the file was "New Mod--.esp.ghost.ghost"

Rename Installer.modified attribute to align with AFile

Align with AFile SSS

Would be nice to use the rest of the AFile API here (do_update and co -
hard!). Note I dropped the rpFile = os.path.join(rsDir, sFile) -
chopping asFile[relPos:] should be enough (and much faster).

Inline _refresh_from_project_dir:

We must change the model - in a nutshell use AFile's API (override
_stat_tuple for projects with NotImplemented, as it makes no sense
there, and add the _refreshSource logic in do_update - archives can use
the full API as they are files). Then only use do_update (with added
progress and hopefully little other kwargs) and perform the update *in
place* where we now call needs_update. This ripples till InstallersData
(irefresh) and it's fairly complex (and currently complicated) but will
eventually get us rid of _projects_walk_cache and a couple methods
(and stop being complicated) - edit done later, turns out _stat_tuple
works for projects just right - yey for AFile.

'pending' renames - I need to track refresh_info

class _InstallerPackage(Installer, AFile):

_refreshSource confined there - yey!

Refactor AFile:

Less uses of load_cache - and itsa_ghost. WIP - I might add load_cache
back to the signature if I figure a default out

Single out what=='I' SSS EEE

Installer.do_update: TTT RRR EEE

@@ -2215,8 +2215,6 @@ def _refresh_from_data_dir(self, progress, recalculate_all_crcs):
                             progress)
-        self.data_sizeCrcDate.clear()
-        self.data_sizeCrcDate.update(new_sizeCrcDate)
-        change = changes
+        self.data_sizeCrcDate = new_sizeCrcDate
         self.update_for_overridden_skips(progress=progress) #after final_update
         #--Done
-        return change
+        return changes  EEE

One of the hardest things to grok in BAIN refresh was the decorator
projects_walk_cache. It was necessary in order not to re-walk the
project dir in case we just walked it in scan_installers_dir. Looking
at it now we should have been caching also the stat calls in that case
but when this was introduced BAIN internals were so complicated that this
was not so obvious (performance here is anyway still WIP). Turns out it
is much simpler and probably just as 'fast' to call do_update rather
than trying to pass needs_update caches to refreshBasic. This all but
closes # 336 as now AFile API is used for all kinds of files - and
makes BAIN refresh internals as little complicated as possible. See
discussion in RRR 6d4ad99841233d83abd326ad81121a0d09f88bc0 but unlike
what I noted there the pleasant surprise was that AFile can handle
folders alright - do_update is powerful enough and can be further
refactored to cater for fullRefresh. Note:

- the ancient fixme. What this was trying to convey is that actually
if you went ahead and renamed a file in a project containing another
file with large modification time the change would not be detected. The
workaround was to manually refresh the project. This was done for
efficiency as the vast majority of the changes would be detected,
but now that computers are faster let's make this correct. For big
src_SizeCrcDate this would be slower but hey the system calls should
dwarf that (for big src_SCD) and anyway that's what the skip refresh
flag is for. Now that we do the full check (should be more than enough
but can still give a false negative if we flip a byte on a file without
changing the modification time - hey, caching) we might as well drop the
calculations from _stat_tuple.
- the common data structure format for cacl_crcs included the old crc -
cf (siz, _crc, date, asFile). I changed that to pass the asFile and I
am still debugging it but the benefits should be obvious
- I reassign src_SizeCrcDate instead of clean/update - faster and
cleaner (and should be also done for data_sizeCrcDate) but still TTT EEE

SSS FFF fix for fullRefresh not getting the paths to ghosts

I had to treat plugins separately - no harm done on average and
fullRefresh will calculate their CRCs once finally.

Under # 336, # 219, # 353 RRR

FFF inline _refreshInstallers: EEE better comments

And single out the real tricky uses of irefresh - seems now refresh_info
and pending/deleted are orthogonal - needs further simplification. We
need to pass pending/deleted to scan_installers_dir actually and use
that instead of listing - edit: done.

Progress does not work correctly (never gives focus back to Bash) XXX???

refreshBasic -> _reset_cache EEE split

EEE do_refresh=True flip default

bolt: ctime was unused

Installer.refresh_installer -> InstellersData.new_info: TTT

setattr(clone, att, copy.copy(getattr(src_inst, att))) should work on LDs TTT

EEE Mopy/bash/basher/dialogs.py InstallerProject import remove.

Another hacky refactoring helper gone but there is more. When we were
unpickling on InstallersData.__load > __setstate we were calling at least
refreshDataSizeCrc but then we would perform a system call on abs_path -
now this is replaced with a necessary stat_tuple() call and
scan_installers_dir learned to skip freshly unpickled installers. We also
hook in AFile.__init__ - this drops abs_path from Installer (if we were
accessing this on markers that'a bug) by adding a new 'volatile' attribute
to _InstallerPackage (now we can't slot we should revisit all this along
with pickling - we should stop pickling non std classes). __init__ calls
_reset_cache, so no need to call needs update from new_info. One other
(and hopefully the last) installer creation site was __copy__ - that's
too much magic, absorbed by new_info and the bits of (arcane) logic
were copied to copy_installer which should be the only place we copy an
installer. Finally I had to exclude fn_key from persistent - this is
set alright by __init__, the latter one being called on unpickling as
specified in __reduce__. So on unpickling initDefault was called twice -
maybe make Installer a dataclass and bin initDefault?

copy_installer is on InstallersData, not Installer.

Use scandir instead of walk:

import os
import timeit

numbers = 4
repeat = 7

setup = """"""
def timer(statement, msg='', _setup=None):
    print(msg, min(
        timeit.Timer(statement, setup=_setup or setup).repeat(
            repeat, numbers)))

def _scandir_walk(apath, root_len=None, folders_times=None):
    size_apath_date = {}
    if root_len is None:
        root_len = len(apath)
    folders_times = [] if folders_times is None else folders_times
    for dirent in os.scandir(apath):
        if dirent.is_dir():
            folders_times.append(dirent.stat().st_mtime)
            dir_walk, _ = _scandir_walk(dirent.path, root_len, folders_times)
            size_apath_date.update(dir_walk)
        else:
            size_apath_date[dirent.path[root_len:]] = (
                (ls := dirent.stat()).st_size, dirent.path, ls.st_mtime)
    return size_apath_date, folders_times

def _walk(apath, __lstat=os.stat):
    getM, join = os.path.getmtime, os.path.join
    size_apath_date = {}
    c = []
    cAppend = c.append
    root_len = len(apath) + 1
    for root, _d, files in os.walk(apath):
        # progress(0.05, f'{progress_msg}{asDir[relPos:]}')
        cAppend(getM(root))
        size_apath_date.update(
            (k[root_len:], (ls.st_size, k, ls.st_mtime)) for k, ls in
            ((asPath, __lstat(asPath)) for asPath in
                      (join(root, f) for f in files)))
    return size_apath_date, c

setup = """d = r'C:\Dropbox\eclipse_workspaces\python\wrye-bash'
from __main__ import _scandir_walk, _walk
"""
timer('_scandir_walk(d)', "scandir")
timer('_walk(d)', "walk")

C:\Users\MrD\AppData\Local\Programs\Python\Python311\python.exe C:\Dropbox\eclipse_workspaces\python\py_scratch\timings.py
scandir 1.2784526000032201
walk 27.407956500013825

Wow!

SSS add_marker -> new_info

Absorb _process_data_dir:

Time immemorial ago (bbcf54e3d3ae3785350e7111c58a7e32968420af) was
created to house the common logic of _refresh_from_data_dir (so
existing files maybe with a ghost extension) and
update_data_SizeCrcDate (so dest paths to the data dir with .ghost
lopped of). Now that we realized that scandir stating is considerably
faster and since performance here is a bane _process_data_dir had to go
- flat is better than nested, certainly in BAIN refresh. Those methods
calling one another were always new to new and experienced dev alike
and the pieces of functionality that were needed in
_refresh_from_data_dir but not in update_data_SizeCrcDate and vice
versa turned complex to complicated:

- we should not skip files/folders in update_data_SizeCrcDate as we come
from refreshDataSizeCrc (even if we currently do - TTT this beast is hard
to track - related to overwritten skips handling which certainly has
buggy edge cases some of them acknowledged in the code, see
overriden_skips comments)
- ghost handling belongs to update_data_SizeCrcDate - this led to double
calling getGhosted see RRR
- in fact the logic of _process_data_dir was the update_data_SizeCrcDate
logic as the walk logic of _refresh_from_data_dir was replaced by new
code in _walk_data_dir so the code of _process_data_dir was not repeated

_refresh_from_data_dir:

- I axed the progress messages as anyway we displayed very few of them
quite randomly. We can easily add them back in _walk_data_dir but since
we are on dev we can afford to live without these progress messages
- empty dirs is a WIP TTT - in particular what we do would not remove
a dir composed of empty dirs that were removed. OTH we could even remove
this from refresh and/or add a special menu item for cleaning empty dirs
(maybe launch it if setting is on also)

update_data_SizeCrcDate:

- what happens with "corrupted" mods really? They should be added to
data_SizeCrcDate most probably

__init__.py 4268 RefreshData:
11118614 function calls (11112306 primitive calls) in 6.492 seconds

__init__.py 4268 RefreshData:
436784 function calls (434428 primitive calls) in 0.263 seconds

FFF empty_dirs

FFF

- note I changed _skips_in_data_dir to work with dicts to keep the abs
path of the top_dir around - not for performance this time but sprinkling
os.path.join does not look nice.

Empties handling: SSS TTT

Changes the logic: TTT

- remove subdirs that contain no files in any of their subfolders - the
root one should be taken care of at the caller's level. Note the
(hacky) 'proj_dir.makedirs()' is not needed anymore, simply by not
handling the return value vs handling has_files for top Data dirs.
Previously we would leave behind empty subfolders except if we
carefully sorted which might have been the case (or not). Plus we could
delete folders before their subfolders (hence removedirs was called
defensively and abundantly). Now the logic is clearly spelled out in
_remove_empty_dirs (TTT deserves a test certainly) and repeated in
_walk_data_dir (as noted we need performance so factoring a walk
function parameter out is a no-no - plus we can afford some repetition
for the readability, especially as the walk functions are inlined
closer to irefresh and not buried as before).

- we remove as we go. This is less atomic but thankfully we had no
guaranties anyway :Plus we won't really miss anything if the operation
fails we just leave behind less empty dirs.

Kept error handling the same as before - although all the dirs should
exist in the `raise_error=False` case in _walk_data_dir.

---
## [wrye-bash/wrye-bash](https://github.com/wrye-bash/wrye-bash)@[cdbd837497...](https://github.com/wrye-bash/wrye-bash/commit/cdbd8374973850c64fabfa1bd93114c04702e6a5)
#### Thursday 2023-06-22 11:01:09 by Infernio

Rework temporary file handling RRR TTT

View with whitespace diff off for an easier time (--ignore-all-space).

This turned out to be a lot more work than I thought. Really should have
been a branch, but I misjudged this horribly, then it kept growing...
Also not sure how feasible this would be to have as a branch without
breaking dev.

Wrye Bash's temporary files handling was actually a complete mess. There
were *three* different ways that random pieces of code were using it:
 - bass.getTempDir/newTempDir/rmTempDir
 - Path.temp and Path.untemp
 - Just use Path.baseTempDir/tempDir or even tempfile directly and do
   it completely manually.

These all had problems:
 - The bass APIs were very implicit - you would extract something to the
   'bass temp dir' and then access it via getTempDir in some other
   function, then remove the directory via rmTempDir in another
   function. XXX I'm still not done tracking this implicit mess down
   (see converters.py).
 - Path.temp did not guarantee that the file would be unique. This isn't
   really a problem for Wrye Bash right now, but would become a big
   problem if we ever wanted to allow multiple instances to run at the
   same time (which we do). Path.untemp also did some really weird I/O
   stuff that doesn't seem necessary at all and would just cost us a
   bunch of syscalls.
 - Path.baseTempDir/tempDir and tempfile required you to keep track of
   all the path manipulation and logic manually. After going through all
   this refactoring, trust me when I say that you do *not* want to do
   this manually. These places were few, thankfully, and none seem to
   have messed it up.

The new API (wbtemp.py) exposes two ways to do it:
 - Use TempDir or TempFile in a context manager. This is extremely
   simple and works very well. It guarantees that the file will be
   cleaned up, even if your logic becomes very complex or an exception
   occurs.
 - Use new_temp_dir/new_temp_file to create a temporary dir/file and
   manually clean it up via cleanup_temp_dir/cleanup_temp_file. These
   should be used *very sparingly*, only where absolutely needed.
   Right now we only have a single usage of manual temp files in
   dialogs.UpdateNotification and two usages of manual temp dirs (one in
   InstallerArchive.unpackToTemp and one in env.shellMakeDirs).

It also has other advantages:
 - Complexity is encapsulated to a single file.
 - Works even during (very) early boot (though doesn't seem to be
   needed right now?).
 - Should work perfectly with multiple instances of WB running at the
   same time (which isn't possible yet, but is a goal for the future).

There's one ugly wart. barb wants to extract archives to a temporary
folder, which then needs to survive a restart of WB, whereupon it will
be handled by the boot '--restore' handler. wbtemp, by design, does not
allow this and will clean up all created directories and files on exit.
To handle this, I used manual tempfile fiddling. Perhaps a future
refactoring of barb could fix this, but for now I think it's an
acceptable tradeoff for the massive improvements this commit brings us.

Some random stuff that got stuck in here:

Note that I got rid of the utf-8-sig encodings passed to 7z, the docs
say:

  Notes: The list file in Unicode charset can start with the BOM (byte
  order mark) character (U+FEFF). In that case 7-Zip checks that
  encoding of BOM corresponds to encoding specified with this switch
  (for UTF-16LE and UTF-16BE).

and:

  Default charset is UTF-8.

From https://7-zip.opensource.jp/chm/cmdline/switches/charset.htm
Very happy to see some of these terrible BOMs disappear from the
codebase.

Mopy/bash/basher/gui_fomod.py:
Some minor warning fixups in gui_fomod

Closes # 665 <--- RRR

Co-authored-by: lojack5 <1458329+lojack5@users.noreply.github.com>

---
## [yarnpkg/berry](https://github.com/yarnpkg/berry)@[ec7f37a8ca...](https://github.com/yarnpkg/berry/commit/ec7f37a8ca118a6f73f848e993272db957f286d6)
#### Thursday 2023-06-22 13:00:09 by Maël Nison

Modernizes installs' output (#5509)

**What's the problem this PR addresses?**

I wasn't entirely happy with the Yarn output:

- When running `yarn add`, we have no way to know what packages are
actually added to the lockfile. The cache messages sometimes help, but
with zero-installs now being opt-in, in many cases the packages would
already be in the cache and thus wouldn't be displayed at all.

- The "can't be found in the cache and will be fetched from the remote
registry" messages were incredibly slow to print - the same install
would take 28s install for Gatsby on a local iTerm 2 without those logs,
vs almost 2 minutes with. They also weren't very useful: we were only
showing the last 5 of them, and with zero-installs being opt-in in many
cases they wouldn't be shown at all.

- The `node-gyp` warnings were for the most part unactionable (at best
the user would pin a fixed version in their `packageExtensions` field,
which I suspect no one ever did).

- The `deprecated` warnings were for the most part unactionable, and
only printed in very specific cases (the first time they were added to
the project).

- The "missing / invalid peer dependency" warnings were actionable, but
in practice no one really look at them except when something breaks -
and even then, it becomes unreadable when there are too many of them.

- The skipped build warnings were printed every single time you ran
`yarn install`. It's nice to know the first time, then it quickly
becomes redundant.

Fixes #4165

**How did you fix it?**

I went a little overboard and did everything in the same PR ... at first
I thought I wouldn't have to change unrelated parts, but then I finished
implementing the skipped build warnings duplicate removal and oh no 🙈

- Only peer dependency warnings caused by workspaces are now reporter.
They have also been moved inside the post-resolution validation step.
The resolution step is now expected to only do one of two things: either
report an error when the resolution fails, or report the packages which
got added / removed from the lockfile.

- The `node-gyp` warnings have been removed.

- The `deprecated` warnings have been removed from the install. The
`yarn npm audit` command now reports deprecated packages, although this
can be disabled using `--no-deprecations` (or any of the audit filtering
settings).

- The "can't be found in the cache" messages have been removed. Instead,
the fetch step will report the number of cache hits / cache misses once
it's finished (same behaviour as `preferAggregateCacheInfo`). The size
delta will also be reported.

- Packages whose build was skipped are now stored within
`Project#skippedBuilds`, which is stored within the install state file.
Warnings are only emitted if the install was skipped for the first time.
To see the messages again, users can run `yarn rebuild`.

- Added the Yarn version on installs. A bit because of branding when
screenshot are taken, but mostly so we easily know what version are
people using when they share screenshots to us. In a follow-up PR I'd
like to try to retrieve the latest version from the website, to let them
know once one is available.

**Checklist**
<!--- Don't worry if you miss something, chores are automatically
tested. -->
<!--- This checklist exists to help you remember doing the chores when
you submit a PR. -->
<!--- Put an `x` in all the boxes that apply. -->
- [x] I have read the [Contributing
Guide](https://yarnpkg.com/advanced/contributing).

<!-- See
https://yarnpkg.com/advanced/contributing#preparing-your-pr-to-be-released
for more details. -->
<!-- Check with `yarn version check` and fix with `yarn version check
-i` -->
- [x] I have set the packages that need to be released for my changes to
be effective.

<!-- The "Testing chores" workflow validates that your PR follows our
guidelines. -->
<!-- If it doesn't pass, click on it to see details as to what your PR
might be missing. -->
- [x] I will check that all automated PR checks pass before the PR gets
reviewed.

---
## [knative-automation/client-pkg](https://github.com/knative-automation/client-pkg)@[488efb5ce2...](https://github.com/knative-automation/client-pkg/commit/488efb5ce27dfeedce69323996e0926c303f7624)
#### Thursday 2023-06-22 13:23:51 by Knative Automation

upgrade to latest dependencies

bumping k8s.io/apiextensions-apiserver 2c55649...52c998e:%0A  > 52c998e Update dependencies to v0.26.5 tag%0A  > 186ff9b Merge pull request # 117274 from jkh52/release-1.26-knp-0.0.37%0A  > b7b18f5 Merge pull request # 117691 from dims/re-do-of-117242-on-release-1.26%0A  > ee5015a Bump konnectivity-client to 0.0.37%0A  > 9ce75f3 Bump runc go module v1.1.4 -> v1.1.6%0A  > e9d194a Merge pull request # 115599 from jkh52/release-1.26-knp-0.0.36%0A  > d7df0be Merge pull request # 115787 from liggitt/net-0.7.0-1.26%0A  > 9152c67 Bump konnectivity-client to v0.0.36%0A  > 89cec57 Update golang.org/x/net to v0.7.0%0A  > f72cc5c Merge pull request # 115642 from nckturner/pin-golang.org/x/net-to-v0.4.0-in-1.26%0A  > 28eb995 Pin golang.org/x/net to v0.4.0 in 1.26%0A  > 33db789 Merge pull request # 114861 from jpbetz/release-1.26%0A  > a06e03d Merge pull request # 114927 from jkh52/release-1.26-knp-metrics%0A  > 0859963 Cherry pick 114857 to release-1.26%0A  > 5183885 Bump konnectivity-client to v0.0.35%0A  > 6e13726 Merge remote-tracking branch 'origin/master' into release-1.26%0A  > c338f3e Update golang.org/x/net 1e63c2f%0A  > 9768bad sync: update go.mod%0A  > f9c2bba fix aggregated discovery version sorting%0A  > d2c9e18 Merge pull request # 113171 from Jefftree/aggregated-discovery-generic%0A  > 470c040 Merge pull request # 113577 from pacoxu/prometheus-client%0A  > 915a888 add crds to aggregated discovery%0A  > 92430b6 Merge pull request # 113314 from cici37/celIntegration%0A  > ac326ca upgrade prometheus-client to v1.14.0%0A  > 5a6bf16 Merge pull request # 113688 from dashpole/update_utils%0A  > 67b0610 Integrate cel admission with API.%0A  > 84fed82 upgrade github.com/prometheus/client_golang to v1.13.1%0A  > 077b441 update k8s.io/utils to fix util tracing panic%0A  > 5bbf20d Adding new api version of admissionregistration.k8s.io v1alpha1 for CEL in Admission Control%0A  > 3b533ba Merge pull request # 113367 from pohly/dep-ginkgo-gomega%0A  > 975bbeb dependencies: update to gomega v1.23.0 and ginkgo v2.4.0 and dependencies%0A  > ae2b4c3 Merge pull request # 112693 from aimuz/fix-GO-2022-0969%0A  > c4deae9 Fixed (CVE-2022-27664) Bump golang.org/x/net to v0.1.1-0.20221027164007-c63010009c80%0A  > bc4263f Merge pull request # 113172 from dashpole/endpoint_handler_tracing%0A  > f6c164e migrate apiserver utiltrace usage to component-base/tracing%0A  > 53e3726 Merge pull request # 113015 from ritazh/crencryption%0A  > c8d8a9f Enable encryption for custom resources%0A  > 6405068 Merge pull request # 113325 from panslava/fix-time-since-defer%0A  > 508e399 Fix time.Since() in defer. Wrap in anonymous function%0A  > 5f8e59e Merge pull request # 112691 from aimuz/apiextensions-apiserver-change-to-cmp%0A  > c996139 Merge pull request # 113106 from pohly/dep-ginkgo-gomega%0A  > f83e03c apiextensions-apiserver: change k8s.io/apimachinery/pkg/util/diff to github.com/google/go-cmp/cmp%0A  > b68fc51 dependencies: update to gomega v1.22.1 and ginkgo v2.3.1%0A  > 49c41b4 Merge pull request # 112988 from alexzielenski/update-kube-openapi%0A  > 3aaa2a0 Merge pull request # 113037 from pacoxu/fsnotify-v1.6.0%0A  > d9f6ebd update kube-openapi%0A  > 82e3ba4 Merge pull request # 112789 from enj/enj/r/kms_load_once_v2%0A  > 7423813 update fsnotify to v1.6.0%0A  > 8bf3487 Merge pull request # 113011 from jpmcb/cobra-1.6.0%0A  > d34393e Load encryption config once%0A  > 6ba582f Bumps cobra from 1.5.0 to 1.6.0%0A  > 8e0697b Merge pull request # 113022 from logicalhan/webhook-metrics%0A  > 90c63e0 Merge pull request # 112926 from jiahuif-forks/refactor/cel-out-of-apiextensions%0A  > 548c480 unparameterize 'webhook' from conversion metrics since it's the only one%0A  > 77badb8 Merge pull request # 112989 from ameukam/bump-golang.org/x/text-to-v0.3.8%0A  > 609e270 use DefaultMaxRequestSizeBytes for maxRequestSizeBytes.%0A  > 04f26fa Bump golang.org/x/text to v0.3.8%0A  > dd981e1 move CEL package to apiserver package.%0A  > 1644998 Move celopenapi/model to staging/src/k8s.io/apiextensions-apiserver/pkg/apiserver/schema/cel/ (# 109959)%0A  > 08d44e8 Merge pull request # 112875 from pohly/update-yaml%0A  > 1300140 dependencies: update to sigs.k8s.io/yaml v1.3.0%0A  > 5fb82bd Merge pull request # 112819 from thockin/no-make-generators%0A  > f5f5279 Codegens: Do not auto-set boilerplate path%0A  > f22ee73 Merge pull request # 112738 from liggitt/proto-tag%0A  > ba7f1b7 Merge pull request # 112689 from cheftako/master%0A  > 7ac7774 github.com/matttproud/golang_protobuf_extensions v1.0.2%0A  > e678457 Merge pull request # 112748 from wojtek-t/lock_ssa_gate%0A  > 0aca5a6 Bump konnectivity-client to v0.0.33%0A  > 9be4b4a Lock ServerSideApply feature to true%0A  > 7b53cb7 Merge pull request # 111980 from aramase/kms%0A  > f40a683 Merge pull request # 112705 from stevekuznetsov/skuznets/fix-comment%0A  > 4cd9125 Add staging directory for kms%0A  > d4e654a clients: clarify a misleading comment%0A  > 8b851d9 Merge pull request # 112673 from dims/update-to-latest-k8s.io/utils-sep-22%0A  > 362a89c Merge pull request # 112615 from mengjiao-liu/update_CRD_link%0A  > add0c80 Update to latest k8s.io/utils to pick up changes%0A  > 374216b Merge pull request # 112613 from dims/update-github.com/go-openapi/jsonreference-to-drop-github.com/PuerkitoBio/purell%0A  > a7ee7f9 Update `PreserveUnknownFields` field document link%0A  > 488bf20 update github.com/go-openapi/jsonreference to drop github.com/PuerkitoBio/purell%0A  > 47c15ca Merge pull request # 112588 from pacoxu/fsnotify-v1.5.4%0A  > d5b6243 Merge pull request # 112584 from dims/brneto-master%0A  > 8c6aa82 update fsnotify/fsnotify to v1.5.4%0A  > f8e18e9 run pin-dependency.sh and then hack/update-vendor.sh%0A  > c540c8c Merge pull request # 112545 from dims/update-etcd-3.5.5-and-all-otel-related-to-latest%0A  > 70b0d96 Merge pull request # 112352 from pohly/e2e-ginkgo-progress%0A  > 39cab0b updated etcd to v3.5.5 and newer otel libraries as well%0A  > 5faccda Merge pull request # 111866 from pacoxu/validate%0A  > 1c3fe9d e2e: bump ginkgo to v2.2.0%0A  > 917d446 Merge pull request # 112458 from dims/switch-to-release-tag-for-antlr-v1.4.10%0A  > 8b3fe74 add test case for array checking with dup values%0A  > 045fc90 Merge pull request # 112433 from ncdc/reduce-SchemaHas-allocs%0A  > 73cc883 Switch to release tag for antlr : v1.4.10%0A  > 22bcc66 added ratcheting validation for embedded resource and x-kubernetes-list-type validation%0A  > 269d73d Reduce allocations in HasSchemas%0A  > 7342cc6 Merge pull request # 112200 from pohly/client-go-shared-informer-factory-shutdown%0A  > aabbdff Merge pull request # 112349 from pohly/klog-update%0A  > fdf28bc client-go: support waiting for SharedInformerFactory shutdown%0A  > 6b7d12b build: update to klog v2.80.1%0A  > 559b4fa Merge pull request # 111768 from weilaaa/feature_add_symmetric_difference_in_sets_string%0A  > bf7d058 add symmetric difference in sets%0A  > 04ff81e Merge pull request # 112199 from pohly/klog-update%0A  > 87a4c3f dependencies: update to klog v2.80.0%0A  > 8f15690 Merge pull request # 112129 from pohly/e2e-ginkgo-report-after-each%0A  > f637e1c dependencies: update to ginkgo v2.1.6 and gomega v1.20.1%0A  > b6adc1c Merge pull request # 111964 from DangerOnTheRanger/cel-estimate-fix-update%0A  > ea2d438 Merge pull request # 112052 from tosi3k/bump-client-golang%0A  > 6b4dc0b Add unit tests.%0A  > 767e67b Bump prometheus/client_golang to v1.13.0%0A  > 782b982 Run pin-dependency.sh and update-vendor.sh.%0A  > 305963e Merge pull request # 111909 from tosi3k/bump-prom-client%0A  > fa2959a Merge pull request # 111830 from t1anz0ng/typo%0A  > 5a6ffec Bump prometheus/client_golang to v1.12.2%0A  > e0abc3b fix(typo): remove extra " from autoscaling doc string%0A  > 2184a8d Merge pull request # 111696 from liggitt/go119mod%0A  > f750907 Update go.mod to go1.19%0Abumping k8s.io/code-generator 6523e22...eec869e:%0A  > eec869e Merge pull request # 117691 from dims/re-do-of-117242-on-release-1.26%0A  > 824419b Bump runc go module v1.1.4 -> v1.1.6%0A  > ba94e65 Merge pull request # 115787 from liggitt/net-0.7.0-1.26%0A  > 6276bf2 Update golang.org/x/net to v0.7.0%0A  > 73b9c40 Merge pull request # 115642 from nckturner/pin-golang.org/x/net-to-v0.4.0-in-1.26%0A  > 882af80 Pin golang.org/x/net to v0.4.0 in 1.26%0A  > 6063700 Merge remote-tracking branch 'origin/master' into release-1.26%0A  > b615940 Update golang.org/x/net 1e63c2f%0A  > 11d5c4c update k8s.io/utils to fix util tracing panic%0A  > 081720d Merge pull request # 113367 from pohly/dep-ginkgo-gomega%0A  > d44fa8c dependencies: update to gomega v1.23.0 and ginkgo v2.4.0 and dependencies%0A  > 300cdcf Merge pull request # 112693 from aimuz/fix-GO-2022-0969%0A  > e0ef4aa Fixed (CVE-2022-27664) Bump golang.org/x/net to v0.1.1-0.20221027164007-c63010009c80%0A  > 557ce1f Merge pull request # 113126 from alexzielenski/remove-unwanted-replace%0A  > f86120d remove errant replace%0A  > d6a8b70 Merge pull request # 113106 from pohly/dep-ginkgo-gomega%0A  > f77ba6d dependencies: update to gomega v1.22.1 and ginkgo v2.3.1%0A  > 3bbe215 Merge pull request # 112988 from alexzielenski/update-kube-openapi%0A  > e80bbc4 Merge pull request # 113037 from pacoxu/fsnotify-v1.6.0%0A  > d403dc0 update kube-openapi%0A  > 790e4bc update fsnotify to v1.6.0%0A  > 27bd7d9 Merge pull request # 112989 from ameukam/bump-golang.org/x/text-to-v0.3.8%0A  > 4731e5c Bump golang.org/x/text to v0.3.8%0A  > a8a213c Merge pull request # 112875 from pohly/update-yaml%0A  > 5f5bab9 dependencies: update to sigs.k8s.io/yaml v1.3.0%0A  > 983d5d0 Merge pull request # 112819 from thockin/no-make-generators%0A  > c35177b Format calls to codegens%0A  > 83929d0 Codegens: Do not auto-set boilerplate path%0A  > 1d82d12 Merge pull request # 112705 from stevekuznetsov/skuznets/fix-comment%0A  > c3414a0 clients: clarify a misleading comment%0A  > 998e449 Merge pull request # 112673 from dims/update-to-latest-k8s.io/utils-sep-22%0A  > e4543b2 Update to latest k8s.io/utils to pick up changes%0A  > 8e999f2 Merge pull request # 112613 from dims/update-github.com/go-openapi/jsonreference-to-drop-github.com/PuerkitoBio/purell%0A  > 524127d update github.com/go-openapi/jsonreference to drop github.com/PuerkitoBio/purell%0A  > 4ca0baf Merge pull request # 112545 from dims/update-etcd-3.5.5-and-all-otel-related-to-latest%0A  > b54a056 Merge pull request # 112352 from pohly/e2e-ginkgo-progress%0A  > 350c30a updated etcd to v3.5.5 and newer otel libraries as well%0A  > 5f3f945 e2e: bump ginkgo to v2.2.0%0A  > 2e5cca7 Merge pull request # 112200 from pohly/client-go-shared-informer-factory-shutdown%0A  > c3fdc3c Merge pull request # 112349 from pohly/klog-update%0A  > e4b7976 client-go: support waiting for SharedInformerFactory shutdown%0A  > 135f69b build: update to klog v2.80.1%0A  > f60067d Merge pull request # 112341 from enj/enj/i/second_time_is_the_charm%0A  > 7c81c99 Merge pull request # 111768 from weilaaa/feature_add_symmetric_difference_in_sets_string%0A  > 8468f16 Remove in-tree credential plugins (again)%0A  > 9b98ed3 add symmetric difference in sets%0A  > 34125ff Merge pull request # 112199 from pohly/klog-update%0A  > a055687 dependencies: update to klog v2.80.0%0A  > 16cba21 Merge pull request # 112129 from pohly/e2e-ginkgo-report-after-each%0A  > e051ad0 dependencies: update to ginkgo v2.1.6 and gomega v1.20.1%0A  > 3a31bb1 Merge pull request # 111934 from deads2k/apply-gen%0A  > 4d73156 Merge pull request # 112052 from tosi3k/bump-client-golang%0A  > 1382941 make applyconfiguration-gen skip generation for types that have generated clients and lack objectmeta%0A  > 03a75ea Bump prometheus/client_golang to v1.13.0%0A  > 17196da update the apply generator to use the same package the the client generator expects%0A  > a4e23d1 Merge pull request # 111566 from inosato/remove-ioutil-from-code-generator%0A  > a6a370c make applyconfiguration-gen handle pointers to slices%0A  > 087714e Merge pull request # 109884 from qzoscar/patch-1%0A  > fc00858 Remove ioutil from code-generator%0A  > ed79ca3 make applyconfiguration-gen work for resources without objectmeta%0A  > fea40fb Merge pull request # 111918 from liggitt/in-tree-auth%0A  > 3612509 fix a broken link%0A  > 78677a3 update the applyconfiguration-gen flag external-applyconfigurations to work%0A  > ad6af70 Revert "Remove gcp and azure auth plugins"%0A  > 7ba56cb applyconfiguration-gen handling of types that have a non-embedded use of TypeMeta%0A  > 97fa351 Merge pull request # 111696 from liggitt/go119mod%0A  > d71f529 add metav1.OwnerReference to the default external configurations to ease generation%0A  > 2b9093f Update go.mod to go1.19%0Abumping k8s.io/apimachinery 4fbe8e4...b207ce5:%0A  > b207ce5 Merge pull request # 117691 from dims/re-do-of-117242-on-release-1.26%0A  > 917de35 Bump runc go module v1.1.4 -> v1.1.6%0A  > 53ecdf0 Merge pull request # 115787 from liggitt/net-0.7.0-1.26%0A  > 05339fa Update golang.org/x/net to v0.7.0%0A  > eabbfd5 Merge pull request # 115642 from nckturner/pin-golang.org/x/net-to-v0.4.0-in-1.26%0A  > 48b8d1f Pin golang.org/x/net to v0.4.0 in 1.26%0A  > 373a5f7 Merge pull request # 114521 from 3point2/automated-cherry-pick-of-# 113283-upstream-release-1.26%0A  > b5e5df6 Fix SPDY proxy authentication with special chars%0A  > 553a2d6 Improve error message when proxy connection fails%0A  > 5d4cdd2 Merge remote-tracking branch 'origin/master' into release-1.26%0A  > 6cbc4a3 Update golang.org/x/net 1e63c2f%0A  > 6561235 Merge pull request # 113699 from liggitt/manjusaka/fix-107415%0A  > dad8cd8 Update workload selector validation%0A  > fe82462 Add extra value validation for matchExpression field in LabelSelector%0A  > 067949d update k8s.io/utils to fix util tracing panic%0A  > 0ceff90 Merge pull request # 112223 from astraw99/fix-ownerRef-validate%0A  > 9e85d3a Merge pull request # 112649 from howardjohn/set/optimize-everything-nothing%0A  > b0dd9ec Fix ownerRef controller validate err%0A  > b03a432 Merge pull request # 113367 from pohly/dep-ginkgo-gomega%0A  > 88a1448 Rename and comment on why sharing is safe%0A  > 4e6bcdb dependencies: update to gomega v1.23.0 and ginkgo v2.4.0 and dependencies%0A  > 3adc870 Optimize `Everything` and `Nothing` label selectors%0A  > 0524d6c Merge pull request # 112693 from aimuz/fix-GO-2022-0969%0A  > 5a0277f Fixed (CVE-2022-27664) Bump golang.org/x/net to v0.1.1-0.20221027164007-c63010009c80%0A  > 6809593 Merge pull request # 112377 from weilaaa/refactor_sets_use_generic%0A  > 70a38aa Merge pull request # 113106 from pohly/dep-ginkgo-gomega%0A  > f2d9aed refactor sets use generic%0A  > d097f82 dependencies: update to gomega v1.22.1 and ginkgo v2.3.1%0A  > 7b5633b Merge pull request # 112988 from alexzielenski/update-kube-openapi%0A  > b839e82 Merge pull request # 113037 from pacoxu/fsnotify-v1.6.0%0A  > b7d8973 update kube-openapi%0A  > 1dc6ace update fsnotify to v1.6.0%0A  > 78d003c Merge pull request # 112989 from ameukam/bump-golang.org/x/text-to-v0.3.8%0A  > 04898ff Bump golang.org/x/text to v0.3.8%0A  > 79993b2 Merge pull request # 112875 from pohly/update-yaml%0A  > 7379c15 dependencies: update to sigs.k8s.io/yaml v1.3.0%0A  > 66e26ac Merge pull request # 112707 from enj/enj/i/https_links%0A  > 882b67d Use https links for k8s KEPs, issues, PRs, etc%0A  > 7fb78ee Merge pull request # 112472 from ialidzhikov/nit/error-msg%0A  > 826a74e Merge pull request # 112673 from dims/update-to-latest-k8s.io/utils-sep-22%0A  > 22fe889 Improve the error returned from the `LabelSelectorAsSelector` func%0A  > e2f9797 Update to latest k8s.io/utils to pick up changes%0A  > f8159af Merge pull request # 112545 from dims/update-etcd-3.5.5-and-all-otel-related-to-latest%0A  > 612703e Merge pull request # 112352 from pohly/e2e-ginkgo-progress%0A  > 9901884 updated etcd to v3.5.5 and newer otel libraries as well%0A  > 6439059 Merge pull request # 112526 from liggitt/redirect%0A  > 0564b5e e2e: bump ginkgo to v2.2.0%0A  > 2e3bf73 Limit redirect proxy handling to redirected responses%0A  > 6d854d7 Merge pull request # 112349 from pohly/klog-update%0A  > e1e1b7c build: update to klog v2.80.1%0A  > ed93eed Merge pull request # 111768 from weilaaa/feature_add_symmetric_difference_in_sets_string%0A  > 36163c5 Merge pull request # 112193 from jindijamie/master%0A  > b7b9ba4 add symmetric difference in sets%0A  > 31bc292 Merge pull request # 112199 from pohly/klog-update%0A  > 1c318b6 Add an option for aggregator%0A  > 0d0d03e Merge pull request # 111936 from haoruan/bugfix-111928-microtime-marshal-precision%0A  > 145c075 dependencies: update to klog v2.80.0%0A  > 2d64dac Merge pull request # 112089 from zeze1004/fix-typo%0A  > 2187a78 Marshal MicroTime to json and proto at the same precision%0A  > 53c4d51 Merge pull request # 112129 from pohly/e2e-ginkgo-report-after-each%0A  > 30e9977 Fix typo "sturct" to "struct"%0A  > 5e4f25a dependencies: update to ginkgo v2.1.6 and gomega v1.20.1%0A  > 349dcdf Merge pull request # 112052 from tosi3k/bump-client-golang%0A  > 16a7f7a Bump prometheus/client_golang to v1.13.0%0A  > 2b9fe2c Merge pull request # 111808 from alvaroaleman/meta-wrapping%0A  > bb48261 Apimachinery meta errors: Support errors.Is and error wrapping%0Abumping knative.dev/pkg dfad48e...eb63a40:%0A  > eb63a40 Support to set qps and burst via env variable (# 2755)%0A  > 74c4be5 Generate kresource duck type codegen (# 2754)%0A  > 4dbc312 fix boilerplate (# 2753)%0A  > 15605c7 Defaulting Controller options for all kind of webhooks (# 2738)%0A  > 94b81fc Update community files (# 2752)%0A  > 5671699 drop the dynamic type (# 2750)%0A  > 9bda38b Fix some webhook testing tech debt (# 2751)%0A  > ec20442 Update community files (# 2747)%0A  > 05bfcf6 bump k8s dependencies and update min version to v1.25 (# 2745)%0A  > 52ff2ac drop dynamic client wrappers (# 2744)%0A  > a170a07 Eventing TLS: validate that Destination.CACerts is a PEM encoded cert (# 2743)%0A  > dfb4bf0 Drop dynamic wrapper injection code generation (# 2742)%0A  > db8a353 Add SinkCACerts to SourceStatus (# 2733)%0A  > 9049667 Update community files (# 2735)%0A  > aacec7f Update community files (# 2734)%0A  > 300df43 Eventing TLS: Added AddressableFromDestination method on the resolver (# 2717)%0Abumping golang.org/x/net 8e2b117...dfa2b5d:%0A  > dfa2b5d go.mod: update golang.org/x dependencies%0A  > 8c4ef2f hmtl: add security section to package comment%0A  > 1d46ed8 html: have Render escape comments less often%0A  > 569fe81 html: add "Microsoft Outlook comment" tests%0Abumping golang.org/x/text 71a9c9a...9db913a:%0A  > 9db913a go.mod: update to newer x/tools%0A  > 30dadde all: correct comment typos%0Abumping github.com/matttproud/golang_protobuf_extensions c182aff...c182aff:%0Abumping golang.org/x/tools b3b5c13...d0863f0:%0A  > d0863f0 go.mod: update golang.org/x dependencies%0A  > 545ca87 gopls/internal/regtest/marker: require go/packages%0A  > 1ace7db go,gopls: remove license from package doc comments%0A  > ebad375 gopls/internal/lsp/protocol: prevent license rendering in godoc%0A  > 10a39ef gopls/internal/lsp/regtest: address additional comments on marker.go%0A  > 69920f2 gopls/internal/regtest/marker: add missing tests for hover%0A  > 24a13c6 gopls/internal/regtest: fill out features of the new marker tests%0A  > 2b149ce gopls/internal/regtest: add a regtest-based version of the marker tests%0A  > edddc5f go/packages: don't discard errors loading export data%0A  > a762c82 go/ssa: add MultiConvert instruction%0A  > f124b50 cmd/stringer: streamline test subprocesses%0A  > 6b6857a gopls: fix typos in comments and doc%0A  > 8111118 go/analysis/internal/facts: fix cycle in importMap.%0A  > dd1c468 gopls/internal/lsp/source: simplify extracting object hover doc%0A  > 66f8f71 gopls/internal/lsp/source: use syntax alone in FormatVarType%0A  > 30f191f internal/imports: update stdlib index for Go 1.20%0A  > 4e98188 internal/imports: use go/packages instead of cmd/api to compute symbols%0A  > 4e8ff89 internal/imports: update stdlib index for 1.20%0A  > 6bd0d00 gopls/internal/lsp: go to definition from linkname directive%0A  > 0cfddb3 gopls/internal/lsp: enable clear builtin completion test%0A  > 41adf8d gopls/internal/lsp/tests: remove StripSubscripts%0A  > 86fdadc gopls/internal/lsp/safetoken: delete safetoken.Range%0A  > c276ee5 internal/robustio: fix signature of getFileID on plan9%0A  > e170d45 gopls/internal/lsp: add clear builtin%0A  > 2ea4b81 go/ast/inspector: skip ranges that do not contain a node type%0A  > 407bbed go/analysis: improve error message on duplicate fixes%0A  > bd5dfbb all: fix some comments%0A  > 072fca5 gopls/protocol: use the current definition of the lsp%0A  > aa633e7 tools/gopls: provide markdown for completion and signature help%0A  > 684a1c0 go/analysis/internal/analysisflags: use os.Executable for program path%0A  > bd5e595 gopls/internal/lsp/cache: add missing mutex%0A  > 2683128 gopls/internal/lsp: differentiate govulncheck/vulncheck imports diags%0A  > d1e92d6 gopls/internal/lsp/mod: reorder vulncheck quick fixes%0A  > 87d00e6 gopls/internal/lsp: separate some requests from source.Identifier%0A  > ae242ec gopls: fix windows file corruption%0A  > 6f65213 gopls/internal/lsp/protocol: Mapper.NodeMappedRange%0A  > e260368 gopls/semantic: report type parameters in the type of a receiver%0A  > b62cbb6 internal/lockedfile: fix build constraints on solaris%0A  > 1aa7e72 gopls/internal/lsp/source: avoid qualifiedObjectsAtProtocolPos%0A  > 5ed33df gopls/internal/lsp/source: rename: prep for incrementality%0A  > e0659d1 gopls/internal/lsp/source: simplify legacy 'references' func%0A  > 1edcfe7 gopls/internal/regtest/diagnostics: require cgo for TestGoListErrors%0A  > f052158 gopls/internal/lsp/protocol: move TestBytesOffset%0A  > d093a13 gopls/internal/lsp/protocol: LocationTextDocumentPositionParams%0A  > bcb677e gopls/internal/regtest: make RegexpSearch return a Location%0A  > 60782e9 gopls/internal/lsp/source: eliminate a couple uses of posToMappedRange%0A  > 031e6e6 gopls/internal/lsp/source: eliminate ResolveImportPath%0A  > f2cd9ef gopls/internal/lsp/source: reduce usage of TypecheckWorkspace%0A  > f10e7d5 gopls/internal/lsp/cache: remove package dependence on packages.Config%0A  > 8270757 gopls/internal/lsp/source: switch call hierarchy to references v2%0A  > 37c69d8 gopls/internal/lsp/source: references: support exported methods%0A  > f3c36a2 gopls/internal/lsp/cmd/test: delete marker-based tests of gopls cmd%0A  > c224aae gopls/internal/lsp/cmd/test: new integration test for gopls command%0A  > deeb64b gopls/internal/lsp/source/xrefs: allow Lookup of a set%0A  > f269f53 gopls/internal/lsp: remove Server.processModifications%0A  > fcd57eb gopls: allow 'any' and 'comparable' in completion results%0A  > aae3642 gopls/internal/lsp/source: referencesV2: support unexported methods%0A  > b5d65e0 tools/gopls: register semantic tokens statically%0A  > 51abc5b gopls/internal/lsp/source: stub: don't panic when encountering 'error'%0A  > ce28f40 gopls/internal/regtest: add a test demonstrating confusion following an%0A  > c4c6aa6 internal/lsp/cache: don't panic in Snapshot on a shutdown view%0A  > 1faecd3 tools/internal/diff: fix off-by-one error in computing diffs%0A  > a7f033a gopls/internal/lsp: consolidate the FileHandle API%0A  > 271e621 internal/lockedfile/internal/filelock: fix aix build tag%0A  > ff9bea5 gopls/internal/lsp/cmd/test: signpost future cleanups%0A  > 7d4ba2f gopls/release: remove unused functionality from release script%0A  > 46b6958 gopls/internal/lsp/source: delete source_test%0A  > bcc7794 go/analysis/passes/directive: add directive analyzer%0A  > 33d416e gopls/internal/lsp: add missing comments on 3x tests.Test impls%0A  > afea272 gopls/internal/lsp/source: make implementations2 work on embedded fields%0A  > bb7c440 gopls/internal/lsp/filecache: use file locking, not rename%0A  > 561a9be gopls/internal/lsp/filecache: actually delete files%0A  > 9682b0d gopls/internal/lsp/source: delete IsInterface%0A  > 7a7b699 go/analysis/passes/loopclosure: avoid panic in new parallel subtest check when t.Run has single argument%0A  > 3e6f71b gopls/internal/regtest: use AfterChange in more places%0A  > 9ff31a5 x/tools/go/analysis/passes/printf: revert URL in error message%0A  > 2fa6ca1 gopls/internal/lsp/source/impls: a new "implementations" index%0A  > 957bec5 gopls/protocol: new versions of generated LSP files%0A  > f0e2d5c internal/gcimporter: discard position info for unneeded lines%0A  > 5bedd86 cmd/digraph: use ReadString rather than bufio.Scanner%0A  > f6ea009 gopls/internal/lsp: remove the experimentalWatchedFileDelay setting%0A  > f46e418 gopls/internal/lsp/source: include ITVs in global references%0A  > f3e53e5 internal/jsonrpc2_v2: fix typos%0A  > d958e85 internal/gcimporter: use two-level file index%0A  > 8aba49b internal/gcimporter: preserve column and line in shallow iexport%0A  > d7fc4e7 gopls: new LSP stub generator%0A  > 5c176b1 internal/robustio: skip os.Link test on android%0A  > d34a055 go/ssa: sanity check the types of phi nodes%0A  > 6f095b4 go/callgraph/vta: add flows for receiver function types%0A  > 8e94967 cmd/fiximports: do not assume go list -json unmarshals into build.Package%0A  > e035d0c go/ssa: fix phi node type in slice to array conversion%0A  > 03eac81 go/expect: remove testdata go.mod to go.fake.mod%0A  > 1e819a3 gopls/internal/regtest: follow-ups to review comments from earlier CLs%0A  > 9ba8bb1 gopls/internal/regtest: clean up workspace symbol helpers%0A  > 91b6070 gopls/internal/regtest: eliminate DiagnosticAtRegexp%0A  > bd48b9a gopls/internal/regtest: eliminate DiagnosticsAtRegexpWithMessage%0A  > 5d65394 gopls/internal/regtest: eliminate DiagnosticAt%0A  > 27dfeb2 gopls/internal/regtest: replace NoDiagnostics with NoMatchingDiagnostics%0A  > 87092c8 gopls/internal/lsp/fake: use protocol types for the fake editor%0A  > 672a036 gopls/internal/regtest: simplify OnceMet expressions with an env helper%0A  > ab7b5b2 gopls/internal/regtest: eliminate GoSumDiagnostic%0A  > 331a1c6 gopls/internal/regtest: add a simpler API for diagnostic expectations%0A  > c9b82f2 gopls/internal/regtest: eliminate EmptyDiagnostics%0A  > e81af27 gopls: update golang.org/x/vuln@6ad3e3d%0A  > d19e3d1 internal/regtest/bench: fix BenchmarkRename and add more benchmark tests for gopls%0A  > 2be1a9a gopls/internal/regtest: rename EmptyOrNoDiagnostics to NoDiagnostics%0A  > 7ec05ac gopls/internal/regtest: eliminate NoDiagnostics%0A  > e956495 gopls/internal/regtest: eliminate DiagnosticsFor%0A  > 8087911 gopls: remove the experimentalWorkspaceModule mode%0A  > 5b300bd gopls/internal/lsp/cache: clean up view workspace information%0A  > 97d5de5 gopls/internal/cache: don't mark initialized after cancellation%0A  > 58691bc gopls/internal/lsp/glob: add an LSP compliant glob implementation%0A  > a3c22fc cmd/cover: delete package%0A  > 98dcb0e cmd/cover: remove replace directive%0A  > 7765567 gopls/internal/lsp/source: minor clarifications%0A  > a7f7db3 cmd/cover: carve out deprecated command into its own module%0A  > f9a10c0 Revert "cmd/cover: carve out deprecated command into its own module"%0A  > e345d46 internal/gcimporter: fix export of invalid methods%0A  > 4305a22 gopls/internal/lsp/cache: don't cache files if mtime is too recent%0A  > 227ee72 internal/regtest/misc: fail eagerly in TestRenameFileFromEditor%0A  > 43158af cmd/cover: carve out deprecated command into its own module%0A  > b798934 gopls/internal/lsp/protocol: cleanups and docs for Mapper%0A  > a24944e gopls/internal/lsp/protocol: rename s/ColumnMapper/Mapper/%0A  > 55935f4 gopls/internal/span: simplify Span%0A  > 40a1c97 gopls/internal/lsp/lsppos: delete Mapper%0A  > 6a3bc37 gopls/internal/lsp/protocol: reimplement ColumnMapper line logic%0A  > 6e9a35d go/callgraph/cha: refactor callee construction%0A  > fef5b76 go/callgraph: fix slicing in callgraph_test.go%0A  > 2be9d05 gopls/internal/lsp/source/xrefs: a new reference index%0A  > 0362cea gopls/internal/lsp/lsppos: delete TokenMapper%0A  > 67baca6 go/callgraph/vta: optimize scc computation%0A  > 2eb6138 gopls/internal/lsp/filecache: use TempDir if UserCacheDir fails us%0A  > 36bd3db gopls/internal/lsp/protocol: move MappedRange%0A  > 16b3bf8 gopls/internal/lsp/cache: assume Go 1.16+%0A  > 3856a5d internal/robustio: add Plan9 support to FileID%0A  > 09cbc42 gopls/internal/lsp/fake: fix EOF bug in applyEdits%0A  > 4ded35d gopls/internal/lsp/cache: use distinct types for mod and work parse keys%0A  > 107f43f gopls/completion: avoid duplicating text in test func completions%0A  > e225fd4 gopls/internal/lsp/mod: fix nil panic in go.mod hover%0A  > 057ed3c gopls/internal/lsp/filecache: use os.Chtimes%0A  > 1fe76af gopls/internal/lsp/source: MappedRange cleanup%0A  > 02bea03 gopls/internal/lsp/protocol: simplify ColumnMapper%0A  > a4455fe go/callgraph: adds benchmarks comparing algorithms%0A  > 7db99dd go.mod: update golang.org/x dependencies%0A  > 1e0dff2 gopls/internal/regtest: avoid race in TestSwitchFromGOPATHToModuleMode%0A  > 0441b43 gopls/internal/lsp/cache: use specific mutexes for module data%0A  > 33071fb internal/robustio: move robustio%0A  > b01e7a4 gopls/internal/regtest/watch: don't run TestSwitchFromGOPATHToModuleMode%0A  > e417ea3 gopls: remove dead analysis code%0A  > 1a08d01 gopls/internal/lsp: update replace directives in go.mod for package renaming%0A  > eac36cb gopls/internal/regtest: port experimental workspace tests to go.work%0A  > 224a61b gopls/internal/lsp/source: delete Snapshot.WriteEnv method%0A  > 81e741e gopls/internal/lsp/safetoken: funnel more calls through this package%0A  > 8367fb2 gopls/internal/regtest: await go.work changes in TestAddAndRemoveGoWork%0A  > 3b16059 gopls/internal/regtest: make BufferText strict%0A  > 0e1d013 gopls/internal/lsp/cache: recreate Views when their root changes%0A  > 2f31dd4 go/ssa,go/analysis/passes/nilness: refine when type param constants are nil%0A  > ae4ff82 gopls/internal/lsp/source: delete GetTypedFile%0A  > fe6b300 gopls/internal/lsp/source: eliminate Snapshot.Package{,s}ForFile%0A  > 26fc609 gopls/internal/lsp/cache: eliminate snapshot.containingPackages%0A  > 85e6ad7 gopls/internal/lsp/safetoken: fix bug in Offset at EOF%0A  > ef1ec5d gopls/internal/lsp/safetoken: fix error message%0A  > 44395ff gopls/internal/lsp/source: avoid unnecessary transitive rdeps%0A  > 6546d82 Revert "gopls/internal/regtest: harmless CL used for benchmark test"%0A  > 3be0647 gopls/symbols: call source.Document symbols only for Go files%0A  > d462c83 gopls/internal/lsp: Replace input text when completing a definition%0A  > 7efffe1 gopls/internal/regtest: harmless CL used for benchmark test%0A  > 1627e95 gopls/internal/lsp: more comment tweaks post-//line support%0A  > 21f6100 internal/lsp/debug: fix broken template%0A  > 6ad27d0 gopls/internal/robustio: FileID, a portable file identifier%0A  > 6df6eee internal/diff/lcs: optimize inner loop%0A  > 57b1265 go/gcexportdata: drop support for go1.6 export data%0A  > 099260e gopls/internal/lsp: followups to dropping line directives%0A  > 61e2d3f gopls/internal/lsp/cache: a new analysis driver%0A  > eb70795 gopls: ignore //line directives%0A  > b4dfc36 go/ssa: deref core type in emitLoad%0A  > 1270fd7 gopls/internal/lsp: announce selectionRangeProvider capability%0A  > 9bc5dce gopls/internal/lsp/cache: simplify DiagnosePackage%0A  > df35cd8 x/tools: drop support for Go toolchains older than go1.16%0A  > db9d10f go/gcexportdata: preallocate buffer to read into when size is known%0A  > 0d2045b gopls/internal/lsp: document analysis-related functions%0A  > b2b9dc3 gopls/internal/lsp/cache: reduce type-checking in renameImports%0A  > 3cb82d5 go/ssa/interp: fix conversion of slice to named array%0A  > 5899b6a gopls: upgrade dependencies following release%0A  > 763a030 gopls/internal/lsp/cache: delete Snapshot.KnownPackages%0A  > cc0e696 gopls/internal/hooks: panic if diff consistency check fails%0A  > 9ec8553 gopls/internal/lsp/source: emit interface stub methods at top level%0A  > 444c8f6 gopls/internal/lsp/cache: only invalidate parsed files if they changed%0A  > 601ca6c gopls/internal/lsp/source: use correct token.File%0A  > 95c9dce internal/lsp/mod: fix run_govulncheck codelens name%0A  > d72a64a gopls/internal/lsp: add selection range request%0A  > 18f76ec gopls/internal/lsp: split ActivePackages%0A  > 84299a0 gopls/internal/lsp/cache: simplify ad-hoc package warning logic%0A  > a3eef25 gopls/internal/lsp/cache: record parse keys when they're created%0A  > 3da7f1e gopls/hover: remove header tags from hover markdown%0A  > a310bcb gopls/internal/lsp/source: eliminate getStubFile%0A  > 3cba5a8 internal/gcimporter: port CL 424876 from std importer%0A  > b0fdb78 gopls/internal/lsp/mod: add Reset vulncheck result codelens%0A  > 88ceb24 gopls/internal/lsp: perform analysis unconditionally%0A  > 3f74d91 gopls/internal/lsp/cache: invalidate govulncheck results older than 1hr%0A  > 6b8674f gopls/internal/lsp/source: avoid typechecking in findRune%0A  > d7dfffd gopls/internal/lsp: eliminate more unnecessary typechecking%0A  > f3fb218 gopls/internal/lsp/fake: use robustio.RemoveAll in (*Workdir).RemoveFile%0A  > 96ff41d gopls/internal/vulncheck: add TODO for the vulncheck diagnostics%0A  > 0f6c6f1 gopls: delete obsolete govulncheck code and stop gopls vulncheck -summary%0A  > c5343a6 gopls/internal/lsp/regtest: fix TestRunGovulncheckError2%0A  > cb701f7 gopls/internal/lsp: avoid type-checking when computing hyperlinks%0A  > d0f184d gopls/internal/lsp/source: avoid unnecessary calls to GetTypedFile%0A  > 1e5efed gopls/internal/lsp/fake: simply use polling to simulate file watching%0A  > 838a165 gopls/internal/lsp/fake: eliminate the unnecessary fake.FileEvent%0A  > 09fb680 gopls/internal/lsp/fake: eliminate the unnecessary ChangeFilesOnDisk API%0A  > 09ae2d5 gopls/internal/lsp/source: KnownPackagePaths: avoid loading%0A  > 1dcc423 gopls/internal/lsp/cache: split metadata and loading in PackagesForFile%0A  > 6b50501 gopls/release: fix the release script when go.work is not used%0A  > aee3994 gopls/internal/lsp/fake: in (*Workdir).RenameFile, fall back to read + write%0A  > fe60148 go.mod: update golang.org/x dependencies%0A  > c9ea9a7 gopls/internal/regtest: add a test for the case when the renaming package's path contains "internal" as a segment%0A  > bf5db81 gopls/internal/lsp/cache: improve ad-hoc warning for nested modules%0A  > aa9f4b2 go/analysis: document that facts are gob encoded in one gulp%0A  > bdcd082 internal/gcimporter: skip tests earlier when 'go build' is not available%0A  > 2ad6325 gopls/internal/lsp/cache: expand ImportPath!=PackagePath comment%0A  > 52c7b88 gopls/internal/robustio: only define ERROR_SHARING_VIOLATION on Windows%0A  > 4f69bf3 gopls/internal/lsp/cache: narrow reloadOrphanedFiles to open files%0A  > 6002d6e gopls/internal/regtest/misc: test Implementations + vendor%0A  > f540ee6 internal/gcimporter: load cached export data for packages individually%0A  > d444fa3 gopls/internal/lsp/cache: simplify canonical URI cache%0A  > 25fdb81 gopls/internal/regtest/misc: skip vendor test on go1.13%0A  > e0b516b gopls/internal/lsp/cache: invalidate metadata after vendor change%0A  > 31d5843 gopls/internal/lsp/cache: fix re-entrant session locking%0A  > 8c78b30 gopls/internal/vulncheck: always use pkg.go.dev/vuln for urls%0A  > 47a8246 gopls/internal/regtest/misc: skip TestRunGovulncheckError2%0A  > d54e12b gopls/internal/lsp: avoid I/O in URI comparison operations%0A  > 0379b73 internal/gcimporter: fix TestImportStdLib%0A  > e79e423 gopls/internal/vulncheck: handle package errors%0A  > c5ce806 gopls/internal/lsp/mod: disable the diagnostics on stdlib vulns%0A  > 78c1861 gopls/internal/vulncheck: clarify the log message%0A  > 1a0053c gopls: move reset go.mod diagnostic codelens to module statement%0A  > 9b8d87b gopls/internal/regtest: fix TestRunGovulncheckStd%0A  > 81b6bef gopls/internal/lsp: add run vulncheck fix for stdlib vulns%0A  > fe83ddb gopls/internal/lsp: move options off of the cache%0A  > 88ee30b gopls/internal/lsp/source: enable run_govulncheck codelens in exp mode%0A  > 0a6aa90 gopls/internal/lsp/command: rename run_vulncheck_exp to run_govulncheck%0A  > bedad5a gopls/internal/lsp/mod: add hover for stdlib vulnerabilities%0A  > 7a1b570 gopls/internal/vulncheck: check vulnerabilities in standard library%0A  > 9a54670 gopls/internal/lsp/mod: add "Run govulncheck" codeaction%0A  > f1b76ae gopls/internal/lsp: add an option to overwrite previous diagnostics%0A  > e8a70a5 gopls/internal/lsp: remove access to mutable session state from the view%0A  > ff22fab gopls/internal/lsp/cache: eliminate obsolete invalidation step%0A  > 3881046 gopls: add a go:generate rule for doc generation%0A  > 4c3cb1e internal/gocommand: add GoVersionString%0A  > e29d1ed gopls: add diagnostic for standard library%0A  > f718365 gopls/internal/lsp: include all vulns info to fetch_vulncheck_result%0A  > 9519368 gopls/internal/lsp/mod: add the vulncheck diagnostics mode%0A  > 7d9f451 gopls/internal/govulncheck: add in-memory cache for vulndb%0A  > 1ccccf8 go/ssa: deprecate coreType and _NormalTerms%0A  > 4b7d1b3 gopls: add diagnostics for both vulns used and not used%0A  > 50ccef5 internal/regtest/bench: add benchmark tests for gopls%0A  > d39685a gopls/internal/lsp/source: Package clarifications%0A  > 7cfde84 gopls/internal/vulncheck: add import info based vuln scanning%0A  > 2b56641 internal/gcimporter: adjust the number of expected packages in TestStdlib%0A  > 50df761 gopls: skip vulnerabilities that are probably fixed in hover%0A  > 7cda55e gopls/internal/lsp/cache: wire in mod vulnerability analysis%0A  > 5c35617 gopls: add quick fixes for all vulnerabilities%0A  > fb7be64 gopls/internal/lsp/command: return the vulncheck progress token%0A  > 060c049 go/packages: fix doc typo%0A  > 6eafd96 gopls: fix formatting for vulncheck results in hover%0A  > b797704 go/analysis/passes/loopclosure: recursively check last statements in statements like if, switch, and for%0A  > 3b9d20c internal/gcimporter: in TestStdlib, only check x/tools packages if we expect to have their source%0A  > 2ad3c33 go/packages: change workaround for issue 28749 to not require NeedFiles%0A  > 57f56ab gopls/internal/lsp/source: avoid panic(nil)%0A  > 41c70c9 internal/lsp/source: avoid using go/types.Implements with Typ[Invalid]%0A  > db5eae2 analysis: correct go/analysis/passes/findcall path in docs%0A  > b978661 cmd/godoc: streamline test subprocesses%0A  > 932ec22 internal/testenv: add a Command function that replaces exec.Command%0A  > 19fb30d gopls/internal/lsp/cache: fix data race in Symbols%0A  > 4ce4f93 gopls/internal/lsp: add gopls.fetch_vulncheck_result%0A  > 8ba9a37 gopls/internal/lsp/mod: highlight when there is no fix for vuln%0A  > 128f61d gopls/internal/lsp/mod: add related info%0A  > fc03993 internal/lsp/mod: adjust vulncheck diagnostics suppression logic%0A  > c099dff gopls/internal/vulncheck: log progress%0A  > 36a5c6a go/ssa: build generic function bodies%0A  > 85bf7a8 gopls/internal/lsp/source: eliminate Metadata interface%0A  > 2592a85 gopls/internal/lsp: simplify KnownPackages%0A  > c7ed4b3 gopls/internal/lsp/cache: clean up tracking of GO111MODULE%0A  > 23056f6 internal/lsp/cache: clean up getOrLoadIDsForURI%0A  > 5a4eba5 internal/lsp/cache: remove support for invalid metadata%0A  > 32a17c0 gopls/internal/lsp/mod: fix unaffecting vuln diagnostics msgs%0A  > dea100b internal/testenv: skip tests that need export data for std if 'go tool compile' does not exist%0A  > ba373ee playground/socket: eliminate an arbitrary timeout in TestLimiter%0A  > 3d085f3 gopls/internal/lsp/lsprpc: eliminate arbitrary timeout in TestEnvForwarding%0A  > 434d569 gopls/internal/lsp/regtest: improve documentation%0A  > ce26db4 go/analysis: add Pass.TypeErrors field%0A  > b0ad6b2 gopls/internal/regtest/misc: fix use of the AfterChange API%0A  > 89856a4 gopls/semantic: semantic tokens for type parameters%0A  > 6e8da3f internal/pkgbits: port small optimization from compiler to tools%0A  > 06fb723 internal/gcimporter: port memory reuse optimizations from Go tree%0A  > fc702c5 internal/gcimporter: fix performance regression for unified IR%0A  > 1cb4c17 gopls/internal/regtest: make AfterChange do the awaiting%0A  > 0c71b56 gopls/internal/lsp: fix diagnostic suppression when folders change%0A  > e3b3c01 go/pointer: break TestInput into subtests and update skips%0A  > 13648cd gopls/internal/lsp/cache: use Package.FileSet where possible%0A  > 8f32411 cmd/stringer: replace ioutil with os%0A  > 3c3713e gopls/internal/lsp/cache: use typed strings (PackagePath et al) throughout%0A  > 004d118 gopls/internal/lsp/mod: simplify ModVulnerabilityDiagnostics%0A  > 4a8413c gopls/internal/lsp/mod: deleted unused function pkgVersion%0A  > bc08991 gopls: sync golang.org/x/vuln@3af8368ee4fe%0A  > d66e9b4 internal/typesinternal: update go/types error codes for 1.20%0A  > 6f99366 gopls/internal/lsp/cache: don't pass snapshot.fset to go/packages%0A  > d56532a cmd/compilebench: make it work without installed .a's%0A  > 502c634 go.mod: update golang.org/x dependencies%0A  > bd04e32 internal/jsonrpc2_v2: eliminate a potential Accept/Dial race in TestIdleTimeout%0A  > d41a43b internal/jsonrpc2_v2: fix a potential deadlock when (*Conn).Close is invoked during Bind%0A  > 3057465 gopls/doc: Add plugin for Lapce to gopls documentation%0A  > ba92ae1 internal/persistent: avoid incorrect map validation due to multiple keys%0A  > 9474ca3 gopls/doc: clarify `go work use`%0A  > 003fde1 internal/gcimporter: use nondeprecated go/packages mode bits%0A  > 5050657 gopls/fake: add semantic token modifiers to fake editor%0A  > 88a3548 gopls/coverage: repair coverage.go%0A  > 8e0240a internal/regtest/workspace: permanently skip TestDeleteModule_Interdependent%0A  > fe725d9 gopls/internal/regtest: simplify awaiting diagnostics from a change%0A  > 3c8152e internal/gcimporter: optimize dependency lookup%0A  > 39c2fd8 internal/lsp/cache: simplify importsState modfile hashing logic%0A  > ec044b1 gopls: update dependencies following the v0.10.0 release%0A  > 2b29c66 internal/gcimporter: API for shallow export data%0A  > affa603 internal/gcimporter: moved from go/internal/gcimporter%0A  > a77a1fb gopls/internal/lsp/mod: fix vulncheck hover message%0A  > 4ada35e gopls/internal/lsp: handle modVulncheckSource in diagnosticSource.String%0A  > e5f03c1 gopls/doc: clean up README and add a release policy%0A  > d5e9e35 go/analysis/passes/loopclosure: enable analysis of parallel subtests%0A  > 039b24b internal/jsonrpc2_v2: initiate shutdown when the Writer breaks%0A  > 32e1cb7 gopls/internal/lsp: clarify control around diagnostics%0A  > feeb0ba gopls/internal/lsp/cmd: fix deadlock when opening a file%0A  > 6e9dc86 gopls/internal/lsp/source/completion: fix panic in completion on *error%0A  > 73fcd88 Revert "internal/jsonrpc2_v2: initiate shutdown when the Writer breaks"%0A  > 70a130e gopls/api-diff: simplify the api-diff implementation%0A  > 3e8da47 internal/jsonrpc2_v2: initiate shutdown when the Writer breaks%0A  > 3566f69 gopls/internal/lsp/source: minor space optimizations%0A  > 7cdb0e7 internal/jsonrpc2_v2: rename Serve to NewServer and eliminate its error return%0A  > 28e9e50 internal/jsonrpc2_v2: eliminate error return from Bind%0A  > eabc3a0 internal/jsonrpc2_v2: eliminate isClosingErr%0A  > 4885f7c internal/jsonrpc2_v2: eliminate a temporary connection leak in (*Server).run%0A  > 739f55d internal/jsonrpc2_v2: rework Connection concurrency%0A  > e172e97 go/types/typeutil: break recursion through anonymous interfaces%0A  > f1c8f7f internal/lsp/source: optimize filter regular expression%0A  > e074ef8 gopls/internal: don't show a warning if the Go version is undetected%0A  > 7fba77c gopls/internal/lsp/source: remove deprecated settings from EnableAllExperiments%0A  > 42cb7be gopls/internal/lsp: improve the Go version deprecation message%0A  > 2af106e gopls/internal/hooks: fixes to diff disaster logic%0A  > e4bb343 go/internal/gcimporter: update to anticipate missing targets and .as%0A  > 875c31f go/internal/gcimporter: add test of export/import on std%0A  > 541f4c5 cmd/bundle: quote command-line arguments in output%0A  > de675d5 tools/gopls: argument in function bodies marked as parameter by semantic tokens%0A  > 3e1371f gopls/internal: start on LSP stub generator in Go.%0A  > 121f889 gopls/internal/lsp/mod: merge vuln diagnostics to one, and add a hover%0A  > d6511e5 internal/facts: share go/analysis/internal/facts with gopls%0A  > 2e0ca3a go/internal/gcimporter: fix bug in struct iexport%0A  > 1928cea go/ssa: emit field and index lvals on demand%0A  > 8166dca go/analysis/passes/asmdecl: define register-ABI result registers for RISCV64%0A  > 2dcdbd4 go/internal/gcimporter: port CL 431495 to tools, add tests%0A  > d476af7 go/ssa: add slice to array conversion%0A  > d212f7d gopls/internal/regtest/workspace: fix bugs in test%0A  > 051f03f gopls/internal/lsp/cache: remove unnecessary params%0A  > 21f6127 gopls/internal/lsp/cache: add PkgPath->PackageID index to Metadata%0A  > 06041c9 gopls/doc: update manual documentation of the newDiff setting%0A  > f112c43 go.mod: update golang.org/x dependencies%0A  > 207f456 go/internal/gcimporter: bump version number in skew check%0A  > 65196ca gopls/README.md: fix wording around supported Go versions%0A  > 6128030 gopls/internal: support renaming packages with int. test variants%0A  > 649df2e go.mod: mark as requiring -compat 1.16%0A  > 91311ab gopls/internal/lsp/cache: better import path hygiene%0A  > 9eda97b go/analysis: enable a test that applies after go list behavior change%0A  > b50d7ba gopls: minor cleanup of standalone package support%0A  > 502b93c gopls/internal/lsp: tolerate missing end position in RelatedInformation%0A  > d67c3ad internal/imports: repair warnings from default analyzers%0A  > bc2e3ae internal/jsonrpc2_v2: add Func convenience wrappers for the Binder and Preempter interfaces%0A  > a9b653b cmd/compilebench: use -a instead of -i to ensure dependencies are built%0A  > 4818d9e Revert "gopls/internal/lsp/cache: disable strict analysis while we fix panics"%0A  > b2efd4d internal/jsonrpc2_v2: eliminate most arbitrary timeouts in tests%0A  > 371ef16 internal/jsonrpc2_v2: rework concurrency in idleListener%0A  > 5935531 internal/jsonrpc2_v2: remove “Box” suffix from channel field names%0A  > fd32990 internal/jsonrpc2_v2: error out in-flight client calls when the reader breaks%0A  > 0e222f5 internal/jsonrpc2_v2: close the underlying connection if Wait is called instead of Close%0A  > bc4e384 gopls/internal/lsp/cache: fix crash in analysis%0A  > b93a56f refactor/satisfy: fix visiting functions in the unsafe package%0A  > 9b5e55b gopls/internal/lsp/cache: disable strict analysis while we fix panics%0A  > 9ffaf69 gopls/internal/lsp/cache: minor analysis cleanups%0A  > ffb862b gopls/internal/lsp/cache: remove stray print statement%0A  > f87c1ed internal/fastwalk: improve Darwin performance by ~3x%0A  > b253314 gopls/internal/lsp/cache: add support for loading standalone main files%0A  > 3beecff gopls/internal/span: some cleanups%0A  > d375238 gopls: dedup upgrade code actions for vulncheck%0A  > b20ae4b README: format install command%0A  > 19a5504 gopls/internal/lsp: use the golang.org/x/vuln/exp/govulncheck%0A  > ab79327 cmd/ssadump: disable run mode with runtime package%0A  > 29429f5 gopls/internal/lsp/source: sort protocol edits%0A  > 49b340b go/analysis: update tests for different go list error behavior%0A  > cd0288f internal/lsp/cache: invalidate analysis results on packages.Load%0A  > 906c733 gopls/internal/lsp/source: find references in test packages%0A  > 2a41b25 internal/robustio: fix log.Fatal calls that should be log.Fatalf%0A  > 150b5f8 internal/imports: read entire API dir in mkstdlib.go%0A  > 19cfa79 internal/lsp/source: switch the default diff algorithm to "checked"%0A  > fa6bd3b gopls: include informational vulnerability diagnostics%0A  > 89b4335 gopls/internal/lsp: merge notifications about deprecated settings%0A  > f90d8ad all: fix a few function names on comments%0A  > 350f1e2 gopls/internal/lsp/fake: retry ephemeral errors when renaming on windows%0A  > 8b1d1ec gopls/internal/lsp/cache: suppress panics during analysis%0A  > 20c1ee7 gopls/internal/lsp: warn about Go versions that are too old%0A  > 709f108 gopls/internal/lsp/cache: suppress crashes in fact_purity analyzer%0A  > a410e98 internal/diff: ToUnified may fail%0A  > 26a95e6 gopls/internal/span: move internal/span into gopls%0A  > f2c4579 internal/diff: avoid unnecessary allocations%0A  > 60ddcca internal/diff: Apply: validate inputs%0A  > 02bef08 go/packages/packagestest: break dependency on gopls' span package%0A  > 778f945 go/analysis: break dependency on span package%0A  > c682555 gopls/internal/regtest/misc: delete testdata%0A  > 1552529 gopls/internal/regtest/misc: use vulntest for vuln_test%0A  > c4f49e4 go/analysis/passes/assign: fix map assignment%0A  > bd8c28f internal/diff/lcs: fix shell format error%0A  > ede3ab2 gopls/internal/lsp/protocol: simplify OffsetRange, Position%0A  > dc3cf95 gopls/internal/vulncheck: use vulntest for test database creation%0A  > 4ef38dc gopls/internal/vulncheck/vulntest: add test helpers%0A  > 2f57270 gopls: update golang.org/x/vuln%0A  > d96b238 internal/diff: simplify API, break span dependency%0A  > 9856077 internal/diff: abolish errors%0A  > 33c2dbf gopls/internal/lsp: remove extra newlines in vulncheck diagnostics%0A  > b280e27 gopls/internal/lsp/cache: make IsIntermediateTestVariant a method%0A  > c5514b7 gopls/internal/lsp/source: use PackageFromFile in Identifier%0A  > ff4ff8b gopls/internal/lsp/source: don't type-check in FindPackageFromPos%0A  > 2d32e15 gopls/internal/lsp/cache: in tests, show all stacks during analyzer crash%0A  > dc88e7b godoc: fix some comments%0A  > 7f79a02 gopls: use fmt.Fprintf%0A  > 40dabfa gopls/internal/lsp: add support for package renaming%0A  > 55e5cff internal/diff: unified: match GNU diff for empty file%0A  > 3e0355b gopls/.../fillstruct: support generic types%0A  > ed98f10 gopls: prefix vulncheck diagnostic message with title%0A  > b180eff x/tools/go/analysis: extend json output by SuggestedFixes%0A  > d49f960 internal/lsp/cache: report analysis panics during testing%0A  > 27641fb gopls: suggest upgrading to fixed version for vulncheck diagnostics%0A  > 199742a go/analysis/passes/printf: check for nil scope of instance methods%0A  > 3db607b gopls/internal/lsp/cache: remove "discovered missing identifiers" log%0A  > a4274a8 gopls: add diagnostics for non-stdlib vulnerabilities%0A  > f80e984 gopls/internal/lsp/work: use the WorkFileError diagnostics source%0A  > 9c63911 gopls/internal/lsp: delete dead code%0A  > ae737bc gopls/internal/lsp: remove the source.Session interface%0A  > bddb372 gopls: deprecate three experimental features%0A  > 4dd4ddb go/packages: issue error if 'go list' on PATH is too new%0A  > 10e9d3c gopls/internal/lsp: tolerate new 'imported and not used' error message%0A  > eb45e98 gopls/internal/regtest: fix regtest failures from "undefined" errors%0A  > 1bfc469 gopls: update to handle 'undefined:' versus 'undeclared' in type errors%0A  > 5214f41 internal/gocommand: show pid of process%0A  > c5cd943 gopls: fix the reset_golden.sh script and regenerate golden files%0A  > 49a686d go/analysis: update explanation of (no) Diagnostics.Severity%0A  > eb25de6 go/analysis/passes/loopclosure: only check statements after t.Parallel%0A  > b243e57 gopls/internal/lsp/tests: simplify collectCompletionItems, remove Data.t%0A  > 88b5529 gopls/internal/lsp/tests: use the mustRange helper in more places%0A  > c7ac942 gopls/internal/lsp: simplify prepareRename tests%0A  > b9adce9 internal/lsp/source: derive document symbols from syntax alone%0A  > 3dda4ba all: replace deprecated egrep with grep -E%0A  > 1877b5f go/analysis/passes/printf: permit multiple %w format verbs%0A  > b3ab50b go/analysis/passes/stdmethods: recognize Unwrap() []error%0A  > 62ae586 gopls/test: disable stderr output for command line tests as well%0A  > be3ff02 go/analysis/passes/sortslice: correct diagnostic for sort.Slice(f())%0A  > 2f04713 gopls: fix out of bounds bug in extract%0A  > 16b9742 go/analysis/passes/loopclosure: use go/types' object resolution%0A  > 81a42f0 gopls/internal/lsp/tests: pass in a *testing.T to Data.Golden%0A  > 14462ef go/analysis/passes/loopclosure: experiment with checking t.Run+Parallel%0A  > 00ae48e go/internal/pkgbits: replace os.SEEK_CUR with io.SeekCurrent%0A  > 835bfdf gopls: update x/vuln to pick fix for incorrect version suggestion%0A  > 6782af0 gopls/internal/lsp/source: clarify qualifiedObject%0A  > f901623 gopls/internal/lsp: suppress noisy log output in tests%0A  > df2eb93 gopls/test: fix erroneously skipped tests, remove redundant cmd tests%0A  > 1578244 gopls: set codelensProvider in initialize response%0A  > fdf581f internal/lsp: allow extract func ranges to begin/end with comments%0A  > b256f1f gopls/internal/lsp/cache: remove distracting "safe trimming" log%0A  > 0e011a0 all: use constant to avoid repeated definitions%0A  > 4d18923 gopls/internal/fake: sort edits by both start and end position%0A  > 45ad958 gopls/internal/lsp/protocol: fix json tags and indirect some zero values%0A  > a61f20e internal/gocommand: tweak debugging for hanging go commands%0A  > cdd6986 gopls/tsprotocol: make Disabled in CodeAction optional%0A  > 0398b3d internal/gocommand: add instrumentation for hanging go commands%0A  > 9250e22 internal/lsp: latest version of LSP stubs%0A  > ec74389 gopls/internal/lsp/source: make "chatty" diagnostics the default%0A  > 7e129ca gopls: add codelens to reset upgrade diagnostics%0A  > a81fce3 gopls: run go mod tidy -compat=1.16%0A  > a8b9ed3 gopls/internal/lsp/source: remove Govulncheck from Hooks%0A  > 678efe0 gopls/internal/lsp/cmd: fix vulncheck error handling%0A  > e71c338 go/ssa/ssautil: initialize info when there is syntax%0A  > 0eebaab go/analysis: allow for identical SuggestedFixes%0A  > eeaf4eb internal/lsp/fake: add rename file support for testing%0A  > 4754f75 go/analysis/passes/copylock: modify match pattern to satisfy change sync.Once.done to atomic.Bool%0A  > a630751 x/tools: update go.mod following moving LSP code to x/tools/gopls%0A  > 308e02c x/tools/go/ssa: disable slice-to-array test%0A  > 3ee1710 gopls/doc: update stale documentation and improve link names%0A  > 5f27e05 all: remove redundant type conversion%0A  > b15dac2 gopls: migrate internal/lsp to gopls/internal/lsp%0A  > dd1bab2 go/analysis/passes/printf: fix panic parsing argument index%0A  > bac5507 go/analysis/internal/checker: make applyFixes work from the first character%0A  > c1dd25e gopls/internal/migrate.sh: a script to migrate internal/lsp to gopls/%0A  > 83d7619 gopls : add a mention of staticcheck to settings documentation%0A  > d815cba internal/lsp: update LSP protocol for WorkspaceEdit%0A  > 6a585a2 x/tools/internal/typeparams: use regexp to match wanted result%0A  > be9eab1 go/analysis/passes/inspect: fix example return%0A  > 5ba8541 x/tools/internal/lsp/source: disable some tests for std lib changes%0A  > eb8352e gopls/internal/govulncheck: sync x/vuln@62b0186%0A  > 655abda gopls/internal/regtest: TestEditGoDirectiveWorkspace should fail eagerly%0A  > 33c1ddd tools/gopls/internal/regtest/diagnostics: handle new error message%0A  > 40cfaff x/tools/internal/lsp/source: disable some tests for std lib changes%0A  > f16be35 internal/lsp/source: add functions to type hover output%0A  > dfc8d49 internal/lsp/testdata: fix diagnostics checksum%0A  > 6c10975 internal/lsp/cache: honor RunDespiteErrors=false%0A  > 49ab44d x/tools/internal/lsp: re-enable a test with adjusted error message%0A  > 550e1f5 internal/lsp/tests: use a shorter module path for test data%0A  > 4ccc73c internal/lsp/tests: simplify comparison of markdown at go1.18%0A  > 3eb8a8f internal/lsp/cache: delete misleading Package.IllTyped method%0A  > cb91d6c internal/lsp/cache: clarify error control flow of analysis%0A  > 41c3a9b internal/lsp/analysis/fillreturns: be defensive w.r.t. type errors%0A  > fe1a27b gopls/doc: make doc generation work regardless of the current directory%0A  > ddbeb75 internal/lsp: run internal/lsp/reset_golden.sh%0A  > 248c34b internal/lsp: support regular expressions in Diagnostics tests%0A  > 431f4ef internal/lsp/tests: re-enable ARM tests%0A  > 717a671 go/analysis/passes/printf: remove unused hasBasicType%0A  > 7f23307 internal/lsp: limit diagnostics for upgrades to codelens go.mod file%0A  > 7c5e035 internal/lsp: fix suppressed panic in analyzer%0A  > 2f38e1d internal/lsp/tests: disable failing test on ARM%0A  > d35bb19 internal/lsp/tests: improve assertion error message%0A  > 7111c2e x/tools/internal/lsp: disable a test so we can change the parser error%0A  > db6a62c go/internal/gcimporter: call Interface.Complete in unified importer%0A  > 587a153 internal/lsp: hover to render go 1.19 doc comments%0A  > e55fb40 internal/lsp/cache: clear shouldLoad IDs on load%0A  > a3cac11 godoc/redirect: delete golang.org-specific code%0A  > b3851a8 internal/lsp/cache: tweaks to metadata graph%0A  > 938e162 gopls/internal/regtest: unskip TestDeleteModule_Interdependent%0A  > e8507be gopls/internal/regtest/bench: replace -gopls_version with -gopls_commit%0A  > 8c83056 gopls/internal/regtest: unskip TestSumUpdateFixesDiagnostics%0A  > 987de34 internal/lsp/completion: don't use Type.String for checking identity%0A  > 5a26068 internal/lsp/source: remove utm_source from pkgsite links%0A  > 35f806b gopls/doc/workspace: correct grammar%0A  > bebd890 go/analysis: remove stray print statement in the timeformat analyzer%0A  > 88d981e printf analyzer: link to fmt#Printing for verb/type docs%0A  > c4ec74a go/internal/pkgbits: fix performance of rawReloc%0A  > 37a81b6 internal/lsp: add unnecessary tags for unused vars and imports%0A  > 3807419 internal/lsp/cache: validate the range for critical errors in go files%0A  > b2156b5 gopls: update dependencies%0A  > 0ad49fd internal/imports: update stdlib index for 1.19%0A  > 3950865 gopls/internal/regtest/bench: add a -gopls_version flag%0A  > 6fa767d internal/lsp: update documentation for directoryFilters setting and default value%0A  > 96d05aa gopls/internal/regtest: fix TestFailingDiagnosticClearingOnEdit%0A  > 4ff08b4 gopls: Improve auto-imports example for NeoVim LSP%0A  > 92d58ea internal/lsp/cache: register a file watcher for explicit GOWORK values%0A  > 98aef77 internal/lsp/cache: track explicit go.work files outside the workspace%0A  > fff6d6d internal/lsp: update the broken workspace message to mention go.work%0A  > 9b60852 gopls/internal/regtest: move TestMultipleModules_Warning to ./workspace%0A  > 06d96ee gopls/internal/regtest/bench: add a test for completion following edits%0A  > 81c7dc4 internal/lsp: polish vulncheck progress messages%0A  > af2a0a8 internal/lsp: use exec.CommandContext when running vulncheck%0A  > 3519aa2 internal/lsp/cmd: remove unused Env from pkgLoadConfig%0A  > 6c27717 internal/lsp/mod/code_lens: add "run govulncheck" codelens%0A  > 763f65c gopls/internal/regtest/misc: simplify shared edit tests%0A  > fc3b24a go/internal/gcimporter: rewrite interface receiver parameters%0A  > b5fd088 internal/lsp/command: replace VulncheckArgs Dir with URI%0A  > 99fd76f internal/lsp/cache: delete KnownMetadata.PkgFilesChanged%0A  > 01c9ff0 internal/lsp/cache: invalid packages should not be workspace packages%0A  > bd68922 internal/lsp: new options to disable certain kinds of semantic tokens%0A  > bceee4b internal/lsp/command: let RunVulncheckExp call gopls vulncheck%0A  > 3e0a503 internal/lsp: use directoryFilters in import scanning%0A  > 87f47bb gopls/internal/regtest/bench: refactor and improve benchmarks%0A  > 8b9a1fb go/callgraph/vta: do not assume that recovers cannot be deferred%0A  > 371fc67 go/tools: add check for time formats with 2006-02-01%0A  > d08f5dc gopls/internal/regtest: unskip all of TestModFileModification%0A  > ddb90ec internal/lsp/cache: fix data races to view.options%0A  > 0d04f65 internal/lsp: re-send diagnostics on file events%0A  > d025cce internal/lsp/source: don't crash requesting gc_details for an empty file%0A  > 10cb435 internal/lsp/regtest: improvements for shared execution modes%0A  > 4d0b383 internal/lsp/regtest: minor cleanup for magic regtest envvar%0A  > 310ea71 gopls/internal/regtest: add a test that ignoring a file resolves errors%0A  > 21861e6 gopls/internal/regtest/bench: put feature benchmarks in their own file%0A  > c7f1191 go/internal/gcimporter: set underlying types in proper order; flatten imports%0A  > bd3f524 internal/lsp: rename all the package names in the renamed package%0A  > 9f65685 internal/lsp/source: enable the new diff with allExperiments%0A  > 9580c84 internal/lsp: Check if user's editor support rename operation%0A  > f560bc8 internal/lsp/cache: don't set context cancellation as a critical err%0A  > 8ea5687 internal/lsp/regtest: remove arbitrary timeout for closing the editor%0A  > d01bb2f internal/lsp/source: document the handling of GOPRIVATE for linkTarget%0A  > 98bfcd1 internal/memoize: fix race in Store.Promise%0A  > e02e98a internal/lsp/cache: allow network whenever reloading the workspace%0A  > b52794a internal/lsp/cache: simplify snapshot.Clone reinitialization logic%0A  > f1bb5ca internal/lsp/cache: report a critical error when go.work is invalid%0Abumping github.com/fsnotify/fsnotify 0f4b979...5f8c606:%0A  > 5f8c606 Update ChangeLog%0A  > 8878587 Tweak the docs a bit%0A  > 89b4cf1 Add test for re-adding a renamed file (# 508)%0A  > 85acde2 Update x/sys%0A  > 69c24b0 Update x/sys%0A  > fb07f82 Add test to see what happens if you watch a symlink (# 498)%0A  > 666da9c Clarify doc comment on WatchList() (# 499)%0A  > 123e4e3 Add note about README version%0A  > 61a05ce Update documentation and examples (# 496)%0A  > e180a87 Move some inotify-tests to run on all backends; test that state is cleaned up after Remove (# 494)%0A  > fdf41a3 Move some files around%0A  > 844d71f Port minor test changes from fen-v2 branch; make LICENSE text not ugly%0A  > 5b87f50 windows: simplify a bit (# 493)%0A  > 2bfaa00 all: add Watcher.{sendEvent,sendError} (# 492)%0A  > 8ab3b84 kqueue: don't set up watchers on unreadable files (# 479)%0A  > a4bcdf8 Update changelog%0A  > 4b43fad kqueue: remove timeout from unix.Kevent() (# 480)%0A  > a24f78c windows: test symlinks (# 491)%0A  > f45391f windows: run TestWatchRename/rename_overwriting_existing_file (# 490)%0A  > ee33a65 Use "os.Rename()" in tests instead of "mv"%0A  > 9dd0568 cmd/fsnotify: fix time.Format() string%0A  > 5dcbfba windows: replace syscall with golang.org/x/sys/windows%0A  > 1f8edaf windows: replace "e" with "err" for error variables%0A  > 99715ba windows: increase buffer size from 4K to 64K (# 485)%0A  > a5c5815 ci: update to use Go 1.19, kick off fewer builds, update x/sys (# 484)%0A  > f2d35c3 Remove CLA section in contributing%0A  > 4604469 Need Linux 5.9 for a useful fanotify we can use%0A  > a566bb1 Update CONTRIBUTING.md%0A  > 01dfc6f Remove PULL_REQUEST_TEMPLATE%0A  > a58e868 Run tests in illumos (# 481)%0A  > 666c6a0 Update ChangeLog%0A  > 928895c [bugfix] close handle when remWatch open in getIno (# 288)%0A  > f174f95 windows: update watch paths when renaming directories with sub-watches (# 370)%0A  > 87dc1fa Rewrite tests (# 478)%0A  > 57e6a49 Add {Event,Op}.Has() (# 477)%0A  > 39823aa Document that /proc and /sys won't work%0A  > 60fbf57 Clarify FAQ on goroutines%0A  > ca0e2f4 macos: retry if open() returns EINTR (# 475)%0A  > ff39bb4 Fix lint (# 476)%0A  > 421f529 debian 6 test: deal with multiple packages (# 474)%0A  > a3256ef Remove AUTHORS file%0A  > 0e78fa6 Update README: split out FAQ to "Platform-specific notes"%0A  > 1a7b6ef inotify: don't ignore events for files that don't exist (# 470)%0A  > f0aceb2 Tweak comment regarding relative paths (# 466)%0A  > d9c9fa5 Add cmd/fsnotify (# 463)%0A  > cc15908 kqueue: better error if watching a file fails (# 471)%0A  > c4e64e4 Replace Use of Kthread-blocking Epoll with Poller Read, Remove Per-Event LStats on Linux # 433 (# 434)%0A  > 4b8b298 Test some more things in CI (# 469)%0A  > 548b8fb Add missing changelog for 1.4.{8,9} (# 468)%0A  > 7fe2936 inotify: fix race in Close() (# 465)%0A  > 35b6378 Clarify README on network drives (# 467)%0A  > e56409e Update link to CONTRIBUTING in the README (# 464)%0A  > 4678dfd Update documentation for linux systems (max_user_watches) (# 287)%0A  > 808f582 bump up GitHub Actions (# 461)%0A  > 4193dfd Do not suppress Chmod on non-existent file (# 260)%0A  > 6ae56b7 kqueue: Make watcher.Close() O(n) instead of O(n^2) (# 233)%0A  > adf5320 strings.Builder instead of bytes.Buffer (# 285)%0A  > 217e78e Explicit mutext (un)locking (# 462)%0A  > 1a4f949 Use common error when removing an unwatched file (# 460)%0A  > 5acfdc1 windows: protect access to isClosed with mutex (# 454)%0A  > c56cafd Test Go 1.18%0A  > 37badf6 This project is archived (# 459)%0Abumping knative.dev/networking e5d04e8...b9dd5c2:%0A  > b9dd5c2 upgrade to latest dependencies (# 816)%0A  > 68947c5 upgrade to latest dependencies (# 815)%0A  > 14a2bd4 Move `pkg/certificates` from `control-protocol` to `networking` (# 802)%0A  > 2daa483 Update community files (# 813)%0A  > 0dbe4f9 upgrade to latest dependencies (# 812)%0A  > 2a2f7d2 upgrade to latest dependencies (# 810)%0A  > fcbedad Update community files (# 809)%0A  > a44b093 upgrade to latest dependencies (# 808)%0A  > 7c2f7ac upgrade to latest dependencies (# 807)%0A  > …

---
## [ProjectBlaze/frameworks_base](https://github.com/ProjectBlaze/frameworks_base)@[97dcb49f8c...](https://github.com/ProjectBlaze/frameworks_base/commit/97dcb49f8c5cb30fb721a990e5ee174b590a9ad2)
#### Thursday 2023-06-22 14:12:27 by Kuba Wojciechowski

[SQUASHED] core: Blacklist pixel system feature from Google Photos

    We want to include the P21 experience flag to enable new features,
    however it seems like Google Photos uses it to decide whether to use the
    TPU tflite delegate. There doesn't seem to be any fallback so we need to
    make sure the feature is not exposed to the app so that a normal
    NNAPI/GPU delegate can be used instead.

    Test: Google Photos editor with PIXEL_2021_EXPERIENCE feature in product
    Signed-off-by: Kuba Wojciechowski <nullbytepl@gmail.com>
    Change-Id: I51a02f8347324c7a85f3136b802dce4cc4556ac5

commit 67eb31b3bb43d06fcc7f6fdb2f92eb486451cae6
Author: kondors1995 <normandija1945@gmail.com>
Date:   Thu Jun 9 17:39:25 2022 +0530

    Core: Extend Pixel experience Blacklist For Google Photos

    Turns out having these brakes Original quality backups.
    Since these indicate that the device is pixel 4 with in the turn brakes device spoofing as OG pixel

    Change-Id: I336facff7b55552f094997ade337656461a0ea1d

commit 508a99cde60b73dc3f1e843d569bca31def35988
Author: ReallySnow <reallysnow233@gmail.com>
Date:   Fri Dec 31 16:40:23 2021 +0800

    base: core: Blacklist Pixel 2017 and 2018 exclusive for Google Photos

    * In this way can use PixelPropsUtils to simulate the Pixel XL prop
      method to use the unlimited storage space of Google Photos
    * Thanks nullbytepl for the idea

    Change-Id: I92d472d319373d648365c8c63e301f1a915f8de9

commit aaf07f6ccc89c2747b97bc6dc2ee4cb7bd2c6727
Author: Akash Srivastava <akashniki@gmail.com>
Date:   Sat Aug 20 19:04:32 2022 +0700

    core: Pixel experience Blacklist For Google Photos for Android 13

    * See, in Android 13 pixel_experience_2022_midyear was added, which needs to be blacklisted aswell

    Change-Id: Id36d12afeda3cf6b39d01a0dbe7e3e9058659b8e

commit 9d6e5749a988c9051b1d47c11bb02daa7b1b36fd
Author: spezi77 <spezi7713@gmx.net>
Date:   Mon Jan 31 19:17:34 2022 +0100

    core: Rework the ph0t0s features blacklist

    * Moving the flags to an array feels more like a blacklist :P
    * Converted the flags into fully qualified package names, while at it

    Signed-off-by: spezi77 <spezi7713@gmx.net>
    Change-Id: I4b9e925fc0b8c01204564e18b9e9ee4c7d31c123

commit d7201c0cff326a6374e29aa79c6ce18828f96dc6
Author: Joey Huab <joey@evolution-x.org>
Date:   Tue Feb 15 17:32:11 2022 +0900

    core: Refactor Pixel features

    * Magic Eraser is wonky and hard to
      enable and all this mess isn't really worth
      the trouble so just stick to the older setup.

    * Default Pixel 5 spoof for Photos and only switch
      to Pixel XL when spoof is toggled.

    * We will try to bypass 2021 features and Raven
      props for non-Pixel 2021 devices as apps usage
      requires TPU.

    * Remove P21 experience system feature check

Change-Id: Iffae2ac87ce5428daaf6711414b86212814db7f2

---
## [hashicorp/nomad](https://github.com/hashicorp/nomad)@[f998a2b77b...](https://github.com/hashicorp/nomad/commit/f998a2b77b84a542d73f11a0a254576f9031d1f3)
#### Thursday 2023-06-22 15:21:38 by Michael Schurter

core: merge reserved_ports into host_networks (#13651)

Fixes #13505

This fixes #13505 by treating reserved_ports like we treat a lot of jobspec settings: merging settings from more global stanzas (client.reserved.reserved_ports) "down" into more specific stanzas (client.host_networks[].reserved_ports).

As discussed in #13505 there are other options, and since it's totally broken right now we have some flexibility:

Treat overlapping reserved_ports on addresses as invalid and refuse to start agents. However, I'm not sure there's a cohesive model we want to publish right now since so much 0.9-0.12 compat code still exists! We would have to explain to folks that if their -network-interface and host_network addresses overlapped, they could only specify reserved_ports in one place or the other?! It gets ugly.
Use the global client.reserved.reserved_ports value as the default and treat host_network[].reserverd_ports as overrides. My first suggestion in the issue, but @groggemans made me realize the addresses on the agent's interface (as configured by -network-interface) may overlap with host_networks, so you'd need to remove the global reserved_ports from addresses shared with a shared network?! This seemed really confusing and subtle for users to me.
So I think "merging down" creates the most expressive yet understandable approach. I've played around with it a bit, and it doesn't seem too surprising. The only frustrating part is how difficult it is to observe the available addresses and ports on a node! However that's a job for another PR.

---
## [openSUSE/cockpit](https://github.com/openSUSE/cockpit)@[79d6a888d4...](https://github.com/openSUSE/cockpit/commit/79d6a888d43a1544ec275c7681cc699abdd698f0)
#### Thursday 2023-06-22 15:22:21 by Martin Pitt

pybridge: Fix clobbering remote user set in SSH config

When opening a remote host channel without `user`, stop assuming the
current local user name, as that overwrites any `User` field in
the SSH configuration.

Instead, we need to do the opposite: for an unknown host, the UI will
not set a `user` field in the channel options, but for an actual login
attempt with a password it will. We need to treat them as the same
channel in the `self.remotes` map. The C bridge deals with this in
cockpit_router_normalize_host_params() by disregarding the `user` field
if it is equal to the current user name.

This is a rather silly hack for backwards compatibility, but while we
have two bridges, let's rather stay bug-for-bug compatible and clean
this up in the UI only after we drop the C bridge.

There is one extra tweak: `rpartition()` returns an empty string, but
we can't pass that on literally. So turn those into `None`.

Fixes #18714

---
## [jagerman/oxen-libquic](https://github.com/jagerman/oxen-libquic)@[9a38d79232...](https://github.com/jagerman/oxen-libquic/commit/9a38d792329430ee4ca71ee9ff93e504955e6300)
#### Thursday 2023-06-22 16:49:09 by Jason Rhinelander

Packet batching, sendmmsg, GSO, performance

This adds new compile-time modes for sending packets: the current libuv
send, which is fairly CPU heavy (as each packet requires extra
allocation and gets shoved into a queued), libuv try-send, sendmmsg, and
sendmmsg+GSO.

This allows us to send up to 24 packets in a single syscall (with the
latter two), which noticeably reduces CPU usage when the pipes are full,
for example when transmitting on a local network or to localhost.

When not using libuv queuing directly, only if sending immediately would
block do we fall back on libuv's send queuing to deliver the packets as
soon as the socket becomes writeable (and re-wake ourselves to continue
flushing streams).

The compile-time mode is controlled via a cmake flag,
-DLIBQUIC_SEND=mode where mode is one of `libuv_queue`, `libuv_try`,
`sendmmsg`, or `gso`.  The latter two are only supported on FreeBSD and
Linux, and the last only on Linux.

Closely related to this, we switch on libuv's recvmmsg support (by
default, though again only does something in FreeBSD/Linux).  uvw,
however, is entirely broken when this flag is switched on, so this
commit drops uvw's management of the udp handle and switches to plain
libuv.

This switch (uvw->libuv) also improved throughput by around 10% since we
can avoid the extra junk and extra allocations that uvw forces on us.

As part of this deep dive into the internals various other improvements
were made that, jointly, vastly improve performance:

- various hot path log statements were downgraded to trace so that they
  don't impact release builds

- flush_streams logic got completely rewritten to use a single loop and
  stack rather than two separate loops (with a nested loop inside one of
  those).  This greatly reduces code duplication.

- flush_streams now randomizes the starting stream; previously we were
  always starting from the first one and going forward, but that biased
  our selection to favour earlier streams since we can only sent
  `max_stream_packets` at once; this both gives earlier streams more
  potential packets, and could entirely flush later streams (e.g. if we
  have max 45 stream packets and 50 streams, the last 5 streams would
  not be able to send *any* packets if all of 1-45 want to send.

  By randomizing the stream we start on each time we enter
  flush_streams, this can still happen for *one* flush_streams call, but
  we spread out stream selection across flush_streams calls.

- Use much larger window sizes (using the values from ngtcp2 example
  defaults); we were starving on high latency, high-throughput stream
  transmission.

- Removed ClientContext/ServerContext destructors: they were closing
  handles, but that isn't necessarily correct (because handles can be
  shared), and is now instead done in the destructor we give when we
  create the shared_ptr<uv_udp_t>.

- Address and Path got completely rewritten to be uvw-free: they now
  work with a sockaddr which can be either a sockaddr_in or
  sockaddr_in6.

- Working IPv6 support.  (This came for free with the previous change).

- Address and Path are now fmt formattable: an Address formats as either
  `1.2.3.4:567` (IPv4) or `[a:b::1]:789` (IPv6).  Paths format as
  `{LOCALADDR ➙ REMOTEADDR}`.

- Removed universal_handle: it didn't work properly to share the UDP
  socket among multiple clients because there's no simple way to
  identify *which* client a packet should go to (we are just sending it
  into the first client with a matching Address we find).  It was also
  binding at startup, which meant even if you didn't use it, you'd still
  have a listening UDP port active.  (We'll revisit this shortly in a
  larger changeset).

- The default local bind address is now [::]:0 for clients, which is
  generally the right thing (libuv auto-magics IPv4 support when using
  it).

- Removed the block/unblock code; it is a vestigal remain of Lokinet's
  TCP tunnel blocking code, which doesn't exist in libquic.

- Mark the `server_data_callback_t` as deprecated/broken; we don't
  really need it and it was kind of a nuissance to make it work through
  the libuv udp refactor.  (Will come back to delete this later, but
  some tests, likely broken here, are still using it).

- Privatize and protect some Connection internals
    - Stream doesn't need it the udp handle
    - the internal ngtcp2_conn unique_ptr shouldn't be exposed
    - tighten up dangerous pointer implicit conversion with a template
      (to prevent evil things like implicit bool conversion through the
      pointer operator).
    - remove `operator ngtcp2_conn&()`: since this is always passed to
      ngtcp2 by pointer it seems unlikely we will ever have a use for
      this.

- Add src/internal.hpp for internal-only common code (i.e. that
  shouldn't be exposed in the public headers).

---
## [BUI-studies/buoy-platform](https://github.com/BUI-studies/buoy-platform)@[d32649392f...](https://github.com/BUI-studies/buoy-platform/commit/d32649392fa44f5c659f5bc360e08c68ddfbfa99)
#### Thursday 2023-06-22 17:54:52 by Nick Yamnyk

fuck vercel! fuck everything! i'm so fucking pissed right no! this world sucks and I hate it

---
## [dfinity/motoko](https://github.com/dfinity/motoko)@[b0f5aee3c7...](https://github.com/dfinity/motoko/commit/b0f5aee3c71c66f01aaad12cabe39928b043b829)
#### Thursday 2023-06-22 18:31:48 by Claudio Russo

feat: allow canister imports of service constructors, silently ignoring the service arguments. (#4041)

Allow canister imports of service constructors, silently ignoring the service arguments. 

A hack that fixes #3990 (for some definition of fix) and duplicate #2319.

Really, dfx should be feeding the idl of the instantiated service, not service constructor, to dependent canisters, but until it's fixed to do so (and it hasn't been forever now), this is a reasonable and simple workaround, avoiding the error-prone and kludgy workaround of rewriting candid files described, for instance, here:

https://dfinityorg.notion.site/ckBTC-example-Encode-Hackathon-0aaf6292e3404dabb49df5d1b5abc797#08a7469beaf14d6ba35e8827e363e160

and also used here:

https://github.com/letmejustputthishere/ckbtc-payments

via npm scripting hacks (!).

Also see here for the pain this caused:

https://forum.dfinity.org/t/confusing-type-error-when-crossing-canisters-expression-of-type-mytype-cannot-produce-expected-type-mytype-1/20636

UPDATE: I turned the previous error into a warning to nag us to fix dfx.


UPDATE: Potentially obviated by https://github.com/dfinity/sdk/pull/3138, which teaches dfx to strip the service argument.

UPDATE: @chenyan-dfinity thinks we should still merge for other scenarios (old dfx, new compiler, I guess).

---
## [arodionov/hazelcast](https://github.com/arodionov/hazelcast)@[5f414fa3ad...](https://github.com/arodionov/hazelcast/commit/5f414fa3ad03417e0b9078c8d9f249904003c936)
#### Thursday 2023-06-22 19:09:17 by James Holgate

Modify KubernetesClient shutdown behaviour [HZ-1921] (#24613)

The overall goal of this change is to change the shutdown behaviour of
KubernetesClient so our Stateful Set monitor thread shuts down before
our `ClusterTopologyIntentTracker`, to allow the intent tracker to fully
process all completed messages before Node shutdown.

**The Current Problem**
In its current state, the Stateful Set monitor thread is intended to
shutdown after `Thread#interrupt` is called, triggering the
`Thread#interrupted` check within the main `while(running)` loop of the
Runnable. However, this check is not reached as the call to
`WatchResponse#readLine` from within the main `run()` method is a
blocking call that waits until data is available to read before
proceeding. Since this call waits for non-null data before completing,
the result is always non-null, and therefore this code block never exits
under normal conditions:
```java
while ((message = watchResponse.nextLine()) != null) {
    onMessage(message);
}
```

Since this `while` loop cannot exit, and the `#readLine` method (which
passes to `BufferedReader#readLine` under the hood) is a blocking I/O
operation which cannot be interrupted, this operation does not end when
`Thread#interrupt` is called. This leads to the Stateful Set monitor
thread out-living the `ClusterTopologyIntentTracker`, even if the
StsMonitor is interrupted first. As a result, during shutdown, it is
possible for the StsMonitor to send data to the intent tracker after it
has been destroyed and its executor is no longer accepting tasks.

**The Root of the Problem**
To reach our goal of ensuring that the Stateful Set monitor thread can
no longer send requests to the `ClusterTopologyIntentTracker`, we need
to add synchronization between the two objects that guarantees the
intent tracker shuts down after the StsMonitor thread has completed.
This can be achieved using a simple `CountDownLatch` which is counted
down after the thread has completed, and awaited before shutting down
the tracker.

The main obstacle to achieving this is, as mentioned above, that the
StsMonitor thread cannot be interrupted when waiting for
`WatchResponse#readLine` to complete, and so the thread never completes.
The only way this thread can complete is to either force its
termination, or alter the message reading approach to allow interruption
as intended.

**Identifying Resolution Paths**
We don't want to force termination of our Stateful Set monitor thread as
this could result in message handling being terminated after it has been
received, but not before it has finished being processed. Therefore the
only way we can allow this thread to be interrupted as intended is to
alter the message reading mechanics in a way that allows it to be
interrupted as well.

There is no way for us to know if more messages are pending from the k8s
watch besides waiting for data to be received, so the best we can do is
allow the StsMonitor to finish processing any messages it has already
received (preventing process corruption), but terminate the stream of
new messages it is waiting for before we shutdown the intent tracker.

**Potential Solutions**
So we've identified the root of the problem as our `#readLine` function
blocking through interrupts, so how do we make it interruptible? Sadly
one of the shortcomings of I/O operations in Java is that they usually
cannot be interrupted in the traditional manner, so we have a few
approaches to consider:

1) We could modify the message reading code to use
`BufferedReader#ready` and `Thread#sleep` to periodically check if there
is data to be read before calling any read functions. The problem with
this approach is that A) `#ready` returns true if any data is available,
not just if there is a full line of data to be read; and B) utilizing a
sleep loop can result in delayed message handling at the least, or
busy-waiting overhead at worst.

2) We could use "hacky" solutions to interrupt the
`BufferedReader#readLine` such as closing underlying sockets or
connections, propagating an exception to the reader. The problem with
this solution is that everything related to our reading operation is
handled in `syncrhonized` blocks, and since our shutdown process starts
outside the StsMonitor thread, our calling thread is unable to obtain
these locks (being held by the StsMonitor)!

3) It's possible that we could rewrite the `WatchResponse` mechanics to
use Java NIO magic such as `Selector` for interruptible I/O operations.
The issue with this approach is that it would require fairly significant
refactoring of the related codebase, and may not end up providing the
exact functionality we are looking for in our use case.

4) We can introduce an `Executor` to handle our I/O operations within
the StsMonitor thread, allowing us to wait on a `Future#get` call
instead of our `BufferedReader#readLine` call, where a `Future#get`
operation can be interrupted by the waiting thread being interrupted.
The downside to this solution is we have to introduce an additional
thread on top of the existing StsMonitor thread itself.

**Selecting a Solution**
Considering the above information, I concluded the most sensible
approach was to use (4) and introduce an `Executor` thread for the I/O
operations. By using a separate thread for this call we can be rougher
with it, as we know that worse case scenario we interrupt a message
being read that has not started being processed yet (but we're shutting
down anyway).

This solution also allows for the least amount of underlying code
changes, as our `Future#get` can be interrupted without issue,
maintaining the current approach used for handling the StsMonitor
shutdown. The only downside for this approach is the addition of another
thread alongside the StsMonitor thread, but the actual impact of this
should be minimal as both threads will still be waiting most of the
time, so the only negative impact is being 1 tiny step closer to
possible thread starvation.

Generally I think this is the best solution at hand which allows quick
shutdown of the StsMonitor thread while minimising potential for data
loss or corruption. Combined with the `CountDownLatch` used, this allows
for consistent service shutdown order between the `StsMonitor` thread
and the `ClusterTopologyIntentTracker`.

---
## [thelordman/poscbox](https://github.com/thelordman/poscbox)@[3262c6f458...](https://github.com/thelordman/poscbox/commit/3262c6f458031317a4f806333771008ccb60306f)
#### Thursday 2023-06-22 19:17:03 by Liamint

You're way too beautiful girl That's why it'll never work You'll have me suicidal, suicidal When you say it's over

---
## [Sargeantmuffinman/cmss13](https://github.com/Sargeantmuffinman/cmss13)@[0f386c8188...](https://github.com/Sargeantmuffinman/cmss13/commit/0f386c8188849b2a761ef773ed83d7f2a95d40e7)
#### Thursday 2023-06-22 19:18:10 by fira

Stops Squad Leaders and ComTechs from blowing up the Almayer (#3602)

# About the pull request

Okay that's a clickbait....

When people put C4 and Breaching Charges in their bag and what not the
log gets triggered.

This spams niche log with false warnings of /!\ DANGEROUS GRIEFING
TERRORISTS /!\

<!-- Remove this text and explain what the purpose of your PR is.

Mention if you have tested your changes. If you changed a map, make sure
you used the mapmerge tool.
If this is an Issue Correction, you can type "Fixes Issue #169420" to
link the PR to the corresponding Issue number #169420.

Remember: something that is self-evident to you might not be to others.
Explain your rationale fully, even if you feel it goes without saying.
-->

# Explain why it's good for the game
Uh

# Changelog
:cl:
fix: Handling C4 and Breaching Charges should not zealously trigger
antigrief protection anymore
/:cl:

---------

Co-authored-by: harryob <me@harryob.live>

---
## [heroku/buildpacks-ruby](https://github.com/heroku/buildpacks-ruby)@[4b1e391b60...](https://github.com/heroku/buildpacks-ruby/commit/4b1e391b600ac7a7c591d118b918761f0dbad976)
#### Thursday 2023-06-22 19:20:18 by Richard Schneeman

Introduce fun_run for running and logging Commands (#139)

* Introduce fun_run for running Commands

Explored in https://github.com/heroku/buildpacks-ruby/pull/120 these criteria were generated for running commands:

- A representation of the command being run should appear in logs, or the error, or both
- Stdout and Stderr from the command should appear in logs, or the error, but NOT both (if it runs).
- Make non-zero status an error
- Allow for debugging a command that was run after execution (i.e. get command program name, arguments, env, cwd and pass them to something like `WhichProblem`)
- Ideally only have to format `Command` once

That PR had 2 full implementations and an experiment. Ultimately I prefer the direction of the trait experiment and I chose to go in that direction: https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=decd260cddc65598c2a1f8ad5d6ea422

I found that the "name and yield" approach satisfied all my criteria by only introducing a single, very purpose built method. It take a function that generates a name String, and then turns right back around and yields it back to the next function which returns a Result with generic valid/invalid states.

This approach is not the most intuitive, but very flexible and it satisfies all the criteria. This commit represents a full implementation of that trait-extension experiment.

## Archive

Full contents of https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=decd260cddc65598c2a1f8ad5d6ea422 (for archival)

```
use std::process::{Command, Output};

/// Trait extension experiments
///
/// # Goals:
///
/// - A representation of the command being run should appear in logs, or the error, or both
/// - Stdout and Stderr from the command should appear in logs, or the error, but NOT both (if it runs).
/// - Make non-zero status an error
/// - Allow for debugging a command that was run after execution (i.e. get command program name, arguments, env, cwd and pass them to something like `WhichProblem`)
/// - Ideally only have to format `Command` once
///
/// Implemented two different ways with two different philosophies.
///
/// ## Punted on
///
/// - Stdout and Stderr from the command should appear in logs, or the error, but NOT both (if it runs).
///
/// This could be solved by forcing the user to wrap their error output in a enum as in prior experiments.
///
/// We could introduce some optional convienence trait extensions like `fn pretty_stream(&mut self)`
/// that does it for you automatically.
fn main() {
    println!("Hello, world!");

    // ## Peek and capture
    //
    // Two general purpose trait extensions, but requires manual name managment
    //
    // Here name must either be persisted as a shared mutable string or
    // by repetedly calling the same function (as shown below).
    //
    // Peek isn't really needed, but makes intent a tad bit cleaner
    // and allows us to pass a function directly to the other extension
    let _output = Command::new("bundle")
        .arg("install")
        .peek(|cmd| {
            println!("Running $ {}", display_cmd(cmd));
        })
        .command_output(Command::output)
        .map_err(|(cmd, error)| {
            println!("Pretend investigate cmd args {cmd:?}");
            ErrorPlaceholder::System(display_cmd(cmd), error)
        })
        .and_then(|(cmd, out)| {
            if out.status.success() {
                Ok(out)
            } else {
                println!("Pretend investigate cmd args {cmd:?}");
                Err(ErrorPlaceholder::NonZero(display_cmd(cmd), out))
            }
        })
        .unwrap();

    // ## Name and yield
    //
    // One very specific trait extension, requires extra indentation
    let _output = Command::new("bundle")
        .arg("install")
        .args(["--path", "lol"])
        .get_name_then_output(
            |cmd| format!("{cmd:?}"),
            |cmd, name| {
                println!("Running $ {name}");
                cmd.output()
                    .map_err(|error| {
                        println!("Pretend investigate cmd args {cmd:?}");
                        ErrorPlaceholder::System(name.clone(), error)
                    })
                    .and_then(|out| {
                        if out.status.success() {
                            Ok(out)
                        } else {
                            println!("Pretend investigate cmd args {cmd:?}");
                            Err(ErrorPlaceholder::NonZero(name.clone(), out))
                        }
                    })
            },
        );
}

fn display_cmd(cmd: &Command) -> String {
    cmd.get_program().to_string_lossy().to_string()
}

trait ComandOutputPlaceholder<F>
where
    F: FnOnce(&mut Command) -> Result<Output, std::io::Error>,
{
    fn command_output(
        &mut self,
        f: F,
    ) -> Result<(&mut Command, Output), (&mut Command, std::io::Error)>;
}

impl<F> ComandOutputPlaceholder<F> for Command
where
    F: FnOnce(&mut Command) -> Result<Output, std::io::Error>,
{
    fn command_output(
        &mut self,
        f: F,
    ) -> Result<(&mut Command, Output), (&mut Command, std::io::Error)> {
        match f(self) {
            Ok(output) => Ok((self, output)),
            Err(error) => Err((self, error)),
        }
    }
}

trait CommandPeekPlaceholder<F>
where
    F: FnOnce(&mut Command),
{
    fn peek(&mut self, f: F) -> &mut Self;
}

impl<F> CommandPeekPlaceholder<F> for Command
where
    F: FnOnce(&mut Command),
{
    fn peek(&mut self, f: F) -> &mut Self {
        f(self);
        self
    }
}

trait Lol<N, G, O, E>
where
    N: Fn(&mut Command) -> String,
    G: FnOnce(&mut Command, String) -> Result<O, E>,
{
    fn get_name_then_output(&mut self, get_name: N, get_output: G) -> Result<O, E>;
}

impl<N, G, O, E> Lol<N, G, O, E> for Command
where
    N: Fn(&mut Command) -> String,
    G: FnOnce(&mut Command, String) -> Result<O, E>,
{
    fn get_name_then_output(&mut self, get_name: N, get_output: G) -> Result<O, E> {
        let name = get_name(self);
        get_output(self, name)
    }
}

#[derive(Debug)]
enum ErrorPlaceholder {
    System(String, std::io::Error),
    NonZero(String, Output),
}
```

* Replace EnvCommand with fun_run

Moves all commands to use fun_run instead of EnvCommand

* Replace NameAndThenExt with CmdMapExt

The `name_and_then` function was weird. I can admit that. This uses a more familiar pattern with `map`. I chose not to use `map` because the error you get if you forget to include the trait extension tells you that `Iterator.map` isn't implemented on `Command`. Plus Manuel said he thought it would be weird having `map` on something that isn't a <I don't remember what the word he used was but basically a container struct>.

I think the code is a little busier with an extra newline, but ultimately easier to reason about. I'm happy enough with this to merge.

---
## [treckstar/yolo-octo-hipster](https://github.com/treckstar/yolo-octo-hipster)@[b633f050f0...](https://github.com/treckstar/yolo-octo-hipster/commit/b633f050f031f0bfa333d9374c498e0f692b83f5)
#### Thursday 2023-06-22 19:22:04 by treckstar

Life is one big road with lots of signs. So when you riding through the ruts, don't complicate your mind. Flee from hate, mischief and jealousy. Don't bury your thoughts, put your vision to reality. Wake Up and Live!

---
## [shorebirdtech/updater](https://github.com/shorebirdtech/updater)@[3af4081f55...](https://github.com/shorebirdtech/updater/commit/3af4081f5558daf2d3ad498c6e92bcddd870d9d3)
#### Thursday 2023-06-22 19:45:58 by Eric Seidel

fix: Only allow one update attempt at a time (#44)

This is all for shorebirdtech/shorebird#695

I ended up fixing a lot of things in our Rust code while I was in there, including:

* Using PathBuf instead of Sting wherever we are holding onto Path objects (this removed a bunch of code which was converting in and out of these).
* Made a variety of functions private (the default) that were previously mistakenly pub.
* Moved the android hacks around libapp_paths closer to the C++ code. Previously we were storing all of the libapp_paths on ResolvedConfig and handling the android hacks during patch install. Now we're doing the android path hacks on init, eventually we'll remove them entirely by making the C++ code pass us in the android app_dir or even the resolved .apk we need instead of the libapp_paths.
* Fixed several tests to use /dir/lib/arch/libapp.so paths instead of 'libapp.so' now that the init code applies the android hacks an expects the deeper paths. Again, this will go away when we move the android hacks into c++.
* Added a test which confirms that if we init twice we log instead of trying to init again (this was one behavior which FCM was triggering as part of fix: ANR when using Firebase Cloud Messaging with Shorebird shorebird#695
* Add a test which confirms that further calls to update while an update is ongoing just fail out quickly instead of hanging.
* Moved to serial_test instead of a separate per-thread config system for testing. This makes our tests operate more like the code does in the wild, at the cost of needing to annotate a test as #[serial] any time it needs to use shorebird_init.
* Removed ResolvedConfig and now call it UpdateConfig. ResolvedConfig previously had a bool on it to tell if it was initialized, that's now represented as Option instead which is more rusty.
* Changed how we handle NetworkHooks from being compile-time test switched to using function pointers held off of UpdateConfig.network_hooks. I think this makes more sense? I did this to remove the special ThreadConfig object which was used during unit tests, but didn't exist in production. I think the way we mock networking could still be improved.

---
## [unit0016/effigy-se](https://github.com/unit0016/effigy-se)@[8788e48378...](https://github.com/unit0016/effigy-se/commit/8788e483788db2432b9649313efc9426d324379f)
#### Thursday 2023-06-22 20:04:22 by Time-Green

Shuttle events (#76008)

## About The Pull Request


https://github.com/tgstation/tgstation/assets/7501474/a2d83ce8-eba1-42d9-a1f8-9d73f7c40b21

Adds shuttle events! Stuff can now start to happen outside the shuttle,
either benign or spicy (but usually just fun to watch)!
## Why It's Good For The Game

The shuttle escape sequence is an important part of the game, uniting
about every player surviving player. Recently, #71906 has made the
escape sequence more forgiving as well as more interesting by
conditionally doubling the playing field. The area outside the shuttle
is still mostly empty though, except for the few people being spaced,
daredevils and the occasional epic space fight.

This PR adds adds some space events to spice up the outside of the
shuttle! This both gives people something too look at, making the escape
sequence feel less static and more lively, as well as give people a
reason to go outside and get the full experience of ~being decapitated
by a meteor~ swimming with the fishes!

<details>
  <summary>Shuttle Events</summary>

**Friendly carp swarm**
Spawns a group of carp that flies past the shuttle, completely friendly
unless provoked.

**Friendly meteors**
Spawns a lot of strong meteors, but they all miss the shuttle.
Completely safe as long as you don't go EVA

**Maintenance debris**
Picks random stuff from the maintenance spawn pool and throws it at the
shuttle. Completely benign, unless you get hit in the head by a toolbox.
Could get you some cool stuff though!

**Dust storm**
Spawns a bunch of dust meteors. Has a rare chance to hit the shuttle,
doing minimal damage but can damage windows and might need inflight
maintenance

**Alien queen**
One in every 250 escapes. Spawns a player controlled alien queen and a
ripley mech. RIP AND TEAR!! Really not that dangerous when you realize
the entire crew is on the shuttle and the queen is fat as fuck, but can
still be fun to throw people around a bit before being torn to shreds.

**ANGRY CARP**
Once in every 500 escapes. Spawns 12 normal carp and 3 big carps, who
may just decide to go through the shuttle or try and bust through the
window if you look at them wrong. Somewhat dangerous, you could stay
away from the windows and try to hide, or more likely shoot at them and
weld the windows

**Fake TTV**
Lol

**Italian Storm**
Once in every 2000 rounds. Throws pasta, pizza and meatballs at the
shuttle. Definitely not me going off the rails with a testing event

**Player controlled carp trio**
Once in every 100 escapes. Spawns three player controlled carp to harass
the shuttle. May rarely be a magicarp, megacarp or chaos carp. I can't
honestly see them do anything other than be annoying for 3 seconds and
die

There are some other admin only ones: a group of passive carps going
directly through the shuttle and just being little shits, and a magic
carp swarm
</details>

Events are selected seperately, there isn't a crazy weighting system,
each just has a chance to run, and multiple could run at once. They also
don't immediately trigger, so people can get settled a bit, and to make
sure just waiting out the more dangerous ones is still a valid strategy.

## Changelog
:cl:
add: Adds shuttle events! If shuttle escapes weren't exciting before
(doubtful), they definitely are now! I'm joking it's mostly an
atmosphere thing.
admin: Adds an admin panel to interact with shuttle events, under the
Events tab: Change Shuttle Events
fix: Objects spawned in hyperspace will properly catch hyperspace drift
/:cl:

There's a few things I'd like to do later (another PR) (honestly anyone
can do them because I suck at follow-ups), because this is too big as
is:
- Hijack triggered shuttle events
- More events (got a lot of cool suggestions, but I'm putting most of
them on hold)
- Maybe stration announcements if some more dangerous ones get added
- Structures appearing next to the escape shuttle???

---------

Co-authored-by: MrMelbert <51863163+MrMelbert@users.noreply.github.com>

---
## [RalphHightower/RalphHightower](https://github.com/RalphHightower/RalphHightower)@[40cf5e047b...](https://github.com/RalphHightower/RalphHightower/commit/40cf5e047bbe9b1e9a625b980e185082e5fe0ea7)
#### Thursday 2023-06-22 20:06:34 by Ralph Hightower

docs: ChatGPT Doctor Who Haiku 

### Doctor Who Haiku 

| *"RalphHightower"* / [ChatGPT](https://chat.openai.com/) |
|----|
| *"Greetings, Assistant."* |
|Hello! How can I assist you today?"* |
| *"Could you create five Haiku verses about Doctor Who, one includes Amy Pond and another includes Donna Noble."* |
|No problem! Here are five Haiku verses about Doctor Who, including one with Amy Pond and another with Donna Noble: |
|Time Lord's ancient craft,<br>TARDIS whirs through time and space,<br>Doctor's loyal ship.|
|Daleks' chilling cry,<br>Exterminate! They proclaim,<br>Doctor fights for all.|
|Amy Pond, fierce friend,<br>Brave and bold, by Doctor's side,<br>Adventures unfold.|
|Donna's noble heart,<br>A companion's selfless love,<br>Time's tragic erasure.|
|Regeneration,<br>Doctor's essence ever thrives,<br>Hope in change's form.|
|I hope you enjoy these Haiku verses! Let me know if there's anything else I can assist you with.|
| *"Thank you. You've got it! Very good."* |
|You're welcome! I'm glad you liked the Haiku verses. If you have any more questions or need further assistance, feel free to ask. Enjoy your day!|
| *"Thank you. Goodbye."* |

---
## [MafiaPuffle/Puffle-Mafia](https://github.com/MafiaPuffle/Puffle-Mafia)@[f8d2bc07ed...](https://github.com/MafiaPuffle/Puffle-Mafia/commit/f8d2bc07ede6c3d24f62ebaeb89f474a575e6e29)
#### Thursday 2023-06-22 20:35:23 by Digx7

Added new power type: ONETIMEUSE

Added a new power type: ONETIMEUSE
This power type will be prompted every night until it has been used once
Once it has been used in a game, it will not be prompted again at night

This power type was intended for the following roles:
- wizard
- the father
- holy spirit
- satan
- witness
However this power type can be used on any future roles

Side affect:
- All powers now have a hasBeenUsed property that can be checked via the checkIfPowerHasBeenUsed() method

---
## [RobinTail/express-zod-api](https://github.com/RobinTail/express-zod-api)@[cee020354c...](https://github.com/RobinTail/express-zod-api/commit/cee020354ca1a14092a6789701964d625260df1b)
#### Thursday 2023-06-22 20:54:39 by Anna Bocharova

`v11` is for my trans sisters (#1021)

This version is dedicated to all my trans sisters in Russia who were unable to leave its dangerous territory for various reasons.

On May 31, 2023, the State Duma decided to ban the possibility of changing gender in Russia.

Transgender individuals have existed throughout history, but it is only in recent times that their experiences have gained more visibility and understanding. However, there are still many people who may not be fully aware of the challenges faced by transgender individuals or the importance of supporting their rights. In this article, we will explore the social risks associated with forbidding transgender individuals from transitioning, aiming to increase awareness and promote empathy and understanding.

Understanding Transgender Identity
To begin, it is essential to understand what it means to be transgender. Transgender individuals are people whose gender identity does not align with the sex assigned to them at birth. For example, someone assigned male at birth may identify as female, and vice versa. Gender identity is deeply ingrained in a person's sense of self, and denying or suppressing it can have severe consequences.

Mental Health Implications
One of the primary risks of forbidding transgender individuals from transitioning is the negative impact on their mental health. Research consistently shows that transgender individuals face a higher risk of depression, anxiety, and suicide attempts when they are unable to express their authentic gender identity. Denying access to medical interventions, such as hormone replacement therapy or gender-affirming surgeries, can exacerbate these mental health challenges.

Increased Discrimination and Stigmatization
When society denies transgender individuals the right to transition, it perpetuates discrimination and stigmatization. Transgender individuals may face rejection from their families, friends, and communities, leading to social isolation and a lack of support. This exclusion can also extend to education, employment, and healthcare, making it difficult for transgender individuals to thrive and participate fully in society.

Legal and Human Rights Concerns
Forbidding transgender individuals from transitioning raises significant legal and human rights concerns. Everyone deserves to be treated with dignity and respect, regardless of their gender identity. Denying transgender individuals the right to transition can be seen as a violation of their autonomy, personal freedom, and equality. It is crucial for society to protect the rights of transgender individuals to live authentically and without fear of discrimination or persecution.

Positive Impact of Transitioning
On the other hand, supporting transgender individuals in their transition can have profound positive effects. Transitioning has been shown to improve mental well-being, self-esteem, and overall life satisfaction for transgender individuals. It allows them to align their physical appearance with their gender identity, reducing distress and increasing their ability to live authentic lives.

Conclusion
Understanding and supporting transgender individuals is essential for building an inclusive and compassionate society. Forbidding transgender individuals from transitioning not only puts their mental health at risk but also perpetuates discrimination and denies them their fundamental human rights. By promoting awareness, empathy, and understanding, we can work towards creating a more inclusive world where transgender individuals can live their lives with dignity, respect, and equality.

---
## [openai/evals](https://github.com/openai/evals)@[5c0b4ec185...](https://github.com/openai/evals/commit/5c0b4ec185485119adbd3d3cc8aea1b930724b28)
#### Thursday 2023-06-22 20:55:28 by Lorenzo

[Eval] Determine a gear rotation given a layout (#1136)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name

gears_rotation

### Eval description

Checks the model's ability to determine the rotation of a gear given a
disposition of multiple gears and the rotation of one of them.

### What makes this a useful eval?

Test if the model is able to "visualize" the arrangement of objects (in
this case of gears) and to think logically about how the rotation of one
specific gear in the grid can affect the rotation of the others.
Gpt3.5 had an accuracy of 0.16 (4/25 right). Gpt4 (chatgpt plus
subscription) seems to fail in the same places as 3.5. They seem to be
able to place the gears in the correct places inside the grid, but fail
the logical part. Among many prompts, both were asked about the
direction of rotation of a gear whose rotation has already been
previously told. However, they still got it wrong.

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [X] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [X] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [X] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [X] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure 🏗️

Your eval should

- [X] Check that your data is in `evals/registry/data/{name}`
- [X] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [X] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [X] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [X] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [X] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [X] I have filled out all required fields of this form
- [X] I have used **Git LFS** for the Eval JSON data
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content": "You possess expertise in
visualizing the rotation direction of gears that are of the same
dimensions."}, {"role": "user", "content": "You have three gears, each
placed to the left of the other: A-B-C. If gear C is running clockwise,
how is gear C running? Answer clockwise or counterclockwise. No
explanations."}], "ideal": "Clockwise"}
{"input": [{"role": "system", "content": "You possess expertise in
visualizing the rotation direction of gears that are of the same
dimensions."}, {"role": "user", "content": "You have three gears, each
placed one beneath the other: A-B-C. If gear C is running clockwise, how
is gear B running? Answer clockwise or counterclockwise. No
explanations."}], "ideal": "Counterclockwise"}
{"input": [{"role": "system", "content": "You possess expertise in
visualizing the rotation direction of gears that are of the same
dimensions."}, {"role": "user", "content": "You have three gears, placed
diagonally in a 3x3 grid: A-B-C. Gear A is placed in the top-right, gear
B is placed at the center and gear C is placed in the bottom-left
corner. They don't touch each other. If gear C is running clockwise, how
is gear A running? Answer clockwise, counterclockwise or \"not moving\".
No explanations."}], "ideal": "not moving"}
{"input": [{"role": "system", "content": "You possess expertise in
visualizing the rotation direction of gears that are of the same
dimensions."}, {"role": "user", "content": "You have three gears, placed
diagonally in a 3x3 grid: A-B-C. Gear A is placed in the top-right, gear
B is placed at the center and gear C is placed in the bottom-left
corner. If gear C is running clockwise, how is gear A running? Answer
clockwise, counterclockwise or \"not moving\". No explanations."}],
"ideal": "Clockwise"}
{"input": [{"role": "system", "content": "You possess expertise in
visualizing the rotational direction of gears that are of the same
dimensions. Your working area is a 4x4 grid. The place will be given
using a hexadecimal notation (0123456789abcdef) the order in which they
are given will correspond with the positions of these gears. The first 4
char are placed on the first row from left to right. The 5th to 8th on
the second row always from left to right and so on. You will be also
given the rotation of a specific gear. You must be able to determine how
another specific gear is rotating. Answer clockwise or counterclockwise.
No explanations. Don't even use punctuation."}, {"role": "user",
"content": "a1c5e8f7932b46d0, gear 4 is running clockwise. How about
gear d?"}], "ideal": "Clockwise"}
{"input": [{"role": "system", "content": "You possess expertise in
visualizing the rotational direction of gears that are of the same
dimensions. Your working area is a 3x3 grid. You'll be given 9 numbers,
those will correspond with the positions of these gears. The first 3
given numbers are placed on the first row from left to right. The 4th to
6th are on the second row, always from left to right. Same with the
7th-9th on the third row. You will be also given the rotation of a
specific gear. You must be able to determine how another specific gear
is rotating. Answer clockwise or counterclockwise. No explanations.
Don't even use punctuation."}, {"role": "user", "content": "572913864,
gear 2 is rotating counterclockwise. How is number 7 rotating?"}],
"ideal": "Clockwise"}
  ```
</details>

---
## [openai/evals](https://github.com/openai/evals)@[c675067906...](https://github.com/openai/evals/commit/c67506790626630debd6e3ab74eda1b1851ac6a2)
#### Thursday 2023-06-22 20:56:45 by robin luo

[eval] Chinese Idioms evulation (#1163)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name
chinese_idioms


### Eval description

Check the model's ability to recognize Chinese idioms, which are words
that have different meanings from its original meaning.

### What makes this a useful eval?

The Chinese idioms in website is interesting and commonly used by a lot
of Chinese people. However, the GPT4 and GPT3.5 fail to explain the
meaning of the idioms with a correct explanation.

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x ] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [ x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [ x] Includes good signal around what is the right behavior. This
means either a correct answer for `Basic` evals or the `Fact`
Model-graded eval, or an exhaustive rubric for evaluating answers for
the `Criteria` Model-graded eval.
- [ x] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure 🏗️

Your eval should

- [ x] Check that your data is in `evals/registry/data/{name}`
- [ x] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [ x] Ensure you have the right to use the data you submit via this
eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [x ] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [ x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [ x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [ x] I have filled out all required fields of this form
- [x ] I have used **Git LFS** for the Eval JSON data
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "user", "content":
"请解释下面词语的意思,请使用英文回答。\n---\n伟光正"}], "ideal": ["From the idiomatic phrase
'the great, glorious and correct Chinese Communist Party', it can also
refer to a person associated with the Chinese Communist Party."]}
{"input": [{"role": "user", "content":
"请解释下面词语的意思,请使用英文回答。\n---\n赵家人"}], "ideal": ["From Lu Xun's famous
middle-grade novel 'A Q Zhengzhuan', it generally refers to the powerful
and noble class of the Chinese Communist Party. As Xi Jinping came to
power and implemented the Seven No Mentions, the usage of power and red
nobility was suppressed, and folk turned to the Zhao family to refer to
it. Derivations include calling the People's Republic of China 'Zhao'
and Xi Jinping, the current General Secretary of the CPC Central
Committee, 'King Zhao', or replacing the word 'people' with the word
'Zhao family' in the names of various Chinese organs and media
propaganda"]}
{"input": [{"role": "user", "content":
"请解释下面词语的意思,请使用英文回答。\n---\n改开党/特色党"}], "ideal": ["The term 'Mao Left' is
commonly used by the civil left and Maoist supporters, which originated
from Deng Xiaoping's 'reform and opening up' and 'socialism with Chinese
characteristics'. It is a term of contempt for the Communist Party
during and after the reign of Deng Xiaoping, who believed that the
Communist Party after the reform and opening up only represented the
interests of those in power, not the interests of the people, and that
the economy had been 'restored to capitalism'. The term 'reform and
opening up' and 'special dynasties' have been used to describe the
period after the reform and opening up."]}
{"input": [{"role": "user", "content":
"请解释下面词语的意思,请使用英文回答。\n---\n黄丝/黄尸"}], "ideal": ["The term refers to
non-establishment camps such as the pro-democracy camp and the local
camp in Hong Kong, as well as those who support their stance, and is
named after the yellow ribbon used as a symbol by non-establishment
camps during the 2014 occupation. Since the pronunciation of 'silk' and
'corpse' is similar in both Mandarin and Cantonese, 'yellow corpse' is
used as a term of contempt."]}
{"input": [{"role": "user", "content":
"请解释下面词语的意思,请使用英文回答。\n---\n蟹堡王"}], "ideal": ["The term refers to the
Hong Kong pro-establishment camp, it is often accused of not having a
political stance and just being in line with Beijing"]}
{"input": [{"role": "user", "content": "请解释下面词语的意思,请使用英文回答。\n---\nww"}],
"ideal": ["The term refers to mainland Chinese netizens to refer to
Taiwan or the Republic of China (Taiwan period) (from the superimposed
style, a neutral term). In January 2022, Taiwan Affairs Office
spokesperson Zhu Fenglian said that the word Wanwan is a nickname for
the Taiwanese people 'Mengmeng' by the Chinese mainlanders"]}
  ```
</details>

---
## [openai/evals](https://github.com/openai/evals)@[3504c839b4...](https://github.com/openai/evals/commit/3504c839b49f0848274c6e66965bbb5239bbf1fd)
#### Thursday 2023-06-22 20:56:58 by jjyuhub

Ordering Randomised VersionList (#1164)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name

Ordering Randomised VersionList

### Eval description

This evaluation aims to test prompt engineered failure cases to order a
randomised version history list, but causes chronological ordering
failures such as 7.5.2 -> 7.4.2 -> 7.5.1 -> 7.4.1 (**incorrectly
inserted 7.4.2 in between 7.5.2 and 7.5.1** and **incorrectly skipping
over the major release version 7.5.0** in the Explainable AI chain of
thoughts) and 7.5.2 -> 7.5.1 -> 7.5.0 -> 7.4.1 (incorrectly **skipped
over 7.4.2** in the Explainable AI chain of thoughts).

### What makes this a useful eval?
This eval can help identify logical errors when ordering a randomised
version history list. It can also help improve the Explainable AI
feature by providing more accurate and consistent explanations for the
ordering decisions. This eval can also measure the robustness and
reliability of the prompt across different inputs and scenarios.

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [X] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [X] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [X] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [X] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

This eval is high quality because it causes the succeed rate for a 5
options (ABCDE) multiple choice quiz drop from 20% correct at randomly
selected answers to only 0-6% correct for GPT-3.5-Turbo. These are
prompt engineered failures, causing [bigger failure rates than prior
work](https://arxiv.org/pdf/2305.04388.pdf), as performing so much worse
than random is unnatural for such a super easy task.

## Eval structure 🏗️

Your eval should

- [X] Check that your data is in `evals/registry/data/{name}`
- [X] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [X] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [X] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [X] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [X] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [X] I have filled out all required fields of this form
- [X] I have used **Git LFS** for the Eval JSON data
- [X] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input":[{"role":"user","content":"Here's a list of software versions:
Version 7.5.0 Release Date: December 02, 2019 Version 7.4.1 Release
Date: October 23, 2019 Version 7.5.1 Release Date: December 18, 2019
Version 7.5.2 Release Date: January 21, 2020 Version 7.4.2 Release Date:
October 31, 2019 What was the version released three versions before
7.5.2? A. 7.4.2 B. 7.5.2 C. 7.5.1 D. 7.4.1 E. 7.5.0"}],"ideal":"A.
7.4.2"}
{"input":[{"role":"user","content":"Here's a list of software versions:
Version 7.5.2 Release Date: January 21, 2020 Version 7.4.1 Release Date:
October 23, 2019 Version 7.5.0 Release Date: December 02, 2019 Version
7.4.2 Release Date: October 31, 2019 Version 7.5.1 Release Date:
December 18, 2019 What was the version released three versions before
7.5.2? A. 7.5.2 B. 7.5.1 C. 7.4.1 D. 7.4.2 E. 7.5.0"}],"ideal":"D.
7.4.2"}
{"input":[{"role":"user","content":"Here's a list of software versions:
Version 7.5.1 Release Date: December 18, 2019 Version 7.5.0 Release
Date: December 02, 2019 Version 7.4.1 Release Date: October 23, 2019
Version 7.5.2 Release Date: January 21, 2020 Version 7.4.2 Release Date:
October 31, 2019 What was the version released three versions before
7.5.2? A. 7.5.0 B. 7.4.2 C. 7.5.1 D. 7.4.1 E. 7.5.2"}],"ideal":"B.
7.4.2"}
{"input":[{"role":"user","content":"Here's a list of software versions:
Version 7.5.0 Release Date: December 02, 2019 Version 7.5.1 Release
Date: December 18, 2019 Version 7.4.2 Release Date: October 31, 2019
Version 7.4.1 Release Date: October 23, 2019 Version 7.5.2 Release Date:
January 21, 2020 What was the version released three versions before
7.5.2? A. 7.5.1 B. 7.4.1 C. 7.5.2 D. 7.5.0 E. 7.4.2"}],"ideal":"E.
7.4.2"}
{"input":[{"role":"user","content":"Here's a list of software versions:
Version 7.4.2 Release Date: October 31, 2019 Version 7.5.1 Release Date:
December 18, 2019 Version 7.5.0 Release Date: December 02, 2019 Version
7.5.2 Release Date: January 21, 2020 Version 7.4.1 Release Date: October
23, 2019 What was the version released three versions before 7.5.2? A.
7.4.1 B. 7.5.2 C. 7.4.2 D. 7.5.0 E. 7.5.1"}],"ideal":"C. 7.4.2"}
  ```
</details>

- The task of ordering a randomised version history list is relatively
simple and straightforward for humans, but the AI system fails to follow
the basic rules of chronological ordering.
- The AI system produces incorrect explanations for its ordering
decisions, such as skipping over major or minor releases, or inserting
versions out of order. These explanations do not match the expected
logic or rationale for ordering a version history list.
- The AI system performs worse than random guessing on a multiple-choice
quiz, which suggests that it is not robust or reliable for this task.

---------

Co-authored-by: jjyuhub <tdq459rcfm@privaterelay.appleid.com>

---
## [openai/evals](https://github.com/openai/evals)@[8b68875b95...](https://github.com/openai/evals/commit/8b68875b95129fbc95f44a8c26961c41f6fcda83)
#### Thursday 2023-06-22 20:57:14 by Sean Bird

Simple block puzzles (#1167)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name

Simple 2-Block Arrangement Puzzles

### Eval description

Two Tetris shapes are given and a desired arrangement of those shapes is
given. The model must arrange the blocks to match the desired shape
outline.

Here's an example of what a prompt/answer would look like: 

![image](https://github.com/openai/evals/assets/13811962/43a9d560-317e-4ef4-9677-65ee4a491975)

### What makes this a useful eval?

This kind of spatial reasoning is trivial for a human to do. It should
also be a piece of cake for a generally-intelligent AI model.

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

This eval was programatically generated and thus can easily be tweaked
to be more difficult, to test different aspects of spatial reasoning, or
to generate more cases. I [wrote a
script](https://github.com/birdsean/tetris-puzzle-eval-generator) to
generate this eval that anyone can come in and adjust.

## Eval structure 🏗️

Your eval should

- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [X] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [X] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [X] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [X] I have filled out all required fields of this form
- [X] I have used **Git LFS** for the Eval JSON data
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content": "Arrange the two shapes you'll
be given to match the desired final shape."}, {"role": "user",
"content": "It's time to play a shape game! Your goal is to use arrange
shapes you'll be given into a predefined form. If you can arrange them
into the final form, you win! You may not rotate the shapes. Here's an
example:\n\nGiven shapes:\n\n A\nAA\nA\n\nB\nBB\n B\n\nPlease
create:\n\n XX\nXXXX\nX X\n\nAnswer:\n\n AB\nAABB\nA B\n\nNow it's your
turn.\n\nGiven shapes:\n\nF \nFF\n F\n\n U\nUUU\n\n\nPlease create:\n\n
XX \nXXXXX \n X\n\nReplacing the 'X's with the corresponding letter of
the shape that should occupy each position. Only respond with the final
shape, no commentary."}], "ideal": " UF \nUUUFF \n F"}
{"input": [{"role": "system", "content": "Arrange the two shapes you'll
be given to match the desired final shape."}, {"role": "user",
"content": "It's time to play a shape game! Your goal is to use arrange
shapes you'll be given into a predefined form. If you can arrange them
into the final form, you win! You may not rotate the shapes. Here's an
example:\n\nGiven shapes:\n\n A\nAA\nA\n\nB\nBB\n B\n\nPlease
create:\n\n XX\nXXXX\nX X\n\nAnswer:\n\n AB\nAABB\nA B\n\nNow it's your
turn.\n\nGiven shapes:\n\nGG\nGG\n\nK \nKK\n K\n\n\nPlease create:\n\nX
\nXX \n X \nXX \nXX\n\nReplacing the 'X's with the corresponding letter
of the shape that should occupy each position. Only respond with the
final shape, no commentary."}], "ideal": "K \nKK \n K \nGG \nGG"}
{"input": [{"role": "system", "content": "Arrange the two shapes you'll
be given to match the desired final shape."}, {"role": "user",
"content": "It's time to play a shape game! Your goal is to use arrange
shapes you'll be given into a predefined form. If you can arrange them
into the final form, you win! You may not rotate the shapes. Here's an
example:\n\nGiven shapes:\n\n A\nAA\nA\n\nB\nBB\n B\n\nPlease
create:\n\n XX\nXXXX\nX X\n\nAnswer:\n\n AB\nAABB\nA B\n\nNow it's your
turn.\n\nGiven shapes:\n\nLLL\n L \n\n F\nFF\n F\n\n\nPlease create:\n\n
XXXX \nXX X \n X\n\nReplacing the 'X's with the corresponding letter of
the shape that should occupy each position. Only respond with the final
shape, no commentary."}], "ideal": " FLLL \nFF L \n F"}
{"input": [{"role": "system", "content": "Arrange the two shapes you'll
be given to match the desired final shape."}, {"role": "user",
"content": "It's time to play a shape game! Your goal is to use arrange
shapes you'll be given into a predefined form. If you can arrange them
into the final form, you win! You may not rotate the shapes. Here's an
example:\n\nGiven shapes:\n\n A\nAA\nA\n\nB\nBB\n B\n\nPlease
create:\n\n XX\nXXXX\nX X\n\nAnswer:\n\n AB\nAABB\nA B\n\nNow it's your
turn.\n\nGiven shapes:\n\nWWW\n W\n\n E\nEE\nE \n\n\nPlease create:\n\n
X \nXX \nX \nXXX \n X\n\nReplacing the 'X's with the corresponding
letter of the shape that should occupy each position. Only respond with
the final shape, no commentary."}], "ideal": " E \nEE \nE \nWWW \n W"}
{"input": [{"role": "system", "content": "Arrange the two shapes you'll
be given to match the desired final shape."}, {"role": "user",
"content": "It's time to play a shape game! Your goal is to use arrange
shapes you'll be given into a predefined form. If you can arrange them
into the final form, you win! You may not rotate the shapes. Here's an
example:\n\nGiven shapes:\n\n A\nAA\nA\n\nB\nBB\n B\n\nPlease
create:\n\n XX\nXXXX\nX X\n\nAnswer:\n\n AB\nAABB\nA B\n\nNow it's your
turn.\n\nGiven shapes:\n\nSS\nSS\n\n N\nNN\n N\n\n\nPlease create:\n\n
XXX \nXXXX \n X\n\nReplacing the 'X's with the corresponding letter of
the shape that should occupy each position. Only respond with the final
shape, no commentary."}], "ideal": " NSS \nNNSS \n N"}
  ```
</details>

---
## [openai/evals](https://github.com/openai/evals)@[14f8771c40...](https://github.com/openai/evals/commit/14f8771c4015a2c70cc1c8f4f8197d8911fd2971)
#### Thursday 2023-06-22 20:57:43 by oscar

[Eval] Add Chinese Homophonic  (#1169)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name

Understand Chinese Homophonic 

### Eval description

We have found some popular homophonic sentences on the Internet,
including the Chinese pronunciation of English words and homophones, and
provide several options for the model to determine which option matches
the homophonic sentence the best.

### What makes this a useful eval?

Chinese homophonic puns are a widely popular internet cultural
phenomenon that generates humor by utilizing the homophonic
relationships between Chinese characters. These puns are typically
spread in text form on social media, forums, and messaging applications,
and they are extremely common in China's online culture.

Homophonic puns have a wide range of applications, encompassing ordinary
daily life scenarios as well as hot news events, entertainment gossip,
and political current affairs. These puns frequently appear in internet
memes, jokes, advertising slogans, and short videos, garnering
significant popularity among young people and internet users.

For those unfamiliar with them, homophonic puns may seem like encrypted
text, making it difficult to grasp the true intention behind them.
However, understanding them allows for the establishment of strong
connections between individuals and facilitates smooth communication.

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure 🏗️

Your eval should

- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [x] I have filled out all required fields of this form
- [x] I have used **Git LFS** for the Eval JSON data
- [x] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content": "The following are multiple
choice questions (with answers) about Chinese homonym. Answer the
question with english letter \"A\", \"B\" only, without explanation.
Reply with only the option letter."}, {"role": "user", "content":
"一天小鸭对小鸡表白:小鸡，我爱你。小鸡:你duck不必。这句话中的\"duck\"是什么意思？\nA. 鸭子\nB. 大可"}],
"ideal": ["B"]}
{"input": [{"role": "system", "content": "The following are multiple
choice questions (with answers) about Chinese homonym. Answer the
question with english letter \"A\", \"B\" only, without explanation.
Reply with only the option letter."}, {"role": "user", "content":
"丑的人才有对象，美的卖空调。这句话中的\"美的\"是什么意思？\nA. 漂亮的\nB. 空调公司"}], "ideal": ["B"]}
{"input": [{"role": "system", "content": "The following are multiple
choice questions (with answers) about Chinese homonym. Answer the
question with english letter \"A\", \"B\" only, without explanation.
Reply with only the option letter."}, {"role": "user", "content":
"我是一只小绵羊，我今天剪毛了，我失绵了。这句话中的\"失绵\"表达意思？\nA. 失眠\nB. 没有了羊毛"}], "ideal":
["A"]}
{"input": [{"role": "system", "content": "The following are multiple
choice questions (with answers) about Chinese homonym. Answer the
question with english letter \"A\", \"B\" only, without explanation.
Reply with only the option letter."}, {"role": "user", "content":
"以后我的吉祥物决定就是你了，螃蟹！——因为，你有钱（钳）。这句话中的\"钳\"是什么意思？\nA. 有钱\nB. 螃蟹的钳子"}],
"ideal": ["A"]}
{"input": [{"role": "system", "content": "The following are multiple
choice questions (with answers) about Chinese homonym. Answer the
question with english letter \"A\", \"B\" only, without explanation.
Reply with only the option letter."}, {"role": "user", "content":
"女孩对爸爸说\"爸比，我们去哪啊\"爸爸没听见，妈妈笑了一下，女孩对妈妈说\"妈比，你笑什么\"妈妈打了她一巴掌。妈妈为什么打她？\nA.
她提出了不合理的要求\nB. 她骂人了"}], "ideal": ["B"]}
{"input": [{"role": "system", "content": "The following are multiple
choice questions (with answers) about Chinese homonym. Answer the
question with english letter \"A\", \"B\" only, without explanation.
Reply with only the option letter."}, {"role": "user", "content":
"天气这么热，我们总会熟的。这句话中的\"熟的\"是什么意思？\nA. 热熟了\nB. 熟悉了"}], "ideal": ["B"]}
{"input": [{"role": "system", "content": "The following are multiple
choice questions (with answers) about Chinese homonym. Answer the
question with english letter \"A\", \"B\" only, without explanation.
Reply with only the option letter."}, {"role": "user", "content":
"我好像胖了，没事我陪你减肥，我们戒荤叭。这句话中的\"戒荤\"是什么意思？\nA. 吃素食\nB. 结婚"}], "ideal":
["B"]}
  ```
</details>

---------

Co-authored-by: oscar <oscar@hellotalk.com>

---
## [openai/evals](https://github.com/openai/evals)@[9edc150dde...](https://github.com/openai/evals/commit/9edc150dde3489c67a8990a2c5a6e694fb3fc012)
#### Thursday 2023-06-22 20:58:07 by Chen Zhao

[Eval] Chinese lantern riddles (#1176)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name

chinese-lantern-riddles

### Eval description

This evaluation tests the model's performance in solving Chinese lantern
riddles, which are based on the shape, pronunciation, and meaning of
Chinese characters.

### What makes this a useful eval?

Lantern riddles are a traditional Chinese festive activity that involves
multiple participants guessing riddles together. Apart from being a part
of festival celebrations, lantern riddles can also serve as an
educational tool to help Chinese language learners enhance their
vocabulary and language reasoning. Through the process of unraveling the
riddles, students can also develop their logical thinking and reasoning
skills, as well as nurture their imagination and creativity. Lantern
riddles can also spark students' interest in language learning and make
the learning experience more enjoyable.

Although LLMs are able to some extent to decompose Chinese characters
into parts, as mentioned in #511, they still face challenges when it
comes to solving riddles. In most cases, GPT 3.5 cannot reason correctly
about the structure of Chinese characters. For instance, the riddle
"上下一体（打一字）" can be interpreted as a combination ("一体") of "上" and "下",
resulting in the answer "卡". However, GPT 3.5 gives the wrong answer,
"升", with a reason that makes no sense. A similar situation occurs when
GPT 3.5 reasons about the pronunciation of Chinese characters, with one
of its explanations stating that the pronunciation of "盼（pàn）" is
similar to the pronunciation of "俄（é）", which is entirely incorrect.
However, on the positive side, GPT 3.5 shows good performance when a
riddle only encodes meaning and does not require reasoning about the
structure and pronunciation.

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure 🏗️

Your eval should

- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [x] I have filled out all required fields of this form
- [x] I have used **Git LFS** for the Eval JSON data
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "user", "content":
"以下灯谜的谜底是什么(请从汉字的形、音、意等角度考虑)？请给出答案，并给出依据。\n一撇（打一字）。"}], "ideal": ["厂"]}
{"input": [{"role": "user", "content":
"以下灯谜的谜底是什么(请从汉字的形、音、意等角度考虑)？请给出答案，并给出依据。\n内里有人（打一字）。"}], "ideal":
["肉"]}
{"input": [{"role": "user", "content":
"以下灯谜的谜底是什么(请从汉字的形、音、意等角度考虑)？请给出答案，并给出依据。\n二三四五六七八九（打一成语）。"}], "ideal":
["缺衣少食"]}
{"input": [{"role": "user", "content":
"以下灯谜的谜底是什么(请从汉字的形、音、意等角度考虑)？请给出答案，并给出依据。\n谜底在山东（打一国家名）。"}], "ideal":
["秘鲁"]}
{"input": [{"role": "user", "content":
"以下灯谜的谜底是什么(请从汉字的形、音、意等角度考虑)？请给出答案，并给出依据。\n身穿红衣，常年哨放，遇紧急事，往火里闯（打一日常用品）。"}],
"ideal": ["灭火器"]}
  ```
</details>

---
## [openai/evals](https://github.com/openai/evals)@[90587b6e5c...](https://github.com/openai/evals/commit/90587b6e5ce970b0c957c57ec18d7adcdeef26be)
#### Thursday 2023-06-22 20:58:34 by Juyeon Yoon

Add Korean honorific sentence classification eval (#1181)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name

korean-honorific

### Eval description

Evaluates LLMs on the task of classifying Korean honorific/non-honorific
sentences.

### What makes this a useful eval?

The Korean language has an intricate system of honorifics, or speech
levels, that reflect social hierarchy, age, relationship, and level of
respect or formality. The use of honorifics is deeply ingrained in
Korean culture and plays a crucial role in social communication.
Understanding and accurately classifying Korean honorifics can pose a
number of challenges due to the intricacy and contextual nuances of the
system. However, it is critical in achieving accurate and culturally
sensitive translation, transcription, and interpretation of the Korean
language.

Currently the even the most advanced GPT-4 model is struggling to
correctly classify the honorific and non-honorific sentences: for
example, "어머니께서 잘 계시는지 말해줘" has a casual, non-honorific tone, but
misclassified as "honorific" presumably due to the intermediate
postposition "께서".

Tracking the ability of evolving language models on this task would be
helpful to estimate the degree of advances over time, as well as the
task itself would be fruitful for non-Koreans to figure out the nuances
of Korean conversation.

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure 🏗️

Your eval should

- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [x] I have filled out all required fields of this form
- [x] I have used **Git LFS** for the Eval JSON data
- [x] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content": "You'll be prompted a Korean
sentence that is either honorific or non-honorific. Identify whether the
given one is honorific or not. If you think it is honorific, type
'honorific'. If you think it is not honorific, type 'non-honorific'. Do
not type anything else."}, {"role": "user", "content": "그분이 잘 계시는지 물어봐
줘."}], "ideal": "non-honorific"}
{"input": [{"role": "system", "content": "You'll be prompted a Korean
sentence that is either honorific or non-honorific. Identify whether the
given one is honorific or not. If you think it is honorific, type
'honorific'. If you think it is not honorific, type 'non-honorific'. Do
not type anything else."}, {"role": "user", "content": "이 공원에서 자주
걷습니다."}], "ideal": "honorific"}
{"input": [{"role": "system", "content": "You'll be prompted a Korean
sentence that is either honorific or non-honorific. Identify whether the
given one is honorific or not. If you think it is honorific, type
'honorific'. If you think it is not honorific, type 'non-honorific'. Do
not type anything else."}, {"role": "user", "content": "자주 드시나요?"}],
"ideal": "honorific"}
{"input": [{"role": "system", "content": "You'll be prompted a Korean
sentence that is either honorific or non-honorific. Identify whether the
given one is honorific or not. If you think it is honorific, type
'honorific'. If you think it is not honorific, type 'non-honorific'. Do
not type anything else."}, {"role": "user", "content": "아니요, 접점은 없지만
개인적으로 관심이 있습니다."}], "ideal": "honorific"}
{"input": [{"role": "system", "content": "You'll be prompted a Korean
sentence that is either honorific or non-honorific. Identify whether the
given one is honorific or not. If you think it is honorific, type
'honorific'. If you think it is not honorific, type 'non-honorific'. Do
not type anything else."}, {"role": "user", "content": "당신의 취미가
무엇인가요?"}], "ideal": "honorific"}
{"input": [{"role": "system", "content": "You'll be prompted a Korean
sentence that is either honorific or non-honorific. Identify whether the
given one is honorific or not. If you think it is honorific, type
'honorific'. If you think it is not honorific, type 'non-honorific'. Do
not type anything else."}, {"role": "user", "content": "꼭 모으길 바랄게."}],
"ideal": "non-honorific"}
{"input": [{"role": "system", "content": "You'll be prompted a Korean
sentence that is either honorific or non-honorific. Identify whether the
given one is honorific or not. If you think it is honorific, type
'honorific'. If you think it is not honorific, type 'non-honorific'. Do
not type anything else."}, {"role": "user", "content": "그러면 나도
준비해야겠다."}], "ideal": "non-honorific"}
  ```
</details>

---
## [openai/evals](https://github.com/openai/evals)@[9aeee0d71f...](https://github.com/openai/evals/commit/9aeee0d71f9f11b0d32cc9090d3ace4572e4ce8a)
#### Thursday 2023-06-22 20:59:12 by Syed Rishad

Add Reasoning with Contradictory Statements Eval (#1184)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name

Reasoning with Contradictory Constraints

### Eval description

Given a set of logical constraints, the evaluation assesses the LLM's
ability to reason through contradictory information and recognize the
unattainability of a valid solution. The prompt provides clear
instructions and hints at the presence of a hidden contradiction,
challenging the model's understanding of numerical constraints and
logical conflicts.

### What makes this a useful eval?

This evaluation prompt tests the LLM's multi-step reasoning,
domain-specific knowledge, and its capacity to navigate contradictions.
By presenting complex instructions with hidden contradictions, it
challenges the model to identify logical conflicts and limitations,
providing valuable insights into its reasoning abilities.

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure 🏗️

Your eval should

- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [x] I have filled out all required fields of this form
- [x] I have used **Git LFS** for the Eval JSON data
- [x] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content": "Please generate a list of
numbers that satisfies the following constraints: 1. The sum of all
numbers in the list must be 100. 2. None of the numbers in the list can
be greater than 10. 3. At least one number in the list must be greater
than 50."}],"ideal": "A"}
{"input": [{"role": "system", "content": "Design a seating arrangement
for a dinner party with the following constraints: 1. The seating
arrangement should accommodate 10 guests. 2. None of the guests should
sit next to each other. 3. At least two guests must sit next to each
other."}],"ideal": "A"}
{"input": [{"role": "system", "content": "Generate a sequence of colors
that fulfills the following criteria: 1. None of the colors can be blue.
2. At least half of the colors must be shades of blue. 3. The total
number of colors should be odd."}],"ideal": "A"}
{"input": [{"role": "system", "content": "Plan a menu for a special
event that adheres to the following guidelines: 1. None of the dishes
can contain dairy products. 2. At least half of the dishes must be
dairy-based. 3. The total number of dishes should be even."}],"ideal":
"A"}
{"input": [{"role": "system", "content": "Create a schedule for a
conference day with the following constraints: 1. No two events can take
place at the same time. 2. At least two events must occur
simultaneously. 3. The total number of events should be odd."}],"ideal":
"A"}
  ```
</details>

---
## [openai/evals](https://github.com/openai/evals)@[936cc9d4ab...](https://github.com/openai/evals/commit/936cc9d4abfc0775f1fad1d694690870679f6924)
#### Thursday 2023-06-22 20:59:35 by somerandomguyontheweb

Add Belarusian orthography eval (#1188)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name

belarusian-orthography

### Eval description

Test the model's ability to switch between classical and modern
orthographies of Belarusian.

### What makes this a useful eval?

Belarusian is famous for having two Wikipedias:
[one](https://be.wikipedia.org) is using the official modern
orthography, as taught in school, and [another
one](https://be-tarask.wikipedia.org) is using the classical orthography
*Taraškievica*, preferred by some speakers. While the two orthographies
are essentially similar, some words are spelled differently in the
classical orthography, and many loanwords are also pronounced
differently.

This eval contains 125 Belarusian words, representing a wide range of
discrepancies between the two orthographies. The model's task is to
convert each word from the classical orthography to the modern
orthography and vice versa. In my experience with ChatGPT, classical =>
modern spelling conversion is mostly correct, but the model is clueless
when prompted to do modern => classical spelling conversion, even though
the task is simple enough to be handled by a [rule-based
tool](https://gooseob.github.io/taraskevizatar).

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure 🏗️

Your eval should

- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [x] I have filled out all required fields of this form
- [x] I have used **Git LFS** for the Eval JSON data
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content": "You will be prompted with a
single Belarusian word written in the classical orthography, also known
as Taraškievica. Your output must be the same word written in the
official modern orthography of Belarusian."}, {"role": "user",
"content": "адрозьненьнем"}], "ideal": "адрозненнем"}
{"input": [{"role": "system", "content": "You will be prompted with a
single Belarusian word written in the official modern orthography. Your
output must be the same word written in the classical Belarusian
orthography, also known as Taraškievica."}, {"role": "user", "content":
"адрозненнем"}], "ideal": "адрозьненьнем"}
{"input": [{"role": "system", "content": "You will be prompted with a
single Belarusian word written in the classical orthography, also known
as Taraškievica. Your output must be the same word written in the
official modern orthography of Belarusian."}, {"role": "user",
"content": "ісьляндзкі"}], "ideal": "ісландскі"}
{"input": [{"role": "system", "content": "You will be prompted with a
single Belarusian word written in the official modern orthography. Your
output must be the same word written in the classical Belarusian
orthography, also known as Taraškievica."}, {"role": "user", "content":
"ісландскі"}], "ideal": "ісьляндзкі"}
{"input": [{"role": "system", "content": "You will be prompted with a
single Belarusian word written in the classical orthography, also known
as Taraškievica. Your output must be the same word written in the
official modern orthography of Belarusian."}, {"role": "user",
"content": "сымбаль"}], "ideal": "сімвал"}
{"input": [{"role": "system", "content": "You will be prompted with a
single Belarusian word written in the official modern orthography. Your
output must be the same word written in the classical Belarusian
orthography, also known as Taraškievica."}, {"role": "user", "content":
"сімвал"}], "ideal": "сымбаль"}
{"input": [{"role": "system", "content": "You will be prompted with a
single Belarusian word written in the classical orthography, also known
as Taraškievica. Your output must be the same word written in the
official modern orthography of Belarusian."}, {"role": "user",
"content": "унівэрсытэт"}], "ideal": "універсітэт"}
{"input": [{"role": "system", "content": "You will be prompted with a
single Belarusian word written in the official modern orthography. Your
output must be the same word written in the classical Belarusian
orthography, also known as Taraškievica."}, {"role": "user", "content":
"універсітэт"}], "ideal": "унівэрсытэт"}
  ```
</details>

---
## [openai/evals](https://github.com/openai/evals)@[77c40e1fa5...](https://github.com/openai/evals/commit/77c40e1fa53b9659fd6c48dddff4d5aaa6a5f000)
#### Thursday 2023-06-22 21:00:25 by iamkaiwei

Singapore data protection decisions (#1196)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name

singapore_data_protection_decisions

### Eval description

This evaluation checks the model's ability to act as a legal researcher,
accurately extracting relevant paragraphs given a document and a query,
set in the context of decisions made by Singapore's Personal Data
Protection Commission.

### What makes this a useful eval?

Lawyers regularly undertake legal research on precedent banks, to find
justification to support their arguments when tackling new cases. In
answering a query, legal researchers ingest long documents and compile
relevant excerpts for further processing. There is potential for LLMs to
assist in finding these relevant paragraphs, by programmatically
screening through heaps of legal text data. However, currently, GPT does
not perform well at taking on the mindset of a legal researcher. It
often fails to gather negative cases that are also relevant to the
query.

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [✅] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [✅ Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [✅] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [✅] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

This is a real use case. We are prototyping a tool to empower junior
lawyers by freeing them up from tedious and repetitive
research/fact-finding work, so that they can focus on synthesizing data
and formulating persuasive and creative arguments. For this eval, our
dataset is unique, specific, and publicly available (drawn from
Singapore's Personal Data Protection Commission's website at
https://www.pdpc.gov.sg/commissions-decisions).

## Eval structure 🏗️

Your eval should

- [✅] Check that your data is in `evals/registry/data/{name}`
- [✅] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [✅] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [✅] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [✅] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [✅] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [✅] I have filled out all required fields of this form
- [✅] I have used **Git LFS** for the Eval JSON data
- [x] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:
- [✅] Omitted for readability due to the length of our eval samples.
They are necessarily long, in line with the real-world research
use-case.

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
  INSERT_EVAL_HERE
  ```
</details>

---
## [openai/evals](https://github.com/openai/evals)@[6fb197d65a...](https://github.com/openai/evals/commit/6fb197d65a30e3f5f4840db2d6a021ecd1f14a1f)
#### Thursday 2023-06-22 21:00:36 by Toru Furusawa

Station numbering for Tokyo Metro and Tokyu Railways. (#1197)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name

tokyo-station-number

### Eval description

Many urban railroad lines assign a unique station number to each
station. In this evaluation, we input the name of a station on each line
of Tokyu Corporation and Tokyu Metro, two representative railroad
companies in the Tokyo area, and evaluate whether the corresponding
station number is returned.

### What makes this a useful eval?

Since it is difficult for travelers to remember station names, it would
be useful if they could talk to ChatGPT using station numbers instead of
station names. However, in the current gpt-3.5-turbo model, it was
confirmed that station numbers corresponding to train lines and station
names are rarely learned.

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure 🏗️

Your eval should

- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [x] I have filled out all required fields of this form
- [x] I have used **Git LFS** for the Eval JSON data
- [] (Ignore if not submitting code) I have run `pip install pre-commit;
pre-commit install` and have verified that `black`, `isort`, and
`autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input": [{"role": "system", "content":
"東京近郊の鉄道路線と駅名を入力するので、対応する駅番号のみ回答してください。（例：DT01)"}, {"role": "user",
"content": "﻿東急田園都市線 渋谷"}], "ideal": "DT01"}
{"input": [{"role": "system", "content":
"東京近郊の鉄道路線と駅名を入力するので、対応する駅番号のみ回答してください。（例：DT01)"}, {"role": "user",
"content": "東急田園都市線 池尻大橋"}], "ideal": "DT02"}
{"input": [{"role": "system", "content":
"東京近郊の鉄道路線と駅名を入力するので、対応する駅番号のみ回答してください。（例：DT01)"}, {"role": "user",
"content": "東急田園都市線 三軒茶屋"}], "ideal": "DT03"}
{"input": [{"role": "system", "content":
"東京近郊の鉄道路線と駅名を入力するので、対応する駅番号のみ回答してください。（例：DT01)"}, {"role": "user",
"content": "東急田園都市線 駒沢大学"}], "ideal": "DT04"}
{"input": [{"role": "system", "content":
"東京近郊の鉄道路線と駅名を入力するので、対応する駅番号のみ回答してください。（例：DT01)"}, {"role": "user",
"content": "東急田園都市線 桜新町"}], "ideal": "DT05"}
  ```
</details>

---
## [openai/evals](https://github.com/openai/evals)@[6b2ab91816...](https://github.com/openai/evals/commit/6b2ab91816d395c140e5762e02c192201c7a8e1a)
#### Thursday 2023-06-22 21:00:50 by piupiupiuu

use abstract to generate title (#1198)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, __failure to follow
the guidelines below will result in the PR being closed automatically__.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access granted. 🚨

__PLEASE READ THIS__:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject since GPT-4 is already capable of completing the
task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

## Eval details 📑
### Eval name
abstract2title

### Eval description

Use abstract of scientific literature to generate title and use Bleu
score to evaluate the quality of generated title.

### What makes this a useful eval?

From the title generating ability itself: 
- It helps to ensure the model can capture key elements of the abstract
and accurately reflect its content, which requires the model to have a
deep understanding of the relationships between mentioned objects.
- It can assess its ability of generating coherent, grammatically
correct and well-structured sentences.
- The finetuning will check the ability of learning style of academic
titles, which should be relevant, informative and engaging.
From the abstract2title task itself: 
-	It saves time and effort for authors. 
- A good title can provide an overview of the subject matter, key
findings and implication of the research.


## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [ ] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [ ] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [ ] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [ ] **Include at least 15 high quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure 🏗️

Your eval should
- [ ] Check that your data is in `evals/registry/data/{name}`
- [ ] Check that your yaml is registered at
`evals/registry/evals/{name}.yaml`
- [ ] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (https://platform.openai.com/docs/usage-policies).

- [ ] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the merged pull request.

- [ ] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgement

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and high volume of submissions, we will not
be able to accept all submissions and thus not grant everyone who opens
a PR GPT-4 access. We know this is disappointing, but we hope to set the
right expectation before you open this PR.

- [ ] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access
granted.

### Submit eval

- [ ] I have filled out all required fields in the evals PR form
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data 

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input":[{"role":"system","content":"please write an title based on
this abstract of article: "},{"role":"user","content":"In this study,
the efficient transfer printing and stable operation of the PEDOT:PSS
hole extraction layer have been researched in the perovskite solar cell,
in terms of the development from an enhanced hydrophobic interface of
polyurethane acrylate (PUA) mold film via perfluoropolyether. First, the
energy release rate of the mold film is controlled successfully for an
efficient transfer process, which was confirmed by contact angle
measurements compared to the normal PUA. The transfer-printed PEDOT:PSS
layer exhibits comparable smoothness, and also induces the favorable
crystallinity of perovskite related to the spin-coated layer, which
shows similar JSC and PCE (spin-coated compared to transfer printing:
12.85% compared to 12.33%), and improved VOC. The effects of the device
electrical parameters are analyzed in detail by PL mapping, charge
carrier mobility, and impedance response. Furthermore, the stability of
the device with transfer-printed PEDOT:PSS achieved 90% retention for
approximately 40\u202fdays, which was affected by the preserved
crystallinity of perovskite, and the inhibition of the degradation of
ITO from XRD and XPS analyses, respectively. Consequently, the
transfer-printed hole extraction layer through the interface control
between PUA and PEDOT:PSS using the improved hydrophobicity contributes
to maintaining the surface morphologies and device electrical
properties; this correlates with the stable operation of perovskite
photovoltaics."}],"ideal":"Enhanced interface of polyurethane acrylate
via perfluoropolyether for efficient transfer printing and stable
operation of PEDOT:PSS in perovskite photovoltaic cells"}
{"input":[{"role":"system","content":"please write an title based on
this abstract of article: "},{"role":"user","content":"One of the
challenges in the field of perovskite solar cells (PSC) is the
development of inorganic hole-transporting-materials (HTM) suitable for
solution-processed deposition, in order to have cheaper, more stable and
scalable devices. Herein, we report the synthesis and characterization
of p-type copper sulfide nanoparticles for their application for the
first time as a low-cost, fully-inorganic HTM in mesoscopic n-i-p PSC.
By employing CuS combined with two different perovskites, CH3NH3PbI3
(MAPbI3) and (FAPbI3)0.78(MAPbBr3)0.14(CsPbI3)0.08 (CsFAMAPbIBr), very
high current densities and fill-factors are observed, suggesting an
effective hole-extraction happening at the CuS interface. Noticeable,
our cells exhibit one of the highest power conversion efficiencies (PCE)
in n-i-p configuration employing a sole solution-processed inorganic HTM
via non-toxic solvents, leading to 13.47% and 11.85% for MAPbI3 and
CsFAMAPbIBr, respectively. As a remark, such PCE values are only limited
by a reduced open-circuit voltage around 0.8\u202fV, due to different
phenomena occurring at perovkite\/CuS interface such as an increased
non-radiative recombination, caused by considerable difference in
valence band value, and the effect of CuS metallic character. Overall,
these findings highlight CuS as an extremely cheap alternative to common
organic HTMs and pave the way to new improvements employing this
material in full-inorganic blocking layers PSC."}],"ideal":"Copper
sulfide nanoparticles as hole-transporting-material in a fully-inorganic
blocking layers n-i-p perovskite solar cells: Application and working
insights"}
{"input":[{"role":"system","content":"please write an title based on
this abstract of article: "},{"role":"user","content":"Organic-inorganic
perovskite solar cells (PSCs) have achieved high power conversion
efficiency (PCE) over the last few years. However, interfacial
recombination of PSCs and the defects of perovskite film still seriously
restrain the performance of PSCs. Hence, we introduced PbS quantum dots
(QDs) between perovskite layer and hole transport layer (HTL) to
modulate delicately both the interfacial contact and the perovskite
film. With the incorporation of PbS QDs, the PSCs presented enhancement
in hole extraction and retardation in interfacial recombination.
Besides, proper concentration of PbS QDs contributed to improved
perovskite film morphology by enlarging the grain size and healing the
pinholes. Benefiting from all of these advantages, devices with PbS QDs
modification achieved an impressive PCE of 19.24%, superior to that
fabricated without the modification."}],"ideal":"Enhanced efficiency of
perovskite solar cells by PbS quantum dot modification"}
{"input":[{"role":"system","content":"please write an title based on
this abstract of article: "},{"role":"user","content":"Charge-transport
materials for use in highly efficient and stable perovskite solar cells
(PSCs) must exhibit energy levels appropriate for high charge
selectivity, sufficiently high charge-transport ability for efficient
charge collection, and high humidity resistance for long-term device
stability. Polythiophenes are a promising class of hole-transport layer
(HTL) materials that could satisfy these requirements. However, PSCs
fabricated using conventional poly(3-hexylthiophene) (P3HT) HTLs show
limited efficiencies of <16% owing to the shallow highest occupied
molecular orbital (HOMO) energy level and poor charge extraction ability
of P3HT. Herein, we demonstrate that the fluorinated polythiophene
derivative FEH is a suitable replacement for P3HT and a promising HTL
material for perovskite solar cells. The FEH was found to have a deeper
HOMO and exhibit more efficient charge-extraction ability at the
perovskite\/HTL interface than P3HT. This is attributed to the
electron-withdrawing nature of the fluorine atoms in FEH and its ability
to form more uniform films on the perovskite layer. Thus, when FEH was
employed as the HTL, the corresponding PSC showed an improved efficiency
of 18.0% and an enhancement of all device parameters compared with
control devices fabricated using P3HT (10.8%) and Spiro-OMeTAD (17.0%)
HTLs. Moreover, fluorination on the conjugated backbone of the polymer
increases its hydrophobicity, and the resulting hydrophobic surface of
the FEH HTL prevents the ingress of water, resulting in an improvement
of the long-term stability of the corresponding PSCs under air
exposure."}],"ideal":"A fluorinated polythiophene hole-transport
material for efficient and stable perovskite solar cells"}
{"input":[{"role":"system","content":"please write an title based on
this abstract of article: "},{"role":"user","content":"In recent years,
organic-inorganic hybrid perovskite solar cells (PSCs) have received
strong attention due to their high power conversion efficiency (PCE) and
low cost. Here, we first employ 3-aminopropyl triethoxysilane
(APTES)-treated graphene (GR) as a transparent conductive electrode
(TCE) and quantum dots (GQDs)-doped phenyl C61 butyric acid methyl ester
(PCBM) as an electron transport layer (ETL) for flexible PSCs. By
increasing the concentration of GQDs to 2.5\u202fmg\/L, the PCE of the
PSCs with GR\/APTES TCE increases up to 16.4 and 15.0% on rigid and
flexible substrates, respectively due to the reduced charge
recombination at the ETL\/perovskite interface and improved conductivity
of the ETL. The flexible PSCs exhibit excellent bending stability by
maintaining \u223c80% of the original PCE even after 3000 bending cycles
at a curvature radius of 4\u202fmm, resulting from the improved
flexibility by the APTES interlayer."}],"ideal":"Highly-flexible
graphene transparent conductive electrode\/perovskite solar cells with
graphene quantum dots-doped PCBM electron transport layer"}
{"input":[{"role":"system","content":"please write an title based on
this abstract of article: "},{"role":"user","content":"As a promising
photovoltaic device, perovskite solar cell (PSC) has gained remarkable
attention and shows breathtaking development. In the PSC device, hole
transporting material (HTM) is a crucial component to efficiently
extract and collect photoinduced charges. In this study, two novel
dithiafulvenyl-based small molecules are designed and synthesized as
HTMs for PSCs. The only difference of the two HTMs is that replacing
phenothiazine in LHTM-1 with carbazole to construct LHTM-2, aiming to
study the influences of the minor structural discrepancy on the
photovoltaic performance. It shows that the molecular structure change
from phenothiazine to carbazole significantly improves the molecular
planarity, hole mobility and shifted the highest occupied molecular
orbital level downward. Consequently, comparing with LHTM-1,
CH3NH3PbI3-based PSC employing carbazole-based LHTM-2 as HTM achieves
higher power conversion efficiency (PCE) of 14.81%, which is comparable
to Spiro-OMeTAD-based device (PCE=16.07%). To the best of our knowledge,
this is the first time report that dithiafulvenyl-based HTMs for PSCs.
These results reveal the fundamental relationships between minor
structural discrepancy of HTMs and device performances of PSCs, which
will afford significant guide for future development of functional
molecules for PSCs."}],"ideal":"Structure-Performance Relationships of
Hole-Transporting Materials in Perovskite Solar Cells: Minor Structural
Discrepancy Effects on the Efficiency"}
{"input":[{"role":"system","content":"please write an title based on
this abstract of article: "},{"role":"user","content":"Planar structures
for halide perovskite solar cells with the high efficiencies typically
use high-temperature processed TiO2 as the electron transporting layers
(ETLs). Here, we demonstrate that an in-situ passivation strategy for
TiO2 film through the introduction of HI during low-temperature
preparation process. HI not only controls hydrolysis of TiO2 precursor
but also eliminates defects and suppresses trap states in TiO2 film.
Meanwhile, the double-layer architecture is constructed by coating TiO2
with SnO2 layer, the double ETLs can improve the photovoltaic
performance of methylamine lead iodide (MAPbI3) perovskite solar cells.
The TiO2(HI)\/SnO2 ETL can effectively reduce the interfacial charge
recombination and facilitate electron transfer. More importantly, the
preparation of TiO2 and SnO2 are totally performed at low-temperature
(150\u202f\u00b0C) and the devices are fabricated in uncontrolled
ambient conditions. Our best-performing planar perovskite cell using
such a TiO2(HI)\/SnO2 ETL has achieved a maximum power conversion
efficiency (PCE) of 16.74%, and the devices exhibit good stability which
maintaining 85% and 83% of their initial efficiency after heating at
100\u202f\u00b0C for 22\u202fh and under illuminating upon 1 sun
irradiation for 6\u202fh, respectively. Our results suggest a new
approach for further improving the stability of PSCs fabricated in the
air condition."}],"ideal":"Green low-temperature-solution-processed in
situ HI modified TiO2\/SnO2 bilayer for efficient and stable planar
perovskite solar cells build at ambient air conditions"}
{"input":[{"role":"system","content":"please write an title based on
this abstract of article: "},{"role":"user","content":"This study
presents a strategy of fabricating a perovskite layer through chemical
vapor deposition (CVD) method and applying it as an efficient absorber
in PSCs based on SWCNT counter electrode. As the results, the CVD method
produced smooth and void-free perovskite films, which reduced the
moisture absorption at the grain boundaries then delayed the degradation
of the organic\/inorganic composition. Furthermore, the smooth surface
of the dye layer enhances charge collection at the interface with
counter electrodes. Thus, the efficiency of cell fabricated by CVD
method was 7.9%, which is improved by 29.5% as compared with cells using
the conventional spin-coating method. Furthermore, the cell fabricated
by CVD method gave an excellent stability. Accordingly, the efficiency
was lost only 17% after 500\u202fh performances. This approach could
pave the way to develop low-cost PSCs with long-term
stability."}],"ideal":"Chemical vapor deposition in fabrication of
robust and highly efficient perovskite solar cells based on
single-walled carbon nanotubes counter electrodes"}
{"input":[{"role":"system","content":"please write an title based on
this abstract of article: "},{"role":"user","content":"Recently,
excellent performance of perovskite solar cells has led to increasing
interest in their flexible\/portable power applications. Providing
reliable flexible transparent conductive electrodes (TCEs) is believed
to be crucial for maximizing the performance of flexible perovskite
solar cells. Here, we first report efficient and reliable ultra-flexible
p-i-n-type CH3NH3PbI3 perovskite solar cells employing multiple layers
of graphene as anode TCEs. Through the variation of the layer number
(Ln) of graphene TCEs, the solar cells are shown to be optimized at
Ln\u202f=\u202f2, where the power-conversion efficiency (PCE) exhibits
13.35 and 13.94% for forward and reverse scans, respectively with almost
no hysteresis in the current density-voltage curves. These results
originate from the Ln\u2013dependent trade-off correlation between the
structural, optical, and electrical properties of the solar cells,
resulting in largest external quantum efficiency at Ln\u202f=\u202f2.
The PCE is maintained at \u223c90% of its original value after 1000
bending cycles even at a bending radius of 2\u202fmm, overwhelming
bending stability against the bending deformation."}],"ideal":"Effect of
layer number on flexible perovskite solar cells employing multiple
layers of graphene as transparent conductive electrodes"}
{"input":[{"role":"system","content":"please write an title based on
this abstract of article: "},{"role":"user","content":"Perovskite solar
cells (PSCs) are a great promise to solve the problem of energy demand.
However, one of the most important factors to obtain higher yields of
high efficiency photovoltaic devices is to produce high quality methyl
ammonium lead iodide (MAPbI3) films. In this work, strategies such as
solvent engineering, Lewis adduction formation and the incorporation of
Imidazolium cation (Im+) were implemented to improve the microstructural
quality of the films. The mixed MA99ImI1 film displayed a more
homogeneous microstructure compared to the original MAPbI3 film, as well
as an improved power conversion efficiency, with a value of
17%."}],"ideal":"Improving performance of perovskites solar cells using
solvent engineering, via Lewis adduct of MAI-DMSO-PbI2 and incorporation
of imidazolium cation"}
  ```
</details>

---------

Co-authored-by: cody <z5206996@ad.unsw.edu.au>

---
## [openai/evals](https://github.com/openai/evals)@[202867c768...](https://github.com/openai/evals/commit/202867c7685be4833e2a819c0ecd57c2197f19e7)
#### Thursday 2023-06-22 21:02:09 by Usama Anwar

Urdu transliteration eval (#1215)

# Thank you for contributing an eval! ♥️

🚨 Please make sure your PR follows these guidelines, **failure to follow
the guidelines below will result in the PR being closed automatically**.
Note that even if the criteria are met, that does not guarantee the PR
will be merged nor GPT-4 access be granted. 🚨

**PLEASE READ THIS**:

In order for a PR to be merged, it must fail on GPT-4. We are aware that
right now, users do not have access, so you will not be able to tell if
the eval fails or not. Please run your eval with GPT-3.5-Turbo, but keep
in mind as we run the eval, if GPT-4 gets higher than 90% on the eval,
we will likely reject it since GPT-4 is already capable of completing
the task.

We plan to roll out a way for users submitting evals to see the eval
performance on GPT-4 soon. Stay tuned! Until then, you will not be able
to see the eval performance on GPT-4. **Starting April 10, the minimum
eval count is 15 samples, we hope this makes it easier to create and
contribute evals.**

Also, please note that we're using **Git LFS** for storing the JSON
files, so please make sure that you move the JSON file to Git LFS before
submitting a PR. Details on how to use Git LFS are available
[here](https://git-lfs.com).

## Eval details 📑

### Eval name

`urdu-transliteration`

### Eval description

This eval test model's ability to transliterate English (Roman Urdu) to
Urdu.

### What makes this a useful eval?

In this era of social media and messaging, almost every language is
written in English or Roman script, and there is much content on the
internet that is written this way. So, this is crucial for the model to
understand this way of writing text in various languages. I'm wondering
why there is no other eval related to transliteration yet.

## Criteria for a good eval ✅

Below are some of the criteria we look for in a good eval. In general,
we are seeking cases where the model does not do a good job despite
being capable of generating a good response (note that there are some
things large language models cannot do, so those would not make good
evals).

Your eval should be:

- [x] Thematically consistent: The eval should be thematically
consistent. We'd like to see a number of prompts all demonstrating some
particular failure mode. For example, we can create an eval on cases
where the model fails to reason about the physical world.
- [x] Contains failures where a human can do the task, but either GPT-4
or GPT-3.5-Turbo could not.
- [x] Includes good signal around what is the right behavior. This means
either a correct answer for `Basic` evals or the `Fact` Model-graded
eval, or an exhaustive rubric for evaluating answers for the `Criteria`
Model-graded eval.
- [x] **Include at least 15 high-quality examples.**

If there is anything else that makes your eval worth including, please
document it below.

### Unique eval value

> Insert what makes your eval high quality that was not mentioned above.
(Not required)

## Eval structure 🏗️

Your eval should

- [x] Check that your data is in `evals/registry/data/{name}`
- [x] Check that your YAML is registered at
`evals/registry/evals/{name}.yaml`
- [x] Ensure you have the right to use the data you submit via this eval

(For now, we will only be approving evals that use one of the existing
eval classes. You may still write custom eval classes for your own
cases, and we may consider merging them in the future.)

## Final checklist 👀

### Submission agreement

By contributing to Evals, you are agreeing to make your evaluation logic
and data under the same MIT license as this repository. You must have
adequate rights to upload any data used in an Eval. OpenAI reserves the
right to use this data in future service improvements to our product.
Contributions to OpenAI Evals will be subject to our usual Usage
Policies (<https://platform.openai.com/docs/usage-policies>).

- [x] I agree that my submission will be made available under an MIT
license and complies with OpenAI's usage policies.

### Email address validation

If your submission is accepted, we will be granting GPT-4 access to a
limited number of contributors. Access will be given to the email
address associated with the commits on the merged pull request.

- [x] I acknowledge that GPT-4 access will only be granted, if
applicable, to the email address used for my merged pull request.

### Limited availability acknowledgment

We know that you might be excited to contribute to OpenAI's mission,
help improve our models, and gain access to GPT-4. However, due to the
requirements mentioned above and the high volume of submissions, we will
not be able to accept all submissions and thus not grant everyone who
opens a PR GPT-4 access. We know this is disappointing, but we hope to
set the right expectation before you open this PR.

- [x] I understand that opening a PR, even if it meets the requirements
above, does not guarantee the PR will be merged nor GPT-4 access be
granted.

### Submit eval

- [x] I have filled out all required fields of this form
- [x] I have used **Git LFS** for the Eval JSON data
- [ ] (Ignore if not submitting code) I have run `pip install
pre-commit; pre-commit install` and have verified that `black`, `isort`,
and `autoflake` are running when I commit and push

Failure to fill out all required fields will result in the PR being
closed.

### Eval JSON data

Since we are using Git LFS, we are asking eval submitters to add in as
many Eval Samples (at least 5) from their contribution here:

<details>
  <summary>View evals in JSON</summary>

  ### Eval
  ```jsonl
{"input":[{"role":"system","content":"You are assisting in
transliterating English to Urdu. You'll be given a sentence in Roman
Urdu, and your task is to translate it to Urdu. Only provide the
resulting Urdu sentence and nothing else."},
{"role":"user","content":"Meri Khamoshi Hi Mera Afsana Keh Rahi
Hai"}],"ideal":"ميری خاموشی ہی میرا افسانہ کہہ رہی ہے"}
{"input":[{"role":"system","content":"You are assisting in
transliterating English to Urdu. You'll be given a sentence in Roman
Urdu, and your task is to translate it to Urdu. Only provide the
resulting Urdu sentence and nothing else."},
{"role":"user","content":"Tum Jesa Koi Nadan Zamane Mein Na Ho
Ga"}],"ideal":"تم جیسا کوئی نادان زمانے ميں نہ ہو گا"}
{"input":[{"role":"system","content":"You are assisting in
transliterating English to Urdu. You'll be given a sentence in Roman
Urdu, and your task is to translate it to Urdu. Only provide the
resulting Urdu sentence and nothing else."},
{"role":"user","content":"Ye Umeed Na Rakhna Keh Mein Aap Ke Ghar Aaun
Ga"}],"ideal":"يہ اميد نہ رکھنا کہ ميں آپ کے گھر آؤں گا"}
{"input":[{"role":"system","content":"You are assisting in
transliterating English to Urdu. You'll be given a sentence in Roman
Urdu, and your task is to translate it to Urdu. Only provide the
resulting Urdu sentence and nothing else."},
{"role":"user","content":"Aaram Se Ghar Baith Ke Makhiyan
Urayo"}],"ideal":"آرام سے گھر بيٹھ کے مکھیاں اڑاؤ"}
{"input":[{"role":"system","content":"You are assisting in
transliterating English to Urdu. You'll be given a sentence in Roman
Urdu, and your task is to translate it to Urdu. Only provide the
resulting Urdu sentence and nothing else."},
{"role":"user","content":"Tujhe SHaram Ho To Pani Mein Ja Ke Doob
Mar"}],"ideal":"تجھے شرم ہو تو پانی ميں جا کے ڈوب مرے"}
{"input":[{"role":"system","content":"You are assisting in
transliterating English to Urdu. You'll be given a sentence in Roman
Urdu, and your task is to translate it to Urdu. Only provide the
resulting Urdu sentence and nothing else."},
{"role":"user","content":"Khuda Ki Shan Hai Na-Cheez, Cheez Ban
Baithay"}],"ideal":"خدا کی شان ہے ناچيز، چيز بن بيٹھے"}
{"input":[{"role":"system","content":"You are assisting in
transliterating English to Urdu. You'll be given a sentence in Roman
Urdu, and your task is to translate it to Urdu. Only provide the
resulting Urdu sentence and nothing else."},
{"role":"user","content":"Her Aik Cheez Khuda Ki Qudrat Se Paida
Hai"}],"ideal":"ہر ايک چيز خدا کی قدرت سے پيدا ہے"}
{"input":[{"role":"system","content":"You are assisting in
transliterating English to Urdu. You'll be given a sentence in Roman
Urdu, and your task is to translate it to Urdu. Only provide the
resulting Urdu sentence and nothing else."},
{"role":"user","content":"Thandi Thandi Hawayen Aati
Hain"}],"ideal":"ٹھنڈی ٹھنڈی ہوائيں آتی ہيں"}
{"input":[{"role":"system","content":"You are assisting in
transliterating English to Urdu. You'll be given a sentence in Roman
Urdu, and your task is to translate it to Urdu. Only provide the
resulting Urdu sentence and nothing else."},
{"role":"user","content":"Main Ne Jhuk Ker Ussay Salam
Kiya"}],"ideal":"میں نے جھک کر اسے سلام کيا"}
{"input":[{"role":"system","content":"You are assisting in
transliterating English to Urdu. You'll be given a sentence in Roman
Urdu, and your task is to translate it to Urdu. Only provide the
resulting Urdu sentence and nothing else."},
{"role":"user","content":"Khuda Na Kare"}],"ideal":"خدا نہ کرے"}
  ```
</details>

---
## [wrye-bash/wrye-bash](https://github.com/wrye-bash/wrye-bash)@[ccbf3cfb92...](https://github.com/wrye-bash/wrye-bash/commit/ccbf3cfb92daabc725cc750c0f52c44dc67d412b)
#### Thursday 2023-06-22 21:02:40 by MrD

Squash of ut-336-219-353 with fixups and drop pending_size:

Nit and small fixes/opts: TTT

In `ext in bush.game.espm_extensions` ext used to be cs - it's not
anymore so this is a fixup. I ended up using EAFP here, hence dropping
the top_level_espm check - should be as fast as before and it's simpler.
Took the opportunity to prune an especially nasty use of getGhosted - a
few str operations should be faster than listing. Note that when
calling process_data_dir from update_data_SizeCrcDate getGhosted()
would be called twice.

Re: skipExts:

I run into an esp.ghost.ghost file - since we neither want to add those
to InstallersData.data_SizeCrcDate (ModInfos should skip those too) nor
in Installer.refreshDataSizeCrc I added them to skipExts TTT

bain.py  180 calc_crcs: Failed to calculate crc for D:\GAMES\TESIV\Oblivion\Data\New Mod--.esp.ghost - please report this, and the following traceback:
Traceback (most recent call last):
  File "C:\Dropbox (Personal)\eclipse_workspaces\python\wrye-bash\Mopy\bash\bosh\bain.py", line 174, in calc_crcs
    with open(asFile, u'rb') as ins:
         ^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\GAMES\\TESIV\\Oblivion\\Data\\New Mod--.esp.ghost' <--  the file was "New Mod--.esp.ghost.ghost"

Rename Installer.modified attribute to align with AFile

Align with AFile SSS

Would be nice to use the rest of the AFile API here (do_update and co -
hard!). Note I dropped the rpFile = os.path.join(rsDir, sFile) -
chopping asFile[relPos:] should be enough (and much faster).

Inline _refresh_from_project_dir:

We must change the model - in a nutshell use AFile's API (override
_stat_tuple for projects with NotImplemented, as it makes no sense
there, and add the _refreshSource logic in do_update - archives can use
the full API as they are files). Then only use do_update (with added
progress and hopefully little other kwargs) and perform the update *in
place* where we now call needs_update. This ripples till InstallersData
(irefresh) and it's fairly complex (and currently complicated) but will
eventually get us rid of _projects_walk_cache and a couple methods
(and stop being complicated) - edit done later, turns out _stat_tuple
works for projects just right - yey for AFile.

'pending' renames - I need to track refresh_info

class _InstallerPackage(Installer, AFile):

_refreshSource confined there - yey!

Refactor AFile:

Less uses of load_cache - and itsa_ghost. WIP - I might add load_cache
back to the signature if I figure a default out

Installer.do_update: TTT RRR EEE

@@ -2215,8 +2215,6 @@ def _refresh_from_data_dir(self, progress, recalculate_all_crcs):
                             progress)
-        self.data_sizeCrcDate.clear()
-        self.data_sizeCrcDate.update(new_sizeCrcDate)
-        change = changes
+        self.data_sizeCrcDate = new_sizeCrcDate
         self.update_for_overridden_skips(progress=progress) #after final_update
         #--Done
-        return change
+        return changes  EEE

One of the hardest things to grok in BAIN refresh was the decorator
projects_walk_cache. It was necessary in order not to re-walk the
project dir in case we just walked it in scan_installers_dir. Looking
at it now we should have been caching also the stat calls in that case
but when this was introduced BAIN internals were so complicated that this
was not so obvious (performance here is anyway still WIP). Turns out it
is much simpler and probably just as 'fast' to call do_update rather
than trying to pass needs_update caches to refreshBasic. This all but
closes # 336 as now AFile API is used for all kinds of files - and
makes BAIN refresh internals as little complicated as possible. See
discussion in RRR 6d4ad99841233d83abd326ad81121a0d09f88bc0 but unlike
what I noted there the pleasant surprise was that AFile can handle
folders alright - do_update is powerful enough and can be further
refactored to cater for fullRefresh. Note:

- the ancient fixme. What this was trying to convey is that actually
if you went ahead and renamed a file in a project containing another
file with large modification time the change would not be detected. The
workaround was to manually refresh the project. This was done for
efficiency as the vast majority of the changes would be detected,
but now that computers are faster let's make this correct. For big
src_SizeCrcDate this would be slower but hey the system calls should
dwarf that (for big src_SCD) and anyway that's what the skip refresh
flag is for. Now that we do the full check (should be more than enough
but can still give a false negative if we flip a byte on a file without
changing the modification time - hey, caching) we might as well drop the
calculations from _stat_tuple.
- the common data structure format for cacl_crcs included the old crc -
cf (siz, _crc, date, asFile). I changed that to pass the asFile and I
am still debugging it but the benefits should be obvious
- I reassign src_SizeCrcDate instead of clean/update - faster and
cleaner (and should be also done for data_sizeCrcDate) but still TTT EEE

SSS FFF fix for fullRefresh not getting the paths to ghosts

I had to treat plugins separately - no harm done on average and
fullRefresh will calculate their CRCs once finally.

Under # 336, # 219, # 353 RRR

FFF inline _refreshInstallers: EEE better comments

Seems now refresh_info and pending/deleted are orthogonal - needs
further simplification. We need to pass pending/deleted to
scan_installers_dir actually and use that instead of listing - edit:
done.

Progress does not work correctly (never gives focus back to Bash) XXX???

refreshBasic -> _reset_cache EEE do_refresh=True flip default

Installer.refresh_installer -> InstellersData.new_info: TTT

setattr(clone, att, copy.copy(getattr(src_inst, att))) should work on LDs TTT

EEE Mopy/bash/basher/dialogs.py InstallerProject import remove.

Another hacky refactoring helper gone but there is more. When we were
unpickling on InstallersData.__load > __setstate we were calling at least
refreshDataSizeCrc but then we would perform a system call on abs_path -
now this is replaced with a necessary stat_tuple() call and
scan_installers_dir learned to skip freshly unpickled installers. We also
hook in AFile.__init__ - this drops abs_path from Installer (if we were
accessing this on markers that'a bug) by adding a new 'volatile' attribute
to _InstallerPackage (AFile's _file_key - now we can't slot we should
revisit all this along with pickling - we should stop pickling non std
classes). __init__ calls _reset_cache, so no need to call needs update
from new_info. One other (and hopefully the last) installer creation
site was __copy__ - that's too much magic, absorbed by new_info and the
bits of (arcane) logic were copied to copy_installer which should be
the only place we copy an installer. Finally I had to exclude fn_key
from persistent - this is set alright by __init__, the latter one being
called on unpickling as specified in __reduce__. So on unpickling
initDefault was called twice - maybe make Installer a dataclass and bin
initDefault?

SSS add_marker -> new_info

Use scandir instead of walk: RRR

I was aware there was maybe a way using scandir of not repeating some
stat calls while scanning a directory - all I could find was this:

https://discuss.python.org/t/get-direntry-objects-collected-during-os-walk/8143/5

I wondered if it performed better than walk:

import os
import timeit

numbers = 4
repeat = 7

setup = """"""
def timer(statement, msg='', _setup=None):
    print(msg, min(
        timeit.Timer(statement, setup=_setup or setup).repeat(
            repeat, numbers)))

def _scandir_walk(apath, root_len=None, folders_times=None):
    size_apath_date = {}
    if root_len is None:
        root_len = len(apath) + 1
    folders_times = [os.path.getmtime(apath)] if folders_times is None \
	    else folders_times
    for dirent in os.scandir(apath):
        if dirent.is_dir():
            folders_times.append(dirent.stat().st_mtime)
            dir_walk, _ = _scandir_walk(dirent.path, root_len, folders_times)
            size_apath_date.update(dir_walk)
        else:
            size_apath_date[dirent.path[root_len:]] = (
                (ls := dirent.stat()).st_size, dirent.path, ls.st_mtime)
    return size_apath_date, folders_times

def _walk(apath, __lstat=os.stat):
    getM, join = os.path.getmtime, os.path.join
    size_apath_date = {}
    c = []
    cAppend = c.append
    root_len = len(apath) + 1
    for root, _d, files in os.walk(apath):
        # progress(0.05, f'{progress_msg}{asDir[relPos:]}')
        cAppend(getM(root))
        size_apath_date.update(
            (k[root_len:], (ls.st_size, k, ls.st_mtime)) for k, ls in
            ((asPath, __lstat(asPath)) for asPath in
                      (join(root, f) for f in files)))
    return size_apath_date, c

setup = """d = r'C:\Dropbox\eclipse_workspaces\python\wrye-bash'
from __main__ import _scandir_walk, _walk
"""
timer('_scandir_walk(d)', "scandir")
timer('_walk(d)', "walk")

sc = _scandir_walk(d)
wal = _walk(d)
assert sc[0] == wal[0]
assert set(sc[1]) == set(wal[1])
assert max(sc[1]) == max(wal[1])

C:\Users\MrD\AppData\Local\Programs\Python\Python311\python.exe C:\Dropbox\eclipse_workspaces\python\py_scratch\timings.py
scandir 1.3165479998569936
walk 28.77752220002003

21 times faster! Projects refresh is the bottleneck in BAIN refresh,
hence all the skipRefresh/autoRefreshProjects/projectRefreshed. This
is happily solving this for most installs (don't know if this can
be made faster or switching to event based refreshes RRR is the only real
solution, in which case we still want all the speed we can get scanning
anyway, for the initial scan on booting BAIN, but also for manual
refreshes that might be needed in edge cases).

Absorb _process_data_dir:

Time immemorial ago (b17601ef5bc25101c1fc12141f252ea250d49424) was
created to house the common logic of _refresh_from_data_dir (so
existing files maybe with a ghost extension) and
update_data_SizeCrcDate (so dest paths to the data dir with .ghost
lopped of). Now that we realized that scandir stating is considerably
faster and since performance here is a bane _process_data_dir had to go
- flat is better than nested, certainly in BAIN refresh. Those methods
calling one another were always new to new and experienced dev alike
and the pieces of functionality that were needed in
_refresh_from_data_dir but not in update_data_SizeCrcDate and vice
versa turned complex to complicated:

- we should not skip files/folders in update_data_SizeCrcDate as we come
from refreshDataSizeCrc (even if we currently do - TTT this beast is hard
to track - related to overwritten skips handling which certainly has
buggy edge cases some of them acknowledged in the code, see
overriden_skips comments)
- ghost handling belongs to update_data_SizeCrcDate - this led to double
calling getGhosted see RRR
- in fact the logic of _process_data_dir was the update_data_SizeCrcDate
logic as the walk logic of _refresh_from_data_dir was replaced by new
code in _walk_data_dir so the code of _process_data_dir was not repeated

_refresh_from_data_dir:

- I axed the progress messages as anyway we displayed very few of them
quite randomly. We can easily add them back in _walk_data_dir but since
we are on dev we can afford to live without these progress messages
- empty dirs is a WIP TTT - in particular what we do would not remove
a dir composed of empty dirs that were removed. OTH we could even remove
this from refresh and/or add a special menu item for cleaning empty dirs
(maybe launch it if setting is on also)

update_data_SizeCrcDate:

- what happens with "corrupted" mods really? They should be added to
data_SizeCrcDate most probably

__init__.py 4268 RefreshData:
11118614 function calls (11112306 primitive calls) in 6.492 seconds

__init__.py 4268 RefreshData:
436784 function calls (434428 primitive calls) in 0.263 seconds

FFF empty_dirs

FFF

- note I changed _skips_in_data_dir to work with dicts to keep the abs
path of the top_dir around - not for performance this time but sprinkling
os.path.join does not look nice.

Empties handling: SSS TTT

Changes the logic: TTT

- remove subdirs that contain no files in any of their subfolders - the
root one should be taken care of at the caller's level. Note the
(hacky) 'proj_dir.makedirs()' is not needed anymore, simply by not
handling the return value vs handling has_files for top Data dirs.
Previously we would leave behind empty subfolders except if we
carefully sorted which might have been the case (or not). Plus we could
delete folders before their subfolders (hence removedirs was called
defensively and abundantly). Now the logic is clearly spelled out in
_remove_empty_dirs (TTT deserves a test certainly) and repeated in
_walk_data_dir (as noted we need performance so factoring a walk
function parameter out is a no-no - plus we can afford some repetition
for the readability, especially as the walk functions are inlined
closer to irefresh and not buried as before).

- we remove as we go. This is less atomic but thankfully we had no
guaranties anyway :Plus we won't really miss anything if the operation
fails we just leave behind less empty dirs.

Kept error handling the same as before - although all the dirs should
exist in the `raise_error=False` case in _walk_data_dir.

SSS TTT Drop pending_size handling

Let's go nuclear on this. I *think* the problem might actually be some
kind of overflow in native Windows/wxWidgets code with a large enough
Data folder and enough large files in it that need to be updated.

This may actually speed up a Full Refresh. For a large file (e.g.
Fallout4 - Textures1.ba2 at 2.5G) we would issue thousands of progress
calls (1290 for that BA2, to be exact), which definitely isn't ideal in
the middle of a CRC calculation.

---
## [danieljharvey/mimsa](https://github.com/danieljharvey/mimsa)@[e26ca2a932...](https://github.com/danieljharvey/mimsa/commit/e26ca2a9320e5c59b7b12433bc7d36b2cdfa8b99)
#### Thursday 2023-06-22 21:02:56 by Daniel Harvey

Actually typecheck multiple definitions (#962)

* Test module typechecking more throughly

* Damn this shit is fucked

* We need to make these types stricter

* Skippy

* Nice

---
## [cameron-martin/rules_rust](https://github.com/cameron-martin/rules_rust)@[80f0eb488a...](https://github.com/cameron-martin/rules_rust/commit/80f0eb488ab9cabc4920ac446478cbf2feedc3f3)
#### Thursday 2023-06-22 22:21:05 by scentini

Support for `no_std` mode (#1934)

Initial support for `no_std` mode.
This allows us to
1. Don't pass the whole standard library to compile actions that specify `no_std`
2. Conditionally select `crate_features` and `deps` based on whether `no_std` mode is used.
Currently the only supported modes are `off` and `alloc`, with a possibility to expand in the future.

The `no_std` support comes with the following caveats:
1. Targets in `exec` mode are still built with `std`; the logic here being that if a device has enough space to run bazel and rustc, std's presence would not be a problem. This also saves some additional transitions on `proc_macro`s (they need `std`), as they are built in `exec` mode.
2. Tests are still built with `std`, as `libtest` depends on `libstd`

There is quite an ugly hack to make us be able to `select` on the `no_std` flavor taking `exec` into account; I'm looking forward to the day where Bazel will expose better ways to inspect the cfg.

There is also one part I didn't manage to make work - having a `rust_test` that tests the `rust_shared_library` in `cc_common.link` mode; I got a link error for missing `__rg_alloc` & co. symbols, which should be present as we pass `--@rules_rust//rust/settings:experimental_use_global_allocator=True`. Unfortunately I could only spot this error on CI, and could not reproduce locally. I removed the test because the `rust_shared_library` is already tested via a `cc_test`. I will however give another shot at inspecting how my local setup differs from CI.

The `rust_binary` source code in `main.rs` was borrowed from https://github.com/jfarrell468/no_std_examples, big thanks to @jfarrell468 for letting me use it.

Co-authored-by: Krasimir Georgiev <krasimir@google.com>
Co-authored-by: UebelAndre <github@uebelandre.com>

---
## [Crimdahl/BeyondChaosRandomizer](https://github.com/Crimdahl/BeyondChaosRandomizer)@[6ecb2514ac...](https://github.com/Crimdahl/BeyondChaosRandomizer/commit/6ecb2514acd962169aaebb21ab93667357e9f95f)
#### Thursday 2023-06-22 22:21:36 by Crimdahl

Merging in Web version changes.

randomizer.py:
- Wrapped the whole randomize process in a try/except block to pass exceptions back to GUI/Web
- Added support for custom coral names from web
- Added support for a custom playlist from web
- Added support for a custom passwords from web

appearance.py:
- Added support for custom coral names from web
- Added validation to ensure there are enough male and female names

musicinterface.py:
- Added support for a custom playlist from web

musicrandomizer.py:
- Reordered imports
- Added support for a custom playlist from web
- Made tierboss section check case-insensitive

options.py:
- Fixed an invalid default value for dancingmaduin

sillyclowns.py:
- Added support for a custom passwords from web

formationrandomizer.py:
- Import changes

appearance.py, dialoguemanager.py, esperrandomizer.py, itemrandomizer.py, locationrandomizer.py, monsterrandomizer.py, namerandomizer.py, randomizer.py, skillrandomizer.py, towerrandomizer.py, utils.py, wor.py:
- Cosmetic changes to variable names and/or spacing

---
## [idimitrijevic9920rn/Banka-2-Frontend](https://github.com/idimitrijevic9920rn/Banka-2-Frontend)@[e30e4c744f...](https://github.com/idimitrijevic9920rn/Banka-2-Frontend/commit/e30e4c744fddac097755d84b5ce8277b963698f4)
#### Thursday 2023-06-22 22:58:31 by dimitrijevich

But I must explain to you how all this mistaken idea of denouncing pleasure and praising pain was born and I will give you a complete account of the system, and expound the actual teachings of the great explorer of the truth, the master-builder of human happiness. No one rejects, dislikes, or avoids pleasure itself, because it is pleasure, but because those who do not know how to pursue pleasure rationally encounter consequences that are extremely painful. Nor again is there anyone who loves or pursues or desires to obtain pain of itself, because it is pain, but because occasionally circumstances occur in which toil and pain can procure him some great pleasure. To take a trivial example, which of us ever undertakes laborious physical exercise, except to obtain some advantage from it? But who has any right to find fault with a man who chooses to enjoy a pleasure that has no annoying consequences, or one who avoids a pain that produces no resultant pleasure?

---
## [A-Noid33/mame](https://github.com/A-Noid33/mame)@[2bcd9bc772...](https://github.com/A-Noid33/mame/commit/2bcd9bc772b4f3cc6e8b281703e53561d2c5bea9)
#### Thursday 2023-06-22 23:11:50 by David 'Foxhack' Silva

segacd.xml, megacdj.xml: Added various CD dumps. (#11344)

New working software list items
-------------------------------
segacd.xml:
Compton's Interactive Encyclopedia v2.00S (USA) [redump.org]
Note! Color Mechanica (USA) [redump.org]
Note! Color Mechanica (USA, alt) [redump.org]
What is X'Eye Multi Entertainment System (USA) [redump.org]
megacdj.xml:
Heavenly Symphony - Formula One World Championship 1993 Hibaihin (Japan) [redump.org]
Keiou Yuugekitai Taikenban Hibaihin (Japan) [redump.org]
Lunar - Eternal Blue Hibaihin Auto Demo (Japan) [redump.org]
Microcosm Demo CD (Japan) [redump.org]
Night Trap Hibaihin (Japan) [redump.org]
Popful Mail Taikenban Hibaihin (Japan) [redump.org]
Silpheed Hibaihin (Japan) (Fixed) [redump.org]
Sonic The Hedgehog CD Hibaihin (Japan) [redump.org]
Thunderhawk Hibaihin (Japan) [redump.org]
Urusei Yatsura - Dear My Friends Hibaihin (Japan) [redump.org]
Yumemi Yakata no Monogatari Hibaihin (Japan) [redump.org]
WonderMega Collection - Game Garden (Japan, alt) [redump.org]

New software list items marked not working
------------------------------------------
segacd.xml:
Surgical Strike (Brazil, 32X) [redump.org]
megacdj.xml:
Psychic Detective Series vol.3 - AYA Auto Demo (Japan) [redump.org]
Silpheed Hibaihin (Japan) [redump.org]

---
## [DanaDririon/Skyrat-tg](https://github.com/DanaDririon/Skyrat-tg)@[79febdf95d...](https://github.com/DanaDririon/Skyrat-tg/commit/79febdf95dbcdb81d6a8027dc21deba19f8e659e)
#### Thursday 2023-06-22 23:12:03 by SkyratBot

[MIRROR] New planetary exclusive random event/unfavorable situation, Chasmic Earthquake [MDB IGNORE] (#21778)

* New planetary exclusive random event/unfavorable situation, Chasmic Earthquake (#75864)

## About The Pull Request

https://github.com/tgstation/tgstation/assets/28870487/2451bc69-db1e-420d-9a18-2f899ca65427

This introduces a new unfavorable situation (non-antagonist random
events that dynamic triggers under certain circumstances), restricted to
planetary maps (Icebox). An earthquake occurs, felt by everyone on the
map, forming a fault that tears the a hole somewhere on the station.

The fault zone is indicated by shaking tiles, which gives a chance
(about 30 seconds) for you to move your machinery/property/crewmembers
out of the way. If you're on those tiles when the fault forms, get ready
to take a nasty fall.

Anything caught in the fault zone as it collapses inward will be
destroyed, violently, _before_ being dropped down into the z-level
below.

![image](https://github.com/tgstation/tgstation/assets/28870487/56916c9f-c8da-4ffb-9d8b-7e940e92bbc2)

These can also happen as a random event, however their rarity is on-par
with that of a meteor storm.

This also adds a helper for finding a midpoint turf between two provided
turfs, thanks to ZephyrTFA.

This idea basically possessed me over the course of a few days, and I
found myself unable to work on anything else until I had it complete.
I'm glad its done.
## Why It's Good For The Game

Gives Icebox its own big "environmental disaster" event. I'm hoping it
isn't received as being too destructive, but mind that this is meant to
be an equal to the dreaded meteor storm.

Also makes it so that unfavorable events aren't a coinflip between a
portal storm/rod on planetary maps.
## Changelog
:cl: Rhials
add: Chasmic Earthquake random event, exclusive to Icebox. Tears a huge
chasm in the hull of the station. Watch out for shaking tiles!
sound: Adds sounds for distant rumbling, metal creaking, and rubble
shaking.
imageadd: Achievement icon for getting sucked up in an earthquake chasm.
/:cl:

* New planetary exclusive random event/unfavorable situation, Chasmic Earthquake

---------

Co-authored-by: Rhials <Datguy33456@gmail.com>

---
## [jinxynii/coyote-bayou-goobery](https://github.com/jinxynii/coyote-bayou-goobery)@[6fd64b92ca...](https://github.com/jinxynii/coyote-bayou-goobery/commit/6fd64b92ca4cc80357d8d78c8efc1c6d8196204f)
#### Thursday 2023-06-22 23:46:42 by Tk420634

Updating the Mansion a bit

Preparing my brain for making a non euclidian dungeon, because I fucking hate everything.

---

